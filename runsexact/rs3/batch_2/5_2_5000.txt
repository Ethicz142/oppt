Run # 1
Initial state: 0 0.698189 0.152565 0.736559 0.462182 0.153126 0.194562 0.56012 0.836561 0.587867 0.837232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 726656 episodes
GETTING ACTION FROM:
action 3, numVisits=726642, meanQ=10.039013, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 1
action 2, numVisits=4, meanQ=2.750025, numObservations: 2
action 1, numVisits=4, meanQ=2.747550, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.698189 0.152565 0.736559 0.462182 0.153126 0.194562 0.56012 0.836561 0.587867 0.837232 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=149875, meanQ=13.253012, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1059814 episodes
GETTING ACTION FROM:
action 2, numVisits=1209689, meanQ=12.365026, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.698189 0.152565 0.736559 0.462182 0.153126 0.194562 0.56012 0.836561 0.587867 0.837232 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 2
Initial state: 0 0.445412 0.624512 0.620238 0.892403 0.703608 0.282278 0.501903 0.830052 0.9814 0.0369415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 743446 episodes
GETTING ACTION FROM:
action 3, numVisits=743438, meanQ=11.189044, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.445412 0.624512 0.620238 0.892403 0.703608 0.282278 0.501903 0.830052 0.9814 0.0369415 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 3
Initial state: 0 0.182112 0.4793 0.591594 0.854295 0.715627 0.252055 0.691319 0.878091 0.387812 0.525848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 824146 episodes
GETTING ACTION FROM:
action 5, numVisits=824134, meanQ=10.388486, numObservations: 5
action 2, numVisits=7, meanQ=3.572886, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.182112 0.4793 0.591594 0.854295 0.715627 0.252055 0.691319 0.878091 0.387812 0.525848 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=33613, meanQ=13.396499, numObservations: 4
action 2, numVisits=12, meanQ=6.250850, numObservations: 3
action 4, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1113241 episodes
GETTING ACTION FROM:
action 1, numVisits=1146854, meanQ=11.526320, numObservations: 4
action 2, numVisits=12, meanQ=6.250850, numObservations: 3
action 4, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.182112 0.4793 0.591594 0.854295 0.715627 0.252055 0.691319 0.878091 0.387812 0.525848 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=99953, meanQ=17.200600, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1180050 episodes
GETTING ACTION FROM:
action 3, numVisits=1280003, meanQ=12.367625, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.182112 0.4793 0.591594 0.854295 0.715627 0.252055 0.691319 0.878091 0.387812 0.525848 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=19503, meanQ=16.251690, numObservations: 5
action 4, numVisits=25, meanQ=9.200816, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1220094 episodes
GETTING ACTION FROM:
action 2, numVisits=1239597, meanQ=12.095787, numObservations: 5
action 4, numVisits=25, meanQ=9.200816, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.182112 0.4793 0.591594 0.854295 0.715627 0.252055 0.691319 0.878091 0.387812 0.525848 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 4
Initial state: 0 0.133491 0.0885563 0.630612 0.874095 0.746521 0.200696 0.337221 0.218324 0.502762 0.822241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 811571 episodes
GETTING ACTION FROM:
action 3, numVisits=811558, meanQ=10.276107, numObservations: 5
action 2, numVisits=4, meanQ=0.752525, numObservations: 2
action 1, numVisits=5, meanQ=0.000020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.133491 0.0885563 0.630612 0.874095 0.746521 0.200696 0.337221 0.218324 0.502762 0.822241 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.554355 0.899147 0.677315 0.832673 0.154427 0.501839 0.212358 0.593597 0.483259 0.234244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 825865 episodes
GETTING ACTION FROM:
action 2, numVisits=825619, meanQ=10.300967, numObservations: 4
action 5, numVisits=241, meanQ=9.745298, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.554355 0.899147 0.677315 0.832673 0.154427 0.501839 0.212358 0.593597 0.483259 0.234244 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.693595 0.822046 0.064107 0.0834585 0.267598 0.0943361 0.822522 0.060255 0.554133 0.893826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 826408 episodes
GETTING ACTION FROM:
action 1, numVisits=826383, meanQ=10.490115, numObservations: 4
action 3, numVisits=12, meanQ=8.166675, numObservations: 2
action 4, numVisits=5, meanQ=4.598000, numObservations: 2
action 5, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.693595 0.822046 0.064107 0.0834585 0.267598 0.0943361 0.822522 0.060255 0.554133 0.893826 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.510889 0.87426 0.120427 0.0729655 0.527856 0.526436 0.588195 0.863036 0.941285 0.942415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 786565 episodes
GETTING ACTION FROM:
action 4, numVisits=786486, meanQ=10.580629, numObservations: 5
action 3, numVisits=70, meanQ=7.205081, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.510889 0.87426 0.120427 0.0729655 0.527856 0.526436 0.588195 0.863036 0.941285 0.942415 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.64587 0.805918 0.459844 0.694977 0.179824 0.397178 0.650097 0.898134 0.539102 0.0610159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 819013 episodes
GETTING ACTION FROM:
action 5, numVisits=818985, meanQ=10.358632, numObservations: 4
action 1, numVisits=17, meanQ=8.220000, numObservations: 4
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action 2, numVisits=5, meanQ=3.820000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.64587 0.805918 0.459844 0.694977 0.179824 0.397178 0.650097 0.898134 0.539102 0.0610159 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.868077 0.27355 0.536572 0.806589 0.0938658 0.257587 0.0712363 0.836381 0.674746 0.833113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 759882 episodes
GETTING ACTION FROM:
action 5, numVisits=759871, meanQ=10.256692, numObservations: 4
action 4, numVisits=6, meanQ=1.998333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.868077 0.27355 0.536572 0.806589 0.0938658 0.257587 0.0712363 0.836381 0.674746 0.833113 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.29743 0.614998 0.657349 0.818141 0.898514 0.0053197 0.595385 0.888005 0.896682 0.112408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 837630 episodes
GETTING ACTION FROM:
action 1, numVisits=837624, meanQ=10.418798, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.29743 0.614998 0.657349 0.818141 0.898514 0.0053197 0.595385 0.888005 0.896682 0.112408 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=242194, meanQ=13.490127, numObservations: 4
action 4, numVisits=6, meanQ=8.501683, numObservations: 2
action 2, numVisits=8, meanQ=8.470013, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1109778 episodes
GETTING ACTION FROM:
action 3, numVisits=1351972, meanQ=12.012086, numObservations: 4
action 4, numVisits=6, meanQ=8.501683, numObservations: 2
action 2, numVisits=8, meanQ=8.470013, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.29743 0.614998 0.657349 0.818141 0.898514 0.0053197 0.595385 0.888005 0.896682 0.112408 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 11
Initial state: 0 0.675 0.3069 0.0162936 0.652354 0.67974 0.836735 0.780765 0.213241 0.578581 0.893358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 783340 episodes
GETTING ACTION FROM:
action 4, numVisits=783322, meanQ=10.428054, numObservations: 4
action 2, numVisits=9, meanQ=6.776689, numObservations: 2
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.675 0.3069 0.0162936 0.652354 0.67974 0.836735 0.780765 0.213241 0.578581 0.893358 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.100807 0.807409 0.566675 0.899066 0.764578 0.342486 0.0344984 0.548144 0.632908 0.838203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 806230 episodes
GETTING ACTION FROM:
action 1, numVisits=806211, meanQ=10.334590, numObservations: 5
action 4, numVisits=12, meanQ=5.090842, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.100807 0.807409 0.566675 0.899066 0.764578 0.342486 0.0344984 0.548144 0.632908 0.838203 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.578285 0.893358 0.141023 0.755777 0.434643 0.620178 0.682911 0.848716 0.861913 0.287911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 822899 episodes
GETTING ACTION FROM:
action 3, numVisits=822891, meanQ=10.353042, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.578285 0.893358 0.141023 0.755777 0.434643 0.620178 0.682911 0.848716 0.861913 0.287911 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=204522, meanQ=13.378475, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1103362 episodes
GETTING ACTION FROM:
action 2, numVisits=1307884, meanQ=11.847014, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.578285 0.893358 0.141023 0.755777 0.434643 0.620178 0.682911 0.848716 0.861913 0.287911 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=21390, meanQ=16.117709, numObservations: 4
action 1, numVisits=8, meanQ=10.875000, numObservations: 2
action 5, numVisits=6, meanQ=9.833350, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1204487 episodes
GETTING ACTION FROM:
action 4, numVisits=1225858, meanQ=11.982940, numObservations: 4
action 1, numVisits=25, meanQ=10.000000, numObservations: 4
action 5, numVisits=8, meanQ=9.000013, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.578285 0.893358 0.141023 0.755777 0.434643 0.620178 0.682911 0.848716 0.861913 0.287911 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 14
Initial state: 0 0.565234 0.891675 0.563112 0.801926 0.515125 0.951841 0.331066 0.491563 0.203767 0.0714816 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 815873 episodes
GETTING ACTION FROM:
action 3, numVisits=815849, meanQ=10.306507, numObservations: 5
action 5, numVisits=7, meanQ=7.140014, numObservations: 2
action 4, numVisits=13, meanQ=6.997692, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.565234 0.891675 0.563112 0.801926 0.515125 0.951841 0.331066 0.491563 0.203767 0.0714816 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.546673 0.802648 0.602966 0.889975 0.807441 0.613635 0.987504 0.458331 0.348117 0.369289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820827 episodes
GETTING ACTION FROM:
action 5, numVisits=820809, meanQ=10.275527, numObservations: 4
action 3, numVisits=7, meanQ=6.282857, numObservations: 3
action 1, numVisits=7, meanQ=6.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.546673 0.802648 0.602966 0.889975 0.807441 0.613635 0.987504 0.458331 0.348117 0.369289 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=203490, meanQ=13.535264, numObservations: 4
action 4, numVisits=6, meanQ=7.183333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1108230 episodes
GETTING ACTION FROM:
action 1, numVisits=1311720, meanQ=11.712463, numObservations: 4
action 4, numVisits=6, meanQ=7.183333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.546673 0.802648 0.602966 0.889975 0.807441 0.613635 0.987504 0.458331 0.348117 0.369289 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 16
Initial state: 0 0.946005 0.0293971 0.560467 0.863044 0.0754908 0.516679 0.6333 0.877698 0.493552 0.656828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820447 episodes
GETTING ACTION FROM:
action 5, numVisits=820441, meanQ=10.254610, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.946005 0.0293971 0.560467 0.863044 0.0754908 0.516679 0.6333 0.877698 0.493552 0.656828 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=203222, meanQ=13.554990, numObservations: 5
action 1, numVisits=9, meanQ=9.787778, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1103101 episodes
GETTING ACTION FROM:
action 4, numVisits=1306317, meanQ=11.957557, numObservations: 5
action 1, numVisits=15, meanQ=8.740673, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.946005 0.0293971 0.560467 0.863044 0.0754908 0.516679 0.6333 0.877698 0.493552 0.656828 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.435403 0.0949748 0.512554 0.813399 0.635416 0.836648 0.388596 0.35691 0.650719 0.755879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 571978 episodes
GETTING ACTION FROM:
action -1, numVisits=571969, meanQ=8.286507, numObservations: 2
action 4, numVisits=4, meanQ=-0.252500, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.435403 0.0949748 0.512554 0.813399 0.635416 0.836648 0.388596 0.35691 0.650719 0.755879 w: 1
Observation: 0 0.449833 0 0.593371 0 0.674493 0 0.37569 0 0.577729 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=442346, meanQ=9.748303, numObservations: 5
action 3, numVisits=60, meanQ=8.762156, numObservations: 4
action 4, numVisits=6, meanQ=4.670033, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 902898 episodes
GETTING ACTION FROM:
action 2, numVisits=1345241, meanQ=9.607590, numObservations: 5
action 3, numVisits=63, meanQ=8.605638, numObservations: 4
action 4, numVisits=6, meanQ=4.670033, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.435403 0.0949748 0.512554 0.813399 0.635416 0.836648 0.388596 0.35691 0.650719 0.755879 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=88217, meanQ=11.369930, numObservations: 4
action 3, numVisits=6, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 961805 episodes
GETTING ACTION FROM:
action 2, numVisits=1050020, meanQ=9.157633, numObservations: 4
action 3, numVisits=8, meanQ=6.500000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.435403 0.0949748 0.512554 0.813399 0.635416 0.836648 0.388596 0.35691 0.650719 0.755879 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 18
Initial state: 0 0.667387 0.819199 0.515263 0.857057 0.14552 0.693407 0.146554 0.202933 0.0522873 0.7954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 799847 episodes
GETTING ACTION FROM:
action 3, numVisits=799835, meanQ=10.137818, numObservations: 5
action 4, numVisits=7, meanQ=5.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.667387 0.819199 0.515263 0.857057 0.14552 0.693407 0.146554 0.202933 0.0522873 0.7954 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=197906, meanQ=12.996613, numObservations: 5
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1055434 episodes
GETTING ACTION FROM:
action 2, numVisits=1253339, meanQ=11.465263, numObservations: 5
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.667387 0.819199 0.515263 0.857057 0.14552 0.693407 0.146554 0.202933 0.0522873 0.7954 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 19
Initial state: 0 0.679558 0.876962 0.469416 0.472126 0.0398343 0.708045 0.0187 0.276998 0.674565 0.895612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 829190 episodes
GETTING ACTION FROM:
action 1, numVisits=829182, meanQ=10.228985, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.679558 0.876962 0.469416 0.472126 0.0398343 0.708045 0.0187 0.276998 0.674565 0.895612 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.28276 0.964906 0.621616 0.823462 0.513766 0.802353 0.882802 0.453294 0.106219 0.286435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820198 episodes
GETTING ACTION FROM:
action 3, numVisits=820184, meanQ=10.712653, numObservations: 4
action 4, numVisits=9, meanQ=7.218889, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.28276 0.964906 0.621616 0.823462 0.513766 0.802353 0.882802 0.453294 0.106219 0.286435 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.560807 0.862561 0.759158 0.285198 0.995016 0.712619 0.170999 0.401231 0.604555 0.893972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 813597 episodes
GETTING ACTION FROM:
action 4, numVisits=813587, meanQ=10.315534, numObservations: 5
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.560807 0.862561 0.759158 0.285198 0.995016 0.712619 0.170999 0.401231 0.604555 0.893972 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=202433, meanQ=13.415503, numObservations: 5
action 5, numVisits=9, meanQ=7.224467, numObservations: 3
action 2, numVisits=9, meanQ=6.777789, numObservations: 3
action 3, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1088438 episodes
GETTING ACTION FROM:
action 1, numVisits=1290871, meanQ=12.041153, numObservations: 5
action 5, numVisits=9, meanQ=7.224467, numObservations: 3
action 2, numVisits=9, meanQ=6.777789, numObservations: 3
action 3, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.560807 0.862561 0.759158 0.285198 0.995016 0.712619 0.170999 0.401231 0.604555 0.893972 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 22
Initial state: 0 0.727113 0.12968 0.574395 0.865747 0.69019 0.86114 0.00212527 0.10829 0.898891 0.026763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 827399 episodes
GETTING ACTION FROM:
action 3, numVisits=827391, meanQ=10.384254, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.727113 0.12968 0.574395 0.865747 0.69019 0.86114 0.00212527 0.10829 0.898891 0.026763 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.887714 0.135181 0.503823 0.802188 0.241281 0.545144 0.82473 0.276415 0.522746 0.866074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 818419 episodes
GETTING ACTION FROM:
action 2, numVisits=818396, meanQ=10.695480, numObservations: 4
action 4, numVisits=12, meanQ=7.125000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.887714 0.135181 0.503823 0.802188 0.241281 0.545144 0.82473 0.276415 0.522746 0.866074 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.846255 0.484777 0.0550976 0.0637597 0.624182 0.840776 0.547436 0.84865 0.0338642 0.742891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 814171 episodes
GETTING ACTION FROM:
action 5, numVisits=814162, meanQ=10.392899, numObservations: 5
action 3, numVisits=4, meanQ=-0.252500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.846255 0.484777 0.0550976 0.0637597 0.624182 0.840776 0.547436 0.84865 0.0338642 0.742891 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=201461, meanQ=13.383465, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1100471 episodes
GETTING ACTION FROM:
action 1, numVisits=1301932, meanQ=11.781159, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.846255 0.484777 0.0550976 0.0637597 0.624182 0.840776 0.547436 0.84865 0.0338642 0.742891 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 25
Initial state: 0 0.948395 0.03631 0.310791 0.703317 0.679936 0.860393 0.503755 0.0571802 0.52741 0.865258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 824168 episodes
GETTING ACTION FROM:
action 1, numVisits=824160, meanQ=10.402016, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.948395 0.03631 0.310791 0.703317 0.679936 0.860393 0.503755 0.0571802 0.52741 0.865258 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=56843, meanQ=10.430747, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1075884 episodes
GETTING ACTION FROM:
action 5, numVisits=1132727, meanQ=11.104001, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.948395 0.03631 0.310791 0.703317 0.679936 0.860393 0.503755 0.0571802 0.52741 0.865258 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 26
Initial state: 0 0.269906 0.533756 0.363942 0.611263 0.698408 0.865975 0.359494 0.0453336 0.682391 0.830649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 792303 episodes
GETTING ACTION FROM:
action 5, numVisits=792295, meanQ=10.327495, numObservations: 5
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.269906 0.533756 0.363942 0.611263 0.698408 0.865975 0.359494 0.0453336 0.682391 0.830649 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.637874 0.830401 0.934755 0.747944 0.0881725 0.135301 0.148242 0.0562195 0.589038 0.822242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816517 episodes
GETTING ACTION FROM:
action 3, numVisits=816509, meanQ=10.224278, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.637874 0.830401 0.934755 0.747944 0.0881725 0.135301 0.148242 0.0562195 0.589038 0.822242 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.640022 0.852533 0.464405 0.696851 0.905059 0.588703 0.380969 0.387336 0.596367 0.879224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 811151 episodes
GETTING ACTION FROM:
action 1, numVisits=811141, meanQ=10.189919, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.640022 0.852533 0.464405 0.696851 0.905059 0.588703 0.380969 0.387336 0.596367 0.879224 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.617031 0.842774 0.321084 0.67808 0.765015 0.411616 0.709102 0.938821 0.645568 0.821725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 824194 episodes
GETTING ACTION FROM:
action 2, numVisits=824180, meanQ=10.288611, numObservations: 4
action 1, numVisits=5, meanQ=5.798020, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.617031 0.842774 0.321084 0.67808 0.765015 0.411616 0.709102 0.938821 0.645568 0.821725 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=237547, meanQ=13.373582, numObservations: 4
action 4, numVisits=23, meanQ=8.532622, numObservations: 4
action 5, numVisits=11, meanQ=7.088182, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1131023 episodes
GETTING ACTION FROM:
action 3, numVisits=1368570, meanQ=11.869504, numObservations: 4
action 4, numVisits=23, meanQ=8.532622, numObservations: 4
action 5, numVisits=11, meanQ=7.088182, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.617031 0.842774 0.321084 0.67808 0.765015 0.411616 0.709102 0.938821 0.645568 0.821725 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 30
Initial state: 0 0.605709 0.898555 0.153548 0.186363 0.501929 0.811284 0.550145 0.387011 0.119668 0.338078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 813228 episodes
GETTING ACTION FROM:
action 2, numVisits=813222, meanQ=10.254042, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.605709 0.898555 0.153548 0.186363 0.501929 0.811284 0.550145 0.387011 0.119668 0.338078 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=201729, meanQ=13.283442, numObservations: 5
action 5, numVisits=8, meanQ=9.997525, numObservations: 2
action 1, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1088375 episodes
GETTING ACTION FROM:
action 4, numVisits=1290102, meanQ=11.837752, numObservations: 5
action 5, numVisits=10, meanQ=9.298020, numObservations: 2
action 1, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.605709 0.898555 0.153548 0.186363 0.501929 0.811284 0.550145 0.387011 0.119668 0.338078 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=125177, meanQ=17.185927, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1184544 episodes
GETTING ACTION FROM:
action 1, numVisits=1309720, meanQ=13.138448, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.605709 0.898555 0.153548 0.186363 0.501929 0.811284 0.550145 0.387011 0.119668 0.338078 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 31
Initial state: 0 0.515896 0.893863 0.550324 0.843186 0.314451 0.0792218 0.924246 0.161624 0.0331547 0.000991899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 829321 episodes
GETTING ACTION FROM:
action 5, numVisits=829313, meanQ=10.358119, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.515896 0.893863 0.550324 0.843186 0.314451 0.0792218 0.924246 0.161624 0.0331547 0.000991899 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=239487, meanQ=13.325268, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1111105 episodes
GETTING ACTION FROM:
action 1, numVisits=1350592, meanQ=11.538333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.515896 0.893863 0.550324 0.843186 0.314451 0.0792218 0.924246 0.161624 0.0331547 0.000991899 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.188733 0.557296 0.535182 0.808839 0.570833 0.861063 0.574564 0.996078 0.142508 0.350818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816404 episodes
GETTING ACTION FROM:
action 1, numVisits=816395, meanQ=10.299985, numObservations: 5
action 4, numVisits=4, meanQ=1.247525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.188733 0.557296 0.535182 0.808839 0.570833 0.861063 0.574564 0.996078 0.142508 0.350818 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=202736, meanQ=13.491989, numObservations: 4
action 4, numVisits=9, meanQ=9.332222, numObservations: 3
action 2, numVisits=6, meanQ=8.831683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1100231 episodes
GETTING ACTION FROM:
action 3, numVisits=1302967, meanQ=12.432463, numObservations: 4
action 4, numVisits=9, meanQ=9.332222, numObservations: 3
action 2, numVisits=6, meanQ=8.831683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.188733 0.557296 0.535182 0.808839 0.570833 0.861063 0.574564 0.996078 0.142508 0.350818 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 33
Initial state: 0 0.620438 0.803462 0.560633 0.895903 0.326718 0.331031 0.139667 0.603458 0.800422 0.468613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812332 episodes
GETTING ACTION FROM:
action 3, numVisits=812318, meanQ=10.411999, numObservations: 5
action 5, numVisits=7, meanQ=6.282857, numObservations: 4
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.620438 0.803462 0.560633 0.895903 0.326718 0.331031 0.139667 0.603458 0.800422 0.468613 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=66444, meanQ=13.104654, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1110059 episodes
GETTING ACTION FROM:
action 4, numVisits=1176503, meanQ=12.535760, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.620438 0.803462 0.560633 0.895903 0.326718 0.331031 0.139667 0.603458 0.800422 0.468613 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=123740, meanQ=15.756635, numObservations: 4
action 1, numVisits=16, meanQ=14.061250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1204197 episodes
GETTING ACTION FROM:
action 5, numVisits=1327925, meanQ=12.971219, numObservations: 4
action 1, numVisits=28, meanQ=10.820714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.620438 0.803462 0.560633 0.895903 0.326718 0.331031 0.139667 0.603458 0.800422 0.468613 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=21302, meanQ=16.835616, numObservations: 5
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1221047 episodes
GETTING ACTION FROM:
action 1, numVisits=1242349, meanQ=12.431858, numObservations: 5
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.620438 0.803462 0.560633 0.895903 0.326718 0.331031 0.139667 0.603458 0.800422 0.468613 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 34
Initial state: 0 0.704372 0.763078 0.595189 0.801901 0.331251 0.189445 0.00531765 0.265459 0.520112 0.860164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 824465 episodes
GETTING ACTION FROM:
action 1, numVisits=824446, meanQ=10.273575, numObservations: 4
action 2, numVisits=11, meanQ=7.642773, numObservations: 2
action 3, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.704372 0.763078 0.595189 0.801901 0.331251 0.189445 0.00531765 0.265459 0.520112 0.860164 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 35
Initial state: 0 0.658508 0.810309 0.620103 0.820195 0.105507 0.672016 0.921967 0.473858 0.069652 0.191186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 830043 episodes
GETTING ACTION FROM:
action 3, numVisits=830031, meanQ=10.280298, numObservations: 3
action 4, numVisits=7, meanQ=5.727143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.658508 0.810309 0.620103 0.820195 0.105507 0.672016 0.921967 0.473858 0.069652 0.191186 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=239696, meanQ=13.499247, numObservations: 4
action 1, numVisits=38, meanQ=11.329484, numObservations: 4
action 4, numVisits=12, meanQ=10.395000, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1105765 episodes
GETTING ACTION FROM:
action 2, numVisits=1345430, meanQ=11.691948, numObservations: 4
action 1, numVisits=62, meanQ=10.452265, numObservations: 4
action 4, numVisits=18, meanQ=9.763894, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.658508 0.810309 0.620103 0.820195 0.105507 0.672016 0.921967 0.473858 0.069652 0.191186 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 36
Initial state: 0 0.110607 0.587059 0.700228 0.0518039 0.0637081 0.959893 0.519223 0.877264 0.698633 0.837032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 809891 episodes
GETTING ACTION FROM:
action 2, numVisits=809885, meanQ=10.687247, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.110607 0.587059 0.700228 0.0518039 0.0637081 0.959893 0.519223 0.877264 0.698633 0.837032 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.727282 0.281129 0.311606 0.929741 0.502041 0.899972 0.600654 0.0386501 0.656666 0.885811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820262 episodes
GETTING ACTION FROM:
action 3, numVisits=820256, meanQ=10.282942, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.727282 0.281129 0.311606 0.929741 0.502041 0.899972 0.600654 0.0386501 0.656666 0.885811 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.692276 0.887972 0.190474 0.56449 0.76389 0.269661 0.66229 0.845455 0.877664 0.177151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 804883 episodes
GETTING ACTION FROM:
action 4, numVisits=804877, meanQ=10.637337, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.692276 0.887972 0.190474 0.56449 0.76389 0.269661 0.66229 0.845455 0.877664 0.177151 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 39
Initial state: 0 0.16082 0.962099 0.73534 0.156652 0.556703 0.817527 0.625827 0.847373 0.988123 0.401926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 827773 episodes
GETTING ACTION FROM:
action 2, numVisits=827765, meanQ=10.315586, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.16082 0.962099 0.73534 0.156652 0.556703 0.817527 0.625827 0.847373 0.988123 0.401926 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.328414 0.277853 0.502121 0.812077 0.75884 0.0792986 0.749964 0.769045 0.683755 0.87299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 818263 episodes
GETTING ACTION FROM:
action 5, numVisits=818257, meanQ=10.313796, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.328414 0.277853 0.502121 0.812077 0.75884 0.0792986 0.749964 0.769045 0.683755 0.87299 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=56549, meanQ=11.725287, numObservations: 3
action 2, numVisits=14, meanQ=9.073593, numObservations: 3
action 3, numVisits=8, meanQ=8.248762, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 994146 episodes
GETTING ACTION FROM:
action 5, numVisits=1050691, meanQ=10.607759, numObservations: 3
action 2, numVisits=15, meanQ=7.735353, numObservations: 3
action 4, numVisits=4, meanQ=6.500000, numObservations: 2
action 3, numVisits=9, meanQ=6.110011, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.328414 0.277853 0.502121 0.812077 0.75884 0.0792986 0.749964 0.769045 0.683755 0.87299 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 41
Initial state: 0 0.827679 0.111822 0.551913 0.869512 0.649178 0.820469 0.563887 0.181104 0.782582 0.515376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820524 episodes
GETTING ACTION FROM:
action 4, numVisits=820508, meanQ=10.336533, numObservations: 4
action 2, numVisits=11, meanQ=7.271845, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.827679 0.111822 0.551913 0.869512 0.649178 0.820469 0.563887 0.181104 0.782582 0.515376 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=204017, meanQ=13.563329, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1082353 episodes
GETTING ACTION FROM:
action 3, numVisits=1286370, meanQ=11.712489, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.827679 0.111822 0.551913 0.869512 0.649178 0.820469 0.563887 0.181104 0.782582 0.515376 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 42
Initial state: 0 0.371049 0.509584 0.552189 0.808231 0.918879 0.976675 0.512169 0.85739 0.862083 0.0805818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 814095 episodes
GETTING ACTION FROM:
action 5, numVisits=814089, meanQ=10.223518, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.371049 0.509584 0.552189 0.808231 0.918879 0.976675 0.512169 0.85739 0.862083 0.0805818 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=56352, meanQ=10.150321, numObservations: 4
action 1, numVisits=35, meanQ=8.933304, numObservations: 4
action 5, numVisits=17, meanQ=7.822376, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1076255 episodes
GETTING ACTION FROM:
action 4, numVisits=1132607, meanQ=11.353344, numObservations: 4
action 1, numVisits=35, meanQ=8.933304, numObservations: 4
action 5, numVisits=17, meanQ=7.822376, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.371049 0.509584 0.552189 0.808231 0.918879 0.976675 0.512169 0.85739 0.862083 0.0805818 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 43
Initial state: 0 0.670726 0.875735 0.51155 0.852637 0.991328 0.74653 0.768112 0.138669 0.204899 0.326703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 818100 episodes
GETTING ACTION FROM:
action 1, numVisits=818069, meanQ=10.448665, numObservations: 5
action 3, numVisits=20, meanQ=6.939030, numObservations: 3
action 5, numVisits=7, meanQ=6.855743, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.670726 0.875735 0.51155 0.852637 0.991328 0.74653 0.768112 0.138669 0.204899 0.326703 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.324108 0.499638 0.664219 0.82786 0.694041 0.810558 0.606871 0.624634 0.918929 0.71511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 817831 episodes
GETTING ACTION FROM:
action 1, numVisits=817823, meanQ=10.440976, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.324108 0.499638 0.664219 0.82786 0.694041 0.810558 0.606871 0.624634 0.918929 0.71511 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=202397, meanQ=13.556129, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1085529 episodes
GETTING ACTION FROM:
action 4, numVisits=1287926, meanQ=12.112444, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.324108 0.499638 0.664219 0.82786 0.694041 0.810558 0.606871 0.624634 0.918929 0.71511 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 45
Initial state: 0 0.573782 0.847495 0.449328 0.202381 0.874976 0.460873 0.297555 0.294679 0.60012 0.881811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 811198 episodes
GETTING ACTION FROM:
action 5, numVisits=811144, meanQ=10.221810, numObservations: 4
action 4, numVisits=41, meanQ=6.423432, numObservations: 5
action 1, numVisits=7, meanQ=5.141429, numObservations: 2
action 3, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.573782 0.847495 0.449328 0.202381 0.874976 0.460873 0.297555 0.294679 0.60012 0.881811 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 46
Initial state: 0 0.152422 0.116751 0.597867 0.896569 0.97792 0.34474 0.692745 0.841764 0.856472 0.619037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812109 episodes
GETTING ACTION FROM:
action 1, numVisits=812054, meanQ=10.279757, numObservations: 5
action 4, numVisits=16, meanQ=8.130006, numObservations: 4
action 2, numVisits=23, meanQ=7.916113, numObservations: 5
action 5, numVisits=10, meanQ=7.701010, numObservations: 4
action 3, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.152422 0.116751 0.597867 0.896569 0.97792 0.34474 0.692745 0.841764 0.856472 0.619037 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=201993, meanQ=13.425049, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action 4, numVisits=7, meanQ=5.727143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1100081 episodes
GETTING ACTION FROM:
action 5, numVisits=1302074, meanQ=11.820587, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action 4, numVisits=7, meanQ=5.727143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.152422 0.116751 0.597867 0.896569 0.97792 0.34474 0.692745 0.841764 0.856472 0.619037 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 47
Initial state: 0 0.992526 0.970035 0.799058 0.528217 0.614506 0.825094 0.555181 0.822514 0.730093 0.123714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 823655 episodes
GETTING ACTION FROM:
action 4, numVisits=823616, meanQ=10.235361, numObservations: 3
action 1, numVisits=13, meanQ=7.306169, numObservations: 3
action 5, numVisits=7, meanQ=7.140014, numObservations: 2
action 3, numVisits=12, meanQ=6.841667, numObservations: 2
action 2, numVisits=5, meanQ=3.820000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 1 0.992526 0.970035 0.799058 0.528217 0.614506 0.825094 0.555181 0.822514 0.730093 0.123714 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 48
Initial state: 0 0.635963 0.851528 0.55587 0.819014 0.0933761 0.968175 0.0480635 0.123414 0.831018 0.243399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 818866 episodes
GETTING ACTION FROM:
action 3, numVisits=818853, meanQ=10.405244, numObservations: 5
action 4, numVisits=8, meanQ=7.498750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.635963 0.851528 0.55587 0.819014 0.0933761 0.968175 0.0480635 0.123414 0.831018 0.243399 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=56506, meanQ=12.460353, numObservations: 3
action 2, numVisits=4, meanQ=3.742500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1008008 episodes
GETTING ACTION FROM:
action 3, numVisits=1064514, meanQ=10.581003, numObservations: 3
action 2, numVisits=4, meanQ=3.742500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.635963 0.851528 0.55587 0.819014 0.0933761 0.968175 0.0480635 0.123414 0.831018 0.243399 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 49
Initial state: 0 0.807429 0.532759 0.0305089 0.718794 0.598584 0.874746 0.0949208 0.115138 0.6701 0.854619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812826 episodes
GETTING ACTION FROM:
action 3, numVisits=812810, meanQ=10.305345, numObservations: 5
action 1, numVisits=11, meanQ=7.453645, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.807429 0.532759 0.0305089 0.718794 0.598584 0.874746 0.0949208 0.115138 0.6701 0.854619 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.246368 0.780879 0.393943 0.544976 0.598622 0.83895 0.623471 0.864329 0.0651552 0.504191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 788822 episodes
GETTING ACTION FROM:
action 5, numVisits=788806, meanQ=10.418102, numObservations: 5
action 1, numVisits=9, meanQ=4.442256, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.246368 0.780879 0.393943 0.544976 0.598622 0.83895 0.623471 0.864329 0.0651552 0.504191 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=195448, meanQ=13.887470, numObservations: 4
action 3, numVisits=14, meanQ=6.792857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1112801 episodes
GETTING ACTION FROM:
action 1, numVisits=1308249, meanQ=12.368526, numObservations: 4
action 3, numVisits=14, meanQ=6.792857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.246368 0.780879 0.393943 0.544976 0.598622 0.83895 0.623471 0.864329 0.0651552 0.504191 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=153528, meanQ=16.973857, numObservations: 4
action 2, numVisits=13, meanQ=11.767692, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1210705 episodes
GETTING ACTION FROM:
action 4, numVisits=1364217, meanQ=12.635710, numObservations: 4
action 2, numVisits=29, meanQ=11.141034, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.246368 0.780879 0.393943 0.544976 0.598622 0.83895 0.623471 0.864329 0.0651552 0.504191 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 51
Initial state: 0 0.762179 0.678752 0.571792 0.807719 0.0331999 0.624999 0.872265 0.954646 0.574125 0.875617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 777379 episodes
GETTING ACTION FROM:
action 4, numVisits=777368, meanQ=10.054293, numObservations: 4
action 3, numVisits=6, meanQ=3.998367, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.762179 0.678752 0.571792 0.807719 0.0331999 0.624999 0.872265 0.954646 0.574125 0.875617 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 52
Initial state: 0 0.348618 0.0723702 0.615374 0.866616 0.322762 0.38864 0.651854 0.821215 0.394675 0.086871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 788871 episodes
GETTING ACTION FROM:
action 5, numVisits=788865, meanQ=10.173846, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.348618 0.0723702 0.615374 0.866616 0.322762 0.38864 0.651854 0.821215 0.394675 0.086871 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=162249, meanQ=13.305139, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1087973 episodes
GETTING ACTION FROM:
action 3, numVisits=1250222, meanQ=11.515163, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.348618 0.0723702 0.615374 0.866616 0.322762 0.38864 0.651854 0.821215 0.394675 0.086871 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=127385, meanQ=16.495996, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1208953 episodes
GETTING ACTION FROM:
action 4, numVisits=1336338, meanQ=12.392713, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.348618 0.0723702 0.615374 0.866616 0.322762 0.38864 0.651854 0.821215 0.394675 0.086871 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 53
Initial state: 0 0.952584 0.203639 0.597736 0.840758 0.666283 0.851808 0.551629 0.513523 0.611599 0.110396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812299 episodes
GETTING ACTION FROM:
action 2, numVisits=812293, meanQ=10.213544, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.952584 0.203639 0.597736 0.840758 0.666283 0.851808 0.551629 0.513523 0.611599 0.110396 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 54
Initial state: 0 0.769464 0.591045 0.071789 0.491813 0.632592 0.885399 0.336376 0.154505 0.578058 0.812077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812552 episodes
GETTING ACTION FROM:
action 4, numVisits=812505, meanQ=10.232392, numObservations: 5
action 1, numVisits=38, meanQ=8.936813, numObservations: 4
action 5, numVisits=5, meanQ=6.602040, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.769464 0.591045 0.071789 0.491813 0.632592 0.885399 0.336376 0.154505 0.578058 0.812077 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=202253, meanQ=13.288785, numObservations: 5
action 1, numVisits=30, meanQ=11.916357, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1081871 episodes
GETTING ACTION FROM:
action 2, numVisits=1284116, meanQ=12.356529, numObservations: 5
action 1, numVisits=38, meanQ=10.776071, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.769464 0.591045 0.071789 0.491813 0.632592 0.885399 0.336376 0.154505 0.578058 0.812077 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=44833, meanQ=16.317971, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1182098 episodes
GETTING ACTION FROM:
action 1, numVisits=1226931, meanQ=11.751690, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.769464 0.591045 0.071789 0.491813 0.632592 0.885399 0.336376 0.154505 0.578058 0.812077 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 55
Initial state: 0 0.401223 0.825725 0.656001 0.801132 0.644283 0.582542 0.575532 0.825731 0.716129 0.922704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 543878 episodes
GETTING ACTION FROM:
action -1, numVisits=543864, meanQ=7.969498, numObservations: 3
action 2, numVisits=9, meanQ=1.122222, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.401223 0.825725 0.656001 0.801132 0.644283 0.582542 0.575532 0.825731 0.716129 0.922704 w: 1
Observation: 0 0.4046 0 0.606561 0 0.653207 0 0.662652 0 0.651488 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=189290, meanQ=8.037640, numObservations: 4
action 1, numVisits=13, meanQ=4.766931, numObservations: 5
action 4, numVisits=19, meanQ=4.354737, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 885462 episodes
GETTING ACTION FROM:
action 3, numVisits=1074752, meanQ=9.943334, numObservations: 4
action 1, numVisits=13, meanQ=4.766931, numObservations: 5
action 4, numVisits=19, meanQ=4.354737, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.401223 0.825725 0.656001 0.801132 0.644283 0.582542 0.575532 0.825731 0.716129 0.922704 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 56
Initial state: 0 0.650026 0.800203 0.511208 0.823049 0.502291 0.375879 0.474567 0.58801 0.261571 0.079826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812778 episodes
GETTING ACTION FROM:
action 2, numVisits=812772, meanQ=10.335438, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.650026 0.800203 0.511208 0.823049 0.502291 0.375879 0.474567 0.58801 0.261571 0.079826 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 57
Initial state: 0 0.208237 0.0641857 0.582456 0.825026 0.584492 0.694857 0.604897 0.82342 0.462304 0.163309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 823676 episodes
GETTING ACTION FROM:
action 2, numVisits=823658, meanQ=10.426030, numObservations: 4
action 1, numVisits=13, meanQ=7.459238, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.208237 0.0641857 0.582456 0.825026 0.584492 0.694857 0.604897 0.82342 0.462304 0.163309 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 58
Initial state: 0 0.456645 0.641796 0.741969 0.566341 0.59761 0.877327 0.213381 0.313503 0.520255 0.869428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 815890 episodes
GETTING ACTION FROM:
action 3, numVisits=815882, meanQ=10.192586, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.456645 0.641796 0.741969 0.566341 0.59761 0.877327 0.213381 0.313503 0.520255 0.869428 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 59
Initial state: 0 0.54521 0.923686 0.579206 0.850178 0.363983 0.740887 0.903528 0.79715 0.609839 0.844056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 798275 episodes
GETTING ACTION FROM:
action 4, numVisits=798265, meanQ=10.523069, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action 5, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.54521 0.923686 0.579206 0.850178 0.363983 0.740887 0.903528 0.79715 0.609839 0.844056 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 60
Initial state: 0 0.0828667 0.203155 0.62074 0.851143 0.682354 0.867046 0.872524 0.580939 0.983544 0.740996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 831473 episodes
GETTING ACTION FROM:
action 2, numVisits=831455, meanQ=10.391282, numObservations: 3
action 1, numVisits=13, meanQ=4.152315, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0828667 0.203155 0.62074 0.851143 0.682354 0.867046 0.872524 0.580939 0.983544 0.740996 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 61
Initial state: 0 0.958048 0.998675 0.838966 0.219628 0.335514 0.0790441 0.664111 0.881723 0.667157 0.868896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816549 episodes
GETTING ACTION FROM:
action 1, numVisits=816527, meanQ=10.346770, numObservations: 5
action 2, numVisits=13, meanQ=7.001554, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.958048 0.998675 0.838966 0.219628 0.335514 0.0790441 0.664111 0.881723 0.667157 0.868896 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 62
Initial state: 0 0.335886 0.851892 0.548093 0.857059 0.690871 0.815339 0.30862 0.225543 0.773695 0.920705 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 817534 episodes
GETTING ACTION FROM:
action 1, numVisits=817528, meanQ=10.249292, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.335886 0.851892 0.548093 0.857059 0.690871 0.815339 0.30862 0.225543 0.773695 0.920705 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=56437, meanQ=9.992524, numObservations: 5
action 4, numVisits=6, meanQ=4.330017, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1051195 episodes
GETTING ACTION FROM:
action 2, numVisits=1107632, meanQ=11.335113, numObservations: 5
action 4, numVisits=6, meanQ=4.330017, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.335886 0.851892 0.548093 0.857059 0.690871 0.815339 0.30862 0.225543 0.773695 0.920705 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=33969, meanQ=10.408649, numObservations: 3
action 3, numVisits=10, meanQ=0.598050, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1145602 episodes
GETTING ACTION FROM:
action 2, numVisits=1090853, meanQ=10.367048, numObservations: 4
action -1, numVisits=88717, meanQ=3.718086, numObservations: 3
action 3, numVisits=10, meanQ=0.598050, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.335886 0.851892 0.548093 0.857059 0.690871 0.815339 0.30862 0.225543 0.773695 0.920705 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 63
Initial state: 0 0.668442 0.865448 0.931744 0.122474 0.371933 0.712192 0.873828 0.952654 0.522243 0.834498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 822445 episodes
GETTING ACTION FROM:
action 2, numVisits=822437, meanQ=10.225000, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.668442 0.865448 0.931744 0.122474 0.371933 0.712192 0.873828 0.952654 0.522243 0.834498 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 64
Initial state: 0 0.678985 0.814769 0.868274 0.402054 0.742485 0.177889 0.0267976 0.0696356 0.527878 0.804144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 818602 episodes
GETTING ACTION FROM:
action 3, numVisits=803810, meanQ=10.247125, numObservations: 4
action 2, numVisits=14769, meanQ=10.143471, numObservations: 4
action 5, numVisits=17, meanQ=8.464129, numObservations: 4
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.678985 0.814769 0.868274 0.402054 0.742485 0.177889 0.0267976 0.0696356 0.527878 0.804144 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 65
Initial state: 0 0.62269 0.202457 0.541319 0.86907 0.559391 0.805352 0.435073 0.480703 0.706157 0.971124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 795051 episodes
GETTING ACTION FROM:
action 1, numVisits=795035, meanQ=10.195390, numObservations: 4
action 4, numVisits=9, meanQ=6.565567, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.62269 0.202457 0.541319 0.86907 0.559391 0.805352 0.435073 0.480703 0.706157 0.971124 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 66
Initial state: 0 0.389316 0.113728 0.540998 0.840244 0.101501 0.0455582 0.520479 0.845305 0.166828 0.246109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 817410 episodes
GETTING ACTION FROM:
action 1, numVisits=817399, meanQ=10.185667, numObservations: 4
action 3, numVisits=6, meanQ=6.418333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.389316 0.113728 0.540998 0.840244 0.101501 0.0455582 0.520479 0.845305 0.166828 0.246109 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=202957, meanQ=13.409225, numObservations: 5
action 4, numVisits=23, meanQ=10.521317, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1102083 episodes
GETTING ACTION FROM:
action 3, numVisits=1305040, meanQ=12.405182, numObservations: 5
action 4, numVisits=23, meanQ=10.521317, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.389316 0.113728 0.540998 0.840244 0.101501 0.0455582 0.520479 0.845305 0.166828 0.246109 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=132003, meanQ=16.747460, numObservations: 5
action 5, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1193571 episodes
GETTING ACTION FROM:
action 4, numVisits=1325573, meanQ=12.725957, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.389316 0.113728 0.540998 0.840244 0.101501 0.0455582 0.520479 0.845305 0.166828 0.246109 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=21445, meanQ=17.360695, numObservations: 4
action 5, numVisits=3, meanQ=12.333333, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1202430 episodes
GETTING ACTION FROM:
action 4, numVisits=1223874, meanQ=11.835165, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 5, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.389316 0.113728 0.540998 0.840244 0.101501 0.0455582 0.520479 0.845305 0.166828 0.246109 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 67
Initial state: 0 0.0381798 0.644249 0.806927 0.586336 0.651711 0.826099 0.717232 0.201768 0.584131 0.862321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816348 episodes
GETTING ACTION FROM:
action 1, numVisits=816335, meanQ=10.411196, numObservations: 5
action 5, numVisits=6, meanQ=7.125000, numObservations: 1
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0381798 0.644249 0.806927 0.586336 0.651711 0.826099 0.717232 0.201768 0.584131 0.862321 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=67517, meanQ=12.893374, numObservations: 4
action 2, numVisits=13, meanQ=9.058469, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1095955 episodes
GETTING ACTION FROM:
action 4, numVisits=1163472, meanQ=12.034044, numObservations: 4
action 2, numVisits=13, meanQ=9.058469, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0381798 0.644249 0.806927 0.586336 0.651711 0.826099 0.717232 0.201768 0.584131 0.862321 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 68
Initial state: 0 0.717735 0.586304 0.722124 0.0326206 0.697798 0.815955 0.550147 0.879008 0.787722 0.474436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 831338 episodes
GETTING ACTION FROM:
action 4, numVisits=831330, meanQ=10.417769, numObservations: 3
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.717735 0.586304 0.722124 0.0326206 0.697798 0.815955 0.550147 0.879008 0.787722 0.474436 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 69
Initial state: 0 0.553087 0.858611 0.471929 0.790239 0.570779 0.833849 0.48222 0.121525 0.338007 0.59217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 576535 episodes
GETTING ACTION FROM:
action -1, numVisits=576526, meanQ=8.337653, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=4, meanQ=-2.250000, numObservations: 2
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.553087 0.858611 0.471929 0.790239 0.570779 0.833849 0.48222 0.121525 0.338007 0.59217 w: 1
Observation: 0 0.539316 0 0.519099 0 0.549712 0 0.417928 0 0.273854 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=365519, meanQ=9.328101, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 886423 episodes
GETTING ACTION FROM:
action 3, numVisits=1251942, meanQ=9.695803, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.553087 0.858611 0.471929 0.790239 0.570779 0.833849 0.48222 0.121525 0.338007 0.59217 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 70
Initial state: 0 0.676381 0.85005 0.672852 0.879937 0.10396 0.110029 0.731082 0.228836 0.319624 0.222232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 814604 episodes
GETTING ACTION FROM:
action 2, numVisits=814596, meanQ=10.323387, numObservations: 5
action 1, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.676381 0.85005 0.672852 0.879937 0.10396 0.110029 0.731082 0.228836 0.319624 0.222232 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 71
Initial state: 0 0.0204099 0.174844 0.567254 0.894432 0.66983 0.809871 0.347516 0.0552758 0.797922 0.276304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 769276 episodes
GETTING ACTION FROM:
action 2, numVisits=769266, meanQ=10.107899, numObservations: 4
action 1, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0204099 0.174844 0.567254 0.894432 0.66983 0.809871 0.347516 0.0552758 0.797922 0.276304 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 72
Initial state: 0 0.844413 0.921365 0.633987 0.88792 0.0288996 0.504077 0.66104 0.870519 0.451597 0.111985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812770 episodes
GETTING ACTION FROM:
action 2, numVisits=812759, meanQ=10.418347, numObservations: 4
action 4, numVisits=6, meanQ=2.668350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.844413 0.921365 0.633987 0.88792 0.0288996 0.504077 0.66104 0.870519 0.451597 0.111985 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 73
Initial state: 0 0.0341001 0.0796123 0.549732 0.810669 0.532413 0.809087 0.37314 0.849862 0.807916 0.603608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 579212 episodes
GETTING ACTION FROM:
action 0, numVisits=579201, meanQ=11.614827, numObservations: 6
action 2, numVisits=5, meanQ=-0.804000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.0341001 0.0796123 0.549732 0.810669 0.532413 0.809087 0.37314 0.849862 0.807916 0.603608 w: 1
Observation: 0 0 0.00055488 0 0.800876 0 0.827392 0 0.913985 0 0.692607 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81647, meanQ=14.162629, numObservations: 4
action 5, numVisits=21, meanQ=9.535714, numObservations: 4
action 3, numVisits=6, meanQ=8.831683, numObservations: 2
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 917633 episodes
GETTING ACTION FROM:
action 2, numVisits=998917, meanQ=10.915466, numObservations: 4
action 5, numVisits=217, meanQ=10.407712, numObservations: 4
action 3, numVisits=173, meanQ=10.352588, numObservations: 4
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0341001 0.0796123 0.549732 0.810669 0.532413 0.809087 0.37314 0.849862 0.807916 0.603608 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 74
Initial state: 0 0.602807 0.813272 0.721364 0.41309 0.208056 0.261822 0.50106 0.862576 0.0653784 0.870739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 803009 episodes
GETTING ACTION FROM:
action 2, numVisits=802994, meanQ=10.167550, numObservations: 5
action 3, numVisits=8, meanQ=6.125037, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.602807 0.813272 0.721364 0.41309 0.208056 0.261822 0.50106 0.862576 0.0653784 0.870739 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=56027, meanQ=9.988533, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action 2, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1108362 episodes
GETTING ACTION FROM:
action 1, numVisits=1164389, meanQ=11.237182, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action 2, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.602807 0.813272 0.721364 0.41309 0.208056 0.261822 0.50106 0.862576 0.0653784 0.870739 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 75
Initial state: 0 0.558179 0.842129 0.652892 0.865405 0.745898 0.54969 0.443064 0.1071 0.65292 0.930224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820149 episodes
GETTING ACTION FROM:
action 2, numVisits=820143, meanQ=10.270856, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.558179 0.842129 0.652892 0.865405 0.745898 0.54969 0.443064 0.1071 0.65292 0.930224 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 76
Initial state: 0 0.536321 0.821098 0.842839 0.524863 0.616937 0.876838 0.163463 0.874438 0.780404 0.0167829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 829106 episodes
GETTING ACTION FROM:
action 4, numVisits=829098, meanQ=10.477863, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.536321 0.821098 0.842839 0.524863 0.616937 0.876838 0.163463 0.874438 0.780404 0.0167829 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=239294, meanQ=13.475378, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1128626 episodes
GETTING ACTION FROM:
action 5, numVisits=1367920, meanQ=11.920877, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.536321 0.821098 0.842839 0.524863 0.616937 0.876838 0.163463 0.874438 0.780404 0.0167829 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 77
Initial state: 0 0.550996 0.840302 0.705343 0.139298 0.95543 0.214041 0.386904 0.972507 0.671775 0.854604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 737300 episodes
GETTING ACTION FROM:
action 4, numVisits=737265, meanQ=10.624825, numObservations: 4
action 2, numVisits=30, meanQ=4.032357, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.550996 0.840302 0.705343 0.139298 0.95543 0.214041 0.386904 0.972507 0.671775 0.854604 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 78
Initial state: 0 0.669086 0.887218 0.19237 0.781019 0.367902 0.114804 0.651795 0.803553 0.0196721 0.0229041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 815546 episodes
GETTING ACTION FROM:
action 4, numVisits=815532, meanQ=10.483422, numObservations: 4
action 2, numVisits=7, meanQ=6.282857, numObservations: 4
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.669086 0.887218 0.19237 0.781019 0.367902 0.114804 0.651795 0.803553 0.0196721 0.0229041 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 79
Initial state: 0 0.0124817 0.499673 0.447094 0.184475 0.713223 0.531557 0.581802 0.826285 0.670513 0.808318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 818034 episodes
GETTING ACTION FROM:
action 2, numVisits=818026, meanQ=10.299179, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0124817 0.499673 0.447094 0.184475 0.713223 0.531557 0.581802 0.826285 0.670513 0.808318 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=203062, meanQ=13.448793, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1110829 episodes
GETTING ACTION FROM:
action 5, numVisits=1313890, meanQ=12.010463, numObservations: 4
action 3, numVisits=5, meanQ=4.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.0124817 0.499673 0.447094 0.184475 0.713223 0.531557 0.581802 0.826285 0.670513 0.808318 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 80
Initial state: 0 0.698564 0.822619 0.440993 0.598243 0.529048 0.924804 0.051136 0.439789 0.514974 0.833667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 822241 episodes
GETTING ACTION FROM:
action 1, numVisits=822235, meanQ=10.430732, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.698564 0.822619 0.440993 0.598243 0.529048 0.924804 0.051136 0.439789 0.514974 0.833667 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 81
Initial state: 0 0.537998 0.802913 0.151331 0.103135 0.690032 0.807476 0.104396 0.899734 0.821375 0.120327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 732765 episodes
GETTING ACTION FROM:
action 1, numVisits=732759, meanQ=9.843162, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.537998 0.802913 0.151331 0.103135 0.690032 0.807476 0.104396 0.899734 0.821375 0.120327 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 82
Initial state: 0 0.259039 0.76203 0.0299547 0.37292 0.380136 0.0350888 0.597493 0.820901 0.616988 0.845895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 822902 episodes
GETTING ACTION FROM:
action 1, numVisits=822892, meanQ=10.307564, numObservations: 4
action 2, numVisits=5, meanQ=5.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.259039 0.76203 0.0299547 0.37292 0.380136 0.0350888 0.597493 0.820901 0.616988 0.845895 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 83
Initial state: 0 0.562255 0.886234 0.631084 0.882956 0.15281 0.188787 0.966574 0.336488 0.315414 0.446445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 801513 episodes
GETTING ACTION FROM:
action 1, numVisits=801507, meanQ=10.517851, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.562255 0.886234 0.631084 0.882956 0.15281 0.188787 0.966574 0.336488 0.315414 0.446445 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 84
Initial state: 0 0.847717 0.825574 0.624973 0.859975 0.623144 0.868368 0.790269 0.16798 0.40656 0.365101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816228 episodes
GETTING ACTION FROM:
action 2, numVisits=816220, meanQ=10.379759, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.847717 0.825574 0.624973 0.859975 0.623144 0.868368 0.790269 0.16798 0.40656 0.365101 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 85
Initial state: 0 0.962501 0.325089 0.560086 0.830614 0.687367 0.866804 0.303723 0.0809378 0.0264561 0.0517334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 810366 episodes
GETTING ACTION FROM:
action 5, numVisits=796495, meanQ=10.258778, numObservations: 5
action 1, numVisits=13866, meanQ=10.125935, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.962501 0.325089 0.560086 0.830614 0.687367 0.866804 0.303723 0.0809378 0.0264561 0.0517334 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=164201, meanQ=13.470783, numObservations: 5
action 4, numVisits=8, meanQ=7.498750, numObservations: 4
action 3, numVisits=7, meanQ=7.140014, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1091583 episodes
GETTING ACTION FROM:
action 1, numVisits=1255784, meanQ=12.339831, numObservations: 5
action 4, numVisits=8, meanQ=7.498750, numObservations: 4
action 3, numVisits=7, meanQ=7.140014, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.962501 0.325089 0.560086 0.830614 0.687367 0.866804 0.303723 0.0809378 0.0264561 0.0517334 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 86
Initial state: 0 0.694202 0.814198 0.350185 0.745694 0.554465 0.820217 0.37512 0.556697 0.11196 0.453934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 822186 episodes
GETTING ACTION FROM:
action 4, numVisits=822164, meanQ=10.340791, numObservations: 4
action 2, numVisits=13, meanQ=7.153862, numObservations: 4
action 5, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.694202 0.814198 0.350185 0.745694 0.554465 0.820217 0.37512 0.556697 0.11196 0.453934 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=237978, meanQ=13.383955, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1110360 episodes
GETTING ACTION FROM:
action 1, numVisits=1348338, meanQ=11.940262, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.694202 0.814198 0.350185 0.745694 0.554465 0.820217 0.37512 0.556697 0.11196 0.453934 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 87
Initial state: 0 0.41831 0.0863641 0.715165 0.671565 0.279919 0.453871 0.652255 0.822954 0.672604 0.873677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 779240 episodes
GETTING ACTION FROM:
action 5, numVisits=779226, meanQ=10.491184, numObservations: 5
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action 4, numVisits=3, meanQ=4.670033, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 1 0.41831 0.0863641 0.715165 0.671565 0.279919 0.453871 0.652255 0.822954 0.672604 0.873677 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 88
Initial state: 0 0.297633 0.531491 0.676414 0.890099 0.072642 0.681504 0.361718 0.431183 0.509775 0.843448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 740603 episodes
GETTING ACTION FROM:
action 3, numVisits=740594, meanQ=9.814587, numObservations: 4
action 4, numVisits=4, meanQ=3.742500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.297633 0.531491 0.676414 0.890099 0.072642 0.681504 0.361718 0.431183 0.509775 0.843448 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 89
Initial state: 0 0.542066 0.877754 0.209776 0.596139 0.765424 0.391514 0.0560846 0.279548 0.611709 0.845583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812530 episodes
GETTING ACTION FROM:
action 1, numVisits=812514, meanQ=10.467069, numObservations: 5
action 2, numVisits=11, meanQ=7.088182, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.542066 0.877754 0.209776 0.596139 0.765424 0.391514 0.0560846 0.279548 0.611709 0.845583 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 90
Initial state: 0 0.6871 0.932794 0.147398 0.563722 0.552433 0.892621 0.911934 0.886959 0.600017 0.84281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 809913 episodes
GETTING ACTION FROM:
action 4, numVisits=809907, meanQ=10.275096, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.6871 0.932794 0.147398 0.563722 0.552433 0.892621 0.911934 0.886959 0.600017 0.84281 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 91
Initial state: 0 0.683173 0.805794 0.399676 0.514064 0.0355969 0.941678 0.673628 0.869989 0.439925 0.985175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 811617 episodes
GETTING ACTION FROM:
action 1, numVisits=811595, meanQ=10.299939, numObservations: 5
action 5, numVisits=11, meanQ=6.553645, numObservations: 3
action 4, numVisits=7, meanQ=5.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.683173 0.805794 0.399676 0.514064 0.0355969 0.941678 0.673628 0.869989 0.439925 0.985175 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 92
Initial state: 0 0.609503 0.893236 0.557216 0.839579 0.209029 0.910551 0.886949 0.350969 0.232945 0.955954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 821780 episodes
GETTING ACTION FROM:
action 1, numVisits=821765, meanQ=10.355950, numObservations: 4
action 5, numVisits=7, meanQ=-2.002829, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.609503 0.893236 0.557216 0.839579 0.209029 0.910551 0.886949 0.350969 0.232945 0.955954 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 93
Initial state: 0 0.322467 0.144364 0.524415 0.862564 0.999609 0.0261361 0.501255 0.866307 0.398309 0.290549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 797192 episodes
GETTING ACTION FROM:
action 4, numVisits=797184, meanQ=10.277300, numObservations: 5
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.322467 0.144364 0.524415 0.862564 0.999609 0.0261361 0.501255 0.866307 0.398309 0.290549 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 94
Initial state: 0 0.711616 0.941859 0.610146 0.839218 0.492856 0.6142 0.505209 0.899929 0.231526 0.645808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 822034 episodes
GETTING ACTION FROM:
action 3, numVisits=822028, meanQ=10.380898, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.711616 0.941859 0.610146 0.839218 0.492856 0.6142 0.505209 0.899929 0.231526 0.645808 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=203978, meanQ=13.525101, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1111554 episodes
GETTING ACTION FROM:
action 5, numVisits=1315532, meanQ=11.932896, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.711616 0.941859 0.610146 0.839218 0.492856 0.6142 0.505209 0.899929 0.231526 0.645808 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=156604, meanQ=17.216471, numObservations: 4
action 1, numVisits=8, meanQ=11.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1196161 episodes
GETTING ACTION FROM:
action 2, numVisits=1352758, meanQ=12.807800, numObservations: 4
action 1, numVisits=15, meanQ=10.532667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.711616 0.941859 0.610146 0.839218 0.492856 0.6142 0.505209 0.899929 0.231526 0.645808 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 95
Initial state: 0 0.247567 0.587646 0.00351744 0.767151 0.636501 0.217932 0.589039 0.849973 0.569812 0.869635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 785359 episodes
GETTING ACTION FROM:
action 3, numVisits=785353, meanQ=10.195554, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.247567 0.587646 0.00351744 0.767151 0.636501 0.217932 0.589039 0.849973 0.569812 0.869635 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 96
Initial state: 0 0.336773 0.320239 0.928735 0.254025 0.276802 0.641624 0.69368 0.884431 0.508711 0.824248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812746 episodes
GETTING ACTION FROM:
action 2, numVisits=812723, meanQ=10.301702, numObservations: 5
action 3, numVisits=15, meanQ=2.935367, numObservations: 4
action 1, numVisits=4, meanQ=-0.252500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.336773 0.320239 0.928735 0.254025 0.276802 0.641624 0.69368 0.884431 0.508711 0.824248 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 97
Initial state: 0 0.854244 0.222389 0.665402 0.895951 0.198754 0.510768 0.222091 0.269436 0.605446 0.884559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 828677 episodes
GETTING ACTION FROM:
action 4, numVisits=828671, meanQ=10.313958, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.854244 0.222389 0.665402 0.895951 0.198754 0.510768 0.222091 0.269436 0.605446 0.884559 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=238855, meanQ=13.534043, numObservations: 4
action 3, numVisits=16, meanQ=7.998125, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=7, meanQ=5.998586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1099171 episodes
GETTING ACTION FROM:
action 1, numVisits=1338026, meanQ=11.834196, numObservations: 4
action 3, numVisits=16, meanQ=7.998125, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=7, meanQ=5.998586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.854244 0.222389 0.665402 0.895951 0.198754 0.510768 0.222091 0.269436 0.605446 0.884559 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 98
Initial state: 0 0.691933 0.820352 0.472596 0.60654 0.616192 0.884881 0.379087 0.729502 0.0799043 0.43008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 616715 episodes
GETTING ACTION FROM:
action -1, numVisits=616705, meanQ=8.071684, numObservations: 3
action 2, numVisits=5, meanQ=-0.804000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.691933 0.820352 0.472596 0.60654 0.616192 0.884881 0.379087 0.729502 0.0799043 0.43008 w: 1
Observation: 0 0.647109 0 0.475302 0 0.579284 0 0.371187 0 0.0661582 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=93793, meanQ=13.038634, numObservations: 3
action 2, numVisits=13, meanQ=9.210777, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 932869 episodes
GETTING ACTION FROM:
action 1, numVisits=1026662, meanQ=11.642042, numObservations: 3
action 2, numVisits=13, meanQ=9.210777, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.691933 0.820352 0.472596 0.60654 0.616192 0.884881 0.379087 0.729502 0.0799043 0.43008 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 99
Initial state: 0 0.56219 0.853698 0.678632 0.830247 0.493276 0.847037 0.769417 0.934688 0.342935 0.320017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812847 episodes
GETTING ACTION FROM:
action 1, numVisits=812727, meanQ=10.129632, numObservations: 4
action 3, numVisits=115, meanQ=9.363873, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.56219 0.853698 0.678632 0.830247 0.493276 0.847037 0.769417 0.934688 0.342935 0.320017 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 100
Initial state: 0 0.758238 0.75282 0.778394 0.854319 0.552478 0.83967 0.550934 0.895008 0.138605 0.870243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 744653 episodes
GETTING ACTION FROM:
action 5, numVisits=744644, meanQ=10.245080, numObservations: 4
action 2, numVisits=4, meanQ=0.752525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.758238 0.75282 0.778394 0.854319 0.552478 0.83967 0.550934 0.895008 0.138605 0.870243 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=184731, meanQ=13.963478, numObservations: 7
action 3, numVisits=4, meanQ=-2.250000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 910448 episodes
GETTING ACTION FROM:
action 0, numVisits=1095179, meanQ=5.646002, numObservations: 7
action 3, numVisits=4, meanQ=-2.250000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.758238 0.75282 0.778394 0.854319 0.552478 0.83967 0.550934 0.895008 0.138605 0.870243 w: 1
Observation: 0 0 0.667521 0 0.884438 0 0.889417 0 0.814621 0 0.854662 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=302584, meanQ=13.754399, numObservations: 4
action 4, numVisits=6, meanQ=7.831667, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1129608 episodes
GETTING ACTION FROM:
action 1, numVisits=1432192, meanQ=12.670872, numObservations: 4
action 4, numVisits=6, meanQ=7.831667, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.758238 0.75282 0.778394 0.854319 0.552478 0.83967 0.550934 0.895008 0.138605 0.870243 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7611
Run # 101
Initial state: 0 0.590917 0.855698 0.186418 0.0895093 0.681222 0.858916 0.896424 0.5038 0.0399285 0.920187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812581 episodes
GETTING ACTION FROM:
action 5, numVisits=812575, meanQ=10.284517, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.590917 0.855698 0.186418 0.0895093 0.681222 0.858916 0.896424 0.5038 0.0399285 0.920187 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 102
Initial state: 0 0.897455 0.629152 0.245603 0.302144 0.748676 0.617781 0.617071 0.861026 0.594742 0.879974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 824624 episodes
GETTING ACTION FROM:
action 3, numVisits=824615, meanQ=10.405720, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.897455 0.629152 0.245603 0.302144 0.748676 0.617781 0.617071 0.861026 0.594742 0.879974 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 103
Initial state: 0 0.749792 0.811174 0.165692 0.633446 0.672654 0.837316 0.362267 0.214301 0.547778 0.8806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 798163 episodes
GETTING ACTION FROM:
action 4, numVisits=664920, meanQ=10.267219, numObservations: 4
action 3, numVisits=132975, meanQ=10.245154, numObservations: 3
action 5, numVisits=264, meanQ=9.761035, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.749792 0.811174 0.165692 0.633446 0.672654 0.837316 0.362267 0.214301 0.547778 0.8806 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=137457, meanQ=13.599147, numObservations: 5
action 5, numVisits=17, meanQ=8.939412, numObservations: 4
action 2, numVisits=9, meanQ=7.444467, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1111843 episodes
GETTING ACTION FROM:
action 1, numVisits=1249299, meanQ=11.683125, numObservations: 5
action 5, numVisits=17, meanQ=8.939412, numObservations: 4
action 2, numVisits=9, meanQ=7.444467, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.749792 0.811174 0.165692 0.633446 0.672654 0.837316 0.362267 0.214301 0.547778 0.8806 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 104
Initial state: 0 0.0525412 0.970881 0.866434 0.918034 0.671633 0.59399 0.579744 0.87178 0.504934 0.849421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 740351 episodes
GETTING ACTION FROM:
action 3, numVisits=740337, meanQ=10.914093, numObservations: 5
action 4, numVisits=9, meanQ=1.083333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0525412 0.970881 0.866434 0.918034 0.671633 0.59399 0.579744 0.87178 0.504934 0.849421 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=182850, meanQ=15.655428, numObservations: 5
action 2, numVisits=7, meanQ=0.998586, numObservations: 2
action 1, numVisits=5, meanQ=0.804040, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 925631 episodes
GETTING ACTION FROM:
action 0, numVisits=1108481, meanQ=6.250433, numObservations: 5
action 2, numVisits=7, meanQ=0.998586, numObservations: 2
action 1, numVisits=5, meanQ=0.804040, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.0525412 0.970881 0.866434 0.918034 0.671633 0.59399 0.579744 0.87178 0.504934 0.849421 w: 1
Observation: 0 0 1 0 0.915063 0 0.499683 0 0.805898 0 0.822662 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=212281, meanQ=16.778801, numObservations: 4
action 1, numVisits=25, meanQ=14.991208, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1092730 episodes
GETTING ACTION FROM:
action 5, numVisits=1304852, meanQ=12.322758, numObservations: 4
action 1, numVisits=184, meanQ=11.720871, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0525412 0.970881 0.866434 0.918034 0.671633 0.59399 0.579744 0.87178 0.504934 0.849421 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 105
Initial state: 0 0.688242 0.863581 0.114083 0.579207 0.53881 0.849672 0.807052 0.102658 0.478151 0.289826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 821835 episodes
GETTING ACTION FROM:
action 4, numVisits=821829, meanQ=10.461438, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.688242 0.863581 0.114083 0.579207 0.53881 0.849672 0.807052 0.102658 0.478151 0.289826 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 106
Initial state: 0 0.537227 0.827712 0.975642 0.768305 0.517189 0.866206 0.0846996 0.557061 0.994607 0.293665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 809837 episodes
GETTING ACTION FROM:
action 3, numVisits=809827, meanQ=10.261057, numObservations: 5
action 1, numVisits=5, meanQ=5.798020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.537227 0.827712 0.975642 0.768305 0.517189 0.866206 0.0846996 0.557061 0.994607 0.293665 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 107
Initial state: 0 0.82085 0.708196 0.747782 0.615546 0.695193 0.87112 0.619787 0.378428 0.577672 0.87458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 823623 episodes
GETTING ACTION FROM:
action 2, numVisits=823615, meanQ=10.318240, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.82085 0.708196 0.747782 0.615546 0.695193 0.87112 0.619787 0.378428 0.577672 0.87458 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 108
Initial state: 0 0.585314 0.895346 0.841434 0.48864 0.594726 0.939139 0.609234 0.844766 0.729043 0.294132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816314 episodes
GETTING ACTION FROM:
action 5, numVisits=816303, meanQ=10.311533, numObservations: 5
action 2, numVisits=6, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.585314 0.895346 0.841434 0.48864 0.594726 0.939139 0.609234 0.844766 0.729043 0.294132 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 109
Initial state: 0 0.654395 0.87474 0.0529635 0.641429 0.00895386 0.5106 0.696819 0.176588 0.655977 0.838988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 541781 episodes
GETTING ACTION FROM:
action -1, numVisits=541772, meanQ=8.713867, numObservations: 4
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=4, meanQ=-2.250000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.654395 0.87474 0.0529635 0.641429 0.00895386 0.5106 0.696819 0.176588 0.655977 0.838988 w: 1
Observation: 0 0.680096 0 0.131489 0 0 0 0.666036 0 0.662823 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=74869, meanQ=13.336282, numObservations: 5
action 5, numVisits=4, meanQ=-5.999975, numObservations: 2
action 2, numVisits=3, meanQ=-6.336633, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 626701 episodes
GETTING ACTION FROM:
action 0, numVisits=701570, meanQ=13.887900, numObservations: 7
action 5, numVisits=4, meanQ=-5.999975, numObservations: 2
action 2, numVisits=3, meanQ=-6.336633, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.654395 0.87474 0.0529635 0.641429 0.00895386 0.5106 0.696819 0.176588 0.655977 0.838988 w: 1
Observation: 0 0 0.963402 0 0.585403 0 0.540419 0 0.0964078 0 0.824003 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=383130, meanQ=13.328102, numObservations: 5
action 4, numVisits=12, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 900714 episodes
GETTING ACTION FROM:
action 1, numVisits=1283844, meanQ=12.108538, numObservations: 5
action 4, numVisits=12, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.654395 0.87474 0.0529635 0.641429 0.00895386 0.5106 0.696819 0.176588 0.655977 0.838988 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.5424
Run # 110
Initial state: 0 0.914052 0.650084 0.295776 0.978543 0.211167 0.127734 0.521472 0.874901 0.630959 0.875279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 815647 episodes
GETTING ACTION FROM:
action 1, numVisits=815627, meanQ=10.310554, numObservations: 5
action 4, numVisits=15, meanQ=6.931333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.914052 0.650084 0.295776 0.978543 0.211167 0.127734 0.521472 0.874901 0.630959 0.875279 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 111
Initial state: 0 0.0480875 0.239683 0.298645 0.61669 0.198577 0.275708 0.525191 0.899202 0.623544 0.877567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 799748 episodes
GETTING ACTION FROM:
action 5, numVisits=799733, meanQ=10.359619, numObservations: 4
action 3, numVisits=10, meanQ=5.410010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0480875 0.239683 0.298645 0.61669 0.198577 0.275708 0.525191 0.899202 0.623544 0.877567 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 112
Initial state: 0 0.632947 0.82986 0.614487 0.710789 0.0848537 0.989029 0.67894 0.858246 0.146255 0.277871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 811332 episodes
GETTING ACTION FROM:
action 5, numVisits=811324, meanQ=10.695740, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.632947 0.82986 0.614487 0.710789 0.0848537 0.989029 0.67894 0.858246 0.146255 0.277871 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=166671, meanQ=13.480956, numObservations: 5
action 3, numVisits=7, meanQ=5.141429, numObservations: 2
action 2, numVisits=4, meanQ=2.747550, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1093314 episodes
GETTING ACTION FROM:
action 1, numVisits=1259985, meanQ=11.750485, numObservations: 5
action 3, numVisits=7, meanQ=5.141429, numObservations: 2
action 2, numVisits=4, meanQ=2.747550, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.632947 0.82986 0.614487 0.710789 0.0848537 0.989029 0.67894 0.858246 0.146255 0.277871 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 113
Initial state: 0 0.961302 0.985231 0.55512 0.805765 0.314766 0.678161 0.528372 0.847307 0.0344421 0.315201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 590700 episodes
GETTING ACTION FROM:
action 0, numVisits=590685, meanQ=13.323076, numObservations: 5
action 2, numVisits=5, meanQ=-0.001960, numObservations: 2
action 4, numVisits=5, meanQ=-0.804000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.961302 0.985231 0.55512 0.805765 0.314766 0.678161 0.528372 0.847307 0.0344421 0.315201 w: 1
Observation: 0 0 0.989271 0 0.897133 0 0.721499 0 0.789024 0 0.341915 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=151899, meanQ=16.151247, numObservations: 5
action 3, numVisits=44, meanQ=12.317964, numObservations: 5
action 5, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 898356 episodes
GETTING ACTION FROM:
action 2, numVisits=1049817, meanQ=10.945474, numObservations: 5
action 3, numVisits=481, meanQ=10.607978, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.961302 0.985231 0.55512 0.805765 0.314766 0.678161 0.528372 0.847307 0.0344421 0.315201 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 114
Initial state: 0 0.190619 0.323366 0.599627 0.833781 0.869623 0.114067 0.567946 0.847236 0.821353 0.981448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 823146 episodes
GETTING ACTION FROM:
action 3, numVisits=823140, meanQ=10.259545, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.190619 0.323366 0.599627 0.833781 0.869623 0.114067 0.567946 0.847236 0.821353 0.981448 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 115
Initial state: 0 0.213519 0.774272 0.494323 0.612058 0.372999 0.143364 0.510345 0.826908 0.663168 0.887879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 827921 episodes
GETTING ACTION FROM:
action 4, numVisits=827915, meanQ=10.309624, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.213519 0.774272 0.494323 0.612058 0.372999 0.143364 0.510345 0.826908 0.663168 0.887879 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 116
Initial state: 0 0.93205 0.36402 0.470181 0.567716 0.790105 0.971487 0.653368 0.803959 0.658977 0.859008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 815160 episodes
GETTING ACTION FROM:
action 4, numVisits=815138, meanQ=10.272449, numObservations: 5
action 1, numVisits=9, meanQ=2.447800, numObservations: 3
action 2, numVisits=9, meanQ=1.971111, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.93205 0.36402 0.470181 0.567716 0.790105 0.971487 0.653368 0.803959 0.658977 0.859008 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 117
Initial state: 0 0.517193 0.813827 0.57992 0.845152 0.910405 0.248188 0.168058 0.983971 0.816948 0.512938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 599566 episodes
GETTING ACTION FROM:
action -1, numVisits=599557, meanQ=7.994000, numObservations: 2
action 5, numVisits=4, meanQ=-0.252500, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.517193 0.813827 0.57992 0.845152 0.910405 0.248188 0.168058 0.983971 0.816948 0.512938 w: 1
Observation: 0 0.579614 0 0.519015 0 0.882984 0 0.181913 0 0.825334 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=273061, meanQ=8.901977, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 892404 episodes
GETTING ACTION FROM:
action 1, numVisits=1165465, meanQ=10.270052, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.517193 0.813827 0.57992 0.845152 0.910405 0.248188 0.168058 0.983971 0.816948 0.512938 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 118
Initial state: 0 0.471415 0.35593 0.425379 0.715949 0.504652 0.865589 0.548328 0.84575 0.370192 0.140561 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 813771 episodes
GETTING ACTION FROM:
action 2, numVisits=813765, meanQ=10.257831, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.471415 0.35593 0.425379 0.715949 0.504652 0.865589 0.548328 0.84575 0.370192 0.140561 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=201621, meanQ=13.468651, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1104120 episodes
GETTING ACTION FROM:
action 4, numVisits=1305741, meanQ=12.375189, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.471415 0.35593 0.425379 0.715949 0.504652 0.865589 0.548328 0.84575 0.370192 0.140561 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 119
Initial state: 0 0.516887 0.804551 0.653968 0.568326 0.541205 0.846338 0.303511 0.637261 0.908921 0.169746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 814685 episodes
GETTING ACTION FROM:
action 5, numVisits=814677, meanQ=10.384811, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.516887 0.804551 0.653968 0.568326 0.541205 0.846338 0.303511 0.637261 0.908921 0.169746 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 120
Initial state: 0 0.844728 0.891698 0.478377 0.448126 0.549597 0.805415 0.357569 0.860126 0.579677 0.830285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 815883 episodes
GETTING ACTION FROM:
action 2, numVisits=815873, meanQ=10.476400, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.844728 0.891698 0.478377 0.448126 0.549597 0.805415 0.357569 0.860126 0.579677 0.830285 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=235470, meanQ=13.736453, numObservations: 5
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1093389 episodes
GETTING ACTION FROM:
action 4, numVisits=1328859, meanQ=12.419064, numObservations: 5
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.844728 0.891698 0.478377 0.448126 0.549597 0.805415 0.357569 0.860126 0.579677 0.830285 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=54297, meanQ=15.657766, numObservations: 4
action 5, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1209065 episodes
GETTING ACTION FROM:
action 1, numVisits=1263352, meanQ=12.659902, numObservations: 4
action 5, numVisits=12, meanQ=10.082500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.844728 0.891698 0.478377 0.448126 0.549597 0.805415 0.357569 0.860126 0.579677 0.830285 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 121
Initial state: 0 0.592169 0.802628 0.58809 0.871395 0.667121 0.354899 0.435275 0.706508 0.576313 0.00824715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 824290 episodes
GETTING ACTION FROM:
action 3, numVisits=823360, meanQ=10.328336, numObservations: 4
action 2, numVisits=925, meanQ=9.847780, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.592169 0.802628 0.58809 0.871395 0.667121 0.354899 0.435275 0.706508 0.576313 0.00824715 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 122
Initial state: 0 0.536726 0.800557 0.624908 0.81463 0.916593 0.33028 0.904437 0.766256 0.665994 0.0220786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 746601 episodes
GETTING ACTION FROM:
action 4, numVisits=746595, meanQ=10.482490, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.536726 0.800557 0.624908 0.81463 0.916593 0.33028 0.904437 0.766256 0.665994 0.0220786 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 123
Initial state: 0 0.890689 0.510021 0.583831 0.816555 0.161879 0.397701 0.561016 0.867224 0.699466 0.754452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 799215 episodes
GETTING ACTION FROM:
action 1, numVisits=799203, meanQ=10.385845, numObservations: 4
action 3, numVisits=7, meanQ=5.998586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.890689 0.510021 0.583831 0.816555 0.161879 0.397701 0.561016 0.867224 0.699466 0.754452 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 124
Initial state: 0 0.576338 0.846553 0.753984 0.0685197 0.258405 0.847328 0.516035 0.843115 0.018379 0.46301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 811472 episodes
GETTING ACTION FROM:
action 1, numVisits=811463, meanQ=10.286611, numObservations: 5
action 5, numVisits=4, meanQ=3.245025, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.576338 0.846553 0.753984 0.0685197 0.258405 0.847328 0.516035 0.843115 0.018379 0.46301 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 125
Initial state: 0 0.470298 0.924763 0.53397 0.808727 0.581075 0.813933 0.834938 0.420813 0.797905 0.896861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 796808 episodes
GETTING ACTION FROM:
action 2, numVisits=796798, meanQ=10.184955, numObservations: 5
action 5, numVisits=5, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.470298 0.924763 0.53397 0.808727 0.581075 0.813933 0.834938 0.420813 0.797905 0.896861 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 126
Initial state: 0 0.128714 0.68019 0.635249 0.824113 0.712708 0.0644405 0.927668 0.254666 0.65382 0.850978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 815270 episodes
GETTING ACTION FROM:
action 2, numVisits=815264, meanQ=10.169149, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.128714 0.68019 0.635249 0.824113 0.712708 0.0644405 0.927668 0.254666 0.65382 0.850978 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 127
Initial state: 0 0.449906 0.873388 0.605582 0.821091 0.14109 0.282627 0.543467 0.876887 0.757574 0.661096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 822079 episodes
GETTING ACTION FROM:
action 1, numVisits=822005, meanQ=10.241694, numObservations: 4
action 5, numVisits=66, meanQ=7.782910, numObservations: 3
action 2, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.449906 0.873388 0.605582 0.821091 0.14109 0.282627 0.543467 0.876887 0.757574 0.661096 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=236274, meanQ=13.381565, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1093632 episodes
GETTING ACTION FROM:
action 2, numVisits=1329906, meanQ=11.687011, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.449906 0.873388 0.605582 0.821091 0.14109 0.282627 0.543467 0.876887 0.757574 0.661096 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 128
Initial state: 0 0.681364 0.868446 0.58636 0.885612 0.447424 0.100718 0.0619959 0.35353 0.871056 0.0357135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 814076 episodes
GETTING ACTION FROM:
action 1, numVisits=814070, meanQ=10.277814, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.681364 0.868446 0.58636 0.885612 0.447424 0.100718 0.0619959 0.35353 0.871056 0.0357135 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 129
Initial state: 0 0.783226 0.148123 0.279488 0.443923 0.665235 0.815231 0.477541 0.265607 0.512656 0.871693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 810187 episodes
GETTING ACTION FROM:
action 5, numVisits=810174, meanQ=10.235263, numObservations: 5
action 1, numVisits=8, meanQ=7.498750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.783226 0.148123 0.279488 0.443923 0.665235 0.815231 0.477541 0.265607 0.512656 0.871693 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=55669, meanQ=9.907429, numObservations: 5
action 3, numVisits=13, meanQ=4.000008, numObservations: 3
action 4, numVisits=11, meanQ=3.725464, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1095045 episodes
GETTING ACTION FROM:
action 1, numVisits=1150714, meanQ=12.023772, numObservations: 5
action 3, numVisits=13, meanQ=4.000008, numObservations: 3
action 4, numVisits=11, meanQ=3.725464, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.783226 0.148123 0.279488 0.443923 0.665235 0.815231 0.477541 0.265607 0.512656 0.871693 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 130
Initial state: 0 0.528081 0.814316 0.734855 0.218161 0.285022 0.10417 0.581704 0.883639 0.270311 0.739535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 791629 episodes
GETTING ACTION FROM:
action 1, numVisits=791621, meanQ=10.444873, numObservations: 5
action 3, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.528081 0.814316 0.734855 0.218161 0.285022 0.10417 0.581704 0.883639 0.270311 0.739535 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=55174, meanQ=13.123179, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 899550 episodes
GETTING ACTION FROM:
action 1, numVisits=396184, meanQ=10.171184, numObservations: 5
action 0, numVisits=558541, meanQ=4.255718, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.528081 0.814316 0.734855 0.218161 0.285022 0.10417 0.581704 0.883639 0.270311 0.739535 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 131
Initial state: 0 0.855108 0.117128 0.140124 0.452147 0.571752 0.825068 0.434168 0.345173 0.619287 0.814171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 822900 episodes
GETTING ACTION FROM:
action 2, numVisits=822875, meanQ=10.405147, numObservations: 4
action 1, numVisits=16, meanQ=7.063150, numObservations: 4
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.855108 0.117128 0.140124 0.452147 0.571752 0.825068 0.434168 0.345173 0.619287 0.814171 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=236741, meanQ=13.448621, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1090805 episodes
GETTING ACTION FROM:
action 3, numVisits=1327546, meanQ=12.491866, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.855108 0.117128 0.140124 0.452147 0.571752 0.825068 0.434168 0.345173 0.619287 0.814171 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 132
Initial state: 0 0.450178 0.31903 0.746833 0.662901 0.746882 0.500903 0.505526 0.897657 0.541069 0.83266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 814130 episodes
GETTING ACTION FROM:
action 3, numVisits=814094, meanQ=10.200611, numObservations: 5
action 5, numVisits=31, meanQ=6.395070, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.450178 0.31903 0.746833 0.662901 0.746882 0.500903 0.505526 0.897657 0.541069 0.83266 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 133
Initial state: 0 0.642046 0.864341 0.309794 0.525699 0.243217 0.129167 0.67422 0.805647 0.266208 0.0399939 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 821196 episodes
GETTING ACTION FROM:
action 4, numVisits=820942, meanQ=10.275889, numObservations: 4
action 5, numVisits=240, meanQ=9.606169, numObservations: 4
action 1, numVisits=10, meanQ=7.674000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.642046 0.864341 0.309794 0.525699 0.243217 0.129167 0.67422 0.805647 0.266208 0.0399939 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 134
Initial state: 0 0.83784 0.580279 0.651302 0.861551 0.93777 0.659917 0.59584 0.856069 0.829944 0.318788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 829768 episodes
GETTING ACTION FROM:
action 4, numVisits=829762, meanQ=10.243653, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.83784 0.580279 0.651302 0.861551 0.93777 0.659917 0.59584 0.856069 0.829944 0.318788 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 135
Initial state: 0 0.0243399 0.753919 0.180784 0.459584 0.582071 0.831508 0.403801 0.263161 0.647755 0.875375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820428 episodes
GETTING ACTION FROM:
action 2, numVisits=820409, meanQ=10.316295, numObservations: 3
action 3, numVisits=14, meanQ=4.214314, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0243399 0.753919 0.180784 0.459584 0.582071 0.831508 0.403801 0.263161 0.647755 0.875375 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=236416, meanQ=13.506865, numObservations: 5
action 1, numVisits=6, meanQ=8.831683, numObservations: 2
action 4, numVisits=5, meanQ=7.000020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1072431 episodes
GETTING ACTION FROM:
action 5, numVisits=1308847, meanQ=12.091926, numObservations: 5
action 1, numVisits=6, meanQ=8.831683, numObservations: 2
action 4, numVisits=5, meanQ=7.000020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.0243399 0.753919 0.180784 0.459584 0.582071 0.831508 0.403801 0.263161 0.647755 0.875375 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 136
Initial state: 0 0.529003 0.834566 0.674118 0.835585 0.490096 0.958809 0.29256 0.372184 0.800545 0.0950955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 809941 episodes
GETTING ACTION FROM:
action 2, numVisits=791625, meanQ=10.354152, numObservations: 4
action 4, numVisits=18309, meanQ=10.299679, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.529003 0.834566 0.674118 0.835585 0.490096 0.958809 0.29256 0.372184 0.800545 0.0950955 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 137
Initial state: 0 0.856343 0.511418 0.707054 0.886426 0.0144995 0.243529 0.571552 0.856235 0.588349 0.895177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 819187 episodes
GETTING ACTION FROM:
action 3, numVisits=819179, meanQ=10.247270, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.856343 0.511418 0.707054 0.886426 0.0144995 0.243529 0.571552 0.856235 0.588349 0.895177 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 138
Initial state: 0 0.650234 0.845068 0.652622 0.883598 0.4922 0.273 0.137919 0.337504 0.758181 0.58122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 810238 episodes
GETTING ACTION FROM:
action 5, numVisits=810221, meanQ=10.292302, numObservations: 5
action 1, numVisits=10, meanQ=5.798020, numObservations: 2
action 2, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.650234 0.845068 0.652622 0.883598 0.4922 0.273 0.137919 0.337504 0.758181 0.58122 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 139
Initial state: 0 0.599209 0.808712 0.637766 0.822267 0.938155 0.0282462 0.845127 0.915486 0.336408 0.631575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 829895 episodes
GETTING ACTION FROM:
action 5, numVisits=829889, meanQ=10.447360, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.599209 0.808712 0.637766 0.822267 0.938155 0.0282462 0.845127 0.915486 0.336408 0.631575 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=238965, meanQ=13.460173, numObservations: 5
action 4, numVisits=6, meanQ=10.163350, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1096485 episodes
GETTING ACTION FROM:
action 2, numVisits=1334560, meanQ=12.211665, numObservations: 5
action 4, numVisits=896, meanQ=11.965606, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.599209 0.808712 0.637766 0.822267 0.938155 0.0282462 0.845127 0.915486 0.336408 0.631575 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 140
Initial state: 0 0.573654 0.80267 0.595676 0.399611 0.512663 0.865261 0.929152 0.391685 0.118203 0.17523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820733 episodes
GETTING ACTION FROM:
action 2, numVisits=820727, meanQ=10.423824, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.573654 0.80267 0.595676 0.399611 0.512663 0.865261 0.929152 0.391685 0.118203 0.17523 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 141
Initial state: 0 0.57504 0.889458 0.669832 0.89222 0.31007 0.512543 0.681801 0.388664 0.205987 0.749305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812950 episodes
GETTING ACTION FROM:
action 4, numVisits=812937, meanQ=10.444025, numObservations: 5
action 3, numVisits=8, meanQ=0.718763, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.57504 0.889458 0.669832 0.89222 0.31007 0.512543 0.681801 0.388664 0.205987 0.749305 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 142
Initial state: 0 0.682636 0.869031 0.532907 0.863248 0.489156 0.248465 0.47419 0.739895 0.228627 0.248369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 567949 episodes
GETTING ACTION FROM:
action -1, numVisits=567942, meanQ=8.525499, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.682636 0.869031 0.532907 0.863248 0.489156 0.248465 0.47419 0.739895 0.228627 0.248369 w: 1
Observation: 0 0.586487 0 0.475698 0 0.426067 0 0.471772 0 0.144159 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=290115, meanQ=11.660768, numObservations: 5
action 4, numVisits=3, meanQ=2.033333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 894400 episodes
GETTING ACTION FROM:
action 2, numVisits=1184515, meanQ=11.228147, numObservations: 5
action 4, numVisits=3, meanQ=2.033333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.682636 0.869031 0.532907 0.863248 0.489156 0.248465 0.47419 0.739895 0.228627 0.248369 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=119916, meanQ=13.176766, numObservations: 4
action 3, numVisits=13, meanQ=6.393085, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1089163 episodes
GETTING ACTION FROM:
action 4, numVisits=1209079, meanQ=11.767530, numObservations: 4
action 3, numVisits=13, meanQ=6.393085, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.682636 0.869031 0.532907 0.863248 0.489156 0.248465 0.47419 0.739895 0.228627 0.248369 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=94023, meanQ=18.407334, numObservations: 5
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1192968 episodes
GETTING ACTION FROM:
action 1, numVisits=1286991, meanQ=13.029401, numObservations: 5
action 5, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.682636 0.869031 0.532907 0.863248 0.489156 0.248465 0.47419 0.739895 0.228627 0.248369 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 13.4068
Run # 143
Initial state: 0 0.88946 0.561915 0.695933 0.859281 0.620323 0.839329 0.208599 0.472871 0.867621 0.502406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 812240 episodes
GETTING ACTION FROM:
action 4, numVisits=812234, meanQ=10.269948, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.88946 0.561915 0.695933 0.859281 0.620323 0.839329 0.208599 0.472871 0.867621 0.502406 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=202343, meanQ=13.409993, numObservations: 5
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1101395 episodes
GETTING ACTION FROM:
action 5, numVisits=1303736, meanQ=11.575570, numObservations: 5
action 1, numVisits=5, meanQ=6.196000, numObservations: 2
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.88946 0.561915 0.695933 0.859281 0.620323 0.839329 0.208599 0.472871 0.867621 0.502406 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 144
Initial state: 0 0.471596 0.252436 0.685596 0.836067 0.687028 0.864904 0.167422 0.903864 0.984077 0.55021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820595 episodes
GETTING ACTION FROM:
action 4, numVisits=820580, meanQ=10.352661, numObservations: 4
action 5, numVisits=7, meanQ=2.140014, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=4, meanQ=-1.225000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.471596 0.252436 0.685596 0.836067 0.687028 0.864904 0.167422 0.903864 0.984077 0.55021 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=56845, meanQ=10.296428, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1091008 episodes
GETTING ACTION FROM:
action 2, numVisits=1147853, meanQ=12.044835, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.471596 0.252436 0.685596 0.836067 0.687028 0.864904 0.167422 0.903864 0.984077 0.55021 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 145
Initial state: 0 0.0386453 0.662408 0.423573 0.471923 0.64374 0.824103 0.642957 0.862173 0.179399 0.0022207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 822455 episodes
GETTING ACTION FROM:
action 2, numVisits=822436, meanQ=10.380680, numObservations: 4
action 3, numVisits=14, meanQ=3.502171, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0386453 0.662408 0.423573 0.471923 0.64374 0.824103 0.642957 0.862173 0.179399 0.0022207 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=203568, meanQ=13.348152, numObservations: 5
action 5, numVisits=4, meanQ=8.497500, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1097778 episodes
GETTING ACTION FROM:
action 3, numVisits=1301346, meanQ=12.367207, numObservations: 5
action 5, numVisits=4, meanQ=8.497500, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0386453 0.662408 0.423573 0.471923 0.64374 0.824103 0.642957 0.862173 0.179399 0.0022207 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 146
Initial state: 0 0.643543 0.827525 0.703948 0.638436 0.315053 0.996463 0.571623 0.887284 0.165377 0.795339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 811512 episodes
GETTING ACTION FROM:
action 1, numVisits=811506, meanQ=10.311453, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.643543 0.827525 0.703948 0.638436 0.315053 0.996463 0.571623 0.887284 0.165377 0.795339 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 147
Initial state: 0 0.697658 0.877134 0.453162 0.388161 0.80134 0.422566 0.454212 0.148641 0.697563 0.887627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 808350 episodes
GETTING ACTION FROM:
action 1, numVisits=808344, meanQ=10.250178, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.697658 0.877134 0.453162 0.388161 0.80134 0.422566 0.454212 0.148641 0.697563 0.887627 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 148
Initial state: 0 0.355986 0.140113 0.169205 0.59976 0.664013 0.867227 0.565611 0.820891 0.548851 0.501983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 806208 episodes
GETTING ACTION FROM:
action 5, numVisits=806181, meanQ=10.243585, numObservations: 5
action 3, numVisits=11, meanQ=6.727282, numObservations: 3
action 4, numVisits=5, meanQ=5.402020, numObservations: 3
action 1, numVisits=8, meanQ=4.872513, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.355986 0.140113 0.169205 0.59976 0.664013 0.867227 0.565611 0.820891 0.548851 0.501983 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 149
Initial state: 0 0.332545 0.912925 0.549123 0.838527 0.826395 0.12937 0.589887 0.858433 0.82799 0.0215871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 578330 episodes
GETTING ACTION FROM:
action -1, numVisits=578324, meanQ=8.321367, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.332545 0.912925 0.549123 0.838527 0.826395 0.12937 0.589887 0.858433 0.82799 0.0215871 w: 1
Observation: 0 0.34364 0 0.579447 0 0.854138 0 0.530538 0 0.808357 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=129995, meanQ=10.229122, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 896722 episodes
GETTING ACTION FROM:
action 3, numVisits=1026717, meanQ=10.617240, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.332545 0.912925 0.549123 0.838527 0.826395 0.12937 0.589887 0.858433 0.82799 0.0215871 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 150
Initial state: 0 0.878619 0.790131 0.506985 0.80869 0.290483 0.797452 0.589622 0.872821 0.894711 0.38298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820977 episodes
GETTING ACTION FROM:
action 2, numVisits=820971, meanQ=10.202685, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.878619 0.790131 0.506985 0.80869 0.290483 0.797452 0.589622 0.872821 0.894711 0.38298 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 151
Initial state: 0 0.679402 0.836215 0.106702 0.996873 0.1195 0.436947 0.866808 0.684252 0.638473 0.883626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 819421 episodes
GETTING ACTION FROM:
action 3, numVisits=819415, meanQ=10.435575, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.679402 0.836215 0.106702 0.996873 0.1195 0.436947 0.866808 0.684252 0.638473 0.883626 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=202833, meanQ=13.877741, numObservations: 4
action 2, numVisits=5, meanQ=6.196000, numObservations: 2
action 4, numVisits=5, meanQ=4.598000, numObservations: 2
action 1, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1091719 episodes
GETTING ACTION FROM:
action 5, numVisits=1294552, meanQ=12.502341, numObservations: 4
action 2, numVisits=5, meanQ=6.196000, numObservations: 2
action 4, numVisits=5, meanQ=4.598000, numObservations: 2
action 1, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.679402 0.836215 0.106702 0.996873 0.1195 0.436947 0.866808 0.684252 0.638473 0.883626 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 152
Initial state: 0 0.172326 0.94924 0.695222 0.826289 0.750672 0.714728 0.727573 0.906531 0.512666 0.850479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 815640 episodes
GETTING ACTION FROM:
action 2, numVisits=815634, meanQ=10.205915, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.172326 0.94924 0.695222 0.826289 0.750672 0.714728 0.727573 0.906531 0.512666 0.850479 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 153
Initial state: 0 0.990577 0.853436 0.673414 0.805558 0.511736 0.632998 0.360935 0.453352 0.564164 0.828735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 818340 episodes
GETTING ACTION FROM:
action 3, numVisits=818334, meanQ=10.379304, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.990577 0.853436 0.673414 0.805558 0.511736 0.632998 0.360935 0.453352 0.564164 0.828735 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 154
Initial state: 0 0.0524599 0.160374 0.281435 0.404678 0.558652 0.800384 0.700632 0.00921534 0.576774 0.845318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 577109 episodes
GETTING ACTION FROM:
action 0, numVisits=577102, meanQ=12.016326, numObservations: 7
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0524599 0.160374 0.281435 0.404678 0.558652 0.800384 0.700632 0.00921534 0.576774 0.845318 w: 1
Observation: 0 0 0.180326 0 0.316135 0 0.859734 0 0.0106443 0 0.820711 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=65154, meanQ=19.344963, numObservations: 5
action 5, numVisits=5, meanQ=11.598000, numObservations: 3
action 4, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 867535 episodes
GETTING ACTION FROM:
action 3, numVisits=932617, meanQ=11.666569, numObservations: 5
action 5, numVisits=75, meanQ=10.740798, numObservations: 4
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0524599 0.160374 0.281435 0.404678 0.558652 0.800384 0.700632 0.00921534 0.576774 0.845318 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 155
Initial state: 0 0.0392598 0.0878736 0.67662 0.838654 0.375398 0.746785 0.232674 0.26269 0.607329 0.884714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 817852 episodes
GETTING ACTION FROM:
action 5, numVisits=817096, meanQ=10.416773, numObservations: 4
action 1, numVisits=736, meanQ=10.128916, numObservations: 4
action 4, numVisits=12, meanQ=8.166675, numObservations: 4
action 3, numVisits=5, meanQ=7.000020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.0392598 0.0878736 0.67662 0.838654 0.375398 0.746785 0.232674 0.26269 0.607329 0.884714 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 156
Initial state: 0 0.604552 0.874721 0.99185 0.628324 0.249319 0.609807 0.613305 0.815924 0.341223 0.52734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 817841 episodes
GETTING ACTION FROM:
action 5, numVisits=817830, meanQ=10.374298, numObservations: 5
action 2, numVisits=4, meanQ=1.745000, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.604552 0.874721 0.99185 0.628324 0.249319 0.609807 0.613305 0.815924 0.341223 0.52734 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=33334, meanQ=13.386933, numObservations: 5
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1091412 episodes
GETTING ACTION FROM:
action 3, numVisits=1124746, meanQ=11.546679, numObservations: 5
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.604552 0.874721 0.99185 0.628324 0.249319 0.609807 0.613305 0.815924 0.341223 0.52734 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=37344, meanQ=16.383706, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1191976 episodes
GETTING ACTION FROM:
action 4, numVisits=1229318, meanQ=11.893594, numObservations: 5
action 2, numVisits=6, meanQ=7.831667, numObservations: 3
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.604552 0.874721 0.99185 0.628324 0.249319 0.609807 0.613305 0.815924 0.341223 0.52734 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 157
Initial state: 0 0.371798 0.779544 0.5826 0.804576 0.501941 0.886739 0.769643 0.680615 0.808384 0.672467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 805153 episodes
GETTING ACTION FROM:
action 3, numVisits=804552, meanQ=10.531400, numObservations: 5
action 1, numVisits=596, meanQ=10.221756, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.371798 0.779544 0.5826 0.804576 0.501941 0.886739 0.769643 0.680615 0.808384 0.672467 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 158
Initial state: 0 0.694154 0.893346 0.666006 0.831629 0.720894 0.674402 0.0910535 0.681863 0.604806 0.46907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 798975 episodes
GETTING ACTION FROM:
action 5, numVisits=798956, meanQ=10.182154, numObservations: 4
action 4, numVisits=8, meanQ=7.498750, numObservations: 2
action 1, numVisits=7, meanQ=6.857157, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.694154 0.893346 0.666006 0.831629 0.720894 0.674402 0.0910535 0.681863 0.604806 0.46907 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 159
Initial state: 0 0.624346 0.892115 0.129657 0.750221 0.034506 0.728926 0.650909 0.837264 0.80205 0.548244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 807521 episodes
GETTING ACTION FROM:
action 5, numVisits=807513, meanQ=10.316393, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.624346 0.892115 0.129657 0.750221 0.034506 0.728926 0.650909 0.837264 0.80205 0.548244 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 160
Initial state: 0 0.666218 0.370397 0.670611 0.850613 0.549777 0.85621 0.878699 0.605076 0.056556 0.540658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 541805 episodes
GETTING ACTION FROM:
action -1, numVisits=541799, meanQ=8.441624, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.666218 0.370397 0.670611 0.850613 0.549777 0.85621 0.878699 0.605076 0.056556 0.540658 w: 1
Observation: 0 0.648241 0 0.713939 0 0.598357 0 0.942522 0 0 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=190859, meanQ=10.986036, numObservations: 3
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action 1, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 904138 episodes
GETTING ACTION FROM:
action 2, numVisits=1094997, meanQ=10.912290, numObservations: 3
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action 1, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.666218 0.370397 0.670611 0.850613 0.549777 0.85621 0.878699 0.605076 0.056556 0.540658 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 161
Initial state: 0 0.546513 0.846093 0.379257 0.265831 0.366386 0.862031 0.65746 0.835835 0.911396 0.35298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 815925 episodes
GETTING ACTION FROM:
action 1, numVisits=815912, meanQ=10.342267, numObservations: 5
action 2, numVisits=8, meanQ=0.746250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.546513 0.846093 0.379257 0.265831 0.366386 0.862031 0.65746 0.835835 0.911396 0.35298 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 162
Initial state: 0 0.674505 0.809109 0.510355 0.215437 0.516563 0.821642 0.13986 0.720386 0.671085 0.252593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 801091 episodes
GETTING ACTION FROM:
action 4, numVisits=801085, meanQ=10.218092, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.674505 0.809109 0.510355 0.215437 0.516563 0.821642 0.13986 0.720386 0.671085 0.252593 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=199763, meanQ=13.423983, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1097031 episodes
GETTING ACTION FROM:
action 1, numVisits=1296794, meanQ=11.916173, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.674505 0.809109 0.510355 0.215437 0.516563 0.821642 0.13986 0.720386 0.671085 0.252593 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 163
Initial state: 0 0.64521 0.863452 0.226397 0.911555 0.581872 0.883487 0.967009 0.328811 0.201232 0.570684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 819049 episodes
GETTING ACTION FROM:
action 1, numVisits=819037, meanQ=10.280272, numObservations: 4
action 3, numVisits=5, meanQ=5.348000, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.64521 0.863452 0.226397 0.911555 0.581872 0.883487 0.967009 0.328811 0.201232 0.570684 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 164
Initial state: 0 0.664206 0.810137 0.346513 0.380829 0.0917441 0.0642784 0.35199 0.594231 0.649174 0.899396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 574326 episodes
GETTING ACTION FROM:
action 0, numVisits=574319, meanQ=9.552137, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.664206 0.810137 0.346513 0.380829 0.0917441 0.0642784 0.35199 0.594231 0.649174 0.899396 w: 1
Observation: 0 0 0.711718 0 0.315813 0 0.142272 0 0.582473 0 0.960477 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=38337, meanQ=21.509686, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 894402 episodes
GETTING ACTION FROM:
action 1, numVisits=932739, meanQ=10.774368, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.664206 0.810137 0.346513 0.380829 0.0917441 0.0642784 0.35199 0.594231 0.649174 0.899396 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 165
Initial state: 0 0.812456 0.518068 0.631645 0.0047002 0.635173 0.843935 0.66547 0.870595 0.997968 0.979575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 819507 episodes
GETTING ACTION FROM:
action 5, numVisits=819493, meanQ=10.381987, numObservations: 4
action 1, numVisits=9, meanQ=7.414456, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.812456 0.518068 0.631645 0.0047002 0.635173 0.843935 0.66547 0.870595 0.997968 0.979575 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 166
Initial state: 0 0.664984 0.880019 0.562083 0.826114 0.547734 0.660806 0.168254 0.317427 0.43101 0.349993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 747099 episodes
GETTING ACTION FROM:
action 5, numVisits=747091, meanQ=10.366924, numObservations: 5
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.664984 0.880019 0.562083 0.826114 0.547734 0.660806 0.168254 0.317427 0.43101 0.349993 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=154041, meanQ=11.609891, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 923386 episodes
GETTING ACTION FROM:
action 2, numVisits=123618, meanQ=12.601226, numObservations: 5
action -1, numVisits=953810, meanQ=4.403513, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.664984 0.880019 0.562083 0.826114 0.547734 0.660806 0.168254 0.317427 0.43101 0.349993 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 167
Initial state: 0 0.601772 0.87758 0.628776 0.876047 0.347463 0.714913 0.90718 0.967416 0.783691 0.936042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 807923 episodes
GETTING ACTION FROM:
action 4, numVisits=807904, meanQ=10.136861, numObservations: 5
action 1, numVisits=14, meanQ=6.465000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.601772 0.87758 0.628776 0.876047 0.347463 0.714913 0.90718 0.967416 0.783691 0.936042 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 168
Initial state: 0 0.661932 0.871141 0.0221465 0.447915 0.551517 0.400029 0.549614 0.945885 0.662624 0.889069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 825409 episodes
GETTING ACTION FROM:
action 1, numVisits=825398, meanQ=10.268760, numObservations: 4
action 3, numVisits=6, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.661932 0.871141 0.0221465 0.447915 0.551517 0.400029 0.549614 0.945885 0.662624 0.889069 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 169
Initial state: 0 0.142859 0.625242 0.999298 0.00940266 0.530761 0.875039 0.875031 0.561757 0.673786 0.863339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 794648 episodes
GETTING ACTION FROM:
action 2, numVisits=794632, meanQ=10.113277, numObservations: 5
action 4, numVisits=11, meanQ=7.088182, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.142859 0.625242 0.999298 0.00940266 0.530761 0.875039 0.875031 0.561757 0.673786 0.863339 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 170
Initial state: 0 0.985599 0.346787 0.554533 0.8212 0.612103 0.214799 0.810082 0.644638 0.665927 0.899777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 825413 episodes
GETTING ACTION FROM:
action 3, numVisits=824300, meanQ=10.397710, numObservations: 3
action 2, numVisits=1100, meanQ=10.165539, numObservations: 4
action 5, numVisits=9, meanQ=7.885567, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.985599 0.346787 0.554533 0.8212 0.612103 0.214799 0.810082 0.644638 0.665927 0.899777 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 171
Initial state: 0 0.222642 0.635589 0.530215 0.843646 0.842994 0.0291366 0.624108 0.858613 0.327688 0.422666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816653 episodes
GETTING ACTION FROM:
action 2, numVisits=816645, meanQ=10.710460, numObservations: 5
action 3, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.222642 0.635589 0.530215 0.843646 0.842994 0.0291366 0.624108 0.858613 0.327688 0.422666 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 172
Initial state: 0 0.0190946 0.923277 0.660628 0.864077 0.875034 0.662359 0.887239 0.898436 0.567377 0.85244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820410 episodes
GETTING ACTION FROM:
action 3, numVisits=820404, meanQ=10.266410, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.0190946 0.923277 0.660628 0.864077 0.875034 0.662359 0.887239 0.898436 0.567377 0.85244 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 173
Initial state: 0 0.600175 0.814286 0.746606 0.396621 0.148486 0.216019 0.147423 0.197255 0.648943 0.869726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 824227 episodes
GETTING ACTION FROM:
action 4, numVisits=824221, meanQ=10.294112, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.600175 0.814286 0.746606 0.396621 0.148486 0.216019 0.147423 0.197255 0.648943 0.869726 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=204399, meanQ=13.435074, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1091425 episodes
GETTING ACTION FROM:
action 5, numVisits=1295824, meanQ=12.097697, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.600175 0.814286 0.746606 0.396621 0.148486 0.216019 0.147423 0.197255 0.648943 0.869726 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 174
Initial state: 0 0.653476 0.890265 0.444391 0.345263 0.69162 0.82585 0.134829 0.629975 0.462843 0.615302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 806326 episodes
GETTING ACTION FROM:
action 3, numVisits=806315, meanQ=10.185401, numObservations: 5
action 1, numVisits=6, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.653476 0.890265 0.444391 0.345263 0.69162 0.82585 0.134829 0.629975 0.462843 0.615302 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 175
Initial state: 0 0.244691 0.0315675 0.979897 0.258869 0.818032 0.142205 0.698842 0.862008 0.564496 0.831352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 805101 episodes
GETTING ACTION FROM:
action 4, numVisits=805088, meanQ=10.261222, numObservations: 4
action 3, numVisits=6, meanQ=-1.171667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.244691 0.0315675 0.979897 0.258869 0.818032 0.142205 0.698842 0.862008 0.564496 0.831352 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 176
Initial state: 0 0.114503 0.444629 0.591408 0.861478 0.522104 0.859723 0.375179 0.413899 0.840723 0.908596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 836407 episodes
GETTING ACTION FROM:
action 4, numVisits=836401, meanQ=10.413296, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.114503 0.444629 0.591408 0.861478 0.522104 0.859723 0.375179 0.413899 0.840723 0.908596 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=241039, meanQ=13.391509, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1111032 episodes
GETTING ACTION FROM:
action 1, numVisits=1352070, meanQ=11.378503, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.114503 0.444629 0.591408 0.861478 0.522104 0.859723 0.375179 0.413899 0.840723 0.908596 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=181797, meanQ=15.959689, numObservations: 5
action 3, numVisits=217, meanQ=14.875463, numObservations: 5
action 2, numVisits=6, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1177150 episodes
GETTING ACTION FROM:
action 5, numVisits=1358662, meanQ=12.973519, numObservations: 5
action 3, numVisits=471, meanQ=12.623010, numObservations: 5
action 2, numVisits=37, meanQ=11.350814, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.114503 0.444629 0.591408 0.861478 0.522104 0.859723 0.375179 0.413899 0.840723 0.908596 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 177
Initial state: 0 0.498132 0.29867 0.712386 0.63022 0.118504 0.292474 0.660494 0.881228 0.5058 0.87554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 823329 episodes
GETTING ACTION FROM:
action 3, numVisits=823304, meanQ=10.408972, numObservations: 4
action 4, numVisits=14, meanQ=8.220729, numObservations: 3
action 2, numVisits=7, meanQ=6.290029, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.498132 0.29867 0.712386 0.63022 0.118504 0.292474 0.660494 0.881228 0.5058 0.87554 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=204426, meanQ=13.607904, numObservations: 4
action 5, numVisits=20, meanQ=4.398020, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1123298 episodes
GETTING ACTION FROM:
action 1, numVisits=1327724, meanQ=12.883739, numObservations: 4
action 5, numVisits=20, meanQ=4.398020, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.498132 0.29867 0.712386 0.63022 0.118504 0.292474 0.660494 0.881228 0.5058 0.87554 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=127281, meanQ=17.999473, numObservations: 4
action 5, numVisits=28, meanQ=14.785004, numObservations: 3
action 4, numVisits=12, meanQ=14.330833, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1217766 episodes
GETTING ACTION FROM:
action 2, numVisits=1345020, meanQ=13.174082, numObservations: 4
action 5, numVisits=35, meanQ=11.799434, numObservations: 3
action 4, numVisits=32, meanQ=11.359063, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.498132 0.29867 0.712386 0.63022 0.118504 0.292474 0.660494 0.881228 0.5058 0.87554 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=15032, meanQ=20.361810, numObservations: 4
action 5, numVisits=6, meanQ=14.996667, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1235197 episodes
GETTING ACTION FROM:
action 4, numVisits=1250143, meanQ=12.638045, numObservations: 4
action 2, numVisits=58, meanQ=11.465345, numObservations: 3
action 5, numVisits=36, meanQ=10.832778, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.498132 0.29867 0.712386 0.63022 0.118504 0.292474 0.660494 0.881228 0.5058 0.87554 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 178
Initial state: 0 0.521402 0.884005 0.528577 0.832914 0.593004 0.226509 0.590652 0.723592 0.746344 0.108247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 814970 episodes
GETTING ACTION FROM:
action 3, numVisits=814960, meanQ=10.422516, numObservations: 5
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.521402 0.884005 0.528577 0.832914 0.593004 0.226509 0.590652 0.723592 0.746344 0.108247 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 179
Initial state: 0 0.546773 0.869781 0.670959 0.259011 0.592114 0.806665 0.231148 0.0659454 0.526633 0.272667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 554952 episodes
GETTING ACTION FROM:
action 0, numVisits=554928, meanQ=13.305693, numObservations: 7
action 4, numVisits=18, meanQ=0.166678, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.546773 0.869781 0.670959 0.259011 0.592114 0.806665 0.231148 0.0659454 0.526633 0.272667 w: 1
Observation: 0 0 0.848622 0 0.350155 0 0.752402 0 0.0793794 0 0.341556 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=17231, meanQ=22.528383, numObservations: 3
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 907562 episodes
GETTING ACTION FROM:
action 1, numVisits=924782, meanQ=10.380100, numObservations: 3
action 3, numVisits=14, meanQ=8.212143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.546773 0.869781 0.670959 0.259011 0.592114 0.806665 0.231148 0.0659454 0.526633 0.272667 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 180
Initial state: 0 0.140088 0.763143 0.574621 0.885072 0.843429 0.534892 0.581273 0.891185 0.850175 0.133776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816804 episodes
GETTING ACTION FROM:
action 1, numVisits=816787, meanQ=10.319738, numObservations: 5
action 2, numVisits=10, meanQ=4.611010, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.140088 0.763143 0.574621 0.885072 0.843429 0.534892 0.581273 0.891185 0.850175 0.133776 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=202042, meanQ=13.774625, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1110395 episodes
GETTING ACTION FROM:
action 5, numVisits=1312437, meanQ=12.782745, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.140088 0.763143 0.574621 0.885072 0.843429 0.534892 0.581273 0.891185 0.850175 0.133776 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 181
Initial state: 0 0.614937 0.883338 0.0668138 0.515283 0.988054 0.219535 0.680393 0.80631 0.178757 0.430256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 807535 episodes
GETTING ACTION FROM:
action 3, numVisits=807525, meanQ=10.266782, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.614937 0.883338 0.0668138 0.515283 0.988054 0.219535 0.680393 0.80631 0.178757 0.430256 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 182
Initial state: 0 0.269881 0.461817 0.63918 0.831393 0.918125 0.231912 0.694126 0.877829 0.234967 0.774419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 820108 episodes
GETTING ACTION FROM:
action 2, numVisits=820102, meanQ=10.279410, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.269881 0.461817 0.63918 0.831393 0.918125 0.231912 0.694126 0.877829 0.234967 0.774419 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 183
Initial state: 0 0.340381 0.152726 0.56356 0.828708 0.90751 0.12348 0.654132 0.877999 0.924704 0.176762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 816006 episodes
GETTING ACTION FROM:
action 1, numVisits=815990, meanQ=10.238985, numObservations: 5
action 5, numVisits=4, meanQ=6.500000, numObservations: 2
action 2, numVisits=5, meanQ=4.598000, numObservations: 3
action 4, numVisits=4, meanQ=1.745000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.340381 0.152726 0.56356 0.828708 0.90751 0.12348 0.654132 0.877999 0.924704 0.176762 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=202288, meanQ=13.406049, numObservations: 5
action 5, numVisits=98, meanQ=11.426752, numObservations: 5
action 4, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1096649 episodes
GETTING ACTION FROM:
action 3, numVisits=1298937, meanQ=12.489542, numObservations: 5
action 5, numVisits=98, meanQ=11.426752, numObservations: 5
action 4, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.340381 0.152726 0.56356 0.828708 0.90751 0.12348 0.654132 0.877999 0.924704 0.176762 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 184
Initial state: 0 0.0550632 0.238339 0.418326 0.114814 0.612085 0.819221 0.573818 0.144233 0.696877 0.85219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 833517 episodes
GETTING ACTION FROM:
action 1, numVisits=833511, meanQ=10.211525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0550632 0.238339 0.418326 0.114814 0.612085 0.819221 0.573818 0.144233 0.696877 0.85219 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=241029, meanQ=13.399158, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1108197 episodes
GETTING ACTION FROM:
action 2, numVisits=1349226, meanQ=12.564607, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0550632 0.238339 0.418326 0.114814 0.612085 0.819221 0.573818 0.144233 0.696877 0.85219 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=168126, meanQ=17.153213, numObservations: 3
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action 5, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1208272 episodes
GETTING ACTION FROM:
action 4, numVisits=1376392, meanQ=13.150668, numObservations: 3
action 3, numVisits=9, meanQ=10.220000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.0550632 0.238339 0.418326 0.114814 0.612085 0.819221 0.573818 0.144233 0.696877 0.85219 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 185
Initial state: 0 0.77136 0.162899 0.839847 0.231761 0.502583 0.864418 0.1243 0.223964 0.645508 0.812027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 821142 episodes
GETTING ACTION FROM:
action 5, numVisits=821131, meanQ=10.296300, numObservations: 4
action 2, numVisits=6, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.77136 0.162899 0.839847 0.231761 0.502583 0.864418 0.1243 0.223964 0.645508 0.812027 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 186
Initial state: 0 0.53563 0.809451 0.58449 0.243066 0.977258 0.285821 0.638613 0.842498 0.0797398 0.105129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 790663 episodes
GETTING ACTION FROM:
action 4, numVisits=790655, meanQ=10.464894, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.53563 0.809451 0.58449 0.243066 0.977258 0.285821 0.638613 0.842498 0.0797398 0.105129 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 187
Initial state: 0 0.240502 0.151447 0.538256 0.861748 0.611485 0.81619 0.37622 0.58972 0.788165 0.388046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 810254 episodes
GETTING ACTION FROM:
action 5, numVisits=810244, meanQ=10.737200, numObservations: 5
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.240502 0.151447 0.538256 0.861748 0.611485 0.81619 0.37622 0.58972 0.788165 0.388046 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 188
Initial state: 0 0.407112 0.0630443 0.656441 0.887023 0.193479 0.283014 0.561292 0.861376 0.313921 0.293744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 788350 episodes
GETTING ACTION FROM:
action 4, numVisits=788335, meanQ=10.240358, numObservations: 4
action 3, numVisits=8, meanQ=3.123750, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.407112 0.0630443 0.656441 0.887023 0.193479 0.283014 0.561292 0.861376 0.313921 0.293744 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 189
Initial state: 0 0.590238 0.892032 0.260142 0.389749 0.550821 0.806627 0.825235 0.118598 0.359285 0.395015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 727568 episodes
GETTING ACTION FROM:
action 4, numVisits=727562, meanQ=10.694465, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.590238 0.892032 0.260142 0.389749 0.550821 0.806627 0.825235 0.118598 0.359285 0.395015 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=50357, meanQ=10.299437, numObservations: 4
action 3, numVisits=6, meanQ=2.998350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1070827 episodes
GETTING ACTION FROM:
action 5, numVisits=1121184, meanQ=11.395769, numObservations: 4
action 3, numVisits=6, meanQ=2.998350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.590238 0.892032 0.260142 0.389749 0.550821 0.806627 0.825235 0.118598 0.359285 0.395015 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=93143, meanQ=10.869401, numObservations: 4
action 1, numVisits=5, meanQ=6.196000, numObservations: 3
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1138924 episodes
GETTING ACTION FROM:
action 4, numVisits=1232067, meanQ=11.241628, numObservations: 4
action 1, numVisits=5, meanQ=6.196000, numObservations: 3
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.590238 0.892032 0.260142 0.389749 0.550821 0.806627 0.825235 0.118598 0.359285 0.395015 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 190
Initial state: 0 0.65829 0.420994 0.0902821 0.989341 0.651769 0.86858 0.659188 0.800897 0.228095 0.922518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 759483 episodes
GETTING ACTION FROM:
action 5, numVisits=759471, meanQ=10.925024, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=4, meanQ=-1.225000, numObservations: 2
action 1, numVisits=4, meanQ=-1.225000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.65829 0.420994 0.0902821 0.989341 0.651769 0.86858 0.659188 0.800897 0.228095 0.922518 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=41522, meanQ=17.945803, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 980120 episodes
GETTING ACTION FROM:
action 5, numVisits=1021642, meanQ=10.030610, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.65829 0.420994 0.0902821 0.989341 0.651769 0.86858 0.659188 0.800897 0.228095 0.922518 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 191
Initial state: 0 0.55033 0.863134 0.0530903 0.333823 0.021777 0.278192 0.875084 0.433886 0.655805 0.804426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 809646 episodes
GETTING ACTION FROM:
action 1, numVisits=809640, meanQ=10.306199, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.55033 0.863134 0.0530903 0.333823 0.021777 0.278192 0.875084 0.433886 0.655805 0.804426 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 192
Initial state: 0 0.692283 0.86227 0.108804 0.652657 0.0163696 0.763371 0.158442 0.702826 0.505462 0.819292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 825373 episodes
GETTING ACTION FROM:
action 1, numVisits=825367, meanQ=10.247006, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.692283 0.86227 0.108804 0.652657 0.0163696 0.763371 0.158442 0.702826 0.505462 0.819292 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 193
Initial state: 0 0.128608 0.857829 0.613215 0.832694 0.896698 0.856502 0.129689 0.781876 0.636164 0.835473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 827348 episodes
GETTING ACTION FROM:
action 5, numVisits=827326, meanQ=10.420340, numObservations: 4
action 4, numVisits=17, meanQ=8.572947, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.128608 0.857829 0.613215 0.832694 0.896698 0.856502 0.129689 0.781876 0.636164 0.835473 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=238362, meanQ=13.541903, numObservations: 4
action 4, numVisits=15, meanQ=7.334687, numObservations: 4
action 2, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1110360 episodes
GETTING ACTION FROM:
action 1, numVisits=1348722, meanQ=11.838322, numObservations: 4
action 4, numVisits=15, meanQ=7.334687, numObservations: 4
action 2, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.128608 0.857829 0.613215 0.832694 0.896698 0.856502 0.129689 0.781876 0.636164 0.835473 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=21013, meanQ=16.902154, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1196021 episodes
GETTING ACTION FROM:
action 4, numVisits=1217034, meanQ=13.063275, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.128608 0.857829 0.613215 0.832694 0.896698 0.856502 0.129689 0.781876 0.636164 0.835473 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=24004, meanQ=18.974898, numObservations: 5
action 3, numVisits=4652, meanQ=18.442888, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1236850 episodes
GETTING ACTION FROM:
action 2, numVisits=1137900, meanQ=12.222288, numObservations: 5
action 3, numVisits=127606, meanQ=12.209020, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.128608 0.857829 0.613215 0.832694 0.896698 0.856502 0.129689 0.781876 0.636164 0.835473 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 194
Initial state: 0 0.659076 0.851066 0.726439 0.162419 0.851472 0.581314 0.687181 0.866499 0.393593 0.410914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 832748 episodes
GETTING ACTION FROM:
action 2, numVisits=832737, meanQ=10.259847, numObservations: 3
action 3, numVisits=6, meanQ=1.998333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.659076 0.851066 0.726439 0.162419 0.851472 0.581314 0.687181 0.866499 0.393593 0.410914 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=56933, meanQ=10.107238, numObservations: 4
action 2, numVisits=39, meanQ=8.772056, numObservations: 4
action 4, numVisits=8, meanQ=7.498750, numObservations: 3
action 3, numVisits=7, meanQ=6.572886, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1105308 episodes
GETTING ACTION FROM:
action 1, numVisits=1162241, meanQ=11.086092, numObservations: 4
action 2, numVisits=39, meanQ=8.772056, numObservations: 4
action 4, numVisits=8, meanQ=7.498750, numObservations: 3
action 3, numVisits=7, meanQ=6.572886, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.659076 0.851066 0.726439 0.162419 0.851472 0.581314 0.687181 0.866499 0.393593 0.410914 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 195
Initial state: 0 0.533458 0.819233 0.597869 0.825421 0.0341698 0.954362 0.423728 0.915402 0.872685 0.976488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879965 episodes
GETTING ACTION FROM:
action 3, numVisits=879957, meanQ=10.302360, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.533458 0.819233 0.597869 0.825421 0.0341698 0.954362 0.423728 0.915402 0.872685 0.976488 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=60832, meanQ=10.526556, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1152503 episodes
GETTING ACTION FROM:
action 1, numVisits=1213335, meanQ=11.556987, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.533458 0.819233 0.597869 0.825421 0.0341698 0.954362 0.423728 0.915402 0.872685 0.976488 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 196
Initial state: 0 0.541276 0.817164 0.618497 0.818671 0.256984 0.601019 0.432475 0.996102 0.703989 0.641697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 861549 episodes
GETTING ACTION FROM:
action 5, numVisits=861543, meanQ=10.422971, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.541276 0.817164 0.618497 0.818671 0.256984 0.601019 0.432475 0.996102 0.703989 0.641697 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 197
Initial state: 0 0.793767 0.11645 0.651836 0.8753 0.572086 0.884373 0.201751 0.856752 0.25205 0.993269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 852253 episodes
GETTING ACTION FROM:
action 5, numVisits=852240, meanQ=10.471747, numObservations: 5
action 3, numVisits=6, meanQ=4.000017, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.793767 0.11645 0.651836 0.8753 0.572086 0.884373 0.201751 0.856752 0.25205 0.993269 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=59036, meanQ=13.683706, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 988593 episodes
GETTING ACTION FROM:
action 0, numVisits=1047629, meanQ=4.760517, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.793767 0.11645 0.651836 0.8753 0.572086 0.884373 0.201751 0.856752 0.25205 0.993269 w: 1
Observation: 0 0 0.0634529 0 0.877637 0 0.890928 0 0.910093 0 1 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=104114, meanQ=18.451613, numObservations: 4
action 1, numVisits=6, meanQ=9.163333, numObservations: 2
action 2, numVisits=8, meanQ=8.751275, numObservations: 3
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1153246 episodes
GETTING ACTION FROM:
action 4, numVisits=1257359, meanQ=12.123863, numObservations: 4
action 2, numVisits=8, meanQ=8.751275, numObservations: 3
action 1, numVisits=7, meanQ=6.282857, numObservations: 2
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.793767 0.11645 0.651836 0.8753 0.572086 0.884373 0.201751 0.856752 0.25205 0.993269 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 5, numVisits=17226, meanQ=11.173618, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=4, meanQ=-1.225000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1202330 episodes
GETTING ACTION FROM:
action 5, numVisits=1219556, meanQ=11.650410, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=4, meanQ=-1.225000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.793767 0.11645 0.651836 0.8753 0.572086 0.884373 0.201751 0.856752 0.25205 0.993269 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action -1, numVisits=6379, meanQ=17.693251, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1334998 episodes
GETTING ACTION FROM:
action 1, numVisits=1311072, meanQ=12.921630, numObservations: 4
action -1, numVisits=30306, meanQ=3.377785, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.793767 0.11645 0.651836 0.8753 0.572086 0.884373 0.201751 0.856752 0.25205 0.993269 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -24.3482
Run # 198
Initial state: 0 0.504413 0.861247 0.577559 0.876035 0.395043 0.653161 0.39127 0.556081 0.0018835 0.729761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877210 episodes
GETTING ACTION FROM:
action 4, numVisits=877198, meanQ=10.721098, numObservations: 5
action 3, numVisits=5, meanQ=5.798020, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.504413 0.861247 0.577559 0.876035 0.395043 0.653161 0.39127 0.556081 0.0018835 0.729761 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=181039, meanQ=13.618201, numObservations: 4
action 5, numVisits=7, meanQ=6.855743, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1193060 episodes
GETTING ACTION FROM:
action 3, numVisits=1374099, meanQ=12.057239, numObservations: 4
action 5, numVisits=7, meanQ=6.855743, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.504413 0.861247 0.577559 0.876035 0.395043 0.653161 0.39127 0.556081 0.0018835 0.729761 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=143443, meanQ=15.575918, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1335670 episodes
GETTING ACTION FROM:
action 2, numVisits=1479113, meanQ=11.956392, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.504413 0.861247 0.577559 0.876035 0.395043 0.653161 0.39127 0.556081 0.0018835 0.729761 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 199
Initial state: 0 0.459967 0.729769 0.542415 0.866241 0.00143168 0.738156 0.615223 0.877901 0.985418 0.119738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 795101 episodes
GETTING ACTION FROM:
action 4, numVisits=795095, meanQ=10.807603, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.459967 0.729769 0.542415 0.866241 0.00143168 0.738156 0.615223 0.877901 0.985418 0.119738 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 200
Initial state: 0 0.630724 0.854787 0.265682 0.458773 0.294733 0.161138 0.945587 0.743939 0.581382 0.819646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 620637 episodes
GETTING ACTION FROM:
action -1, numVisits=620631, meanQ=8.094812, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.630724 0.854787 0.265682 0.458773 0.294733 0.161138 0.945587 0.743939 0.581382 0.819646 w: 1
Observation: 0 0.695051 0 0.257895 0 0.230016 0 0.853714 0 0.536421 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=620405, meanQ=10.186640, numObservations: 5
action 1, numVisits=197, meanQ=9.633334, numObservations: 5
action 4, numVisits=16, meanQ=8.235019, numObservations: 4
action 2, numVisits=9, meanQ=7.444467, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 984937 episodes
GETTING ACTION FROM:
action 3, numVisits=1605342, meanQ=10.327943, numObservations: 5
action 1, numVisits=197, meanQ=9.633334, numObservations: 5
action 4, numVisits=16, meanQ=8.235019, numObservations: 4
action 2, numVisits=9, meanQ=7.444467, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.630724 0.854787 0.265682 0.458773 0.294733 0.161138 0.945587 0.743939 0.581382 0.819646 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=61247, meanQ=12.811664, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1195620 episodes
GETTING ACTION FROM:
action 5, numVisits=1256867, meanQ=11.685754, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.630724 0.854787 0.265682 0.458773 0.294733 0.161138 0.945587 0.743939 0.581382 0.819646 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 201
Initial state: 0 0.380276 0.294073 0.173284 0.76988 0.463631 0.192873 0.528167 0.818453 0.548106 0.835927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879902 episodes
GETTING ACTION FROM:
action 5, numVisits=879893, meanQ=10.229577, numObservations: 5
action 2, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.380276 0.294073 0.173284 0.76988 0.463631 0.192873 0.528167 0.818453 0.548106 0.835927 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 202
Initial state: 0 0.825559 0.169614 0.664631 0.816459 0.515262 0.822378 0.871871 0.820431 0.779395 0.930505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884193 episodes
GETTING ACTION FROM:
action 1, numVisits=884181, meanQ=10.331690, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.825559 0.169614 0.664631 0.816459 0.515262 0.822378 0.871871 0.820431 0.779395 0.930505 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 203
Initial state: 0 0.523184 0.894945 0.563642 0.881054 0.388831 0.558398 0.957901 0.822577 0.806698 0.0254319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884273 episodes
GETTING ACTION FROM:
action 4, numVisits=884262, meanQ=10.291245, numObservations: 4
action 1, numVisits=6, meanQ=2.681667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.523184 0.894945 0.563642 0.881054 0.388831 0.558398 0.957901 0.822577 0.806698 0.0254319 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 204
Initial state: 0 0.754424 0.433679 0.59478 0.862584 0.796417 0.981918 0.56438 0.505504 0.580968 0.818931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 887862 episodes
GETTING ACTION FROM:
action 2, numVisits=887837, meanQ=10.709109, numObservations: 4
action 4, numVisits=11, meanQ=3.180000, numObservations: 3
action 1, numVisits=7, meanQ=2.140014, numObservations: 3
action 5, numVisits=4, meanQ=0.752525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.754424 0.433679 0.59478 0.862584 0.796417 0.981918 0.56438 0.505504 0.580968 0.818931 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 205
Initial state: 0 0.534588 0.0503074 0.989476 0.581072 0.80914 0.0830045 0.545427 0.889725 0.611773 0.831643 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 874659 episodes
GETTING ACTION FROM:
action 5, numVisits=874646, meanQ=10.254209, numObservations: 5
action 4, numVisits=4, meanQ=-0.252500, numObservations: 2
action 1, numVisits=5, meanQ=-0.397960, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.534588 0.0503074 0.989476 0.581072 0.80914 0.0830045 0.545427 0.889725 0.611773 0.831643 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 206
Initial state: 0 0.662881 0.864662 0.820901 0.378571 0.168814 0.0377936 0.71786 0.55831 0.60291 0.863868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 813314 episodes
GETTING ACTION FROM:
action 5, numVisits=813308, meanQ=10.806266, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.662881 0.864662 0.820901 0.378571 0.168814 0.0377936 0.71786 0.55831 0.60291 0.863868 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 207
Initial state: 0 0.428648 0.758075 0.792438 0.123015 0.509068 0.848014 0.567121 0.955981 0.60508 0.817553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 868238 episodes
GETTING ACTION FROM:
action 1, numVisits=868232, meanQ=10.250985, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.428648 0.758075 0.792438 0.123015 0.509068 0.848014 0.567121 0.955981 0.60508 0.817553 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=215461, meanQ=13.633748, numObservations: 5
action 4, numVisits=15, meanQ=6.407340, numObservations: 3
action 5, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1166610 episodes
GETTING ACTION FROM:
action 3, numVisits=1382071, meanQ=11.789325, numObservations: 5
action 4, numVisits=15, meanQ=6.407340, numObservations: 3
action 5, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.428648 0.758075 0.792438 0.123015 0.509068 0.848014 0.567121 0.955981 0.60508 0.817553 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 208
Initial state: 0 0.323072 0.580902 0.695152 0.869731 0.469485 0.650016 0.674219 0.817133 0.505965 0.0361406 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 788679 episodes
GETTING ACTION FROM:
action 5, numVisits=788667, meanQ=10.046711, numObservations: 5
action 2, numVisits=5, meanQ=4.598000, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.323072 0.580902 0.695152 0.869731 0.469485 0.650016 0.674219 0.817133 0.505965 0.0361406 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 209
Initial state: 0 0.892431 0.600868 0.654146 0.818048 0.595515 0.873118 0.914033 0.974578 0.3646 0.0757925 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 878871 episodes
GETTING ACTION FROM:
action 4, numVisits=878859, meanQ=10.409132, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.892431 0.600868 0.654146 0.818048 0.595515 0.873118 0.914033 0.974578 0.3646 0.0757925 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 210
Initial state: 0 0.893047 0.460064 0.51191 0.856475 0.3661 0.64404 0.896942 0.123721 0.687032 0.82622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877781 episodes
GETTING ACTION FROM:
action 3, numVisits=877759, meanQ=10.252145, numObservations: 5
action 4, numVisits=8, meanQ=7.498750, numObservations: 4
action 1, numVisits=6, meanQ=5.331683, numObservations: 3
action 2, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.893047 0.460064 0.51191 0.856475 0.3661 0.64404 0.896942 0.123721 0.687032 0.82622 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=180540, meanQ=13.641897, numObservations: 4
action 1, numVisits=7, meanQ=10.141429, numObservations: 3
action 2, numVisits=9, meanQ=9.778900, numObservations: 2
action 5, numVisits=6, meanQ=9.163333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1201993 episodes
GETTING ACTION FROM:
action 4, numVisits=1382511, meanQ=11.716878, numObservations: 4
action 1, numVisits=18, meanQ=9.221672, numObservations: 3
action 2, numVisits=11, meanQ=9.182736, numObservations: 2
action 5, numVisits=15, meanQ=8.732000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.893047 0.460064 0.51191 0.856475 0.3661 0.64404 0.896942 0.123721 0.687032 0.82622 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 211
Initial state: 0 0.534773 0.815725 0.859649 0.275364 0.547292 0.353546 0.517776 0.856627 0.522657 0.340283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 637031 episodes
GETTING ACTION FROM:
action 0, numVisits=637014, meanQ=12.077500, numObservations: 4
action 4, numVisits=8, meanQ=-0.252500, numObservations: 3
action 3, numVisits=4, meanQ=-1.225000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.534773 0.815725 0.859649 0.275364 0.547292 0.353546 0.517776 0.856627 0.522657 0.340283 w: 1
Observation: 0 0 0.822217 0 0.321044 0 0.415012 0 0.908444 0 0.258547 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=405823, meanQ=12.223878, numObservations: 3
action 3, numVisits=21, meanQ=6.999057, numObservations: 4
action 5, numVisits=5, meanQ=4.598000, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=5, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 993795 episodes
GETTING ACTION FROM:
action 4, numVisits=1399618, meanQ=10.722901, numObservations: 3
action 3, numVisits=21, meanQ=6.999057, numObservations: 4
action 5, numVisits=5, meanQ=4.598000, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=5, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 0 0.534773 0.815725 0.859649 0.275364 0.547292 0.353546 0.517776 0.856627 0.522657 0.340283 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=101329, meanQ=11.150630, numObservations: 4
action 2, numVisits=13, meanQ=3.690769, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1164114 episodes
GETTING ACTION FROM:
action 5, numVisits=1265443, meanQ=10.886425, numObservations: 4
action 2, numVisits=13, meanQ=3.690769, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.534773 0.815725 0.859649 0.275364 0.547292 0.353546 0.517776 0.856627 0.522657 0.340283 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 212
Initial state: 0 0.669232 0.154495 0.696635 0.835265 0.498526 0.0763947 0.664668 0.810154 0.85023 0.170326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 881566 episodes
GETTING ACTION FROM:
action 1, numVisits=881553, meanQ=10.260757, numObservations: 5
action 3, numVisits=8, meanQ=6.482500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.669232 0.154495 0.696635 0.835265 0.498526 0.0763947 0.664668 0.810154 0.85023 0.170326 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 213
Initial state: 0 0.692751 0.8193 0.261136 0.535369 0.562587 0.812052 0.969047 0.180056 0.879118 0.26913 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 864863 episodes
GETTING ACTION FROM:
action 1, numVisits=864855, meanQ=10.154023, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.692751 0.8193 0.261136 0.535369 0.562587 0.812052 0.969047 0.180056 0.879118 0.26913 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 214
Initial state: 0 0.692397 0.847296 0.556126 0.67915 0.209743 0.557319 0.72624 0.07518 0.543048 0.862719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 605023 episodes
GETTING ACTION FROM:
action 0, numVisits=605013, meanQ=14.666523, numObservations: 6
action 3, numVisits=4, meanQ=-0.252500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.692397 0.847296 0.556126 0.67915 0.209743 0.557319 0.72624 0.07518 0.543048 0.862719 w: 1
Observation: 0 0 0.771071 0 0.595505 0 0.645464 0 0.0316042 0 0.849612 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=151706, meanQ=17.237524, numObservations: 4
action 5, numVisits=4, meanQ=8.497500, numObservations: 1
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 984123 episodes
GETTING ACTION FROM:
action 2, numVisits=1135829, meanQ=12.750149, numObservations: 4
action 5, numVisits=4, meanQ=8.497500, numObservations: 1
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.692397 0.847296 0.556126 0.67915 0.209743 0.557319 0.72624 0.07518 0.543048 0.862719 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 215
Initial state: 0 0.639756 0.88618 0.298686 0.960838 0.627728 0.850816 0.0712091 0.934019 0.724903 0.000455741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 882829 episodes
GETTING ACTION FROM:
action 2, numVisits=882823, meanQ=10.386182, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.639756 0.88618 0.298686 0.960838 0.627728 0.850816 0.0712091 0.934019 0.724903 0.000455741 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 216
Initial state: 0 0.156655 0.28805 0.0745928 0.756705 0.680471 0.812865 0.950926 0.161474 0.686482 0.806003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879918 episodes
GETTING ACTION FROM:
action 5, numVisits=879818, meanQ=10.289524, numObservations: 3
action 1, numVisits=93, meanQ=8.443725, numObservations: 5
action 4, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.156655 0.28805 0.0745928 0.756705 0.680471 0.812865 0.950926 0.161474 0.686482 0.806003 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=7230, meanQ=9.339663, numObservations: 5
action 2, numVisits=7, meanQ=6.282857, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1186921 episodes
GETTING ACTION FROM:
action 1, numVisits=1194151, meanQ=11.144084, numObservations: 5
action 2, numVisits=7, meanQ=6.282857, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.156655 0.28805 0.0745928 0.756705 0.680471 0.812865 0.950926 0.161474 0.686482 0.806003 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=93126, meanQ=16.888183, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1299046 episodes
GETTING ACTION FROM:
action 2, numVisits=1392172, meanQ=12.649646, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.156655 0.28805 0.0745928 0.756705 0.680471 0.812865 0.950926 0.161474 0.686482 0.806003 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=36644, meanQ=20.373047, numObservations: 4
action 5, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1346141 episodes
GETTING ACTION FROM:
action 3, numVisits=1382785, meanQ=13.850805, numObservations: 4
action 5, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.156655 0.28805 0.0745928 0.756705 0.680471 0.812865 0.950926 0.161474 0.686482 0.806003 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 217
Initial state: 0 0.621607 0.0953792 0.129321 0.960791 0.610783 0.846271 0.425489 0.260224 0.547202 0.860407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 893145 episodes
GETTING ACTION FROM:
action 1, numVisits=893111, meanQ=10.330779, numObservations: 4
action 3, numVisits=27, meanQ=8.408148, numObservations: 3
action 2, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.621607 0.0953792 0.129321 0.960791 0.610783 0.846271 0.425489 0.260224 0.547202 0.860407 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 218
Initial state: 0 0.943058 0.194176 0.309277 0.900081 0.435013 0.171711 0.674257 0.873729 0.572208 0.802979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880561 episodes
GETTING ACTION FROM:
action 3, numVisits=880553, meanQ=10.416114, numObservations: 5
action 4, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.943058 0.194176 0.309277 0.900081 0.435013 0.171711 0.674257 0.873729 0.572208 0.802979 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=217642, meanQ=13.473999, numObservations: 4
action 4, numVisits=7, meanQ=6.572886, numObservations: 3
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1211138 episodes
GETTING ACTION FROM:
action 2, numVisits=1428780, meanQ=12.529872, numObservations: 4
action 4, numVisits=7, meanQ=6.572886, numObservations: 3
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.943058 0.194176 0.309277 0.900081 0.435013 0.171711 0.674257 0.873729 0.572208 0.802979 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 219
Initial state: 0 0.303424 0.451836 0.668864 0.803879 0.100752 0.753427 0.266788 0.791574 0.647129 0.840211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 594878 episodes
GETTING ACTION FROM:
action -1, numVisits=594855, meanQ=8.296793, numObservations: 3
action 2, numVisits=18, meanQ=1.561122, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.303424 0.451836 0.668864 0.803879 0.100752 0.753427 0.266788 0.791574 0.647129 0.840211 w: 1
Observation: 0 0.303984 0 0.608559 0 0.0844368 0 0.300504 0 0.598064 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=104673, meanQ=11.105126, numObservations: 4
action 5, numVisits=6, meanQ=7.831667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 983851 episodes
GETTING ACTION FROM:
action 4, numVisits=1088522, meanQ=10.756508, numObservations: 4
action 5, numVisits=8, meanQ=7.498750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.303424 0.451836 0.668864 0.803879 0.100752 0.753427 0.266788 0.791574 0.647129 0.840211 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=331415, meanQ=14.342765, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1202572 episodes
GETTING ACTION FROM:
action 2, numVisits=1533987, meanQ=12.746280, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.303424 0.451836 0.668864 0.803879 0.100752 0.753427 0.266788 0.791574 0.647129 0.840211 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 220
Initial state: 0 0.462831 0.972841 0.533038 0.839771 0.547173 0.898913 0.300676 0.568365 0.209171 0.427655 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 848436 episodes
GETTING ACTION FROM:
action 4, numVisits=848415, meanQ=10.337942, numObservations: 5
action 1, numVisits=5, meanQ=4.598000, numObservations: 3
action 2, numVisits=10, meanQ=3.799000, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.462831 0.972841 0.533038 0.839771 0.547173 0.898913 0.300676 0.568365 0.209171 0.427655 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=175451, meanQ=13.618612, numObservations: 5
action 2, numVisits=6, meanQ=7.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1195472 episodes
GETTING ACTION FROM:
action 3, numVisits=1370923, meanQ=12.327259, numObservations: 5
action 2, numVisits=6, meanQ=7.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.462831 0.972841 0.533038 0.839771 0.547173 0.898913 0.300676 0.568365 0.209171 0.427655 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 221
Initial state: 0 0.578239 0.805756 0.672747 0.898822 0.894149 0.964588 0.724918 0.766429 0.945276 0.650315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 890000 episodes
GETTING ACTION FROM:
action 1, numVisits=889959, meanQ=10.432309, numObservations: 4
action 2, numVisits=17, meanQ=8.427653, numObservations: 4
action 3, numVisits=20, meanQ=8.388500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.578239 0.805756 0.672747 0.898822 0.894149 0.964588 0.724918 0.766429 0.945276 0.650315 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=61596, meanQ=12.076338, numObservations: 4
action 4, numVisits=8, meanQ=7.012500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 907275 episodes
GETTING ACTION FROM:
action 1, numVisits=968871, meanQ=9.989928, numObservations: 4
action 4, numVisits=8, meanQ=7.012500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.578239 0.805756 0.672747 0.898822 0.894149 0.964588 0.724918 0.766429 0.945276 0.650315 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 222
Initial state: 0 0.558849 0.820836 0.699129 0.858583 0.692336 0.454209 0.584184 0.464966 0.253462 0.139065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877947 episodes
GETTING ACTION FROM:
action 4, numVisits=877928, meanQ=10.422780, numObservations: 5
action 1, numVisits=14, meanQ=4.497879, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.558849 0.820836 0.699129 0.858583 0.692336 0.454209 0.584184 0.464966 0.253462 0.139065 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 223
Initial state: 0 0.920208 0.109865 0.649635 0.547611 0.498265 0.735787 0.530211 0.844661 0.528566 0.89723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 866798 episodes
GETTING ACTION FROM:
action 2, numVisits=866792, meanQ=10.201625, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.920208 0.109865 0.649635 0.547611 0.498265 0.735787 0.530211 0.844661 0.528566 0.89723 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 224
Initial state: 0 0.296355 0.194623 0.552641 0.885471 0.863665 0.957873 0.646299 0.811431 0.572045 0.244694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 888983 episodes
GETTING ACTION FROM:
action 3, numVisits=888971, meanQ=10.212467, numObservations: 4
action 2, numVisits=4, meanQ=6.500000, numObservations: 2
action 4, numVisits=4, meanQ=0.772500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.296355 0.194623 0.552641 0.885471 0.863665 0.957873 0.646299 0.811431 0.572045 0.244694 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 225
Initial state: 0 0.500281 0.863921 0.9725 0.526781 0.339338 0.0155949 0.126516 0.45978 0.569262 0.813366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 890136 episodes
GETTING ACTION FROM:
action 4, numVisits=888551, meanQ=10.458644, numObservations: 4
action 1, numVisits=1573, meanQ=10.253963, numObservations: 5
action 3, numVisits=6, meanQ=7.183333, numObservations: 2
action 5, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.500281 0.863921 0.9725 0.526781 0.339338 0.0155949 0.126516 0.45978 0.569262 0.813366 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 226
Initial state: 0 0.566141 0.378467 0.927105 0.157619 0.725354 0.455466 0.636077 0.800236 0.658293 0.866527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 897021 episodes
GETTING ACTION FROM:
action 1, numVisits=897015, meanQ=10.285065, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.566141 0.378467 0.927105 0.157619 0.725354 0.455466 0.636077 0.800236 0.658293 0.866527 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 227
Initial state: 0 0.996235 0.532048 0.980198 0.708618 0.654964 0.854312 0.544655 0.854574 0.0256934 0.348147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 858931 episodes
GETTING ACTION FROM:
action 4, numVisits=858908, meanQ=10.055838, numObservations: 4
action 2, numVisits=18, meanQ=7.944456, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.996235 0.532048 0.980198 0.708618 0.654964 0.854312 0.544655 0.854574 0.0256934 0.348147 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 228
Initial state: 0 0.161373 0.0318277 0.699398 0.13016 0.116055 0.788014 0.600184 0.860923 0.680152 0.825781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 775613 episodes
GETTING ACTION FROM:
action 5, numVisits=775574, meanQ=9.704371, numObservations: 5
action 1, numVisits=29, meanQ=5.062421, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 1
action 3, numVisits=4, meanQ=3.245025, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.161373 0.0318277 0.699398 0.13016 0.116055 0.788014 0.600184 0.860923 0.680152 0.825781 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 229
Initial state: 0 0.182896 0.00214681 0.526655 0.846367 0.55783 0.828026 0.532187 0.17777 0.120055 0.128073 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889399 episodes
GETTING ACTION FROM:
action 4, numVisits=889393, meanQ=10.459528, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.182896 0.00214681 0.526655 0.846367 0.55783 0.828026 0.532187 0.17777 0.120055 0.128073 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 230
Initial state: 0 0.990785 0.394883 0.583853 0.809922 0.0939707 0.990484 0.140459 0.23695 0.67051 0.865205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 894012 episodes
GETTING ACTION FROM:
action 4, numVisits=893979, meanQ=10.239439, numObservations: 3
action 3, numVisits=21, meanQ=8.575243, numObservations: 4
action 2, numVisits=8, meanQ=7.232512, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.990785 0.394883 0.583853 0.809922 0.0939707 0.990484 0.140459 0.23695 0.67051 0.865205 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=258596, meanQ=13.346586, numObservations: 4
action 2, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1213617 episodes
GETTING ACTION FROM:
action 5, numVisits=1472213, meanQ=11.996606, numObservations: 4
action 2, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.990785 0.394883 0.583853 0.809922 0.0939707 0.990484 0.140459 0.23695 0.67051 0.865205 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 231
Initial state: 0 0.529698 0.879882 0.909663 0.226353 0.531236 0.866712 0.0919147 0.187408 0.821355 0.524774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877986 episodes
GETTING ACTION FROM:
action 5, numVisits=877980, meanQ=10.682007, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.529698 0.879882 0.909663 0.226353 0.531236 0.866712 0.0919147 0.187408 0.821355 0.524774 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 232
Initial state: 0 0.949987 0.169479 0.532956 0.888645 0.694856 0.840414 0.840426 0.0434998 0.819471 0.134274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 611591 episodes
GETTING ACTION FROM:
action 0, numVisits=611584, meanQ=11.635986, numObservations: 7
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.949987 0.169479 0.532956 0.888645 0.694856 0.840414 0.840426 0.0434998 0.819471 0.134274 w: 1
Observation: 0 0 0.181869 0 0.799193 0 0.742914 0 0.0438 0 0.174978 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=36847, meanQ=20.828728, numObservations: 3
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 971888 episodes
GETTING ACTION FROM:
action 2, numVisits=1008729, meanQ=10.397704, numObservations: 3
action 3, numVisits=8, meanQ=5.871263, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.949987 0.169479 0.532956 0.888645 0.694856 0.840414 0.840426 0.0434998 0.819471 0.134274 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 233
Initial state: 0 0.626202 0.801504 0.281022 0.677691 0.233452 0.140341 0.681225 0.859965 0.865413 0.568274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 899822 episodes
GETTING ACTION FROM:
action 3, numVisits=899816, meanQ=10.267019, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.626202 0.801504 0.281022 0.677691 0.233452 0.140341 0.681225 0.859965 0.865413 0.568274 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 234
Initial state: 0 0.509187 0.853086 0.335915 0.47623 0.992076 0.289644 0.562078 0.832834 0.609354 0.319828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 892907 episodes
GETTING ACTION FROM:
action 3, numVisits=892895, meanQ=10.435480, numObservations: 4
action 4, numVisits=7, meanQ=5.998586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.509187 0.853086 0.335915 0.47623 0.992076 0.289644 0.562078 0.832834 0.609354 0.319828 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 235
Initial state: 0 0.925685 0.460168 0.249429 0.247743 0.811902 0.989731 0.614292 0.890606 0.519458 0.86335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 878327 episodes
GETTING ACTION FROM:
action 5, numVisits=878318, meanQ=10.234011, numObservations: 4
action 2, numVisits=4, meanQ=1.745000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.925685 0.460168 0.249429 0.247743 0.811902 0.989731 0.614292 0.890606 0.519458 0.86335 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 236
Initial state: 0 0.213024 0.010055 0.629507 0.845129 0.236768 0.0552237 0.378449 0.949489 0.650689 0.870958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 874551 episodes
GETTING ACTION FROM:
action 4, numVisits=874543, meanQ=10.088259, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.213024 0.010055 0.629507 0.845129 0.236768 0.0552237 0.378449 0.949489 0.650689 0.870958 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7213, meanQ=10.252834, numObservations: 4
action 1, numVisits=5, meanQ=4.598000, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1190616 episodes
GETTING ACTION FROM:
action 2, numVisits=1197829, meanQ=12.128075, numObservations: 4
action 1, numVisits=5, meanQ=4.598000, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.213024 0.010055 0.629507 0.845129 0.236768 0.0552237 0.378449 0.949489 0.650689 0.870958 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 237
Initial state: 0 0.662459 0.823992 0.678736 0.883112 0.123336 0.222169 0.149329 0.377346 0.371707 0.978667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 867578 episodes
GETTING ACTION FROM:
action 5, numVisits=867522, meanQ=10.573852, numObservations: 4
action 1, numVisits=27, meanQ=8.787411, numObservations: 5
action 3, numVisits=23, meanQ=8.565670, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.662459 0.823992 0.678736 0.883112 0.123336 0.222169 0.149329 0.377346 0.371707 0.978667 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=47907, meanQ=13.238797, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1198893 episodes
GETTING ACTION FROM:
action 2, numVisits=1246800, meanQ=11.636270, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.662459 0.823992 0.678736 0.883112 0.123336 0.222169 0.149329 0.377346 0.371707 0.978667 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 238
Initial state: 0 0.117365 0.708464 0.0577201 0.537454 0.656899 0.85189 0.532255 0.881762 0.574895 0.77558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 896091 episodes
GETTING ACTION FROM:
action 1, numVisits=896065, meanQ=10.304347, numObservations: 3
action 3, numVisits=15, meanQ=8.199333, numObservations: 3
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action 5, numVisits=5, meanQ=4.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.117365 0.708464 0.0577201 0.537454 0.656899 0.85189 0.532255 0.881762 0.574895 0.77558 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=258137, meanQ=13.408955, numObservations: 5
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1209466 episodes
GETTING ACTION FROM:
action 5, numVisits=1467603, meanQ=12.403535, numObservations: 5
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.117365 0.708464 0.0577201 0.537454 0.656899 0.85189 0.532255 0.881762 0.574895 0.77558 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 239
Initial state: 0 0.511756 0.68013 0.539227 0.841736 0.252137 0.755662 0.689804 0.856989 0.839899 0.00357481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880576 episodes
GETTING ACTION FROM:
action 4, numVisits=880557, meanQ=10.404818, numObservations: 5
action 3, numVisits=14, meanQ=8.221436, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.511756 0.68013 0.539227 0.841736 0.252137 0.755662 0.689804 0.856989 0.839899 0.00357481 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 240
Initial state: 0 0.67033 0.820886 0.565406 0.886566 0.23565 0.261369 0.607511 0.242141 0.202048 0.0264551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877616 episodes
GETTING ACTION FROM:
action 3, numVisits=877604, meanQ=10.257675, numObservations: 5
action 5, numVisits=5, meanQ=4.598000, numObservations: 2
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.67033 0.820886 0.565406 0.886566 0.23565 0.261369 0.607511 0.242141 0.202048 0.0264551 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=179320, meanQ=13.519984, numObservations: 5
action 4, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1192854 episodes
GETTING ACTION FROM:
action 5, numVisits=1372174, meanQ=12.605360, numObservations: 5
action 4, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.67033 0.820886 0.565406 0.886566 0.23565 0.261369 0.607511 0.242141 0.202048 0.0264551 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=126874, meanQ=17.684480, numObservations: 5
action 4, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1302822 episodes
GETTING ACTION FROM:
action 1, numVisits=1429696, meanQ=13.247432, numObservations: 5
action 4, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.67033 0.820886 0.565406 0.886566 0.23565 0.261369 0.607511 0.242141 0.202048 0.0264551 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 241
Initial state: 0 0.737579 0.196138 0.628454 0.82137 0.163002 0.524383 0.535633 0.897362 0.238432 0.126245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 881061 episodes
GETTING ACTION FROM:
action 2, numVisits=881055, meanQ=10.290168, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.737579 0.196138 0.628454 0.82137 0.163002 0.524383 0.535633 0.897362 0.238432 0.126245 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=7266, meanQ=13.355185, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1047599 episodes
GETTING ACTION FROM:
action 2, numVisits=1054847, meanQ=10.362798, numObservations: 5
action 1, numVisits=19, meanQ=8.053163, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.737579 0.196138 0.628454 0.82137 0.163002 0.524383 0.535633 0.897362 0.238432 0.126245 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 242
Initial state: 0 0.928574 0.443875 0.601074 0.80983 0.0896492 0.91335 0.808113 0.212906 0.683567 0.898518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 886657 episodes
GETTING ACTION FROM:
action 4, numVisits=886651, meanQ=10.322158, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.928574 0.443875 0.601074 0.80983 0.0896492 0.91335 0.808113 0.212906 0.683567 0.898518 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 243
Initial state: 0 0.554186 0.480313 0.526335 0.885159 0.652704 0.892516 0.461226 0.414247 0.107164 0.664074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 848925 episodes
GETTING ACTION FROM:
action 1, numVisits=848919, meanQ=10.306682, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.554186 0.480313 0.526335 0.885159 0.652704 0.892516 0.461226 0.414247 0.107164 0.664074 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=174679, meanQ=13.564532, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1201961 episodes
GETTING ACTION FROM:
action 2, numVisits=1376640, meanQ=11.854584, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.554186 0.480313 0.526335 0.885159 0.652704 0.892516 0.461226 0.414247 0.107164 0.664074 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 244
Initial state: 0 0.509298 0.858437 0.0270525 0.527528 0.357371 0.0393664 0.60981 0.888799 0.385067 0.819448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 615660 episodes
GETTING ACTION FROM:
action 0, numVisits=615649, meanQ=11.302006, numObservations: 6
action 2, numVisits=5, meanQ=0.396020, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.509298 0.858437 0.0270525 0.527528 0.357371 0.0393664 0.60981 0.888799 0.385067 0.819448 w: 1
Observation: 0 0 0.806189 0 0.427759 0 0 0 0.853854 0 0.755026 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=67274, meanQ=13.856177, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=5, meanQ=-2.360000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 683053 episodes
GETTING ACTION FROM:
action -1, numVisits=750327, meanQ=10.515099, numObservations: 4
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=5, meanQ=-2.360000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.509298 0.858437 0.0270525 0.527528 0.357371 0.0393664 0.60981 0.888799 0.385067 0.819448 w: 1
Observation: 0 0.544077 0 0 0 0.447227 0 0.688724 0 0.419082 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=61427, meanQ=14.502455, numObservations: 5
action 4, numVisits=15, meanQ=8.007367, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 985186 episodes
GETTING ACTION FROM:
action 1, numVisits=1046613, meanQ=11.380257, numObservations: 5
action 4, numVisits=15, meanQ=8.007367, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.509298 0.858437 0.0270525 0.527528 0.357371 0.0393664 0.60981 0.888799 0.385067 0.819448 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.5424
Run # 245
Initial state: 0 0.582657 0.251861 0.514709 0.400815 0.588974 0.894602 0.81273 0.224317 0.609652 0.876995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 625067 episodes
GETTING ACTION FROM:
action -1, numVisits=625057, meanQ=8.343250, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.250000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.582657 0.251861 0.514709 0.400815 0.588974 0.894602 0.81273 0.224317 0.609652 0.876995 w: 1
Observation: 0 0.578032 0 0.419916 0 0.558976 0 0.792236 0 0.642595 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=544894, meanQ=9.816674, numObservations: 5
action 2, numVisits=102, meanQ=9.012634, numObservations: 5
action 5, numVisits=11, meanQ=6.546382, numObservations: 3
action 3, numVisits=10, meanQ=6.451000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 962995 episodes
GETTING ACTION FROM:
action 4, numVisits=1507889, meanQ=10.009417, numObservations: 5
action 2, numVisits=102, meanQ=9.012634, numObservations: 5
action 5, numVisits=11, meanQ=6.546382, numObservations: 3
action 3, numVisits=10, meanQ=6.451000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.582657 0.251861 0.514709 0.400815 0.588974 0.894602 0.81273 0.224317 0.609652 0.876995 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=70138, meanQ=11.724891, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1022969 episodes
GETTING ACTION FROM:
action 4, numVisits=1093107, meanQ=9.357523, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.582657 0.251861 0.514709 0.400815 0.588974 0.894602 0.81273 0.224317 0.609652 0.876995 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 246
Initial state: 0 0.935797 0.353462 0.566073 0.817035 0.524863 0.869382 0.73163 0.143972 0.463725 0.81162 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 876669 episodes
GETTING ACTION FROM:
action 2, numVisits=876661, meanQ=10.248513, numObservations: 5
action 4, numVisits=3, meanQ=2.033333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.935797 0.353462 0.566073 0.817035 0.524863 0.869382 0.73163 0.143972 0.463725 0.81162 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 247
Initial state: 0 0.130905 0.195761 0.268378 0.499171 0.864404 0.998368 0.694102 0.889166 0.657612 0.818479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884578 episodes
GETTING ACTION FROM:
action 4, numVisits=884564, meanQ=10.263343, numObservations: 4
action 2, numVisits=7, meanQ=6.857157, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.130905 0.195761 0.268378 0.499171 0.864404 0.998368 0.694102 0.889166 0.657612 0.818479 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 248
Initial state: 0 0.414338 0.466678 0.413159 0.609948 0.532705 0.890379 0.515133 0.815803 0.133876 0.38791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 876276 episodes
GETTING ACTION FROM:
action 5, numVisits=876264, meanQ=10.199441, numObservations: 5
action 1, numVisits=7, meanQ=2.140014, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.414338 0.466678 0.413159 0.609948 0.532705 0.890379 0.515133 0.815803 0.133876 0.38791 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 249
Initial state: 0 0.572462 0.810002 0.0785884 0.87965 0.294217 0.383118 0.858729 0.556205 0.605875 0.844598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 637661 episodes
GETTING ACTION FROM:
action 0, numVisits=637654, meanQ=15.081705, numObservations: 7
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.572462 0.810002 0.0785884 0.87965 0.294217 0.383118 0.858729 0.556205 0.605875 0.844598 w: 1
Observation: 0 0 0.832455 0 0.936084 0 0.453442 0 0.483095 0 0.766834 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=190968, meanQ=18.258191, numObservations: 4
action 1, numVisits=15, meanQ=-0.865993, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 957687 episodes
GETTING ACTION FROM:
action 2, numVisits=1148655, meanQ=12.601183, numObservations: 4
action 1, numVisits=15, meanQ=-0.865993, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.572462 0.810002 0.0785884 0.87965 0.294217 0.383118 0.858729 0.556205 0.605875 0.844598 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=107505, meanQ=13.804979, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1170793 episodes
GETTING ACTION FROM:
action 5, numVisits=1278298, meanQ=11.565499, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.572462 0.810002 0.0785884 0.87965 0.294217 0.383118 0.858729 0.556205 0.605875 0.844598 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 250
Initial state: 0 0.641685 0.874341 0.344055 0.147735 0.677772 0.858851 0.606072 0.741887 0.729559 0.12135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 883001 episodes
GETTING ACTION FROM:
action 2, numVisits=882985, meanQ=10.216902, numObservations: 4
action 1, numVisits=5, meanQ=2.392000, numObservations: 4
action 4, numVisits=7, meanQ=1.855743, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.641685 0.874341 0.344055 0.147735 0.677772 0.858851 0.606072 0.741887 0.729559 0.12135 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=218797, meanQ=13.411330, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1213974 episodes
GETTING ACTION FROM:
action 3, numVisits=1432771, meanQ=11.156609, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.641685 0.874341 0.344055 0.147735 0.677772 0.858851 0.606072 0.741887 0.729559 0.12135 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 251
Initial state: 0 0.62612 0.857923 0.640393 0.811448 0.807859 0.43215 0.264413 0.753241 0.193917 0.161583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884169 episodes
GETTING ACTION FROM:
action 1, numVisits=884161, meanQ=10.679590, numObservations: 4
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.62612 0.857923 0.640393 0.811448 0.807859 0.43215 0.264413 0.753241 0.193917 0.161583 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 252
Initial state: 0 0.612252 0.804289 0.632103 0.858961 0.576478 0.495977 0.269105 0.228093 0.932466 0.508639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 888190 episodes
GETTING ACTION FROM:
action 4, numVisits=888176, meanQ=10.247851, numObservations: 4
action 1, numVisits=9, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.612252 0.804289 0.632103 0.858961 0.576478 0.495977 0.269105 0.228093 0.932466 0.508639 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=256276, meanQ=13.357272, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1197300 episodes
GETTING ACTION FROM:
action 2, numVisits=1453576, meanQ=11.535721, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.612252 0.804289 0.632103 0.858961 0.576478 0.495977 0.269105 0.228093 0.932466 0.508639 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 253
Initial state: 0 0.605966 0.992125 0.570701 0.845397 0.651873 0.839828 0.367866 0.0112776 0.0901481 0.692047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877629 episodes
GETTING ACTION FROM:
action 3, numVisits=877623, meanQ=10.280409, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.605966 0.992125 0.570701 0.845397 0.651873 0.839828 0.367866 0.0112776 0.0901481 0.692047 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 254
Initial state: 0 0.54677 0.811415 0.96203 0.0177068 0.00808495 0.179006 0.518703 0.0925153 0.584751 0.872614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880992 episodes
GETTING ACTION FROM:
action 5, numVisits=880982, meanQ=10.426860, numObservations: 4
action 3, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.54677 0.811415 0.96203 0.0177068 0.00808495 0.179006 0.518703 0.0925153 0.584751 0.872614 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 255
Initial state: 0 0.327927 0.637936 0.366083 0.0509058 0.859443 0.32944 0.606925 0.877309 0.605131 0.833419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 883583 episodes
GETTING ACTION FROM:
action 4, numVisits=883577, meanQ=10.767351, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.327927 0.637936 0.366083 0.0509058 0.859443 0.32944 0.606925 0.877309 0.605131 0.833419 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 256
Initial state: 0 0.503669 0.84673 0.684039 0.0599965 0.992643 0.0993741 0.501447 0.732457 0.561972 0.808839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 866062 episodes
GETTING ACTION FROM:
action 4, numVisits=866056, meanQ=10.288506, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.503669 0.84673 0.684039 0.0599965 0.992643 0.0993741 0.501447 0.732457 0.561972 0.808839 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 257
Initial state: 0 0.473323 0.920876 0.685836 0.846384 0.41865 0.0893783 0.330946 0.837075 0.561574 0.807345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 891526 episodes
GETTING ACTION FROM:
action 2, numVisits=842902, meanQ=10.702841, numObservations: 4
action 3, numVisits=48604, meanQ=10.483905, numObservations: 4
action 4, numVisits=16, meanQ=8.623769, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.473323 0.920876 0.685836 0.846384 0.41865 0.0893783 0.330946 0.837075 0.561574 0.807345 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 258
Initial state: 0 0.136165 0.259213 0.264994 0.953996 0.87057 0.612108 0.622034 0.80881 0.525961 0.808796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 875053 episodes
GETTING ACTION FROM:
action 3, numVisits=875047, meanQ=10.363312, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.136165 0.259213 0.264994 0.953996 0.87057 0.612108 0.622034 0.80881 0.525961 0.808796 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 259
Initial state: 0 0.572996 0.805091 0.158689 0.0257848 0.678791 0.845192 0.241088 0.776097 0.369625 0.649008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 806507 episodes
GETTING ACTION FROM:
action 4, numVisits=806494, meanQ=10.701517, numObservations: 5
action 5, numVisits=6, meanQ=-0.163283, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.572996 0.805091 0.158689 0.0257848 0.678791 0.845192 0.241088 0.776097 0.369625 0.649008 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=166555, meanQ=16.153573, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 994564 episodes
GETTING ACTION FROM:
action 0, numVisits=1161119, meanQ=6.351145, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.572996 0.805091 0.158689 0.0257848 0.678791 0.845192 0.241088 0.776097 0.369625 0.649008 w: 1
Observation: 0 0 0.739693 0 0.0163002 0 0.856031 0 0.690741 0 0.629353 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=303141, meanQ=16.366070, numObservations: 4
action 1, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1179768 episodes
GETTING ACTION FROM:
action 3, numVisits=1482909, meanQ=12.536391, numObservations: 4
action 1, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.572996 0.805091 0.158689 0.0257848 0.678791 0.845192 0.241088 0.776097 0.369625 0.649008 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 260
Initial state: 0 0.412268 0.281815 0.662805 0.809456 0.576119 0.883973 0.734223 0.276489 0.455416 0.917276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877438 episodes
GETTING ACTION FROM:
action 2, numVisits=877421, meanQ=10.264528, numObservations: 5
action 1, numVisits=12, meanQ=7.841683, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.412268 0.281815 0.662805 0.809456 0.576119 0.883973 0.734223 0.276489 0.455416 0.917276 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 261
Initial state: 0 0.237702 0.327391 0.561189 0.857349 0.586298 0.873261 0.939281 0.841225 0.880762 0.018194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 873479 episodes
GETTING ACTION FROM:
action 5, numVisits=872948, meanQ=10.279088, numObservations: 5
action 2, numVisits=526, meanQ=8.302774, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.237702 0.327391 0.561189 0.857349 0.586298 0.873261 0.939281 0.841225 0.880762 0.018194 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 262
Initial state: 0 0.00301225 0.235073 0.502946 0.805791 0.396071 0.00630928 0.555849 0.828878 0.823128 0.310492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 861160 episodes
GETTING ACTION FROM:
action 2, numVisits=861154, meanQ=10.084832, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.00301225 0.235073 0.502946 0.805791 0.396071 0.00630928 0.555849 0.828878 0.823128 0.310492 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 263
Initial state: 0 0.610457 0.476546 0.62235 0.812177 0.559877 0.826108 0.862612 0.260073 0.356798 0.879317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 876172 episodes
GETTING ACTION FROM:
action 2, numVisits=876166, meanQ=10.277492, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.610457 0.476546 0.62235 0.812177 0.559877 0.826108 0.862612 0.260073 0.356798 0.879317 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 264
Initial state: 0 0.537537 0.841275 0.575032 0.807263 0.491215 0.870972 0.783297 0.0361686 0.566672 0.686164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889677 episodes
GETTING ACTION FROM:
action 3, numVisits=889661, meanQ=10.290311, numObservations: 3
action 5, numVisits=9, meanQ=6.997789, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.537537 0.841275 0.575032 0.807263 0.491215 0.870972 0.783297 0.0361686 0.566672 0.686164 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=256692, meanQ=13.462958, numObservations: 5
action 1, numVisits=5, meanQ=7.000020, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1183454 episodes
GETTING ACTION FROM:
action 2, numVisits=1440146, meanQ=12.418066, numObservations: 5
action 1, numVisits=5, meanQ=7.000020, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.537537 0.841275 0.575032 0.807263 0.491215 0.870972 0.783297 0.0361686 0.566672 0.686164 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 265
Initial state: 0 0.981505 0.707644 0.647986 0.895367 0.987866 0.460978 0.24756 0.741891 0.659044 0.879805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879742 episodes
GETTING ACTION FROM:
action 4, numVisits=879730, meanQ=10.400153, numObservations: 5
action 3, numVisits=7, meanQ=6.282857, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.981505 0.707644 0.647986 0.895367 0.987866 0.460978 0.24756 0.741891 0.659044 0.879805 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=219289, meanQ=13.441998, numObservations: 4
action 5, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1213063 episodes
GETTING ACTION FROM:
action 2, numVisits=1432352, meanQ=12.105732, numObservations: 4
action 5, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.981505 0.707644 0.647986 0.895367 0.987866 0.460978 0.24756 0.741891 0.659044 0.879805 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 266
Initial state: 0 0.324888 0.171908 0.581861 0.890396 0.55862 0.805905 0.997906 0.0981659 0.193369 0.510983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 852560 episodes
GETTING ACTION FROM:
action 2, numVisits=852541, meanQ=10.297931, numObservations: 4
action 5, numVisits=12, meanQ=7.507500, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.324888 0.171908 0.581861 0.890396 0.55862 0.805905 0.997906 0.0981659 0.193369 0.510983 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 267
Initial state: 0 0.048636 0.980894 0.232103 0.862652 0.471815 0.423973 0.55957 0.886026 0.69794 0.847434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879491 episodes
GETTING ACTION FROM:
action 4, numVisits=879485, meanQ=10.231001, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.048636 0.980894 0.232103 0.862652 0.471815 0.423973 0.55957 0.886026 0.69794 0.847434 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 268
Initial state: 0 0.666644 0.881081 0.398277 0.148264 0.633847 0.822217 0.29296 0.304341 0.433702 0.448833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 860085 episodes
GETTING ACTION FROM:
action 5, numVisits=859955, meanQ=10.339547, numObservations: 5
action 2, numVisits=125, meanQ=9.605007, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.666644 0.881081 0.398277 0.148264 0.633847 0.822217 0.29296 0.304341 0.433702 0.448833 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=212668, meanQ=13.401551, numObservations: 3
action 4, numVisits=4, meanQ=8.497500, numObservations: 1
action 3, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1232065 episodes
GETTING ACTION FROM:
action 1, numVisits=1444732, meanQ=11.635835, numObservations: 3
action 4, numVisits=5, meanQ=6.196000, numObservations: 2
action 3, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.666644 0.881081 0.398277 0.148264 0.633847 0.822217 0.29296 0.304341 0.433702 0.448833 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 269
Initial state: 0 0.506011 0.817984 0.888884 0.968011 0.413625 0.797517 0.637853 0.896093 0.836268 0.184221 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 859288 episodes
GETTING ACTION FROM:
action 3, numVisits=859282, meanQ=10.134953, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.506011 0.817984 0.888884 0.968011 0.413625 0.797517 0.637853 0.896093 0.836268 0.184221 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 270
Initial state: 0 0.64752 0.817265 0.566185 0.868724 0.725998 0.943129 0.234845 0.35263 0.16283 0.739764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 887419 episodes
GETTING ACTION FROM:
action 2, numVisits=887409, meanQ=10.438307, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.64752 0.817265 0.566185 0.868724 0.725998 0.943129 0.234845 0.35263 0.16283 0.739764 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 271
Initial state: 0 0.559678 0.898836 0.166005 0.0581996 0.712333 0.508594 0.997839 0.940162 0.538665 0.840836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 628765 episodes
GETTING ACTION FROM:
action -1, numVisits=628759, meanQ=8.683938, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.559678 0.898836 0.166005 0.0581996 0.712333 0.508594 0.997839 0.940162 0.538665 0.840836 w: 1
Observation: 0 0.480762 0 0.0663612 0 0.691365 0 1 0 0.549827 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=394238, meanQ=10.367509, numObservations: 4
action 5, numVisits=7, meanQ=5.677143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 986954 episodes
GETTING ACTION FROM:
action 1, numVisits=1381192, meanQ=10.355274, numObservations: 4
action 5, numVisits=7, meanQ=5.677143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.559678 0.898836 0.166005 0.0581996 0.712333 0.508594 0.997839 0.940162 0.538665 0.840836 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 272
Initial state: 0 0.971139 0.42384 0.126713 0.973858 0.634388 0.875376 0.676705 0.822636 0.345762 0.774586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 891447 episodes
GETTING ACTION FROM:
action 1, numVisits=891395, meanQ=10.393732, numObservations: 4
action 4, numVisits=21, meanQ=8.619057, numObservations: 4
action 5, numVisits=25, meanQ=8.532404, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.971139 0.42384 0.126713 0.973858 0.634388 0.875376 0.676705 0.822636 0.345762 0.774586 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 273
Initial state: 0 0.50158 0.683549 0.114547 0.539876 0.652454 0.846562 0.575837 0.893278 0.701398 0.0871104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 897590 episodes
GETTING ACTION FROM:
action 3, numVisits=897580, meanQ=10.235306, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.50158 0.683549 0.114547 0.539876 0.652454 0.846562 0.575837 0.893278 0.701398 0.0871104 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 274
Initial state: 0 0.585661 0.886363 0.595363 0.855978 0.976047 0.835415 0.026733 0.935881 0.818733 0.194414 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889597 episodes
GETTING ACTION FROM:
action 2, numVisits=889546, meanQ=10.390963, numObservations: 4
action 3, numVisits=15, meanQ=8.340007, numObservations: 4
action 4, numVisits=18, meanQ=7.929450, numObservations: 3
action 5, numVisits=15, meanQ=7.866693, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.585661 0.886363 0.595363 0.855978 0.976047 0.835415 0.026733 0.935881 0.818733 0.194414 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 275
Initial state: 0 0.922836 0.0355915 0.76847 0.335012 0.588112 0.855657 0.606016 0.850245 0.454472 0.417377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884960 episodes
GETTING ACTION FROM:
action 4, numVisits=884950, meanQ=10.274837, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.922836 0.0355915 0.76847 0.335012 0.588112 0.855657 0.606016 0.850245 0.454472 0.417377 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 276
Initial state: 0 0.113149 0.781921 0.512811 0.817989 0.451538 0.175901 0.577764 0.834566 0.0638914 0.585569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889240 episodes
GETTING ACTION FROM:
action 2, numVisits=889234, meanQ=10.394768, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.113149 0.781921 0.512811 0.817989 0.451538 0.175901 0.577764 0.834566 0.0638914 0.585569 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 277
Initial state: 0 0.961304 0.271049 0.8395 0.727207 0.654757 0.864615 0.680581 0.835586 0.510653 0.005665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 648385 episodes
GETTING ACTION FROM:
action 0, numVisits=648360, meanQ=14.973772, numObservations: 6
action 5, numVisits=9, meanQ=-0.999989, numObservations: 2
action 3, numVisits=9, meanQ=-1.446667, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.961304 0.271049 0.8395 0.727207 0.654757 0.864615 0.680581 0.835586 0.510653 0.005665 w: 1
Observation: 0 0 0.327782 0 0.732662 0 0.880005 0 0.806538 0 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=154720, meanQ=18.483127, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 951995 episodes
GETTING ACTION FROM:
action 3, numVisits=1106715, meanQ=11.872485, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.961304 0.271049 0.8395 0.727207 0.654757 0.864615 0.680581 0.835586 0.510653 0.005665 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 278
Initial state: 0 0.501686 0.868389 0.614127 0.886902 0.714031 0.438256 0.402572 0.0648438 0.553883 0.495376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 874037 episodes
GETTING ACTION FROM:
action 2, numVisits=874027, meanQ=10.786416, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-8.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.501686 0.868389 0.614127 0.886902 0.714031 0.438256 0.402572 0.0648438 0.553883 0.495376 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 279
Initial state: 0 0.986497 0.730799 0.230639 0.195924 0.685572 0.476814 0.697999 0.888257 0.589033 0.831362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 870340 episodes
GETTING ACTION FROM:
action 3, numVisits=870330, meanQ=10.165033, numObservations: 5
action 2, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.986497 0.730799 0.230639 0.195924 0.685572 0.476814 0.697999 0.888257 0.589033 0.831362 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=214768, meanQ=13.450887, numObservations: 3
action 4, numVisits=68, meanQ=12.464860, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1208569 episodes
GETTING ACTION FROM:
action 5, numVisits=1423226, meanQ=12.228761, numObservations: 3
action 4, numVisits=179, meanQ=11.626562, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.986497 0.730799 0.230639 0.195924 0.685572 0.476814 0.697999 0.888257 0.589033 0.831362 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 280
Initial state: 0 0.542691 0.885118 0.602194 0.887128 0.578318 0.60391 0.734665 0.0427466 0.677981 0.555106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 885827 episodes
GETTING ACTION FROM:
action 5, numVisits=885076, meanQ=10.237676, numObservations: 4
action 1, numVisits=742, meanQ=9.223767, numObservations: 4
action 2, numVisits=5, meanQ=3.820000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.542691 0.885118 0.602194 0.887128 0.578318 0.60391 0.734665 0.0427466 0.677981 0.555106 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 281
Initial state: 0 0.522389 0.951185 0.627739 0.852009 0.642543 0.12516 0.679865 0.850056 0.196615 0.9397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884131 episodes
GETTING ACTION FROM:
action 4, numVisits=884125, meanQ=10.264196, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.522389 0.951185 0.627739 0.852009 0.642543 0.12516 0.679865 0.850056 0.196615 0.9397 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 282
Initial state: 0 0.578504 0.828777 0.590945 0.867674 0.741868 0.353663 0.898124 0.352011 0.671191 0.196535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 885198 episodes
GETTING ACTION FROM:
action 5, numVisits=885173, meanQ=10.374105, numObservations: 4
action 2, numVisits=12, meanQ=7.813342, numObservations: 3
action 3, numVisits=7, meanQ=5.998586, numObservations: 3
action 4, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.578504 0.828777 0.590945 0.867674 0.741868 0.353663 0.898124 0.352011 0.671191 0.196535 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 283
Initial state: 0 0.50185 0.871001 0.00553732 0.467495 0.615297 0.558615 0.227506 0.999533 0.616299 0.892589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 875537 episodes
GETTING ACTION FROM:
action 1, numVisits=875526, meanQ=10.226345, numObservations: 5
action 2, numVisits=4, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.50185 0.871001 0.00553732 0.467495 0.615297 0.558615 0.227506 0.999533 0.616299 0.892589 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 284
Initial state: 0 0.0799726 0.625152 0.976851 0.678492 0.65111 0.802666 0.550853 0.808222 0.223415 0.996413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877902 episodes
GETTING ACTION FROM:
action 1, numVisits=877892, meanQ=10.261352, numObservations: 4
action 5, numVisits=5, meanQ=3.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0799726 0.625152 0.976851 0.678492 0.65111 0.802666 0.550853 0.808222 0.223415 0.996413 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=253524, meanQ=13.357660, numObservations: 5
action 3, numVisits=21, meanQ=9.171905, numObservations: 4
action 2, numVisits=35, meanQ=9.000871, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1193082 episodes
GETTING ACTION FROM:
action 5, numVisits=1446606, meanQ=12.106431, numObservations: 5
action 3, numVisits=21, meanQ=9.171905, numObservations: 4
action 2, numVisits=35, meanQ=9.000871, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.0799726 0.625152 0.976851 0.678492 0.65111 0.802666 0.550853 0.808222 0.223415 0.996413 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=48118, meanQ=12.802293, numObservations: 4
action 2, numVisits=9, meanQ=3.775578, numObservations: 2
action 4, numVisits=4, meanQ=1.247525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1318107 episodes
GETTING ACTION FROM:
action 3, numVisits=1366225, meanQ=12.834414, numObservations: 4
action 2, numVisits=9, meanQ=3.775578, numObservations: 2
action 4, numVisits=4, meanQ=1.247525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0799726 0.625152 0.976851 0.678492 0.65111 0.802666 0.550853 0.808222 0.223415 0.996413 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 285
Initial state: 0 0.164944 0.98474 0.55187 0.841668 0.621834 0.811399 0.338548 0.575396 0.928839 0.511519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 883880 episodes
GETTING ACTION FROM:
action 4, numVisits=883871, meanQ=10.424064, numObservations: 4
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.164944 0.98474 0.55187 0.841668 0.621834 0.811399 0.338548 0.575396 0.928839 0.511519 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=255517, meanQ=13.468805, numObservations: 3
action 1, numVisits=6, meanQ=4.661667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1216400 episodes
GETTING ACTION FROM:
action 2, numVisits=1471917, meanQ=11.517330, numObservations: 3
action 1, numVisits=6, meanQ=4.661667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.164944 0.98474 0.55187 0.841668 0.621834 0.811399 0.338548 0.575396 0.928839 0.511519 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 286
Initial state: 0 0.763655 0.620569 0.436915 0.867407 0.641181 0.859193 0.733666 0.307766 0.56933 0.864931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 883294 episodes
GETTING ACTION FROM:
action 4, numVisits=883288, meanQ=10.432888, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.763655 0.620569 0.436915 0.867407 0.641181 0.859193 0.733666 0.307766 0.56933 0.864931 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 287
Initial state: 0 0.413279 0.601021 0.58681 0.86491 0.623118 0.848807 0.931882 0.662629 0.386962 0.307455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 793597 episodes
GETTING ACTION FROM:
action 3, numVisits=793588, meanQ=10.003509, numObservations: 3
action 5, numVisits=4, meanQ=-0.252500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.413279 0.601021 0.58681 0.86491 0.623118 0.848807 0.931882 0.662629 0.386962 0.307455 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 288
Initial state: 0 0.692976 0.864553 0.634503 0.802397 0.540746 0.467231 0.806587 0.336418 0.775259 0.40047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 895102 episodes
GETTING ACTION FROM:
action 4, numVisits=895096, meanQ=10.480478, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.692976 0.864553 0.634503 0.802397 0.540746 0.467231 0.806587 0.336418 0.775259 0.40047 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=61939, meanQ=12.778337, numObservations: 4
action 2, numVisits=15, meanQ=-0.597987, numObservations: 3
action 3, numVisits=5, meanQ=-1.597980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
Sampled 1049719 episodes
GETTING ACTION FROM:
action 4, numVisits=1111658, meanQ=9.676841, numObservations: 4
action 2, numVisits=15, meanQ=-0.597987, numObservations: 3
action 3, numVisits=5, meanQ=-1.597980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 4
Next state: 2 0.692976 0.864553 0.634503 0.802397 0.540746 0.467231 0.806587 0.336418 0.775259 0.40047 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 289
Initial state: 0 0.53372 0.843226 0.169891 0.789572 0.426889 0.311601 0.585953 0.8973 0.939916 0.563053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879673 episodes
GETTING ACTION FROM:
action 2, numVisits=879665, meanQ=10.301098, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.53372 0.843226 0.169891 0.789572 0.426889 0.311601 0.585953 0.8973 0.939916 0.563053 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=217951, meanQ=13.512315, numObservations: 5
action 5, numVisits=4, meanQ=-2.250000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1202309 episodes
GETTING ACTION FROM:
action 3, numVisits=1420260, meanQ=12.087185, numObservations: 5
action 5, numVisits=4, meanQ=-2.250000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.53372 0.843226 0.169891 0.789572 0.426889 0.311601 0.585953 0.8973 0.939916 0.563053 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=138623, meanQ=16.148138, numObservations: 5
action 4, numVisits=4, meanQ=9.997525, numObservations: 2
action 1, numVisits=8, meanQ=8.248763, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1284077 episodes
GETTING ACTION FROM:
action 5, numVisits=1422696, meanQ=13.388241, numObservations: 5
action 1, numVisits=8, meanQ=8.248763, numObservations: 2
action 4, numVisits=8, meanQ=8.248762, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.53372 0.843226 0.169891 0.789572 0.426889 0.311601 0.585953 0.8973 0.939916 0.563053 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 290
Initial state: 0 0.542209 0.864042 0.985577 0.942818 0.419808 0.162024 0.51852 0.814215 0.556534 0.55284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889209 episodes
GETTING ACTION FROM:
action 5, numVisits=889199, meanQ=10.402534, numObservations: 4
action 3, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.542209 0.864042 0.985577 0.942818 0.419808 0.162024 0.51852 0.814215 0.556534 0.55284 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 291
Initial state: 0 0.751299 0.586635 0.685994 0.805767 0.599942 0.879847 0.41283 0.368048 0.147793 0.829927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 893115 episodes
GETTING ACTION FROM:
action 3, numVisits=893104, meanQ=10.411801, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=4, meanQ=1.745000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.751299 0.586635 0.685994 0.805767 0.599942 0.879847 0.41283 0.368048 0.147793 0.829927 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 292
Initial state: 0 0.186353 0.133448 0.577094 0.87014 0.380213 0.593433 0.545493 0.819214 0.316704 0.209438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889145 episodes
GETTING ACTION FROM:
action 2, numVisits=889135, meanQ=10.418058, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.186353 0.133448 0.577094 0.87014 0.380213 0.593433 0.545493 0.819214 0.316704 0.209438 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 293
Initial state: 0 0.131942 0.712799 0.647878 0.822644 0.858543 0.177768 0.587161 0.881067 0.320319 0.061605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 887592 episodes
GETTING ACTION FROM:
action 5, numVisits=887378, meanQ=10.412911, numObservations: 4
action 2, numVisits=101, meanQ=9.172879, numObservations: 5
action 4, numVisits=103, meanQ=9.090164, numObservations: 4
action 1, numVisits=5, meanQ=5.402020, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 5
Next state: 0 0.131942 0.712799 0.647878 0.822644 0.858543 0.177768 0.587161 0.881067 0.320319 0.061605 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=182284, meanQ=13.614992, numObservations: 5
action 3, numVisits=4, meanQ=1.247525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1194155 episodes
GETTING ACTION FROM:
action 2, numVisits=1376439, meanQ=12.313889, numObservations: 5
action 3, numVisits=4, meanQ=1.247525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.131942 0.712799 0.647878 0.822644 0.858543 0.177768 0.587161 0.881067 0.320319 0.061605 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 294
Initial state: 0 0.550743 0.886893 0.536957 0.326417 0.0917719 0.545296 0.912067 0.218607 0.570882 0.842304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 890319 episodes
GETTING ACTION FROM:
action 2, numVisits=890309, meanQ=10.198871, numObservations: 4
action 4, numVisits=5, meanQ=0.396020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.550743 0.886893 0.536957 0.326417 0.0917719 0.545296 0.912067 0.218607 0.570882 0.842304 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 295
Initial state: 0 0.51078 0.8907 0.68402 0.811076 0.189911 0.172159 0.877739 0.37464 0.739262 0.0151885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877247 episodes
GETTING ACTION FROM:
action 2, numVisits=877236, meanQ=10.370138, numObservations: 4
action 3, numVisits=6, meanQ=2.623333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.51078 0.8907 0.68402 0.811076 0.189911 0.172159 0.877739 0.37464 0.739262 0.0151885 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 296
Initial state: 0 0.458995 0.615474 0.067208 0.094269 0.00934323 0.619183 0.652155 0.850956 0.646751 0.852942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 864163 episodes
GETTING ACTION FROM:
action 3, numVisits=864153, meanQ=10.297641, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.458995 0.615474 0.067208 0.094269 0.00934323 0.619183 0.652155 0.850956 0.646751 0.852942 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 297
Initial state: 0 0.295144 0.295758 0.473574 0.945005 0.666981 0.810605 0.561713 0.884516 0.883663 0.3578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 543736 episodes
GETTING ACTION FROM:
action 0, numVisits=543729, meanQ=11.139437, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.295144 0.295758 0.473574 0.945005 0.666981 0.810605 0.561713 0.884516 0.883663 0.3578 w: 1
Observation: 0 0 0.219256 0 1 0 0.879025 0 0.972233 0 0.414874 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=196649, meanQ=11.782693, numObservations: 3
action 5, numVisits=123780, meanQ=5.819184, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 605587 episodes
GETTING ACTION FROM:
action -1, numVisits=802236, meanQ=10.819819, numObservations: 3
action 5, numVisits=123780, meanQ=5.819184, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.295144 0.295758 0.473574 0.945005 0.666981 0.810605 0.561713 0.884516 0.883663 0.3578 w: 1
Observation: 0 0.355586 0 0.465913 0 0.701259 0 0.646541 0 0.858095 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=190469, meanQ=10.177412, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 653701 episodes
GETTING ACTION FROM:
action -1, numVisits=844170, meanQ=9.734107, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.295144 0.295758 0.473574 0.945005 0.666981 0.810605 0.561713 0.884516 0.883663 0.3578 w: 1
Observation: 0 0.341469 0 0.383681 0 0.64432 0 0.588241 0 0.859648 0 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=335787, meanQ=11.333031, numObservations: 5
action 3, numVisits=8, meanQ=7.498750, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 989687 episodes
GETTING ACTION FROM:
action 2, numVisits=1325474, meanQ=11.763245, numObservations: 5
action 3, numVisits=8, meanQ=7.498750, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.295144 0.295758 0.473574 0.945005 0.666981 0.810605 0.561713 0.884516 0.883663 0.3578 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=75008, meanQ=18.817994, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1092017 episodes
GETTING ACTION FROM:
action 2, numVisits=1167019, meanQ=11.932820, numObservations: 4
action 3, numVisits=8, meanQ=7.498750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.295144 0.295758 0.473574 0.945005 0.666981 0.810605 0.561713 0.884516 0.883663 0.3578 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 4, numVisits=34569, meanQ=15.148083, numObservations: 3
action 5, numVisits=12, meanQ=10.082500, numObservations: 4
action 2, numVisits=4, meanQ=9.502525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1260771 episodes
GETTING ACTION FROM:
action 4, numVisits=1295336, meanQ=11.951377, numObservations: 3
action 5, numVisits=14, meanQ=9.570714, numObservations: 4
action 2, numVisits=6, meanQ=8.501683, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.295144 0.295758 0.473574 0.945005 0.666981 0.810605 0.561713 0.884516 0.883663 0.3578 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9.15998
Run # 298
Initial state: 0 0.521267 0.806898 0.362008 0.226692 0.887637 0.521846 0.520103 0.87217 0.812777 0.0175928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 866598 episodes
GETTING ACTION FROM:
action 1, numVisits=866592, meanQ=10.465678, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.521267 0.806898 0.362008 0.226692 0.887637 0.521846 0.520103 0.87217 0.812777 0.0175928 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 299
Initial state: 0 0.311369 0.190382 0.325074 0.309671 0.630727 0.857763 0.828603 0.591777 0.623164 0.822129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 869938 episodes
GETTING ACTION FROM:
action 2, numVisits=869922, meanQ=10.416899, numObservations: 4
action 5, numVisits=4, meanQ=6.500000, numObservations: 2
action 4, numVisits=6, meanQ=5.330033, numObservations: 3
action 3, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.311369 0.190382 0.325074 0.309671 0.630727 0.857763 0.828603 0.591777 0.623164 0.822129 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=251753, meanQ=13.514493, numObservations: 5
action 5, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1163661 episodes
GETTING ACTION FROM:
action 4, numVisits=1415363, meanQ=11.656455, numObservations: 5
action 5, numVisits=55, meanQ=10.354549, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.311369 0.190382 0.325074 0.309671 0.630727 0.857763 0.828603 0.591777 0.623164 0.822129 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 300
Initial state: 0 0.594039 0.860352 0.89865 0.510674 0.5714 0.885544 0.998491 0.0108536 0.439833 0.21317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 861334 episodes
GETTING ACTION FROM:
action 1, numVisits=861326, meanQ=10.194451, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.594039 0.860352 0.89865 0.510674 0.5714 0.885544 0.998491 0.0108536 0.439833 0.21317 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 301
Initial state: 0 0.417395 0.251063 0.570585 0.874491 0.50332 0.870286 0.513623 0.526177 0.520322 0.0285772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 857063 episodes
GETTING ACTION FROM:
action 2, numVisits=857053, meanQ=10.317207, numObservations: 5
action 3, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.417395 0.251063 0.570585 0.874491 0.50332 0.870286 0.513623 0.526177 0.520322 0.0285772 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 302
Initial state: 0 0.114394 0.0852876 0.290156 0.183236 0.624815 0.811401 0.316092 0.196099 0.591963 0.867261 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 862136 episodes
GETTING ACTION FROM:
action 3, numVisits=862128, meanQ=10.468711, numObservations: 4
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.114394 0.0852876 0.290156 0.183236 0.624815 0.811401 0.316092 0.196099 0.591963 0.867261 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 303
Initial state: 0 0.809283 0.515291 0.673836 0.99831 0.666166 0.874633 0.528192 0.859597 0.500758 0.294684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 872403 episodes
GETTING ACTION FROM:
action 1, numVisits=872390, meanQ=10.380949, numObservations: 4
action 5, numVisits=6, meanQ=-2.481650, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.809283 0.515291 0.673836 0.99831 0.666166 0.874633 0.528192 0.859597 0.500758 0.294684 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 304
Initial state: 0 0.461897 0.144421 0.773264 0.0965291 0.579875 0.873929 0.497981 0.970099 0.665997 0.838264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 859659 episodes
GETTING ACTION FROM:
action 1, numVisits=859653, meanQ=10.300453, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.461897 0.144421 0.773264 0.0965291 0.579875 0.873929 0.497981 0.970099 0.665997 0.838264 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=212909, meanQ=13.436379, numObservations: 4
action 4, numVisits=4, meanQ=8.497500, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1171116 episodes
GETTING ACTION FROM:
action 5, numVisits=1378148, meanQ=11.793098, numObservations: 4
action 4, numVisits=5881, meanQ=11.700596, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.461897 0.144421 0.773264 0.0965291 0.579875 0.873929 0.497981 0.970099 0.665997 0.838264 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=42917, meanQ=13.406613, numObservations: 5
action 2, numVisits=16, meanQ=9.928756, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1240678 episodes
GETTING ACTION FROM:
action 3, numVisits=1283595, meanQ=12.156511, numObservations: 5
action 2, numVisits=16, meanQ=9.928756, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.461897 0.144421 0.773264 0.0965291 0.579875 0.873929 0.497981 0.970099 0.665997 0.838264 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 305
Initial state: 0 0.534732 0.813951 0.424727 0.943774 0.504139 0.860932 0.196608 0.496395 0.615182 0.336735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 864094 episodes
GETTING ACTION FROM:
action 4, numVisits=863962, meanQ=10.377132, numObservations: 4
action 3, numVisits=117, meanQ=8.802532, numObservations: 5
action 5, numVisits=5, meanQ=6.602040, numObservations: 2
action 1, numVisits=7, meanQ=5.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.534732 0.813951 0.424727 0.943774 0.504139 0.860932 0.196608 0.496395 0.615182 0.336735 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=214506, meanQ=13.362527, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1184044 episodes
GETTING ACTION FROM:
action 2, numVisits=1398550, meanQ=12.555506, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.534732 0.813951 0.424727 0.943774 0.504139 0.860932 0.196608 0.496395 0.615182 0.336735 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 306
Initial state: 0 0.535735 0.855988 0.290623 0.56819 0.310173 0.0666636 0.53821 0.805668 0.768022 0.646646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 859778 episodes
GETTING ACTION FROM:
action 4, numVisits=859770, meanQ=10.479370, numObservations: 5
action 3, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.535735 0.855988 0.290623 0.56819 0.310173 0.0666636 0.53821 0.805668 0.768022 0.646646 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 307
Initial state: 0 0.606209 0.802502 0.933302 0.915633 0.0756161 0.748578 0.619065 0.877306 0.00142912 0.549755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 867456 episodes
GETTING ACTION FROM:
action 3, numVisits=867450, meanQ=10.434943, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.606209 0.802502 0.933302 0.915633 0.0756161 0.748578 0.619065 0.877306 0.00142912 0.549755 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=249704, meanQ=13.447499, numObservations: 5
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1161263 episodes
GETTING ACTION FROM:
action 2, numVisits=1410967, meanQ=12.369868, numObservations: 5
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.606209 0.802502 0.933302 0.915633 0.0756161 0.748578 0.619065 0.877306 0.00142912 0.549755 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 308
Initial state: 0 0.673744 0.723418 0.621278 0.814239 0.28291 0.713673 0.379946 0.72072 0.520952 0.838222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 876482 episodes
GETTING ACTION FROM:
action 2, numVisits=876466, meanQ=10.327669, numObservations: 4
action 5, numVisits=11, meanQ=2.389100, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.673744 0.723418 0.621278 0.814239 0.28291 0.713673 0.379946 0.72072 0.520952 0.838222 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 309
Initial state: 0 0.169629 0.409129 0.524095 0.877797 0.20895 0.166047 0.801655 0.0207064 0.580664 0.87915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 866860 episodes
GETTING ACTION FROM:
action 3, numVisits=866854, meanQ=10.312474, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.169629 0.409129 0.524095 0.877797 0.20895 0.166047 0.801655 0.0207064 0.580664 0.87915 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 310
Initial state: 0 0.500373 0.814801 0.663038 0.895346 0.552013 0.906181 0.0623221 0.0098242 0.463609 0.401275 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 870523 episodes
GETTING ACTION FROM:
action 1, numVisits=870514, meanQ=10.274213, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.500373 0.814801 0.663038 0.895346 0.552013 0.906181 0.0623221 0.0098242 0.463609 0.401275 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 311
Initial state: 0 0.595824 0.830077 0.484634 0.0879162 0.258859 0.228454 0.758222 0.494484 0.650037 0.877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 870364 episodes
GETTING ACTION FROM:
action 5, numVisits=870358, meanQ=10.294841, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.595824 0.830077 0.484634 0.0879162 0.258859 0.228454 0.758222 0.494484 0.650037 0.877 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 312
Initial state: 0 0.503577 0.822539 0.998293 0.909814 0.964619 0.340872 0.423658 0.100027 0.575568 0.860605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 775358 episodes
GETTING ACTION FROM:
action 1, numVisits=775346, meanQ=10.779854, numObservations: 5
action 4, numVisits=5, meanQ=5.798020, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.503577 0.822539 0.998293 0.909814 0.964619 0.340872 0.423658 0.100027 0.575568 0.860605 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 313
Initial state: 0 0.0703088 0.542709 0.540625 0.828602 0.390748 0.170631 0.644301 0.880833 0.398321 0.803438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 858291 episodes
GETTING ACTION FROM:
action 4, numVisits=858283, meanQ=10.415060, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0703088 0.542709 0.540625 0.828602 0.390748 0.170631 0.644301 0.880833 0.398321 0.803438 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 314
Initial state: 0 0.870712 0.336499 0.172786 0.720665 0.214646 0.762467 0.596516 0.831636 0.664498 0.817287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 836322 episodes
GETTING ACTION FROM:
action 3, numVisits=836301, meanQ=10.161557, numObservations: 5
action 4, numVisits=14, meanQ=7.641429, numObservations: 3
action 5, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.870712 0.336499 0.172786 0.720665 0.214646 0.762467 0.596516 0.831636 0.664498 0.817287 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=207108, meanQ=13.442323, numObservations: 4
action 1, numVisits=12, meanQ=7.831667, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1177462 episodes
GETTING ACTION FROM:
action 2, numVisits=1384570, meanQ=12.078818, numObservations: 4
action 1, numVisits=12, meanQ=7.831667, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.870712 0.336499 0.172786 0.720665 0.214646 0.762467 0.596516 0.831636 0.664498 0.817287 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=163677, meanQ=17.232664, numObservations: 4
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1279278 episodes
GETTING ACTION FROM:
action 1, numVisits=1442955, meanQ=13.514192, numObservations: 4
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.870712 0.336499 0.172786 0.720665 0.214646 0.762467 0.596516 0.831636 0.664498 0.817287 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 315
Initial state: 0 0.214475 0.693688 0.509508 0.813003 0.643152 0.855184 0.233977 0.0537767 0.441313 0.511658 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 850137 episodes
GETTING ACTION FROM:
action 5, numVisits=846654, meanQ=10.265995, numObservations: 5
action 4, numVisits=3478, meanQ=10.146116, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.214475 0.693688 0.509508 0.813003 0.643152 0.855184 0.233977 0.0537767 0.441313 0.511658 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=174384, meanQ=13.609796, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1165732 episodes
GETTING ACTION FROM:
action 4, numVisits=1340116, meanQ=12.237652, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.214475 0.693688 0.509508 0.813003 0.643152 0.855184 0.233977 0.0537767 0.441313 0.511658 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=119498, meanQ=16.726276, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1270826 episodes
GETTING ACTION FROM:
action 3, numVisits=1390324, meanQ=12.448261, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.214475 0.693688 0.509508 0.813003 0.643152 0.855184 0.233977 0.0537767 0.441313 0.511658 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 316
Initial state: 0 0.601294 0.867675 0.12726 0.550768 0.38422 0.929642 0.612836 0.800739 0.164856 0.465011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 781322 episodes
GETTING ACTION FROM:
action 4, numVisits=781311, meanQ=10.466282, numObservations: 4
action 2, numVisits=4, meanQ=0.772500, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.601294 0.867675 0.12726 0.550768 0.38422 0.929642 0.612836 0.800739 0.164856 0.465011 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 317
Initial state: 0 0.892071 0.426976 0.582928 0.870202 0.874885 0.361782 0.63178 0.882167 0.93629 0.907234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 785313 episodes
GETTING ACTION FROM:
action 4, numVisits=785307, meanQ=10.807963, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.892071 0.426976 0.582928 0.870202 0.874885 0.361782 0.63178 0.882167 0.93629 0.907234 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 318
Initial state: 0 0.525681 0.822994 0.446155 0.84444 0.827878 0.558149 0.681149 0.854037 0.183089 0.938651 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 859351 episodes
GETTING ACTION FROM:
action 1, numVisits=859338, meanQ=10.251878, numObservations: 5
action 5, numVisits=6, meanQ=4.661667, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.525681 0.822994 0.446155 0.84444 0.827878 0.558149 0.681149 0.854037 0.183089 0.938651 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 319
Initial state: 0 0.137083 0.607068 0.747396 0.95196 0.636229 0.840922 0.513462 0.839602 0.0635614 0.178028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 621421 episodes
GETTING ACTION FROM:
action 0, numVisits=621404, meanQ=14.177168, numObservations: 6
action 5, numVisits=5, meanQ=0.396020, numObservations: 3
action 3, numVisits=7, meanQ=0.141429, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.137083 0.607068 0.747396 0.95196 0.636229 0.840922 0.513462 0.839602 0.0635614 0.178028 w: 1
Observation: 0 0 0.693793 0 0.993969 0 0.828521 0 0.839264 0 0.0875631 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=146850, meanQ=15.630684, numObservations: 3
action 4, numVisits=8, meanQ=8.001263, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 970993 episodes
GETTING ACTION FROM:
action 2, numVisits=1117843, meanQ=12.062488, numObservations: 3
action 4, numVisits=8, meanQ=8.001263, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.137083 0.607068 0.747396 0.95196 0.636229 0.840922 0.513462 0.839602 0.0635614 0.178028 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 320
Initial state: 0 0.678179 0.888639 0.657031 0.803558 0.894072 0.543562 0.567022 0.292557 0.469028 0.238156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 866254 episodes
GETTING ACTION FROM:
action 3, numVisits=866226, meanQ=10.251003, numObservations: 4
action 4, numVisits=23, meanQ=7.371743, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.678179 0.888639 0.657031 0.803558 0.894072 0.543562 0.567022 0.292557 0.469028 0.238156 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 321
Initial state: 0 0.183422 0.0220747 0.813709 0.424169 0.61593 0.808361 0.666496 0.887237 0.219123 0.110905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 868269 episodes
GETTING ACTION FROM:
action 4, numVisits=868250, meanQ=10.212092, numObservations: 3
action 1, numVisits=11, meanQ=7.272745, numObservations: 3
action 2, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.183422 0.0220747 0.813709 0.424169 0.61593 0.808361 0.666496 0.887237 0.219123 0.110905 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 322
Initial state: 0 0.65026 0.884943 0.379734 0.148346 0.233157 0.262526 0.665349 0.938832 0.540655 0.854812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 851508 episodes
GETTING ACTION FROM:
action 4, numVisits=851500, meanQ=10.416168, numObservations: 5
action 2, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.65026 0.884943 0.379734 0.148346 0.233157 0.262526 0.665349 0.938832 0.540655 0.854812 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 323
Initial state: 0 0.0472172 0.894768 0.428847 0.937977 0.685608 0.825036 0.8894 0.288195 0.687681 0.863981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 867845 episodes
GETTING ACTION FROM:
action 4, numVisits=867833, meanQ=10.435989, numObservations: 4
action 3, numVisits=7, meanQ=2.147186, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.0472172 0.894768 0.428847 0.937977 0.685608 0.825036 0.8894 0.288195 0.687681 0.863981 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 324
Initial state: 0 0.285116 0.112646 0.534045 0.82962 0.580687 0.841922 0.58958 0.366599 0.969911 0.506582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 855034 episodes
GETTING ACTION FROM:
action 3, numVisits=855028, meanQ=10.284877, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.285116 0.112646 0.534045 0.82962 0.580687 0.841922 0.58958 0.366599 0.969911 0.506582 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 325
Initial state: 0 0.950318 0.488302 0.902776 0.0412776 0.943127 0.129178 0.613571 0.815202 0.613338 0.825299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 858468 episodes
GETTING ACTION FROM:
action 1, numVisits=858457, meanQ=10.258360, numObservations: 5
action 4, numVisits=6, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.950318 0.488302 0.902776 0.0412776 0.943127 0.129178 0.613571 0.815202 0.613338 0.825299 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 326
Initial state: 0 0.5163 0.822348 0.88514 0.454773 0.578324 0.881555 0.766911 0.344021 0.339688 0.723783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 864448 episodes
GETTING ACTION FROM:
action 4, numVisits=864437, meanQ=10.237907, numObservations: 4
action 1, numVisits=3, meanQ=2.033333, numObservations: 1
action 3, numVisits=4, meanQ=0.752525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.5163 0.822348 0.88514 0.454773 0.578324 0.881555 0.766911 0.344021 0.339688 0.723783 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 327
Initial state: 0 0.959651 0.00427028 0.58465 0.837159 0.00525886 0.663356 0.694505 0.884202 0.0311733 0.900897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 798909 episodes
GETTING ACTION FROM:
action 5, numVisits=798892, meanQ=10.245186, numObservations: 4
action 3, numVisits=12, meanQ=7.125000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.959651 0.00427028 0.58465 0.837159 0.00525886 0.663356 0.694505 0.884202 0.0311733 0.900897 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 328
Initial state: 0 0.947962 0.984597 0.679021 0.832282 0.781007 0.192278 0.0581246 0.213597 0.552726 0.839342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 850546 episodes
GETTING ACTION FROM:
action 5, numVisits=850540, meanQ=10.316402, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.947962 0.984597 0.679021 0.832282 0.781007 0.192278 0.0581246 0.213597 0.552726 0.839342 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=58858, meanQ=9.854758, numObservations: 5
action 1, numVisits=5, meanQ=5.798020, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1176515 episodes
GETTING ACTION FROM:
action 3, numVisits=1235373, meanQ=10.839993, numObservations: 5
action 1, numVisits=5, meanQ=5.798020, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.947962 0.984597 0.679021 0.832282 0.781007 0.192278 0.0581246 0.213597 0.552726 0.839342 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 329
Initial state: 0 0.59876 0.868572 0.637782 0.347155 0.630832 0.873 0.389925 0.601859 0.440417 0.204707 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879462 episodes
GETTING ACTION FROM:
action 4, numVisits=879450, meanQ=10.385671, numObservations: 5
action 3, numVisits=7, meanQ=5.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.59876 0.868572 0.637782 0.347155 0.630832 0.873 0.389925 0.601859 0.440417 0.204707 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=181687, meanQ=13.432321, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1210264 episodes
GETTING ACTION FROM:
action 2, numVisits=1391951, meanQ=12.001930, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.59876 0.868572 0.637782 0.347155 0.630832 0.873 0.389925 0.601859 0.440417 0.204707 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 330
Initial state: 0 0.880885 0.764748 0.0692097 0.989431 0.586344 0.804344 0.640914 0.887442 0.187883 0.49677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 881867 episodes
GETTING ACTION FROM:
action 5, numVisits=881841, meanQ=10.334287, numObservations: 5
action 3, numVisits=16, meanQ=6.061263, numObservations: 3
action 2, numVisits=6, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.880885 0.764748 0.0692097 0.989431 0.586344 0.804344 0.640914 0.887442 0.187883 0.49677 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=181913, meanQ=13.932703, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1191146 episodes
GETTING ACTION FROM:
action 1, numVisits=1373059, meanQ=12.635688, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.880885 0.764748 0.0692097 0.989431 0.586344 0.804344 0.640914 0.887442 0.187883 0.49677 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 331
Initial state: 0 0.122474 0.734704 0.80742 0.167794 0.64209 0.847181 0.210295 0.438758 0.526409 0.80206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 888206 episodes
GETTING ACTION FROM:
action 4, numVisits=888200, meanQ=10.740562, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.122474 0.734704 0.80742 0.167794 0.64209 0.847181 0.210295 0.438758 0.526409 0.80206 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=183601, meanQ=13.446454, numObservations: 5
action 2, numVisits=244, meanQ=13.010445, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1198812 episodes
GETTING ACTION FROM:
action 2, numVisits=655686, meanQ=11.872797, numObservations: 4
action 5, numVisits=726971, meanQ=11.869488, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.122474 0.734704 0.80742 0.167794 0.64209 0.847181 0.210295 0.438758 0.526409 0.80206 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 332
Initial state: 0 0.313785 0.733648 0.594794 0.893526 0.981942 0.768403 0.716405 0.762213 0.544679 0.861534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 869309 episodes
GETTING ACTION FROM:
action 4, numVisits=869303, meanQ=10.442925, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.313785 0.733648 0.594794 0.893526 0.981942 0.768403 0.716405 0.762213 0.544679 0.861534 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 333
Initial state: 0 0.588075 9.5031e-05 0.721902 0.611144 0.176492 0.329778 0.638419 0.872088 0.517292 0.807086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 874383 episodes
GETTING ACTION FROM:
action 5, numVisits=874375, meanQ=10.210145, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.588075 9.5031e-05 0.721902 0.611144 0.176492 0.329778 0.638419 0.872088 0.517292 0.807086 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 334
Initial state: 0 0.581261 0.882425 0.111189 0.582953 0.122138 0.99211 0.666164 0.846042 0.977405 0.574854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 845203 episodes
GETTING ACTION FROM:
action 4, numVisits=845179, meanQ=10.517438, numObservations: 4
action 2, numVisits=19, meanQ=2.961068, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.581261 0.882425 0.111189 0.582953 0.122138 0.99211 0.666164 0.846042 0.977405 0.574854 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 335
Initial state: 0 0.143928 0.800965 0.636858 0.868783 0.647736 0.836591 0.318319 0.0263772 0.864095 0.929598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 897487 episodes
GETTING ACTION FROM:
action 5, numVisits=897477, meanQ=10.432307, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=5, meanQ=-1.201980, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.143928 0.800965 0.636858 0.868783 0.647736 0.836591 0.318319 0.0263772 0.864095 0.929598 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 336
Initial state: 0 0.667003 0.848852 0.647144 0.882058 0.467012 0.997032 0.118042 0.47716 0.830317 0.142089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 844982 episodes
GETTING ACTION FROM:
action 1, numVisits=844963, meanQ=9.996385, numObservations: 4
action 4, numVisits=14, meanQ=7.363571, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.667003 0.848852 0.647144 0.882058 0.467012 0.997032 0.118042 0.47716 0.830317 0.142089 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 337
Initial state: 0 0.642953 0.823877 0.228591 0.376741 0.352486 0.802756 0.928476 0.377277 0.599871 0.887011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879040 episodes
GETTING ACTION FROM:
action 2, numVisits=879028, meanQ=10.274687, numObservations: 5
action 4, numVisits=3, meanQ=4.670033, numObservations: 2
action 5, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.642953 0.823877 0.228591 0.376741 0.352486 0.802756 0.928476 0.377277 0.599871 0.887011 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=181085, meanQ=13.522969, numObservations: 4
action 3, numVisits=4, meanQ=1.745000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1221568 episodes
GETTING ACTION FROM:
action 5, numVisits=1402653, meanQ=11.718910, numObservations: 4
action 3, numVisits=4, meanQ=1.745000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.642953 0.823877 0.228591 0.376741 0.352486 0.802756 0.928476 0.377277 0.599871 0.887011 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 338
Initial state: 0 0.0412403 0.891131 0.590834 0.45606 0.551997 0.88622 0.501815 0.81745 0.507403 0.601475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 644164 episodes
GETTING ACTION FROM:
action -1, numVisits=644154, meanQ=7.903857, numObservations: 2
action 3, numVisits=5, meanQ=-0.804000, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.0412403 0.891131 0.590834 0.45606 0.551997 0.88622 0.501815 0.81745 0.507403 0.601475 w: 1
Observation: 0 0.0968067 0 0.541802 0 0.570262 0 0.51231 0 0.432025 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=555962, meanQ=10.229290, numObservations: 4
action 1, numVisits=30, meanQ=8.784333, numObservations: 4
action 3, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 978230 episodes
GETTING ACTION FROM:
action 5, numVisits=1534192, meanQ=10.666296, numObservations: 4
action 1, numVisits=30, meanQ=8.784333, numObservations: 4
action 3, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.0412403 0.891131 0.590834 0.45606 0.551997 0.88622 0.501815 0.81745 0.507403 0.601475 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 339
Initial state: 0 0.220517 0.598408 0.535745 0.823994 0.549361 0.831182 0.433885 0.433305 0.743735 0.960333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 857134 episodes
GETTING ACTION FROM:
action 1, numVisits=857111, meanQ=10.553569, numObservations: 4
action 3, numVisits=18, meanQ=5.677789, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.220517 0.598408 0.535745 0.823994 0.549361 0.831182 0.433885 0.433305 0.743735 0.960333 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=247342, meanQ=13.492182, numObservations: 4
action 3, numVisits=14, meanQ=10.856450, numObservations: 3
action 4, numVisits=5, meanQ=5.798020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1213908 episodes
GETTING ACTION FROM:
action 5, numVisits=1461103, meanQ=12.134659, numObservations: 4
action 3, numVisits=161, meanQ=11.520647, numObservations: 4
action 4, numVisits=5, meanQ=5.798020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.220517 0.598408 0.535745 0.823994 0.549361 0.831182 0.433885 0.433305 0.743735 0.960333 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 340
Initial state: 0 0.552543 0.892681 0.915844 0.0261682 0.530577 0.88836 0.726498 0.891648 0.456326 0.0706404 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 890638 episodes
GETTING ACTION FROM:
action 1, numVisits=890630, meanQ=10.404333, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.552543 0.892681 0.915844 0.0261682 0.530577 0.88836 0.726498 0.891648 0.456326 0.0706404 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 341
Initial state: 0 0.441003 0.95292 0.658769 0.832131 0.180834 0.175592 0.562035 0.33216 0.661917 0.853777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 875839 episodes
GETTING ACTION FROM:
action 3, numVisits=875191, meanQ=10.282498, numObservations: 5
action 4, numVisits=620, meanQ=9.679995, numObservations: 4
action 5, numVisits=10, meanQ=7.701010, numObservations: 2
action 1, numVisits=13, meanQ=7.306169, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.441003 0.95292 0.658769 0.832131 0.180834 0.175592 0.562035 0.33216 0.661917 0.853777 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=216096, meanQ=13.503769, numObservations: 5
action 2, numVisits=13, meanQ=7.808462, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1200871 episodes
GETTING ACTION FROM:
action 4, numVisits=1416967, meanQ=12.131100, numObservations: 5
action 2, numVisits=13, meanQ=7.808462, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.441003 0.95292 0.658769 0.832131 0.180834 0.175592 0.562035 0.33216 0.661917 0.853777 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=47300, meanQ=16.166556, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1300072 episodes
GETTING ACTION FROM:
action 5, numVisits=1347372, meanQ=12.240344, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.441003 0.95292 0.658769 0.832131 0.180834 0.175592 0.562035 0.33216 0.661917 0.853777 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 342
Initial state: 0 0.94097 0.583953 0.503503 0.820947 0.99903 0.666398 0.633129 0.882851 0.027038 0.492103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 868979 episodes
GETTING ACTION FROM:
action 4, numVisits=868966, meanQ=10.255051, numObservations: 5
action 1, numVisits=5, meanQ=4.598000, numObservations: 2
action 5, numVisits=4, meanQ=0.772500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.94097 0.583953 0.503503 0.820947 0.99903 0.666398 0.633129 0.882851 0.027038 0.492103 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 343
Initial state: 0 0.518332 0.848884 0.554343 0.893581 0.627134 0.707481 0.392261 0.00128353 0.33804 0.00197219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884736 episodes
GETTING ACTION FROM:
action 3, numVisits=884716, meanQ=10.349131, numObservations: 4
action 1, numVisits=15, meanQ=4.459353, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.518332 0.848884 0.554343 0.893581 0.627134 0.707481 0.392261 0.00128353 0.33804 0.00197219 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 344
Initial state: 0 0.692307 0.845785 0.656108 0.879454 0.316475 0.155973 0.16325 0.710883 0.71842 0.875653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 580467 episodes
GETTING ACTION FROM:
action 0, numVisits=580460, meanQ=13.295834, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.692307 0.845785 0.656108 0.879454 0.316475 0.155973 0.16325 0.710883 0.71842 0.875653 w: 1
Observation: 0 0 0.861111 0 0.787062 0 0.206061 0 0.795364 0 0.972549 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=77095, meanQ=17.669837, numObservations: 4
action 5, numVisits=9, meanQ=14.108889, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 987469 episodes
GETTING ACTION FROM:
action 4, numVisits=1064559, meanQ=11.122292, numObservations: 4
action 5, numVisits=14, meanQ=8.499293, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.692307 0.845785 0.656108 0.879454 0.316475 0.155973 0.16325 0.710883 0.71842 0.875653 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 345
Initial state: 0 0.704652 0.173579 0.546369 0.888862 0.686521 0.829301 0.883291 0.91369 0.712926 0.0155572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 631119 episodes
GETTING ACTION FROM:
action -1, numVisits=631109, meanQ=7.963778, numObservations: 2
action 5, numVisits=5, meanQ=0.396020, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.704652 0.173579 0.546369 0.888862 0.686521 0.829301 0.883291 0.91369 0.712926 0.0155572 w: 1
Observation: 0 0.776508 0 0.564386 0 0.769738 0 0.915409 0 0.746468 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=199664, meanQ=7.648506, numObservations: 5
action 1, numVisits=15, meanQ=4.598000, numObservations: 4
action 4, numVisits=6, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 918100 episodes
GETTING ACTION FROM:
action 2, numVisits=1117764, meanQ=8.794078, numObservations: 5
action 1, numVisits=15, meanQ=4.598000, numObservations: 4
action 4, numVisits=6, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.704652 0.173579 0.546369 0.888862 0.686521 0.829301 0.883291 0.91369 0.712926 0.0155572 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 346
Initial state: 0 0.97831 0.375361 0.781679 0.516262 0.548131 0.866373 0.662125 0.833564 0.0650172 0.777248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 860146 episodes
GETTING ACTION FROM:
action 5, numVisits=860106, meanQ=10.187384, numObservations: 4
action 4, numVisits=35, meanQ=7.350300, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.97831 0.375361 0.781679 0.516262 0.548131 0.866373 0.662125 0.833564 0.0650172 0.777248 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=212649, meanQ=13.466417, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1207042 episodes
GETTING ACTION FROM:
action 4, numVisits=1419691, meanQ=11.660297, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.97831 0.375361 0.781679 0.516262 0.548131 0.866373 0.662125 0.833564 0.0650172 0.777248 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 347
Initial state: 0 0.728769 0.543434 0.58617 0.83834 0.57304 0.826085 0.932326 0.741248 0.316409 0.452194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880623 episodes
GETTING ACTION FROM:
action 1, numVisits=880606, meanQ=10.209169, numObservations: 5
action 5, numVisits=5, meanQ=4.598000, numObservations: 2
action 3, numVisits=6, meanQ=4.330017, numObservations: 2
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.728769 0.543434 0.58617 0.83834 0.57304 0.826085 0.932326 0.741248 0.316409 0.452194 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 348
Initial state: 0 0.246457 0.288633 0.511753 0.831875 0.589065 0.54524 0.760906 0.588199 0.69172 0.828416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 873493 episodes
GETTING ACTION FROM:
action 4, numVisits=873485, meanQ=10.244998, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.246457 0.288633 0.511753 0.831875 0.589065 0.54524 0.760906 0.588199 0.69172 0.828416 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=217421, meanQ=13.379908, numObservations: 5
action 2, numVisits=11, meanQ=7.637309, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1207628 episodes
GETTING ACTION FROM:
action 3, numVisits=1425049, meanQ=12.286615, numObservations: 5
action 2, numVisits=11, meanQ=7.637309, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.246457 0.288633 0.511753 0.831875 0.589065 0.54524 0.760906 0.588199 0.69172 0.828416 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=126311, meanQ=17.713299, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1306562 episodes
GETTING ACTION FROM:
action 2, numVisits=1432873, meanQ=12.508521, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.246457 0.288633 0.511753 0.831875 0.589065 0.54524 0.760906 0.588199 0.69172 0.828416 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 349
Initial state: 0 0.268536 0.758519 0.269929 0.663798 0.54982 0.928753 0.603378 0.818949 0.687875 0.86473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 874052 episodes
GETTING ACTION FROM:
action 4, numVisits=874034, meanQ=10.244989, numObservations: 5
action 1, numVisits=13, meanQ=5.690785, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.268536 0.758519 0.269929 0.663798 0.54982 0.928753 0.603378 0.818949 0.687875 0.86473 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 350
Initial state: 0 0.664586 0.859863 0.218446 0.689075 0.612128 0.877249 0.393964 0.539374 0.628544 0.0889153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 883948 episodes
GETTING ACTION FROM:
action 3, numVisits=883919, meanQ=10.473347, numObservations: 4
action 2, numVisits=20, meanQ=6.449510, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.664586 0.859863 0.218446 0.689075 0.612128 0.877249 0.393964 0.539374 0.628544 0.0889153 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 351
Initial state: 0 0.568957 0.8257 0.64259 0.820126 0.267418 0.36212 0.208846 0.329236 0.863038 0.0518523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877778 episodes
GETTING ACTION FROM:
action 4, numVisits=877766, meanQ=10.391056, numObservations: 4
action 0, numVisits=3, meanQ=-2.333300, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=2, meanQ=-8.950000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.568957 0.8257 0.64259 0.820126 0.267418 0.36212 0.208846 0.329236 0.863038 0.0518523 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=218304, meanQ=13.396125, numObservations: 4
action 1, numVisits=6, meanQ=7.831667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1192355 episodes
GETTING ACTION FROM:
action 2, numVisits=1410659, meanQ=11.710747, numObservations: 4
action 1, numVisits=6, meanQ=7.831667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.568957 0.8257 0.64259 0.820126 0.267418 0.36212 0.208846 0.329236 0.863038 0.0518523 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 352
Initial state: 0 0.570874 0.857209 0.81962 0.920156 0.504518 0.866439 0.172254 0.187409 0.846515 0.71302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 885779 episodes
GETTING ACTION FROM:
action 2, numVisits=885763, meanQ=10.362828, numObservations: 4
action 5, numVisits=7, meanQ=6.282857, numObservations: 2
action 1, numVisits=5, meanQ=3.042000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.570874 0.857209 0.81962 0.920156 0.504518 0.866439 0.172254 0.187409 0.846515 0.71302 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 353
Initial state: 0 0.839959 0.157262 0.838816 0.758538 0.637996 0.813018 0.518136 0.860189 0.125038 0.0288473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 875443 episodes
GETTING ACTION FROM:
action 4, numVisits=875437, meanQ=10.349419, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.839959 0.157262 0.838816 0.758538 0.637996 0.813018 0.518136 0.860189 0.125038 0.0288473 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 354
Initial state: 0 0.570294 0.893662 0.444389 0.271997 0.750201 0.533294 0.529582 0.804422 0.273716 0.304564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880457 episodes
GETTING ACTION FROM:
action 1, numVisits=880451, meanQ=10.292169, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.570294 0.893662 0.444389 0.271997 0.750201 0.533294 0.529582 0.804422 0.273716 0.304564 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 355
Initial state: 0 0.52666 0.80163 0.441918 0.961163 0.10951 0.29928 0.548267 0.82464 0.0726318 0.586654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889405 episodes
GETTING ACTION FROM:
action 3, numVisits=889385, meanQ=10.453883, numObservations: 4
action 4, numVisits=13, meanQ=7.001554, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.52666 0.80163 0.441918 0.961163 0.10951 0.29928 0.548267 0.82464 0.0726318 0.586654 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=256356, meanQ=13.588177, numObservations: 5
action 5, numVisits=20, meanQ=9.450515, numObservations: 3
action 1, numVisits=8, meanQ=8.497500, numObservations: 3
action 2, numVisits=8, meanQ=7.498750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1183460 episodes
GETTING ACTION FROM:
action 4, numVisits=1439816, meanQ=11.944214, numObservations: 5
action 5, numVisits=20, meanQ=9.450515, numObservations: 3
action 1, numVisits=8, meanQ=8.497500, numObservations: 3
action 2, numVisits=8, meanQ=7.498750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.52666 0.80163 0.441918 0.961163 0.10951 0.29928 0.548267 0.82464 0.0726318 0.586654 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 356
Initial state: 0 0.618091 0.602894 0.552831 0.802057 0.222702 0.189802 0.0890759 0.271493 0.519099 0.869528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 874851 episodes
GETTING ACTION FROM:
action 2, numVisits=874835, meanQ=10.276669, numObservations: 5
action 5, numVisits=9, meanQ=6.997789, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.618091 0.602894 0.552831 0.802057 0.222702 0.189802 0.0890759 0.271493 0.519099 0.869528 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 357
Initial state: 0 0.625204 0.809244 0.604624 0.850865 0.66417 0.778049 0.203882 0.0793386 0.511586 0.283512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 892380 episodes
GETTING ACTION FROM:
action 4, numVisits=892374, meanQ=10.293152, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.625204 0.809244 0.604624 0.850865 0.66417 0.778049 0.203882 0.0793386 0.511586 0.283512 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=258047, meanQ=13.542434, numObservations: 4
action 1, numVisits=81, meanQ=12.645655, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1212598 episodes
GETTING ACTION FROM:
action 5, numVisits=1470569, meanQ=12.493085, numObservations: 4
action 1, numVisits=157, meanQ=11.833017, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.625204 0.809244 0.604624 0.850865 0.66417 0.778049 0.203882 0.0793386 0.511586 0.283512 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 358
Initial state: 0 0.158932 0.521206 0.587374 0.898062 0.497081 0.287071 0.50403 0.801772 0.240313 0.0794725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 886828 episodes
GETTING ACTION FROM:
action 2, numVisits=886820, meanQ=10.259880, numObservations: 4
action 1, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.158932 0.521206 0.587374 0.898062 0.497081 0.287071 0.50403 0.801772 0.240313 0.0794725 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 359
Initial state: 0 0.313532 0.815114 0.328824 0.249152 0.608043 0.860265 0.116697 0.982388 0.646346 0.836023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 886220 episodes
GETTING ACTION FROM:
action 3, numVisits=886214, meanQ=10.361064, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.313532 0.815114 0.328824 0.249152 0.608043 0.860265 0.116697 0.982388 0.646346 0.836023 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 360
Initial state: 0 0.623242 0.832682 0.838603 0.913539 0.36335 0.147433 0.721247 0.950391 0.638979 0.879527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 869685 episodes
GETTING ACTION FROM:
action 3, numVisits=869673, meanQ=10.316481, numObservations: 5
action 1, numVisits=7, meanQ=5.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.623242 0.832682 0.838603 0.913539 0.36335 0.147433 0.721247 0.950391 0.638979 0.879527 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=178233, meanQ=13.439400, numObservations: 5
action 5, numVisits=12, meanQ=11.082517, numObservations: 4
action 1, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1192619 episodes
GETTING ACTION FROM:
action 2, numVisits=1370851, meanQ=11.844815, numObservations: 5
action 5, numVisits=13, meanQ=9.383862, numObservations: 4
action 1, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.623242 0.832682 0.838603 0.913539 0.36335 0.147433 0.721247 0.950391 0.638979 0.879527 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 361
Initial state: 0 0.596073 0.825314 0.465979 0.4622 0.542898 0.821815 0.416794 0.0111432 0.853724 0.67155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 881008 episodes
GETTING ACTION FROM:
action 1, numVisits=880978, meanQ=10.368572, numObservations: 5
action 5, numVisits=22, meanQ=4.142741, numObservations: 3
action 3, numVisits=4, meanQ=0.752525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.596073 0.825314 0.465979 0.4622 0.542898 0.821815 0.416794 0.0111432 0.853724 0.67155 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=60642, meanQ=12.120392, numObservations: 3
action 2, numVisits=22, meanQ=7.774559, numObservations: 4
action 5, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 955378 episodes
GETTING ACTION FROM:
action 1, numVisits=1016019, meanQ=9.852086, numObservations: 4
action 2, numVisits=22, meanQ=7.774559, numObservations: 4
action 5, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.596073 0.825314 0.465979 0.4622 0.542898 0.821815 0.416794 0.0111432 0.853724 0.67155 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 362
Initial state: 0 0.608132 0.841637 0.436323 0.70102 0.638408 0.88118 0.891157 0.596895 0.880766 0.657246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 878149 episodes
GETTING ACTION FROM:
action 4, numVisits=878134, meanQ=10.309028, numObservations: 5
action 1, numVisits=10, meanQ=7.250000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.608132 0.841637 0.436323 0.70102 0.638408 0.88118 0.891157 0.596895 0.880766 0.657246 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 363
Initial state: 0 0.682948 0.889261 0.564621 0.83083 0.586356 0.372241 0.542467 0.790311 0.712169 0.0302254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 882892 episodes
GETTING ACTION FROM:
action 5, numVisits=882883, meanQ=10.284822, numObservations: 5
action -1, numVisits=3, meanQ=-3.656600, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.682948 0.889261 0.564621 0.83083 0.586356 0.372241 0.542467 0.790311 0.712169 0.0302254 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 364
Initial state: 0 0.501906 0.886388 0.673211 0.863311 0.418078 0.164607 0.652034 0.0883965 0.77168 0.515094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 849056 episodes
GETTING ACTION FROM:
action 3, numVisits=849031, meanQ=10.208204, numObservations: 4
action 5, numVisits=14, meanQ=7.606429, numObservations: 4
action 2, numVisits=7, meanQ=6.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.501906 0.886388 0.673211 0.863311 0.418078 0.164607 0.652034 0.0883965 0.77168 0.515094 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=244733, meanQ=12.788777, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1124686 episodes
GETTING ACTION FROM:
action 1, numVisits=1369419, meanQ=11.551351, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.501906 0.886388 0.673211 0.863311 0.418078 0.164607 0.652034 0.0883965 0.77168 0.515094 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 365
Initial state: 0 0.186316 0.96426 0.565059 0.812125 0.138746 0.767713 0.521767 0.887507 0.959543 0.983756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880815 episodes
GETTING ACTION FROM:
action 5, numVisits=880809, meanQ=10.428054, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.186316 0.96426 0.565059 0.812125 0.138746 0.767713 0.521767 0.887507 0.959543 0.983756 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 366
Initial state: 0 0.258564 0.766962 0.0600857 0.634834 0.679303 0.809789 0.650489 0.814519 0.0743115 0.865341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 881712 episodes
GETTING ACTION FROM:
action 5, numVisits=881700, meanQ=10.527109, numObservations: 5
action 3, numVisits=7, meanQ=0.998586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.258564 0.766962 0.0600857 0.634834 0.679303 0.809789 0.650489 0.814519 0.0743115 0.865341 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=85121, meanQ=13.354048, numObservations: 5
action 3, numVisits=21, meanQ=10.239524, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1204972 episodes
GETTING ACTION FROM:
action 2, numVisits=876812, meanQ=11.624093, numObservations: 5
action 1, numVisits=413282, meanQ=11.529046, numObservations: 5
action 3, numVisits=22, meanQ=9.274091, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.258564 0.766962 0.0600857 0.634834 0.679303 0.809789 0.650489 0.814519 0.0743115 0.865341 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=62948, meanQ=16.014340, numObservations: 4
action 4, numVisits=6, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1328940 episodes
GETTING ACTION FROM:
action 4, numVisits=1221893, meanQ=13.318577, numObservations: 3
action 1, numVisits=170001, meanQ=12.951861, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.258564 0.766962 0.0600857 0.634834 0.679303 0.809789 0.650489 0.814519 0.0743115 0.865341 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 367
Initial state: 0 0.939331 0.030048 0.534856 0.868565 0.26188 0.661094 0.663162 0.861131 0.422528 0.912032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877256 episodes
GETTING ACTION FROM:
action 3, numVisits=877242, meanQ=10.441822, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 4, numVisits=5, meanQ=-2.402000, numObservations: 4
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.939331 0.030048 0.534856 0.868565 0.26188 0.661094 0.663162 0.861131 0.422528 0.912032 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=217650, meanQ=13.509213, numObservations: 4
action 5, numVisits=4, meanQ=8.497500, numObservations: 2
action 4, numVisits=6, meanQ=8.456667, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1210524 episodes
GETTING ACTION FROM:
action 1, numVisits=1428174, meanQ=12.302289, numObservations: 4
action 5, numVisits=4, meanQ=8.497500, numObservations: 2
action 4, numVisits=6, meanQ=8.456667, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.939331 0.030048 0.534856 0.868565 0.26188 0.661094 0.663162 0.861131 0.422528 0.912032 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 368
Initial state: 0 0.359336 0.247322 0.284208 0.649059 0.594759 0.834982 0.352537 0.446547 0.554883 0.809941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884122 episodes
GETTING ACTION FROM:
action 4, numVisits=883746, meanQ=10.381696, numObservations: 5
action 1, numVisits=369, meanQ=8.857518, numObservations: 4
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.359336 0.247322 0.284208 0.649059 0.594759 0.834982 0.352537 0.446547 0.554883 0.809941 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=35866, meanQ=12.844563, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1196651 episodes
GETTING ACTION FROM:
action 3, numVisits=1232517, meanQ=11.491315, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.359336 0.247322 0.284208 0.649059 0.594759 0.834982 0.352537 0.446547 0.554883 0.809941 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=32146, meanQ=11.675504, numObservations: 5
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1279399 episodes
GETTING ACTION FROM:
action 5, numVisits=1311545, meanQ=11.019936, numObservations: 5
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.359336 0.247322 0.284208 0.649059 0.594759 0.834982 0.352537 0.446547 0.554883 0.809941 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 369
Initial state: 0 0.51155 0.821915 0.112784 0.216982 0.593287 0.891196 0.424156 0.567542 0.0168461 0.930778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 895300 episodes
GETTING ACTION FROM:
action 2, numVisits=895294, meanQ=10.342122, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.51155 0.821915 0.112784 0.216982 0.593287 0.891196 0.424156 0.567542 0.0168461 0.930778 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=258428, meanQ=13.279235, numObservations: 4
action 5, numVisits=17, meanQ=7.240606, numObservations: 4
action 4, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1203890 episodes
GETTING ACTION FROM:
action 1, numVisits=1462318, meanQ=12.047763, numObservations: 4
action 5, numVisits=17, meanQ=7.240606, numObservations: 4
action 4, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.51155 0.821915 0.112784 0.216982 0.593287 0.891196 0.424156 0.567542 0.0168461 0.930778 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=47503, meanQ=12.422319, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1287069 episodes
GETTING ACTION FROM:
action 3, numVisits=1334572, meanQ=12.707064, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.51155 0.821915 0.112784 0.216982 0.593287 0.891196 0.424156 0.567542 0.0168461 0.930778 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 370
Initial state: 0 0.60031 0.3908 0.119239 0.424529 0.352354 0.582847 0.593447 0.854286 0.640335 0.830079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 875615 episodes
GETTING ACTION FROM:
action 2, numVisits=875607, meanQ=10.187881, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.60031 0.3908 0.119239 0.424529 0.352354 0.582847 0.593447 0.854286 0.640335 0.830079 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=216734, meanQ=13.191629, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1193538 episodes
GETTING ACTION FROM:
action 3, numVisits=1410272, meanQ=12.074115, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.60031 0.3908 0.119239 0.424529 0.352354 0.582847 0.593447 0.854286 0.640335 0.830079 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=135678, meanQ=17.051133, numObservations: 4
action 5, numVisits=11, meanQ=9.909100, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1309923 episodes
GETTING ACTION FROM:
action 4, numVisits=1445601, meanQ=13.136474, numObservations: 4
action 5, numVisits=11, meanQ=9.909100, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.60031 0.3908 0.119239 0.424529 0.352354 0.582847 0.593447 0.854286 0.640335 0.830079 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 371
Initial state: 0 0.0781163 0.302248 0.582039 0.84169 0.185395 0.703418 0.520364 0.884454 0.766693 0.132937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 776325 episodes
GETTING ACTION FROM:
action 5, numVisits=776305, meanQ=9.658679, numObservations: 5
action 2, numVisits=11, meanQ=6.317273, numObservations: 3
action 3, numVisits=5, meanQ=5.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.0781163 0.302248 0.582039 0.84169 0.185395 0.703418 0.520364 0.884454 0.766693 0.132937 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 372
Initial state: 0 0.656495 0.859078 0.681121 0.841432 0.775213 0.502216 0.569073 0.282655 0.880658 0.747087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 857510 episodes
GETTING ACTION FROM:
action 3, numVisits=857504, meanQ=10.110234, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.656495 0.859078 0.681121 0.841432 0.775213 0.502216 0.569073 0.282655 0.880658 0.747087 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 373
Initial state: 0 0.492732 0.495291 0.530172 0.857156 0.644302 0.8512 0.350963 0.785131 0.983225 0.959411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 887856 episodes
GETTING ACTION FROM:
action 2, numVisits=887838, meanQ=10.464557, numObservations: 4
action 1, numVisits=11, meanQ=0.010009, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.492732 0.495291 0.530172 0.857156 0.644302 0.8512 0.350963 0.785131 0.983225 0.959411 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 374
Initial state: 0 0.543223 0.874429 0.196437 0.912708 0.61438 0.863506 0.362538 0.266035 0.0665975 0.508783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 864679 episodes
GETTING ACTION FROM:
action 4, numVisits=864673, meanQ=10.379079, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.543223 0.874429 0.196437 0.912708 0.61438 0.863506 0.362538 0.266035 0.0665975 0.508783 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=215060, meanQ=13.487057, numObservations: 5
action 3, numVisits=24, meanQ=7.748754, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1163269 episodes
GETTING ACTION FROM:
action 5, numVisits=1378329, meanQ=12.439532, numObservations: 5
action 3, numVisits=24, meanQ=7.748754, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.543223 0.874429 0.196437 0.912708 0.61438 0.863506 0.362538 0.266035 0.0665975 0.508783 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=149540, meanQ=16.921168, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1306340 episodes
GETTING ACTION FROM:
action 3, numVisits=1455880, meanQ=12.812500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.543223 0.874429 0.196437 0.912708 0.61438 0.863506 0.362538 0.266035 0.0665975 0.508783 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 375
Initial state: 0 0.054842 0.259775 0.944973 0.15497 0.646033 0.829582 0.461585 0.177384 0.680157 0.8085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 882133 episodes
GETTING ACTION FROM:
action 4, numVisits=881998, meanQ=10.375632, numObservations: 4
action 3, numVisits=128, meanQ=9.699033, numObservations: 5
action 1, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.054842 0.259775 0.944973 0.15497 0.646033 0.829582 0.461585 0.177384 0.680157 0.8085 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=219327, meanQ=13.545598, numObservations: 3
action 2, numVisits=26, meanQ=10.800404, numObservations: 5
action 5, numVisits=11, meanQ=10.089100, numObservations: 2
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1213934 episodes
GETTING ACTION FROM:
action 3, numVisits=1433240, meanQ=12.030283, numObservations: 3
action 2, numVisits=46, meanQ=10.844576, numObservations: 5
action 5, numVisits=12, meanQ=8.997508, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.054842 0.259775 0.944973 0.15497 0.646033 0.829582 0.461585 0.177384 0.680157 0.8085 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 376
Initial state: 0 0.101537 0.381216 0.0766665 0.238959 0.445694 0.183308 0.549021 0.863272 0.567984 0.887882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 900871 episodes
GETTING ACTION FROM:
action 3, numVisits=900865, meanQ=10.264455, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.101537 0.381216 0.0766665 0.238959 0.445694 0.183308 0.549021 0.863272 0.567984 0.887882 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=259215, meanQ=13.330487, numObservations: 3
action 1, numVisits=59, meanQ=9.008688, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1219917 episodes
GETTING ACTION FROM:
action 4, numVisits=1479132, meanQ=12.215961, numObservations: 3
action 1, numVisits=59, meanQ=9.008688, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.101537 0.381216 0.0766665 0.238959 0.445694 0.183308 0.549021 0.863272 0.567984 0.887882 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=47298, meanQ=13.137369, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1321067 episodes
GETTING ACTION FROM:
action 1, numVisits=1368365, meanQ=11.991126, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.101537 0.381216 0.0766665 0.238959 0.445694 0.183308 0.549021 0.863272 0.567984 0.887882 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=13495, meanQ=18.092889, numObservations: 4
action 4, numVisits=8, meanQ=9.000012, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1324801 episodes
GETTING ACTION FROM:
action 2, numVisits=1338296, meanQ=12.132317, numObservations: 4
action 4, numVisits=8, meanQ=9.000012, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.101537 0.381216 0.0766665 0.238959 0.445694 0.183308 0.549021 0.863272 0.567984 0.887882 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 4, numVisits=14115, meanQ=18.880077, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1326551 episodes
GETTING ACTION FROM:
action 4, numVisits=1340666, meanQ=12.810805, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.101537 0.381216 0.0766665 0.238959 0.445694 0.183308 0.549021 0.863272 0.567984 0.887882 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 7.29271
Run # 377
Initial state: 0 0.586738 0.816181 0.168032 0.619787 0.987018 0.32317 0.59832 0.847146 0.233062 0.538367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 886424 episodes
GETTING ACTION FROM:
action 1, numVisits=886409, meanQ=10.295243, numObservations: 4
action 3, numVisits=10, meanQ=5.008000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.586738 0.816181 0.168032 0.619787 0.987018 0.32317 0.59832 0.847146 0.233062 0.538367 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 378
Initial state: 0 0.809615 0.602163 0.845402 0.482337 0.100977 0.390153 0.671352 0.841724 0.680302 0.87648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 885887 episodes
GETTING ACTION FROM:
action 4, numVisits=885869, meanQ=10.451067, numObservations: 4
action 1, numVisits=10, meanQ=4.201010, numObservations: 3
action 5, numVisits=4, meanQ=2.252550, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.809615 0.602163 0.845402 0.482337 0.100977 0.390153 0.671352 0.841724 0.680302 0.87648 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 379
Initial state: 0 0.558311 0.89091 0.177729 0.926647 0.708323 0.0496789 0.604269 0.883803 0.469187 0.392563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 594704 episodes
GETTING ACTION FROM:
action -1, numVisits=594695, meanQ=8.867561, numObservations: 2
action 1, numVisits=4, meanQ=-0.252500, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.558311 0.89091 0.177729 0.926647 0.708323 0.0496789 0.604269 0.883803 0.469187 0.392563 w: 1
Observation: 0 0.560299 0 0.212607 0 0.728081 0 0.670058 0 0.540989 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=406290, meanQ=11.045434, numObservations: 4
action 1, numVisits=186, meanQ=9.409380, numObservations: 5
action 2, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 995048 episodes
GETTING ACTION FROM:
action 4, numVisits=1401338, meanQ=10.870376, numObservations: 4
action 1, numVisits=186, meanQ=9.409380, numObservations: 5
action 2, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.558311 0.89091 0.177729 0.926647 0.708323 0.0496789 0.604269 0.883803 0.469187 0.392563 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 380
Initial state: 0 0.524818 0.846517 0.528182 0.820764 0.685325 0.619323 0.429028 0.630216 0.236787 0.581053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 773644 episodes
GETTING ACTION FROM:
action 2, numVisits=773635, meanQ=9.509243, numObservations: 5
action 5, numVisits=4, meanQ=1.247525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.524818 0.846517 0.528182 0.820764 0.685325 0.619323 0.429028 0.630216 0.236787 0.581053 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 381
Initial state: 0 0.850865 0.642422 0.431043 0.673113 0.644868 0.862415 0.505401 0.830314 0.827208 0.430884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 886327 episodes
GETTING ACTION FROM:
action 1, numVisits=886317, meanQ=10.414160, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.850865 0.642422 0.431043 0.673113 0.644868 0.862415 0.505401 0.830314 0.827208 0.430884 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 382
Initial state: 0 0.677998 0.818294 0.357096 0.442 0.921036 0.133287 0.573991 0.868268 0.219007 0.438279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880428 episodes
GETTING ACTION FROM:
action 2, numVisits=880416, meanQ=10.414896, numObservations: 5
action 1, numVisits=7, meanQ=5.715729, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.677998 0.818294 0.357096 0.442 0.921036 0.133287 0.573991 0.868268 0.219007 0.438279 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=181972, meanQ=13.618901, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1219531 episodes
GETTING ACTION FROM:
action 5, numVisits=1401503, meanQ=13.021040, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.677998 0.818294 0.357096 0.442 0.921036 0.133287 0.573991 0.868268 0.219007 0.438279 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 383
Initial state: 0 0.603498 0.884657 0.879174 0.681112 0.76388 0.444077 0.0441636 0.634387 0.593831 0.891163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 881280 episodes
GETTING ACTION FROM:
action 4, numVisits=879061, meanQ=10.767434, numObservations: 5
action 5, numVisits=2162, meanQ=9.961985, numObservations: 5
action 2, numVisits=48, meanQ=9.107298, numObservations: 4
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 4
Next state: 0 0.603498 0.884657 0.879174 0.681112 0.76388 0.444077 0.0441636 0.634387 0.593831 0.891163 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=181621, meanQ=13.652877, numObservations: 4
action 2, numVisits=44, meanQ=12.489334, numObservations: 4
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1224438 episodes
GETTING ACTION FROM:
action 1, numVisits=1405912, meanQ=12.784569, numObservations: 4
action 2, numVisits=191, meanQ=12.222231, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603498 0.884657 0.879174 0.681112 0.76388 0.444077 0.0441636 0.634387 0.593831 0.891163 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 384
Initial state: 0 0.243403 0.70126 0.848167 0.555139 0.188693 0.41571 0.584954 0.813505 0.62015 0.854156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 881105 episodes
GETTING ACTION FROM:
action 1, numVisits=881095, meanQ=10.227694, numObservations: 4
action 5, numVisits=5, meanQ=3.820000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.243403 0.70126 0.848167 0.555139 0.188693 0.41571 0.584954 0.813505 0.62015 0.854156 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=218703, meanQ=13.498954, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1189941 episodes
GETTING ACTION FROM:
action 3, numVisits=1408644, meanQ=12.536370, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.243403 0.70126 0.848167 0.555139 0.188693 0.41571 0.584954 0.813505 0.62015 0.854156 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=119774, meanQ=16.952136, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1322164 episodes
GETTING ACTION FROM:
action 2, numVisits=1441938, meanQ=13.153832, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.243403 0.70126 0.848167 0.555139 0.188693 0.41571 0.584954 0.813505 0.62015 0.854156 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 385
Initial state: 0 0.88825 0.119402 0.64558 0.817679 0.163189 0.429011 0.407229 0.477445 0.547645 0.848955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 876153 episodes
GETTING ACTION FROM:
action 3, numVisits=876145, meanQ=10.274380, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.88825 0.119402 0.64558 0.817679 0.163189 0.429011 0.407229 0.477445 0.547645 0.848955 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=216485, meanQ=13.468947, numObservations: 4
action 5, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1210552 episodes
GETTING ACTION FROM:
action 4, numVisits=1427036, meanQ=11.623158, numObservations: 4
action 5, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.88825 0.119402 0.64558 0.817679 0.163189 0.429011 0.407229 0.477445 0.547645 0.848955 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=58880, meanQ=16.831853, numObservations: 4
action 1, numVisits=86849, meanQ=15.697202, numObservations: 5
action 5, numVisits=13, meanQ=12.846954, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1316476 episodes
GETTING ACTION FROM:
action 2, numVisits=1287833, meanQ=12.976869, numObservations: 4
action 1, numVisits=174364, meanQ=12.964892, numObservations: 5
action 5, numVisits=21, meanQ=10.429067, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.88825 0.119402 0.64558 0.817679 0.163189 0.429011 0.407229 0.477445 0.547645 0.848955 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 386
Initial state: 0 0.655746 0.802261 0.996141 0.164174 0.799632 0.303184 0.435242 0.598125 0.522958 0.87823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 878681 episodes
GETTING ACTION FROM:
action 5, numVisits=878673, meanQ=10.318908, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.655746 0.802261 0.996141 0.164174 0.799632 0.303184 0.435242 0.598125 0.522958 0.87823 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 387
Initial state: 0 0.618117 0.894781 0.695518 0.322539 0.0682246 0.248955 0.146558 0.199764 0.601879 0.855486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880361 episodes
GETTING ACTION FROM:
action 3, numVisits=880351, meanQ=10.223123, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.618117 0.894781 0.695518 0.322539 0.0682246 0.248955 0.146558 0.199764 0.601879 0.855486 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=217806, meanQ=13.351688, numObservations: 5
action 2, numVisits=8, meanQ=9.000013, numObservations: 3
action 1, numVisits=16, meanQ=8.748138, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1187831 episodes
GETTING ACTION FROM:
action 5, numVisits=1405637, meanQ=12.227806, numObservations: 5
action 2, numVisits=8, meanQ=9.000013, numObservations: 3
action 1, numVisits=16, meanQ=8.748138, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.618117 0.894781 0.695518 0.322539 0.0682246 0.248955 0.146558 0.199764 0.601879 0.855486 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 388
Initial state: 0 0.0735492 0.956362 0.518149 0.872469 0.567026 0.806382 0.350885 0.840925 0.901111 0.697464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880584 episodes
GETTING ACTION FROM:
action 3, numVisits=880551, meanQ=10.395266, numObservations: 5
action 1, numVisits=26, meanQ=8.270388, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0735492 0.956362 0.518149 0.872469 0.567026 0.806382 0.350885 0.840925 0.901111 0.697464 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 389
Initial state: 0 0.637062 0.877401 0.679413 0.967259 0.0611428 0.523981 0.0499041 0.0989507 0.514443 0.861602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877620 episodes
GETTING ACTION FROM:
action 2, numVisits=877570, meanQ=10.247023, numObservations: 4
action 4, numVisits=33, meanQ=8.606976, numObservations: 4
action 3, numVisits=9, meanQ=6.997789, numObservations: 4
action 1, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.637062 0.877401 0.679413 0.967259 0.0611428 0.523981 0.0499041 0.0989507 0.514443 0.861602 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 390
Initial state: 0 0.563322 0.989164 0.14594 0.223399 0.645461 0.811152 0.565727 0.832303 0.321537 0.471152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 886758 episodes
GETTING ACTION FROM:
action 3, numVisits=886740, meanQ=10.768571, numObservations: 5
action 2, numVisits=7, meanQ=2.424286, numObservations: 3
action 5, numVisits=7, meanQ=1.855743, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.563322 0.989164 0.14594 0.223399 0.645461 0.811152 0.565727 0.832303 0.321537 0.471152 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 391
Initial state: 0 0.360233 0.111036 0.625443 0.889418 0.879204 0.744598 0.515334 0.858998 0.782186 0.308064 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 888557 episodes
GETTING ACTION FROM:
action 4, numVisits=888529, meanQ=10.409144, numObservations: 4
action 5, numVisits=21, meanQ=6.999057, numObservations: 4
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.360233 0.111036 0.625443 0.889418 0.879204 0.744598 0.515334 0.858998 0.782186 0.308064 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 392
Initial state: 0 0.801024 0.587659 0.221051 0.601891 0.989517 0.969672 0.687866 0.827108 0.587038 0.834683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877943 episodes
GETTING ACTION FROM:
action 1, numVisits=877937, meanQ=10.205340, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.801024 0.587659 0.221051 0.601891 0.989517 0.969672 0.687866 0.827108 0.587038 0.834683 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=61091, meanQ=10.014176, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1103203 episodes
GETTING ACTION FROM:
action 4, numVisits=1164294, meanQ=11.116579, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.801024 0.587659 0.221051 0.601891 0.989517 0.969672 0.687866 0.827108 0.587038 0.834683 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 393
Initial state: 0 0.776056 0.0667689 0.0399405 0.499125 0.41045 0.569044 0.648077 0.882042 0.506366 0.858153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 881166 episodes
GETTING ACTION FROM:
action 5, numVisits=881158, meanQ=10.203155, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.776056 0.0667689 0.0399405 0.499125 0.41045 0.569044 0.648077 0.882042 0.506366 0.858153 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 394
Initial state: 0 0.663574 0.882328 0.579908 0.893367 0.540262 0.426302 0.150594 0.0687691 0.316293 0.758611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879506 episodes
GETTING ACTION FROM:
action 4, numVisits=829299, meanQ=10.305997, numObservations: 4
action 3, numVisits=45075, meanQ=10.160461, numObservations: 5
action 2, numVisits=5114, meanQ=10.095644, numObservations: 4
action 5, numVisits=15, meanQ=7.207353, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.663574 0.882328 0.579908 0.893367 0.540262 0.426302 0.150594 0.0687691 0.316293 0.758611 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=206684, meanQ=13.438861, numObservations: 4
action 1, numVisits=22, meanQ=8.118200, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1205036 episodes
GETTING ACTION FROM:
action 2, numVisits=1411720, meanQ=12.287724, numObservations: 4
action 1, numVisits=22, meanQ=8.118200, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.663574 0.882328 0.579908 0.893367 0.540262 0.426302 0.150594 0.0687691 0.316293 0.758611 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=47501, meanQ=13.124243, numObservations: 4
action 3, numVisits=8, meanQ=10.246263, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action 5, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1306662 episodes
GETTING ACTION FROM:
action 1, numVisits=1354163, meanQ=12.982656, numObservations: 4
action 3, numVisits=8, meanQ=10.246263, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action 5, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.663574 0.882328 0.579908 0.893367 0.540262 0.426302 0.150594 0.0687691 0.316293 0.758611 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 395
Initial state: 0 0.370977 0.823586 0.159185 0.339749 0.678567 0.855069 0.687364 0.854922 0.214254 0.64418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 892531 episodes
GETTING ACTION FROM:
action 1, numVisits=892519, meanQ=10.435916, numObservations: 4
action 4, numVisits=5, meanQ=6.196000, numObservations: 3
action 2, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.370977 0.823586 0.159185 0.339749 0.678567 0.855069 0.687364 0.854922 0.214254 0.64418 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=35960, meanQ=13.257846, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1208208 episodes
GETTING ACTION FROM:
action 4, numVisits=1244168, meanQ=11.230245, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.370977 0.823586 0.159185 0.339749 0.678567 0.855069 0.687364 0.854922 0.214254 0.64418 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 396
Initial state: 0 0.960361 0.478515 0.678659 0.811996 0.200737 0.522144 0.0526791 0.476359 0.592132 0.806722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 886045 episodes
GETTING ACTION FROM:
action 3, numVisits=886024, meanQ=10.832446, numObservations: 5
action 2, numVisits=7, meanQ=5.141429, numObservations: 4
action 5, numVisits=8, meanQ=5.121250, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.960361 0.478515 0.678659 0.811996 0.200737 0.522144 0.0526791 0.476359 0.592132 0.806722 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=219490, meanQ=13.814020, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1189887 episodes
GETTING ACTION FROM:
action 4, numVisits=1409377, meanQ=12.660817, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.960361 0.478515 0.678659 0.811996 0.200737 0.522144 0.0526791 0.476359 0.592132 0.806722 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=58549, meanQ=16.184961, numObservations: 5
action 5, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1292096 episodes
GETTING ACTION FROM:
action 1, numVisits=1350644, meanQ=13.033691, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.960361 0.478515 0.678659 0.811996 0.200737 0.522144 0.0526791 0.476359 0.592132 0.806722 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 397
Initial state: 0 0.797095 0.57289 0.507054 0.897874 0.51625 0.834645 0.0242101 0.942484 0.0950724 0.0869962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 888803 episodes
GETTING ACTION FROM:
action 1, numVisits=888779, meanQ=10.249908, numObservations: 4
action 5, numVisits=16, meanQ=7.733125, numObservations: 3
action 3, numVisits=4, meanQ=6.500000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.797095 0.57289 0.507054 0.897874 0.51625 0.834645 0.0242101 0.942484 0.0950724 0.0869962 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 398
Initial state: 0 0.921557 0.376745 0.283488 0.467525 0.511064 0.862809 0.873407 0.61407 0.599571 0.897213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880315 episodes
GETTING ACTION FROM:
action 2, numVisits=880299, meanQ=10.460706, numObservations: 4
action 3, numVisits=11, meanQ=1.682727, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.921557 0.376745 0.283488 0.467525 0.511064 0.862809 0.873407 0.61407 0.599571 0.897213 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=254216, meanQ=13.506497, numObservations: 5
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1203461 episodes
GETTING ACTION FROM:
action 1, numVisits=1457677, meanQ=12.180341, numObservations: 5
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.921557 0.376745 0.283488 0.467525 0.511064 0.862809 0.873407 0.61407 0.599571 0.897213 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=47251, meanQ=14.031332, numObservations: 4
action 5, numVisits=22, meanQ=8.999555, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1280290 episodes
GETTING ACTION FROM:
action 5, numVisits=576000, meanQ=11.821548, numObservations: 4
action 1, numVisits=751563, meanQ=10.042938, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.921557 0.376745 0.283488 0.467525 0.511064 0.862809 0.873407 0.61407 0.599571 0.897213 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 399
Initial state: 0 0.75711 0.63006 0.633045 0.829444 0.0192181 0.482274 0.158088 0.0124599 0.671092 0.836035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 882602 episodes
GETTING ACTION FROM:
action 1, numVisits=882591, meanQ=10.265316, numObservations: 4
action 3, numVisits=6, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.75711 0.63006 0.633045 0.829444 0.0192181 0.482274 0.158088 0.0124599 0.671092 0.836035 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=254853, meanQ=13.296095, numObservations: 4
action 4, numVisits=9, meanQ=9.332222, numObservations: 3
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action 3, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1202232 episodes
GETTING ACTION FROM:
action 5, numVisits=1457085, meanQ=12.318466, numObservations: 4
action 4, numVisits=9, meanQ=9.332222, numObservations: 3
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action 3, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.75711 0.63006 0.633045 0.829444 0.0192181 0.482274 0.158088 0.0124599 0.671092 0.836035 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 400
Initial state: 0 0.661485 0.413104 0.650345 0.820657 0.0619999 0.19622 0.112215 0.576709 0.675931 0.882498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 878564 episodes
GETTING ACTION FROM:
action 1, numVisits=878554, meanQ=10.224924, numObservations: 3
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.661485 0.413104 0.650345 0.820657 0.0619999 0.19622 0.112215 0.576709 0.675931 0.882498 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 401
Initial state: 0 0.453676 0.297217 0.674239 0.835844 0.67438 0.807137 0.448556 0.368987 0.7738 0.216611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 855816 episodes
GETTING ACTION FROM:
action 5, numVisits=855791, meanQ=10.377653, numObservations: 4
action 1, numVisits=20, meanQ=5.201015, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.453676 0.297217 0.674239 0.835844 0.67438 0.807137 0.448556 0.368987 0.7738 0.216611 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 402
Initial state: 0 0.695417 0.880183 0.237719 0.3077 0.366018 0.964802 0.486896 0.534393 0.591917 0.838462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 867527 episodes
GETTING ACTION FROM:
action 5, numVisits=854579, meanQ=10.343074, numObservations: 5
action 1, numVisits=12934, meanQ=10.256290, numObservations: 4
action 4, numVisits=10, meanQ=7.899010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.695417 0.880183 0.237719 0.3077 0.366018 0.964802 0.486896 0.534393 0.591917 0.838462 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 403
Initial state: 0 0.7995 0.536466 0.208793 0.367079 0.602525 0.808644 0.649493 0.818334 0.176549 0.410851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 881313 episodes
GETTING ACTION FROM:
action 3, numVisits=881290, meanQ=10.380628, numObservations: 4
action 5, numVisits=10, meanQ=7.709000, numObservations: 3
action 1, numVisits=9, meanQ=5.466667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.7995 0.536466 0.208793 0.367079 0.602525 0.808644 0.649493 0.818334 0.176549 0.410851 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 404
Initial state: 0 0.273436 0.963007 0.6384 0.881903 0.800195 0.0358067 0.224962 0.613093 0.576563 0.876165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 874937 episodes
GETTING ACTION FROM:
action 1, numVisits=874923, meanQ=10.318879, numObservations: 5
action 4, numVisits=5, meanQ=5.020020, numObservations: 2
action 2, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.273436 0.963007 0.6384 0.881903 0.800195 0.0358067 0.224962 0.613093 0.576563 0.876165 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 405
Initial state: 0 0.578993 0.891632 0.568436 0.421383 0.855598 0.790206 0.637954 0.827603 0.120717 0.212538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 882136 episodes
GETTING ACTION FROM:
action 4, numVisits=882130, meanQ=10.273207, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.578993 0.891632 0.568436 0.421383 0.855598 0.790206 0.637954 0.827603 0.120717 0.212538 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 406
Initial state: 0 0.725921 0.385185 0.549908 0.894735 0.501283 0.89307 0.299831 0.0288949 0.29349 0.612498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 871970 episodes
GETTING ACTION FROM:
action 4, numVisits=871958, meanQ=10.199113, numObservations: 4
action 3, numVisits=7, meanQ=2.997171, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.725921 0.385185 0.549908 0.894735 0.501283 0.89307 0.299831 0.0288949 0.29349 0.612498 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=216554, meanQ=13.505680, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1195232 episodes
GETTING ACTION FROM:
action 1, numVisits=1411786, meanQ=11.980419, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.725921 0.385185 0.549908 0.894735 0.501283 0.89307 0.299831 0.0288949 0.29349 0.612498 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 407
Initial state: 0 0.529097 0.563203 0.643479 0.416697 0.690429 0.899138 0.536799 0.629096 0.652251 0.885724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 875205 episodes
GETTING ACTION FROM:
action 3, numVisits=875193, meanQ=10.174580, numObservations: 5
action 2, numVisits=5, meanQ=6.196000, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.529097 0.563203 0.643479 0.416697 0.690429 0.899138 0.536799 0.629096 0.652251 0.885724 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 408
Initial state: 0 0.530385 0.83671 0.150445 0.967921 0.510355 0.823377 0.898073 0.145479 0.781336 0.925756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 876714 episodes
GETTING ACTION FROM:
action 4, numVisits=876698, meanQ=10.422456, numObservations: 5
action 3, numVisits=5, meanQ=5.402020, numObservations: 1
action 5, numVisits=7, meanQ=5.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 2 0.530385 0.83671 0.150445 0.967921 0.510355 0.823377 0.898073 0.145479 0.781336 0.925756 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 409
Initial state: 0 0.631079 0.819997 0.535475 0.83035 0.476175 0.493673 0.272839 0.248579 0.367243 0.512905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 891687 episodes
GETTING ACTION FROM:
action 2, numVisits=891681, meanQ=10.274297, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.631079 0.819997 0.535475 0.83035 0.476175 0.493673 0.272839 0.248579 0.367243 0.512905 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 410
Initial state: 0 0.373432 0.0613804 0.563446 0.825612 0.421115 0.999491 0.857407 0.230657 0.564787 0.827418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 865614 episodes
GETTING ACTION FROM:
action 4, numVisits=865591, meanQ=10.226685, numObservations: 5
action 5, numVisits=13, meanQ=4.305385, numObservations: 4
action 1, numVisits=6, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.373432 0.0613804 0.563446 0.825612 0.421115 0.999491 0.857407 0.230657 0.564787 0.827418 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 411
Initial state: 0 0.379488 0.292332 0.681196 0.834179 0.686703 0.816009 0.713724 0.684096 0.765646 0.488804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 882780 episodes
GETTING ACTION FROM:
action 2, numVisits=882774, meanQ=10.447155, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.379488 0.292332 0.681196 0.834179 0.686703 0.816009 0.713724 0.684096 0.765646 0.488804 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=61122, meanQ=12.238809, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1073439 episodes
GETTING ACTION FROM:
action 2, numVisits=1134561, meanQ=10.596035, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.379488 0.292332 0.681196 0.834179 0.686703 0.816009 0.713724 0.684096 0.765646 0.488804 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 412
Initial state: 0 0.56631 0.828703 0.294157 0.573769 0.749303 0.339819 0.432279 0.43784 0.583906 0.825667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884996 episodes
GETTING ACTION FROM:
action 4, numVisits=884971, meanQ=10.429879, numObservations: 5
action 5, numVisits=18, meanQ=8.625556, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.56631 0.828703 0.294157 0.573769 0.749303 0.339819 0.432279 0.43784 0.583906 0.825667 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=219461, meanQ=13.477826, numObservations: 4
action 1, numVisits=27, meanQ=9.185189, numObservations: 4
action 3, numVisits=9, meanQ=8.444444, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1207700 episodes
GETTING ACTION FROM:
action 2, numVisits=1427161, meanQ=12.014181, numObservations: 4
action 1, numVisits=27, meanQ=9.185189, numObservations: 4
action 3, numVisits=9, meanQ=8.444444, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.56631 0.828703 0.294157 0.573769 0.749303 0.339819 0.432279 0.43784 0.583906 0.825667 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=168656, meanQ=16.779979, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1328663 episodes
GETTING ACTION FROM:
action 1, numVisits=1497319, meanQ=13.398290, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.56631 0.828703 0.294157 0.573769 0.749303 0.339819 0.432279 0.43784 0.583906 0.825667 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 413
Initial state: 0 0.483313 0.0357302 0.619235 0.835773 0.509012 0.890198 0.137117 0.396883 0.808119 0.136022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 869028 episodes
GETTING ACTION FROM:
action 2, numVisits=869020, meanQ=10.376303, numObservations: 4
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.483313 0.0357302 0.619235 0.835773 0.509012 0.890198 0.137117 0.396883 0.808119 0.136022 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 414
Initial state: 0 0.820396 0.037061 0.789283 0.753439 0.385354 0.663278 0.623785 0.889927 0.631366 0.830157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 860379 episodes
GETTING ACTION FROM:
action 5, numVisits=860367, meanQ=10.062177, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.820396 0.037061 0.789283 0.753439 0.385354 0.663278 0.623785 0.889927 0.631366 0.830157 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 415
Initial state: 0 0.586451 0.802248 0.566566 0.897804 0.393974 0.322401 0.3344 0.902946 0.499102 0.613637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 883772 episodes
GETTING ACTION FROM:
action 5, numVisits=883731, meanQ=10.396070, numObservations: 4
action 2, numVisits=28, meanQ=4.262857, numObservations: 5
action 3, numVisits=6, meanQ=3.330000, numObservations: 3
action 4, numVisits=4, meanQ=2.750025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 0 0.586451 0.802248 0.566566 0.897804 0.393974 0.322401 0.3344 0.902946 0.499102 0.613637 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=254938, meanQ=13.796085, numObservations: 5
action 4, numVisits=19, meanQ=6.738437, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1211670 episodes
GETTING ACTION FROM:
action 1, numVisits=1466608, meanQ=12.088971, numObservations: 5
action 4, numVisits=19, meanQ=6.738437, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.586451 0.802248 0.566566 0.897804 0.393974 0.322401 0.3344 0.902946 0.499102 0.613637 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 416
Initial state: 0 0.783674 0.635851 0.654119 0.811031 0.651922 0.80865 0.685157 0.698623 0.0971042 0.164424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 875167 episodes
GETTING ACTION FROM:
action 5, numVisits=875152, meanQ=10.280599, numObservations: 5
action 2, numVisits=10, meanQ=3.799000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.783674 0.635851 0.654119 0.811031 0.651922 0.80865 0.685157 0.698623 0.0971042 0.164424 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 417
Initial state: 0 0.523278 0.328362 0.630995 0.8763 0.517142 0.871309 0.106138 0.755562 0.0322971 0.779904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884502 episodes
GETTING ACTION FROM:
action 5, numVisits=884494, meanQ=10.455606, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.523278 0.328362 0.630995 0.8763 0.517142 0.871309 0.106138 0.755562 0.0322971 0.779904 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=220136, meanQ=13.812807, numObservations: 4
action 3, numVisits=10, meanQ=6.801030, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1219824 episodes
GETTING ACTION FROM:
action 1, numVisits=1439960, meanQ=12.393827, numObservations: 4
action 3, numVisits=10, meanQ=6.801030, numObservations: 3
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.523278 0.328362 0.630995 0.8763 0.517142 0.871309 0.106138 0.755562 0.0322971 0.779904 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=53535, meanQ=17.178758, numObservations: 4
action 3, numVisits=6, meanQ=7.831667, numObservations: 1
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1318351 episodes
GETTING ACTION FROM:
action 2, numVisits=1371886, meanQ=13.156931, numObservations: 4
action 3, numVisits=6, meanQ=7.831667, numObservations: 1
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.523278 0.328362 0.630995 0.8763 0.517142 0.871309 0.106138 0.755562 0.0322971 0.779904 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 4, numVisits=14533, meanQ=15.035738, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1322734 episodes
GETTING ACTION FROM:
action 4, numVisits=1337267, meanQ=12.411487, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.523278 0.328362 0.630995 0.8763 0.517142 0.871309 0.106138 0.755562 0.0322971 0.779904 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=8236, meanQ=21.686576, numObservations: 4
action 3, numVisits=5, meanQ=18.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1355708 episodes
GETTING ACTION FROM:
action 2, numVisits=1363909, meanQ=13.461094, numObservations: 4
action 3, numVisits=40, meanQ=11.949750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.523278 0.328362 0.630995 0.8763 0.517142 0.871309 0.106138 0.755562 0.0322971 0.779904 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 5
Improving policy...
PLANNING FROM:
action 3, numVisits=1467, meanQ=18.949372, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1320319 episodes
GETTING ACTION FROM:
action 3, numVisits=1321785, meanQ=11.975161, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.523278 0.328362 0.630995 0.8763 0.517142 0.871309 0.106138 0.755562 0.0322971 0.779904 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 3.21978
Run # 418
Initial state: 0 0.921485 0.0338643 0.0155216 0.171655 0.696389 0.863171 0.727008 0.638304 0.670097 0.881567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 876641 episodes
GETTING ACTION FROM:
action 2, numVisits=876626, meanQ=10.241785, numObservations: 5
action 3, numVisits=5, meanQ=6.602040, numObservations: 2
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action 5, numVisits=4, meanQ=3.742500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.921485 0.0338643 0.0155216 0.171655 0.696389 0.863171 0.727008 0.638304 0.670097 0.881567 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 419
Initial state: 0 0.854321 0.746536 0.654852 0.818242 0.221805 0.369032 0.523871 0.835473 0.967478 0.0609542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 885386 episodes
GETTING ACTION FROM:
action 5, numVisits=885378, meanQ=10.290018, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.854321 0.746536 0.654852 0.818242 0.221805 0.369032 0.523871 0.835473 0.967478 0.0609542 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 420
Initial state: 0 0.3581 0.233412 0.260972 0.903155 0.87439 0.291928 0.629113 0.832751 0.68042 0.860168 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 808822 episodes
GETTING ACTION FROM:
action 4, numVisits=808813, meanQ=10.971590, numObservations: 4
action 2, numVisits=4, meanQ=-0.252500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.3581 0.233412 0.260972 0.903155 0.87439 0.291928 0.629113 0.832751 0.68042 0.860168 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 421
Initial state: 0 0.893325 0.105202 0.551746 0.811328 0.314583 0.417812 0.835991 0.920149 0.62895 0.812494 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 883385 episodes
GETTING ACTION FROM:
action 2, numVisits=883374, meanQ=10.275629, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=4, meanQ=1.745000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.893325 0.105202 0.551746 0.811328 0.314583 0.417812 0.835991 0.920149 0.62895 0.812494 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 422
Initial state: 0 0.640576 0.872989 0.428976 0.385922 0.139046 0.0390308 0.576976 0.251727 0.610362 0.838819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 891184 episodes
GETTING ACTION FROM:
action 1, numVisits=891169, meanQ=10.469409, numObservations: 4
action 3, numVisits=6, meanQ=6.500000, numObservations: 2
action 4, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.640576 0.872989 0.428976 0.385922 0.139046 0.0390308 0.576976 0.251727 0.610362 0.838819 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 423
Initial state: 0 0.0671328 0.346583 0.575932 0.274291 0.131678 0.75932 0.592518 0.803034 0.65684 0.86307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 626751 episodes
GETTING ACTION FROM:
action -1, numVisits=626744, meanQ=8.274812, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.0671328 0.346583 0.575932 0.274291 0.131678 0.75932 0.592518 0.803034 0.65684 0.86307 w: 1
Observation: 0 0.0846879 0 0.542036 0 0.100726 0 0.500181 0 0.703479 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=269373, meanQ=10.614282, numObservations: 4
action 2, numVisits=69, meanQ=9.648630, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 963287 episodes
GETTING ACTION FROM:
action 5, numVisits=1232648, meanQ=10.222568, numObservations: 4
action 2, numVisits=81, meanQ=9.147261, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.0671328 0.346583 0.575932 0.274291 0.131678 0.75932 0.592518 0.803034 0.65684 0.86307 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 424
Initial state: 0 0.307282 0.25676 0.51822 0.875508 0.580916 0.856192 0.058475 0.460969 0.879295 0.0514246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 638047 episodes
GETTING ACTION FROM:
action 0, numVisits=638040, meanQ=13.070369, numObservations: 6
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.307282 0.25676 0.51822 0.875508 0.580916 0.856192 0.058475 0.460969 0.879295 0.0514246 w: 1
Observation: 0 0 0.27142 0 0.901658 0 0.88655 0 0.387732 0 0.0607127 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=28487, meanQ=22.397513, numObservations: 4
action 2, numVisits=3, meanQ=14.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 977617 episodes
GETTING ACTION FROM:
action 3, numVisits=1006092, meanQ=9.937674, numObservations: 4
action 2, numVisits=15, meanQ=7.466027, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.307282 0.25676 0.51822 0.875508 0.580916 0.856192 0.058475 0.460969 0.879295 0.0514246 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 425
Initial state: 0 0.373091 0.155839 0.51789 0.0116907 0.697171 0.87286 0.662686 0.824666 0.763486 0.488979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 891164 episodes
GETTING ACTION FROM:
action 1, numVisits=891131, meanQ=10.392903, numObservations: 4
action 4, numVisits=19, meanQ=8.682632, numObservations: 5
action 2, numVisits=8, meanQ=7.012500, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.373091 0.155839 0.51789 0.0116907 0.697171 0.87286 0.662686 0.824666 0.763486 0.488979 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=220741, meanQ=13.463262, numObservations: 4
action 3, numVisits=17, meanQ=7.207665, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1198099 episodes
GETTING ACTION FROM:
action 5, numVisits=1418840, meanQ=11.672985, numObservations: 4
action 3, numVisits=17, meanQ=7.207665, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.373091 0.155839 0.51789 0.0116907 0.697171 0.87286 0.662686 0.824666 0.763486 0.488979 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 426
Initial state: 0 0.908217 0.536299 0.591711 0.838211 0.528825 0.856407 0.633406 0.740736 0.536013 0.358504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 887789 episodes
GETTING ACTION FROM:
action 4, numVisits=887779, meanQ=10.440657, numObservations: 4
action 2, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.908217 0.536299 0.591711 0.838211 0.528825 0.856407 0.633406 0.740736 0.536013 0.358504 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=256944, meanQ=13.505804, numObservations: 5
action 1, numVisits=9, meanQ=10.666678, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1188374 episodes
GETTING ACTION FROM:
action 5, numVisits=1445311, meanQ=11.734692, numObservations: 5
action 1, numVisits=16, meanQ=8.999394, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.908217 0.536299 0.591711 0.838211 0.528825 0.856407 0.633406 0.740736 0.536013 0.358504 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=47627, meanQ=14.127473, numObservations: 3
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 4, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1325955 episodes
GETTING ACTION FROM:
action 3, numVisits=1105716, meanQ=12.074924, numObservations: 3
action 5, numVisits=267870, meanQ=11.340704, numObservations: 3
action 4, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.908217 0.536299 0.591711 0.838211 0.528825 0.856407 0.633406 0.740736 0.536013 0.358504 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 427
Initial state: 0 0.495773 0.639396 0.366542 0.928715 0.513541 0.0318316 0.503357 0.812564 0.639001 0.809172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 876260 episodes
GETTING ACTION FROM:
action 3, numVisits=876252, meanQ=10.371455, numObservations: 5
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.495773 0.639396 0.366542 0.928715 0.513541 0.0318316 0.503357 0.812564 0.639001 0.809172 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=85158, meanQ=13.591365, numObservations: 4
action 2, numVisits=42, meanQ=10.482626, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1195652 episodes
GETTING ACTION FROM:
action 4, numVisits=1280810, meanQ=11.871642, numObservations: 4
action 2, numVisits=42, meanQ=10.482626, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.495773 0.639396 0.366542 0.928715 0.513541 0.0318316 0.503357 0.812564 0.639001 0.809172 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 428
Initial state: 0 0.588264 0.881131 0.685501 0.83238 0.0528543 0.712771 0.273064 0.849332 0.747955 0.249955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 851569 episodes
GETTING ACTION FROM:
action 5, numVisits=850998, meanQ=10.220033, numObservations: 5
action 1, numVisits=566, meanQ=9.572626, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.588264 0.881131 0.685501 0.83238 0.0528543 0.712771 0.273064 0.849332 0.747955 0.249955 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 429
Initial state: 0 0.544938 0.883426 0.617902 0.870775 0.74595 0.554989 0.631845 0.431863 0.105063 0.78222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 868234 episodes
GETTING ACTION FROM:
action 4, numVisits=868221, meanQ=10.175436, numObservations: 5
action 1, numVisits=8, meanQ=6.091275, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.544938 0.883426 0.617902 0.870775 0.74595 0.554989 0.631845 0.431863 0.105063 0.78222 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 430
Initial state: 0 0.859138 0.107679 0.541136 0.842011 0.0837669 0.313115 0.8258 0.0465241 0.559996 0.843317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 883780 episodes
GETTING ACTION FROM:
action 5, numVisits=883772, meanQ=10.791578, numObservations: 5
action 1, numVisits=3, meanQ=0.666667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.859138 0.107679 0.541136 0.842011 0.0837669 0.313115 0.8258 0.0465241 0.559996 0.843317 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 431
Initial state: 0 0.231652 0.180697 0.489132 0.119138 0.565324 0.815389 0.556622 0.879623 0.0393622 0.671996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 885791 episodes
GETTING ACTION FROM:
action 2, numVisits=885785, meanQ=10.413628, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.231652 0.180697 0.489132 0.119138 0.565324 0.815389 0.556622 0.879623 0.0393622 0.671996 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=219635, meanQ=13.510858, numObservations: 4
action 1, numVisits=15, meanQ=8.190000, numObservations: 3
action 5, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1194846 episodes
GETTING ACTION FROM:
action 3, numVisits=1414481, meanQ=12.084915, numObservations: 4
action 1, numVisits=15, meanQ=8.190000, numObservations: 3
action 5, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.231652 0.180697 0.489132 0.119138 0.565324 0.815389 0.556622 0.879623 0.0393622 0.671996 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 432
Initial state: 0 0.508878 0.809851 0.671076 0.881146 0.0879122 0.406982 0.306789 0.143391 0.872748 0.567108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 584299 episodes
GETTING ACTION FROM:
action -1, numVisits=584292, meanQ=7.775663, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.508878 0.809851 0.671076 0.881146 0.0879122 0.406982 0.306789 0.143391 0.872748 0.567108 w: 1
Observation: 0 0.438542 0 0.743101 0 0.157673 0 0.295297 0 0.964908 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=214275, meanQ=9.793125, numObservations: 2
action 5, numVisits=4, meanQ=-0.252500, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 672661 episodes
GETTING ACTION FROM:
action -1, numVisits=886936, meanQ=9.473366, numObservations: 2
action 5, numVisits=4, meanQ=-0.252500, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.508878 0.809851 0.671076 0.881146 0.0879122 0.406982 0.306789 0.143391 0.872748 0.567108 w: 1
Observation: 0 0.599031 0 0.736715 0 0.156584 0 0.298346 0 0.784964 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=546343, meanQ=11.052703, numObservations: 4
action 5, numVisits=6, meanQ=4.000017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 991034 episodes
GETTING ACTION FROM:
action 2, numVisits=1537377, meanQ=11.093672, numObservations: 4
action 5, numVisits=6, meanQ=4.000017, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.508878 0.809851 0.671076 0.881146 0.0879122 0.406982 0.306789 0.143391 0.872748 0.567108 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.5424
Run # 433
Initial state: 0 0.274412 0.665182 0.561391 0.892739 0.405921 0.631509 0.586352 0.801188 0.72043 0.698641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 872856 episodes
GETTING ACTION FROM:
action 1, numVisits=872833, meanQ=10.335242, numObservations: 4
action 5, numVisits=12, meanQ=6.841667, numObservations: 2
action 3, numVisits=5, meanQ=6.206040, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.274412 0.665182 0.561391 0.892739 0.405921 0.631509 0.586352 0.801188 0.72043 0.698641 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=216380, meanQ=13.372797, numObservations: 5
action 3, numVisits=11, meanQ=11.180927, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1191944 episodes
GETTING ACTION FROM:
action 2, numVisits=1408323, meanQ=12.132777, numObservations: 5
action 3, numVisits=12, meanQ=9.332517, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.274412 0.665182 0.561391 0.892739 0.405921 0.631509 0.586352 0.801188 0.72043 0.698641 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 434
Initial state: 0 0.527276 0.828417 0.137768 0.346828 0.600669 0.881913 0.597366 0.561743 0.0566406 0.699714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 874624 episodes
GETTING ACTION FROM:
action 4, numVisits=874616, meanQ=10.300825, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.527276 0.828417 0.137768 0.346828 0.600669 0.881913 0.597366 0.561743 0.0566406 0.699714 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=84676, meanQ=13.327494, numObservations: 4
action 5, numVisits=6, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1216987 episodes
GETTING ACTION FROM:
action 3, numVisits=1301661, meanQ=12.412408, numObservations: 4
action 5, numVisits=8, meanQ=9.496250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.527276 0.828417 0.137768 0.346828 0.600669 0.881913 0.597366 0.561743 0.0566406 0.699714 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 435
Initial state: 0 0.692787 0.816808 0.519105 0.88199 0.00572493 0.745027 0.838963 0.778853 0.567314 0.0489121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 859136 episodes
GETTING ACTION FROM:
action 4, numVisits=859119, meanQ=10.193007, numObservations: 4
action 3, numVisits=4, meanQ=-0.252500, numObservations: 2
action 2, numVisits=7, meanQ=-0.414286, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.692787 0.816808 0.519105 0.88199 0.00572493 0.745027 0.838963 0.778853 0.567314 0.0489121 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 436
Initial state: 0 0.364515 0.101456 0.00759336 0.250925 0.608862 0.876666 0.663351 0.138853 0.624935 0.828989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889292 episodes
GETTING ACTION FROM:
action 5, numVisits=889286, meanQ=10.263525, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.364515 0.101456 0.00759336 0.250925 0.608862 0.876666 0.663351 0.138853 0.624935 0.828989 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 437
Initial state: 0 0.115826 0.667238 0.187802 0.462732 0.650291 0.827134 0.936474 0.390633 0.571851 0.813647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879199 episodes
GETTING ACTION FROM:
action 4, numVisits=879193, meanQ=10.230988, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.115826 0.667238 0.187802 0.462732 0.650291 0.827134 0.936474 0.390633 0.571851 0.813647 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 438
Initial state: 0 0.298978 0.253557 0.603564 0.892165 0.284926 0.516403 0.674806 0.828252 0.704379 0.707791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 868011 episodes
GETTING ACTION FROM:
action 2, numVisits=867992, meanQ=10.246204, numObservations: 5
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action 5, numVisits=5, meanQ=6.196000, numObservations: 2
action 3, numVisits=7, meanQ=4.585714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.298978 0.253557 0.603564 0.892165 0.284926 0.516403 0.674806 0.828252 0.704379 0.707791 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 439
Initial state: 0 0.576473 0.816515 0.89946 0.478601 0.687734 0.696719 0.214378 0.282993 0.58126 0.852648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 878565 episodes
GETTING ACTION FROM:
action 1, numVisits=878557, meanQ=10.178464, numObservations: 5
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.576473 0.816515 0.89946 0.478601 0.687734 0.696719 0.214378 0.282993 0.58126 0.852648 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 440
Initial state: 0 0.898219 0.209801 0.745502 0.0171977 0.567214 0.846678 0.544466 0.80499 0.227629 0.969782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 900168 episodes
GETTING ACTION FROM:
action 2, numVisits=899985, meanQ=10.437986, numObservations: 4
action 3, numVisits=178, meanQ=9.781211, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.898219 0.209801 0.745502 0.0171977 0.567214 0.846678 0.544466 0.80499 0.227629 0.969782 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 441
Initial state: 0 0.596672 0.819787 0.103409 0.628584 0.850852 0.201825 0.377683 0.781686 0.624584 0.834852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889062 episodes
GETTING ACTION FROM:
action 4, numVisits=889056, meanQ=10.215860, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.596672 0.819787 0.103409 0.628584 0.850852 0.201825 0.377683 0.781686 0.624584 0.834852 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=183539, meanQ=13.524216, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1193300 episodes
GETTING ACTION FROM:
action 2, numVisits=1376839, meanQ=11.691597, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.596672 0.819787 0.103409 0.628584 0.850852 0.201825 0.377683 0.781686 0.624584 0.834852 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=59549, meanQ=14.200930, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1316320 episodes
GETTING ACTION FROM:
action 5, numVisits=1375869, meanQ=13.484949, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.596672 0.819787 0.103409 0.628584 0.850852 0.201825 0.377683 0.781686 0.624584 0.834852 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 442
Initial state: 0 0.597014 0.853526 0.595632 0.991817 0.00594109 0.302678 0.350134 0.569323 0.61459 0.823875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 882430 episodes
GETTING ACTION FROM:
action 3, numVisits=882422, meanQ=10.289510, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.597014 0.853526 0.595632 0.991817 0.00594109 0.302678 0.350134 0.569323 0.61459 0.823875 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=218579, meanQ=13.411846, numObservations: 4
action 4, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1199532 episodes
GETTING ACTION FROM:
action 5, numVisits=1418110, meanQ=12.075535, numObservations: 4
action 4, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.597014 0.853526 0.595632 0.991817 0.00594109 0.302678 0.350134 0.569323 0.61459 0.823875 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 443
Initial state: 0 0.568744 0.824064 0.511375 0.9289 0.0658139 0.346835 0.458561 0.504454 0.534805 0.843108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 872556 episodes
GETTING ACTION FROM:
action 3, numVisits=431067, meanQ=10.408075, numObservations: 5
action 2, numVisits=441484, meanQ=10.145459, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.568744 0.824064 0.511375 0.9289 0.0658139 0.346835 0.458561 0.504454 0.534805 0.843108 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=107131, meanQ=13.374854, numObservations: 5
action 1, numVisits=9, meanQ=6.997789, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1186394 episodes
GETTING ACTION FROM:
action 4, numVisits=1293525, meanQ=11.527695, numObservations: 5
action 1, numVisits=9, meanQ=6.997789, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.568744 0.824064 0.511375 0.9289 0.0658139 0.346835 0.458561 0.504454 0.534805 0.843108 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=125882, meanQ=16.880031, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1275183 episodes
GETTING ACTION FROM:
action 5, numVisits=1401065, meanQ=12.694687, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.568744 0.824064 0.511375 0.9289 0.0658139 0.346835 0.458561 0.504454 0.534805 0.843108 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=21625, meanQ=20.862779, numObservations: 4
action 2, numVisits=10, meanQ=17.799000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1328232 episodes
GETTING ACTION FROM:
action 2, numVisits=669269, meanQ=13.291953, numObservations: 4
action 1, numVisits=680598, meanQ=13.141815, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.568744 0.824064 0.511375 0.9289 0.0658139 0.346835 0.458561 0.504454 0.534805 0.843108 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -22.5537
Run # 444
Initial state: 0 0.667006 0.881726 0.509589 0.803644 0.142616 0.158729 0.190277 0.463611 0.272751 0.517981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 868814 episodes
GETTING ACTION FROM:
action 5, numVisits=868786, meanQ=10.024118, numObservations: 4
action 1, numVisits=23, meanQ=3.926539, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.667006 0.881726 0.509589 0.803644 0.142616 0.158729 0.190277 0.463611 0.272751 0.517981 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=215194, meanQ=13.344452, numObservations: 5
action 2, numVisits=10, meanQ=3.799000, numObservations: 3
action 4, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1194540 episodes
GETTING ACTION FROM:
action 1, numVisits=1409734, meanQ=11.797771, numObservations: 5
action 2, numVisits=10, meanQ=3.799000, numObservations: 3
action 4, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.667006 0.881726 0.509589 0.803644 0.142616 0.158729 0.190277 0.463611 0.272751 0.517981 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 445
Initial state: 0 0.364331 0.213611 0.524016 0.845347 0.254244 0.469672 0.510295 0.876357 0.367893 0.176731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 878820 episodes
GETTING ACTION FROM:
action 2, numVisits=878806, meanQ=10.253854, numObservations: 5
action 3, numVisits=5, meanQ=6.196000, numObservations: 2
action 4, numVisits=5, meanQ=5.798020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.364331 0.213611 0.524016 0.845347 0.254244 0.469672 0.510295 0.876357 0.367893 0.176731 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 446
Initial state: 0 0.533306 0.884734 0.0913206 0.984482 0.612542 0.874995 0.986158 0.178331 0.9176 0.463994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889794 episodes
GETTING ACTION FROM:
action 1, numVisits=889788, meanQ=10.223640, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.533306 0.884734 0.0913206 0.984482 0.612542 0.874995 0.986158 0.178331 0.9176 0.463994 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 447
Initial state: 0 0.500265 0.879753 0.37515 0.878587 0.620385 0.86886 0.299997 0.282734 0.859321 0.142574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 882576 episodes
GETTING ACTION FROM:
action 5, numVisits=882566, meanQ=10.240630, numObservations: 4
action 3, numVisits=3, meanQ=4.670033, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 2 0.500265 0.879753 0.37515 0.878587 0.620385 0.86886 0.299997 0.282734 0.859321 0.142574 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 448
Initial state: 0 0.672752 0.837704 0.509847 0.82476 0.260864 0.833252 0.652939 0.620676 0.282676 0.311141 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 628267 episodes
GETTING ACTION FROM:
action -1, numVisits=628243, meanQ=8.477746, numObservations: 3
action 5, numVisits=9, meanQ=-1.887767, numObservations: 4
action 0, numVisits=5, meanQ=-2.203940, numObservations: 2
action 2, numVisits=7, meanQ=-2.561371, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.672752 0.837704 0.509847 0.82476 0.260864 0.833252 0.652939 0.620676 0.282676 0.311141 w: 1
Observation: 0 0.575841 0 0.416527 0 0.318078 0 0.655933 0 0.185177 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=150029, meanQ=12.119778, numObservations: 4
action 3, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 958562 episodes
GETTING ACTION FROM:
action 1, numVisits=1108591, meanQ=10.581602, numObservations: 4
action 3, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.672752 0.837704 0.509847 0.82476 0.260864 0.833252 0.652939 0.620676 0.282676 0.311141 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=74105, meanQ=13.008546, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 998638 episodes
GETTING ACTION FROM:
action 0, numVisits=1072743, meanQ=5.077351, numObservations: 6
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.672752 0.837704 0.509847 0.82476 0.260864 0.833252 0.652939 0.620676 0.282676 0.311141 w: 1
Observation: 0 0 0.874126 0 0.90194 0 0.90363 0 0.640112 0 0.350001 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=135025, meanQ=15.004326, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1140739 episodes
GETTING ACTION FROM:
action 2, numVisits=1275752, meanQ=11.709292, numObservations: 5
action 1, numVisits=14, meanQ=9.267857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.672752 0.837704 0.509847 0.82476 0.260864 0.833252 0.652939 0.620676 0.282676 0.311141 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.367
Run # 449
Initial state: 0 0.645571 0.0450651 0.949633 0.409691 0.367974 0.408059 0.555778 0.819914 0.618005 0.834437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879945 episodes
GETTING ACTION FROM:
action 4, numVisits=879933, meanQ=10.323860, numObservations: 5
action 1, numVisits=5, meanQ=7.000020, numObservations: 4
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.645571 0.0450651 0.949633 0.409691 0.367974 0.408059 0.555778 0.819914 0.618005 0.834437 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 450
Initial state: 0 0.173563 0.0397587 0.448866 0.517634 0.185641 0.96066 0.57974 0.801167 0.656955 0.879039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 872221 episodes
GETTING ACTION FROM:
action 5, numVisits=872213, meanQ=10.221238, numObservations: 4
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.173563 0.0397587 0.448866 0.517634 0.185641 0.96066 0.57974 0.801167 0.656955 0.879039 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 451
Initial state: 0 0.599497 0.887125 0.872848 0.529603 0.69119 0.861625 0.660883 0.0634549 0.91329 0.155935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 884791 episodes
GETTING ACTION FROM:
action 1, numVisits=884757, meanQ=10.410331, numObservations: 5
action 2, numVisits=29, meanQ=8.189669, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.599497 0.887125 0.872848 0.529603 0.69119 0.861625 0.660883 0.0634549 0.91329 0.155935 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=61393, meanQ=12.119987, numObservations: 4
action 5, numVisits=4, meanQ=8.497500, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1110340 episodes
GETTING ACTION FROM:
action 3, numVisits=562106, meanQ=12.712522, numObservations: 4
action 1, numVisits=609628, meanQ=10.396951, numObservations: 4
action 5, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.599497 0.887125 0.872848 0.529603 0.69119 0.861625 0.660883 0.0634549 0.91329 0.155935 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 452
Initial state: 0 0.675256 0.810994 0.458921 0.519179 0.652093 0.745215 0.708224 0.960833 0.605526 0.894255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 587586 episodes
GETTING ACTION FROM:
action -1, numVisits=587580, meanQ=8.955162, numObservations: 4
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.675256 0.810994 0.458921 0.519179 0.652093 0.745215 0.708224 0.960833 0.605526 0.894255 w: 1
Observation: 0 0.61793 0 0.50081 0 0.659171 0 0.72357 0 0.513956 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=337883, meanQ=10.631732, numObservations: 4
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action 1, numVisits=5, meanQ=4.598000, numObservations: 2
action 3, numVisits=7, meanQ=4.585714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 915706 episodes
GETTING ACTION FROM:
action 2, numVisits=1253589, meanQ=10.406678, numObservations: 4
action 5, numVisits=3, meanQ=5.993333, numObservations: 2
action 1, numVisits=5, meanQ=4.598000, numObservations: 2
action 3, numVisits=7, meanQ=4.585714, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.675256 0.810994 0.458921 0.519179 0.652093 0.745215 0.708224 0.960833 0.605526 0.894255 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=287137, meanQ=14.098841, numObservations: 3
action 4, numVisits=8, meanQ=8.503775, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1213143 episodes
GETTING ACTION FROM:
action 1, numVisits=1500279, meanQ=11.783650, numObservations: 3
action 4, numVisits=8, meanQ=8.503775, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.675256 0.810994 0.458921 0.519179 0.652093 0.745215 0.708224 0.960833 0.605526 0.894255 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 453
Initial state: 0 0.134161 0.195145 0.317944 0.567994 0.469252 0.245196 0.545852 0.861009 0.522806 0.881125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 634321 episodes
GETTING ACTION FROM:
action 0, numVisits=634294, meanQ=12.798038, numObservations: 6
action 3, numVisits=10, meanQ=0.722010, numObservations: 3
action 2, numVisits=5, meanQ=-0.804000, numObservations: 3
action 1, numVisits=5, meanQ=-0.804000, numObservations: 3
action 5, numVisits=4, meanQ=-1.225000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.134161 0.195145 0.317944 0.567994 0.469252 0.245196 0.545852 0.861009 0.522806 0.881125 w: 1
Observation: 0 0 0.203724 0 0.560505 0 0.268669 0 0.812209 0 0.826969 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=137029, meanQ=16.153840, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 989489 episodes
GETTING ACTION FROM:
action 4, numVisits=1126518, meanQ=11.769636, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.134161 0.195145 0.317944 0.567994 0.469252 0.245196 0.545852 0.861009 0.522806 0.881125 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=78968, meanQ=11.873894, numObservations: 3
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1213468 episodes
GETTING ACTION FROM:
action 5, numVisits=1292435, meanQ=11.536465, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.134161 0.195145 0.317944 0.567994 0.469252 0.245196 0.545852 0.861009 0.522806 0.881125 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 454
Initial state: 0 0.606448 0.825451 0.338264 0.32876 0.288281 0.780432 0.0370133 0.946187 0.514947 0.884964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880029 episodes
GETTING ACTION FROM:
action 3, numVisits=880021, meanQ=10.237471, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.606448 0.825451 0.338264 0.32876 0.288281 0.780432 0.0370133 0.946187 0.514947 0.884964 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 455
Initial state: 0 0.270569 0.60083 0.184612 0.530427 0.647797 0.307209 0.670685 0.841679 0.609337 0.88422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 878970 episodes
GETTING ACTION FROM:
action 2, numVisits=878959, meanQ=10.214978, numObservations: 4
action 1, numVisits=4, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.270569 0.60083 0.184612 0.530427 0.647797 0.307209 0.670685 0.841679 0.609337 0.88422 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=253846, meanQ=13.390435, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1208320 episodes
GETTING ACTION FROM:
action 1, numVisits=1462165, meanQ=11.444209, numObservations: 4
action 3, numVisits=5, meanQ=4.598000, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.270569 0.60083 0.184612 0.530427 0.647797 0.307209 0.670685 0.841679 0.609337 0.88422 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=172363, meanQ=17.198119, numObservations: 4
action 3, numVisits=5, meanQ=5.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1309243 episodes
GETTING ACTION FROM:
action 4, numVisits=1481606, meanQ=13.112071, numObservations: 4
action 3, numVisits=5, meanQ=5.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.270569 0.60083 0.184612 0.530427 0.647797 0.307209 0.670685 0.841679 0.609337 0.88422 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 456
Initial state: 0 0.693039 0.858492 0.476153 0.24571 0.607529 0.809081 0.954358 0.711558 0.357453 0.819131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 887736 episodes
GETTING ACTION FROM:
action 1, numVisits=887726, meanQ=10.264771, numObservations: 4
action 5, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.693039 0.858492 0.476153 0.24571 0.607529 0.809081 0.954358 0.711558 0.357453 0.819131 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=61226, meanQ=9.912658, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1210117 episodes
GETTING ACTION FROM:
action 2, numVisits=1271343, meanQ=10.909110, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.693039 0.858492 0.476153 0.24571 0.607529 0.809081 0.954358 0.711558 0.357453 0.819131 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=140558, meanQ=15.067757, numObservations: 4
action 5, numVisits=19, meanQ=10.843174, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1318121 episodes
GETTING ACTION FROM:
action 3, numVisits=1458678, meanQ=11.791728, numObservations: 4
action 5, numVisits=20, meanQ=9.751015, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.693039 0.858492 0.476153 0.24571 0.607529 0.809081 0.954358 0.711558 0.357453 0.819131 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 457
Initial state: 0 0.2182 0.921399 0.572813 0.527845 0.665974 0.833281 0.507675 0.85134 0.326057 0.905097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 866586 episodes
GETTING ACTION FROM:
action 5, numVisits=866573, meanQ=10.287394, numObservations: 5
action 2, numVisits=8, meanQ=3.123750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.2182 0.921399 0.572813 0.527845 0.665974 0.833281 0.507675 0.85134 0.326057 0.905097 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=60213, meanQ=10.173681, numObservations: 4
action 2, numVisits=5, meanQ=3.750000, numObservations: 2
action 4, numVisits=11, meanQ=3.725464, numObservations: 4
action 1, numVisits=6, meanQ=2.998350, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1115247 episodes
GETTING ACTION FROM:
action 3, numVisits=1175460, meanQ=11.639714, numObservations: 4
action 2, numVisits=5, meanQ=3.750000, numObservations: 2
action 4, numVisits=11, meanQ=3.725464, numObservations: 4
action 1, numVisits=6, meanQ=2.998350, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.2182 0.921399 0.572813 0.527845 0.665974 0.833281 0.507675 0.85134 0.326057 0.905097 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 458
Initial state: 0 0.581342 0.865179 0.49448 0.363679 0.904878 0.653032 0.997898 0.0324555 0.630454 0.852595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 890007 episodes
GETTING ACTION FROM:
action 1, numVisits=889992, meanQ=10.260817, numObservations: 4
action 3, numVisits=4, meanQ=6.500000, numObservations: 1
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action 2, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.581342 0.865179 0.49448 0.363679 0.904878 0.653032 0.997898 0.0324555 0.630454 0.852595 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 459
Initial state: 0 0.841108 0.351145 0.515268 0.843529 0.0409214 0.0800159 0.576715 0.809413 0.9058 0.0442714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879020 episodes
GETTING ACTION FROM:
action 5, numVisits=878995, meanQ=10.380454, numObservations: 5
action 4, numVisits=20, meanQ=5.647505, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.841108 0.351145 0.515268 0.843529 0.0409214 0.0800159 0.576715 0.809413 0.9058 0.0442714 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 460
Initial state: 0 0.541281 0.809055 0.940493 0.792122 0.609366 0.814105 0.0565386 0.499134 0.105109 0.962229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 626150 episodes
GETTING ACTION FROM:
action -1, numVisits=626143, meanQ=8.197744, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.541281 0.809055 0.940493 0.792122 0.609366 0.814105 0.0565386 0.499134 0.105109 0.962229 w: 1
Observation: 0 0.573713 0 0.907008 0 0.613926 0 0.0414967 0 0.0569581 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=313332, meanQ=10.916270, numObservations: 5
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 945485 episodes
GETTING ACTION FROM:
action 3, numVisits=1258817, meanQ=10.346123, numObservations: 5
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.541281 0.809055 0.940493 0.792122 0.609366 0.814105 0.0565386 0.499134 0.105109 0.962229 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 461
Initial state: 0 0.598032 0.825505 0.994576 0.598899 0.616419 0.890855 0.221963 0.151934 0.347934 0.98022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 797038 episodes
GETTING ACTION FROM:
action 5, numVisits=797029, meanQ=9.882223, numObservations: 4
action 1, numVisits=4, meanQ=-0.252500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.598032 0.825505 0.994576 0.598899 0.616419 0.890855 0.221963 0.151934 0.347934 0.98022 w: 1
Observation: 6 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=55471, meanQ=12.302288, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1064644 episodes
GETTING ACTION FROM:
action 5, numVisits=1120115, meanQ=10.960378, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.598032 0.825505 0.994576 0.598899 0.616419 0.890855 0.221963 0.151934 0.347934 0.98022 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=61439, meanQ=13.610519, numObservations: 5
action 3, numVisits=41, meanQ=11.641263, numObservations: 4
action 4, numVisits=6, meanQ=9.456683, numObservations: 2
action 2, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1245215 episodes
GETTING ACTION FROM:
action 1, numVisits=1306654, meanQ=13.458512, numObservations: 5
action 3, numVisits=41, meanQ=11.641263, numObservations: 4
action 4, numVisits=6, meanQ=9.456683, numObservations: 2
action 2, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.598032 0.825505 0.994576 0.598899 0.616419 0.890855 0.221963 0.151934 0.347934 0.98022 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 462
Initial state: 0 0.139019 0.390063 0.656854 0.85462 0.643372 0.841402 0.71331 0.0544617 0.0779422 0.711259 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 883716 episodes
GETTING ACTION FROM:
action 1, numVisits=883705, meanQ=10.361427, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.139019 0.390063 0.656854 0.85462 0.643372 0.841402 0.71331 0.0544617 0.0779422 0.711259 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=182104, meanQ=13.475443, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1195980 episodes
GETTING ACTION FROM:
action 4, numVisits=1378084, meanQ=12.578927, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.139019 0.390063 0.656854 0.85462 0.643372 0.841402 0.71331 0.0544617 0.0779422 0.711259 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=46822, meanQ=12.199121, numObservations: 5
action 4, numVisits=7, meanQ=6.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1282904 episodes
GETTING ACTION FROM:
action 2, numVisits=1329726, meanQ=12.740514, numObservations: 5
action 4, numVisits=7, meanQ=6.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.139019 0.390063 0.656854 0.85462 0.643372 0.841402 0.71331 0.0544617 0.0779422 0.711259 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 463
Initial state: 0 0.298131 0.748338 0.509822 0.839071 0.078243 0.708109 0.546352 0.861725 0.214783 0.789886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 855999 episodes
GETTING ACTION FROM:
action 2, numVisits=855970, meanQ=10.543995, numObservations: 5
action 5, numVisits=22, meanQ=4.410009, numObservations: 4
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.298131 0.748338 0.509822 0.839071 0.078243 0.708109 0.546352 0.861725 0.214783 0.789886 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 464
Initial state: 0 0.605418 0.887511 0.808693 0.379386 0.181755 0.441399 0.0222039 0.11806 0.626321 0.859204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 862709 episodes
GETTING ACTION FROM:
action 1, numVisits=861411, meanQ=9.890168, numObservations: 5
action 3, numVisits=1285, meanQ=9.581599, numObservations: 4
action 5, numVisits=9, meanQ=5.443333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.605418 0.887511 0.808693 0.379386 0.181755 0.441399 0.0222039 0.11806 0.626321 0.859204 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 465
Initial state: 0 0.0644166 0.033986 0.539234 0.857683 0.726837 0.0465747 0.569468 0.845051 0.609981 0.213182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 778654 episodes
GETTING ACTION FROM:
action 1, numVisits=778648, meanQ=9.852305, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0644166 0.033986 0.539234 0.857683 0.726837 0.0465747 0.569468 0.845051 0.609981 0.213182 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=193109, meanQ=12.724297, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 980458 episodes
GETTING ACTION FROM:
action 0, numVisits=1173567, meanQ=5.607469, numObservations: 8
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.0644166 0.033986 0.539234 0.857683 0.726837 0.0465747 0.569468 0.845051 0.609981 0.213182 w: 1
Observation: 0 0 0 0 0.873862 0 0 0 0.814981 0 0.174476 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=22105, meanQ=22.235022, numObservations: 4
action 4, numVisits=8, meanQ=16.248750, numObservations: 1
action 1, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1196941 episodes
GETTING ACTION FROM:
action 2, numVisits=1219029, meanQ=11.424327, numObservations: 4
action 4, numVisits=23, meanQ=9.293043, numObservations: 3
action 1, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0644166 0.033986 0.539234 0.857683 0.726837 0.0465747 0.569468 0.845051 0.609981 0.213182 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 466
Initial state: 0 0.765885 0.914739 0.68117 0.818594 0.551973 0.663738 0.571867 0.513559 0.501047 0.84562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 879860 episodes
GETTING ACTION FROM:
action 1, numVisits=879836, meanQ=10.365111, numObservations: 5
action 2, numVisits=8, meanQ=7.498750, numObservations: 3
action 5, numVisits=8, meanQ=7.498750, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.765885 0.914739 0.68117 0.818594 0.551973 0.663738 0.571867 0.513559 0.501047 0.84562 w: 1
Observation: 9 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 467
Initial state: 0 0.118741 0.523059 0.598059 0.801172 0.257836 0.124558 0.441796 0.676756 0.584384 0.816371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 894345 episodes
GETTING ACTION FROM:
action 5, numVisits=894332, meanQ=10.215655, numObservations: 3
action 2, numVisits=4, meanQ=6.500000, numObservations: 2
action 3, numVisits=5, meanQ=6.206040, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.118741 0.523059 0.598059 0.801172 0.257836 0.124558 0.441796 0.676756 0.584384 0.816371 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=61594, meanQ=9.936850, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1157121 episodes
GETTING ACTION FROM:
action 4, numVisits=1218715, meanQ=11.657306, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.118741 0.523059 0.598059 0.801172 0.257836 0.124558 0.441796 0.676756 0.584384 0.816371 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=109635, meanQ=16.536691, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1315892 episodes
GETTING ACTION FROM:
action 2, numVisits=1425527, meanQ=13.103423, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.118741 0.523059 0.598059 0.801172 0.257836 0.124558 0.441796 0.676756 0.584384 0.816371 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 468
Initial state: 0 0.828338 0.00713062 0.780303 0.839936 0.687162 0.892893 0.44016 0.130517 0.654874 0.8869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 880298 episodes
GETTING ACTION FROM:
action 1, numVisits=880253, meanQ=10.262319, numObservations: 5
action 2, numVisits=38, meanQ=8.648701, numObservations: 4
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.828338 0.00713062 0.780303 0.839936 0.687162 0.892893 0.44016 0.130517 0.654874 0.8869 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 469
Initial state: 0 0.536659 0.3769 0.440117 0.479517 0.649957 0.895162 0.546545 0.80359 0.0766687 0.211997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 871229 episodes
GETTING ACTION FROM:
action 4, numVisits=871198, meanQ=10.256247, numObservations: 4
action 2, numVisits=22, meanQ=8.614550, numObservations: 3
action 1, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.536659 0.3769 0.440117 0.479517 0.649957 0.895162 0.546545 0.80359 0.0766687 0.211997 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 470
Initial state: 0 0.859788 0.670756 0.613182 0.85642 0.559981 0.871045 0.612336 0.747577 0.0404727 0.591042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 890392 episodes
GETTING ACTION FROM:
action 2, numVisits=890386, meanQ=10.280614, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.859788 0.670756 0.613182 0.85642 0.559981 0.871045 0.612336 0.747577 0.0404727 0.591042 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 471
Initial state: 0 0.129714 0.765947 0.630232 0.14838 0.527035 0.882229 0.697349 0.86355 0.730059 0.342305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 891348 episodes
GETTING ACTION FROM:
action 2, numVisits=891320, meanQ=10.347848, numObservations: 4
action 1, numVisits=23, meanQ=5.955670, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.129714 0.765947 0.630232 0.14838 0.527035 0.882229 0.697349 0.86355 0.730059 0.342305 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=256954, meanQ=13.349958, numObservations: 4
action 4, numVisits=9, meanQ=6.336689, numObservations: 2
action 3, numVisits=7, meanQ=6.282857, numObservations: 3
action 5, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1212526 episodes
GETTING ACTION FROM:
action 1, numVisits=1469480, meanQ=11.879031, numObservations: 4
action 4, numVisits=9, meanQ=6.336689, numObservations: 2
action 3, numVisits=7, meanQ=6.282857, numObservations: 3
action 5, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.129714 0.765947 0.630232 0.14838 0.527035 0.882229 0.697349 0.86355 0.730059 0.342305 w: 1
Observation: 1 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 5, numVisits=148031, meanQ=18.171317, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1296058 episodes
GETTING ACTION FROM:
action 5, numVisits=1444089, meanQ=13.084507, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.129714 0.765947 0.630232 0.14838 0.527035 0.882229 0.697349 0.86355 0.730059 0.342305 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 472
Initial state: 0 0.581251 0.888368 0.919951 0.00803337 0.0775061 0.161307 0.606848 0.89182 0.0586634 0.567349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 849364 episodes
GETTING ACTION FROM:
action 2, numVisits=849356, meanQ=10.285467, numObservations: 4
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.581251 0.888368 0.919951 0.00803337 0.0775061 0.161307 0.606848 0.89182 0.0586634 0.567349 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 473
Initial state: 0 0.57834 0.856586 0.515404 0.811039 0.822347 0.0677952 0.597017 0.410711 0.0402454 0.659352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 892541 episodes
GETTING ACTION FROM:
action 1, numVisits=892531, meanQ=10.341659, numObservations: 4
action 2, numVisits=3, meanQ=0.666667, numObservations: 1
action 5, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.57834 0.856586 0.515404 0.811039 0.822347 0.0677952 0.597017 0.410711 0.0402454 0.659352 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 474
Initial state: 0 0.884312 0.032193 0.207511 0.207494 0.594964 0.866114 0.295457 0.904008 0.663274 0.848861 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 889430 episodes
GETTING ACTION FROM:
action 1, numVisits=889422, meanQ=10.216979, numObservations: 3
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.884312 0.032193 0.207511 0.207494 0.594964 0.866114 0.295457 0.904008 0.663274 0.848861 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 475
Initial state: 0 0.545401 0.887782 0.239469 0.265074 0.94792 0.59581 0.239221 0.696082 0.690091 0.874935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 845382 episodes
GETTING ACTION FROM:
action 5, numVisits=845376, meanQ=10.056930, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.545401 0.887782 0.239469 0.265074 0.94792 0.59581 0.239221 0.696082 0.690091 0.874935 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 476
Initial state: 0 0.261073 0.799807 0.579128 0.898093 0.433291 0.722903 0.679505 0.811705 0.941417 0.0565706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 870162 episodes
GETTING ACTION FROM:
action 5, numVisits=870150, meanQ=10.096988, numObservations: 4
action 2, numVisits=7, meanQ=0.998586, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.261073 0.799807 0.579128 0.898093 0.433291 0.722903 0.679505 0.811705 0.941417 0.0565706 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 477
Initial state: 0 0.651023 0.800865 0.673061 0.826632 0.0393362 0.95623 0.477981 0.96861 0.784217 0.229671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 888219 episodes
GETTING ACTION FROM:
action 5, numVisits=888210, meanQ=10.189845, numObservations: 4
action 3, numVisits=4, meanQ=0.752525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.651023 0.800865 0.673061 0.826632 0.0393362 0.95623 0.477981 0.96861 0.784217 0.229671 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 478
Initial state: 0 0.536685 0.800763 0.501729 0.860629 0.96953 0.345494 0.38881 0.431314 0.976447 0.428477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 886011 episodes
GETTING ACTION FROM:
action 3, numVisits=886003, meanQ=10.189668, numObservations: 4
action 1, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.536685 0.800763 0.501729 0.860629 0.96953 0.345494 0.38881 0.431314 0.976447 0.428477 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 479
Initial state: 0 0.589885 0.833695 0.603427 0.843445 0.725227 0.170841 0.153961 0.786638 0.590595 0.369899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 828741 episodes
GETTING ACTION FROM:
action 1, numVisits=807878, meanQ=10.322290, numObservations: 4
action 2, numVisits=20838, meanQ=10.244670, numObservations: 5
action 4, numVisits=17, meanQ=7.942382, numObservations: 3
action 5, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.589885 0.833695 0.603427 0.843445 0.725227 0.170841 0.153961 0.786638 0.590595 0.369899 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 480
Initial state: 0 0.0883366 0.00364999 0.505402 0.836996 0.736155 0.668125 0.0165768 0.10137 0.682345 0.843585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 838811 episodes
GETTING ACTION FROM:
action 2, numVisits=838778, meanQ=10.215693, numObservations: 4
action 3, numVisits=26, meanQ=8.499254, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0883366 0.00364999 0.505402 0.836996 0.736155 0.668125 0.0165768 0.10137 0.682345 0.843585 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 481
Initial state: 0 0.677624 0.872586 0.0289649 0.771105 0.596356 0.899493 0.91836 0.462197 0.69265 0.584358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 860220 episodes
GETTING ACTION FROM:
action 3, numVisits=860182, meanQ=10.282903, numObservations: 5
action 5, numVisits=31, meanQ=7.805829, numObservations: 3
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.677624 0.872586 0.0289649 0.771105 0.596356 0.899493 0.91836 0.462197 0.69265 0.584358 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 482
Initial state: 0 0.371052 0.731517 0.787038 0.333848 0.69564 0.894451 0.643429 0.835148 0.916616 0.979356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 864750 episodes
GETTING ACTION FROM:
action 2, numVisits=864733, meanQ=10.261609, numObservations: 4
action 3, numVisits=10, meanQ=5.000010, numObservations: 2
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.371052 0.731517 0.787038 0.333848 0.69564 0.894451 0.643429 0.835148 0.916616 0.979356 w: 1
Observation: 4 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 483
Initial state: 0 0.611237 0.863154 0.732858 0.592754 0.433311 0.954333 0.539014 0.863295 0.683365 0.705952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 863720 episodes
GETTING ACTION FROM:
action 4, numVisits=863710, meanQ=10.279317, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.611237 0.863154 0.732858 0.592754 0.433311 0.954333 0.539014 0.863295 0.683365 0.705952 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 484
Initial state: 0 0.4005 0.873459 0.641226 0.839622 0.628983 0.858064 0.355674 0.181653 0.0714834 0.74196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 867696 episodes
GETTING ACTION FROM:
action 1, numVisits=867680, meanQ=10.249355, numObservations: 4
action 2, numVisits=11, meanQ=6.180918, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.4005 0.873459 0.641226 0.839622 0.628983 0.858064 0.355674 0.181653 0.0714834 0.74196 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=35317, meanQ=12.944596, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1181289 episodes
GETTING ACTION FROM:
action 4, numVisits=1216606, meanQ=11.619377, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.4005 0.873459 0.641226 0.839622 0.628983 0.858064 0.355674 0.181653 0.0714834 0.74196 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=42879, meanQ=13.035231, numObservations: 4
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 5, numVisits=4, meanQ=8.497500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1271994 episodes
GETTING ACTION FROM:
action 2, numVisits=1314870, meanQ=11.361674, numObservations: 4
action 5, numVisits=6, meanQ=7.831667, numObservations: 4
action 3, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.4005 0.873459 0.641226 0.839622 0.628983 0.858064 0.355674 0.181653 0.0714834 0.74196 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 485
Initial state: 0 0.577847 0.885061 0.689072 0.801192 0.874117 0.516643 0.228381 0.661623 0.702344 0.91746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 852448 episodes
GETTING ACTION FROM:
action 5, numVisits=852440, meanQ=10.222174, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.577847 0.885061 0.689072 0.801192 0.874117 0.516643 0.228381 0.661623 0.702344 0.91746 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 486
Initial state: 0 0.645971 0.871551 0.539335 0.464423 0.233761 0.127633 0.512306 0.922989 0.56484 0.879018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 821197 episodes
GETTING ACTION FROM:
action 1, numVisits=821188, meanQ=10.287019, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.645971 0.871551 0.539335 0.464423 0.233761 0.127633 0.512306 0.922989 0.56484 0.879018 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 487
Initial state: 0 0.602267 0.612528 0.285225 0.817295 0.338547 0.445838 0.539476 0.887189 0.666513 0.890203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 877830 episodes
GETTING ACTION FROM:
action 4, numVisits=877793, meanQ=10.387053, numObservations: 3
action 3, numVisits=30, meanQ=8.169020, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.602267 0.612528 0.285225 0.817295 0.338547 0.445838 0.539476 0.887189 0.666513 0.890203 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 488
Initial state: 0 0.243831 0.507411 0.51887 0.813523 0.654161 0.852663 0.422035 0.665461 0.788959 0.949477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 627072 episodes
GETTING ACTION FROM:
action 0, numVisits=627064, meanQ=13.226985, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.243831 0.507411 0.51887 0.813523 0.654161 0.852663 0.422035 0.665461 0.788959 0.949477 w: 1
Observation: 0 0 0.464819 0 0.721573 0 0.923703 0 0.594099 0 0.869712 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=262632, meanQ=13.860395, numObservations: 5
action 5, numVisits=82, meanQ=8.366212, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 946787 episodes
GETTING ACTION FROM:
action 3, numVisits=1209419, meanQ=12.038771, numObservations: 5
action 5, numVisits=82, meanQ=8.366212, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.243831 0.507411 0.51887 0.813523 0.654161 0.852663 0.422035 0.665461 0.788959 0.949477 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 489
Initial state: 0 0.88659 0.452372 0.974148 0.343331 0.542292 0.860636 0.638643 0.863774 0.796724 0.643605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 562208 episodes
GETTING ACTION FROM:
action -1, numVisits=562202, meanQ=8.339343, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.88659 0.452372 0.974148 0.343331 0.542292 0.860636 0.638643 0.863774 0.796724 0.643605 w: 1
Observation: 0 0.829738 0 0.927147 0 0.461806 0 0.71474 0 0.853545 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=358375, meanQ=9.996403, numObservations: 4
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action 2, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 940746 episodes
GETTING ACTION FROM:
action 4, numVisits=1299121, meanQ=10.473963, numObservations: 4
action 5, numVisits=3, meanQ=4.670033, numObservations: 2
action 2, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 1 0.88659 0.452372 0.974148 0.343331 0.542292 0.860636 0.638643 0.863774 0.796724 0.643605 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 490
Initial state: 0 0.454204 0.893847 0.418013 0.383692 0.590171 0.846038 0.348956 0.209329 0.535911 0.866862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 851685 episodes
GETTING ACTION FROM:
action 3, numVisits=851679, meanQ=9.858556, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.454204 0.893847 0.418013 0.383692 0.590171 0.846038 0.348956 0.209329 0.535911 0.866862 w: 1
Observation: 8 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 491
Initial state: 0 0.379298 0.583089 0.582584 0.897554 0.578499 0.896555 0.407557 0.504164 0.857008 0.530321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 636407 episodes
GETTING ACTION FROM:
action 0, numVisits=636400, meanQ=14.499262, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.379298 0.583089 0.582584 0.897554 0.578499 0.896555 0.407557 0.504164 0.857008 0.530321 w: 1
Observation: 0 0 0.582155 0 0.836897 0 0.879627 0 0.522599 0 0.498471 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=125581, meanQ=19.202032, numObservations: 5
action 3, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 953120 episodes
GETTING ACTION FROM:
action 2, numVisits=1078701, meanQ=11.514515, numObservations: 5
action 3, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.379298 0.583089 0.582584 0.897554 0.578499 0.896555 0.407557 0.504164 0.857008 0.530321 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 492
Initial state: 0 0.706907 0.39495 0.0325283 0.0316563 0.561085 0.852025 0.679762 0.897602 0.360568 0.0534585 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 869226 episodes
GETTING ACTION FROM:
action 3, numVisits=869206, meanQ=10.216071, numObservations: 4
action 4, numVisits=11, meanQ=5.976364, numObservations: 2
action 5, numVisits=5, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.706907 0.39495 0.0325283 0.0316563 0.561085 0.852025 0.679762 0.897602 0.360568 0.0534585 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 493
Initial state: 0 0.51981 0.859796 0.535788 0.816497 0.0581628 0.0675211 0.0610911 0.844408 0.289643 0.478915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 623530 episodes
GETTING ACTION FROM:
action 0, numVisits=623523, meanQ=13.553032, numObservations: 6
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.51981 0.859796 0.535788 0.816497 0.0581628 0.0675211 0.0610911 0.844408 0.289643 0.478915 w: 1
Observation: 0 0 0.917672 0 0.870673 0 0.162793 0 0.835889 0 0.552208 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=39710, meanQ=17.701586, numObservations: 5
action 2, numVisits=11, meanQ=8.463636, numObservations: 3
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 971813 episodes
GETTING ACTION FROM:
action 4, numVisits=1011523, meanQ=11.322360, numObservations: 5
action 2, numVisits=11, meanQ=8.463636, numObservations: 3
action 1, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.51981 0.859796 0.535788 0.816497 0.0581628 0.0675211 0.0610911 0.844408 0.289643 0.478915 w: 1
Observation: 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=35752, meanQ=14.515298, numObservations: 5
action 2, numVisits=10, meanQ=11.209000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1186755 episodes
GETTING ACTION FROM:
action 1, numVisits=1222506, meanQ=11.508469, numObservations: 5
action 2, numVisits=11, meanQ=9.190000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.51981 0.859796 0.535788 0.816497 0.0581628 0.0675211 0.0610911 0.844408 0.289643 0.478915 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 494
Initial state: 0 0.569509 0.821543 0.581256 0.871922 0.318635 0.0851097 0.119557 0.501503 0.147656 0.246558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 857314 episodes
GETTING ACTION FROM:
action 2, numVisits=390931, meanQ=10.266367, numObservations: 4
action 3, numVisits=466372, meanQ=10.263779, numObservations: 5
action 1, numVisits=7, meanQ=6.301443, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.569509 0.821543 0.581256 0.871922 0.318635 0.0851097 0.119557 0.501503 0.147656 0.246558 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 495
Initial state: 0 0.795622 0.27447 0.453096 0.743704 0.620293 0.852193 0.585957 0.874323 0.468361 0.623532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 858521 episodes
GETTING ACTION FROM:
action 3, numVisits=858515, meanQ=10.270567, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.795622 0.27447 0.453096 0.743704 0.620293 0.852193 0.585957 0.874323 0.468361 0.623532 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 496
Initial state: 0 0.684242 0.843543 0.971004 0.038155 0.413757 0.260147 0.180709 0.96521 0.64712 0.851159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 766734 episodes
GETTING ACTION FROM:
action 3, numVisits=766719, meanQ=9.682215, numObservations: 5
action 5, numVisits=7, meanQ=1.857157, numObservations: 4
action 2, numVisits=4, meanQ=1.745000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.684242 0.843543 0.971004 0.038155 0.413757 0.260147 0.180709 0.96521 0.64712 0.851159 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 497
Initial state: 0 0.560062 0.880651 0.662411 0.12808 0.0760261 0.283487 0.0397226 0.211631 0.586572 0.86487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 831017 episodes
GETTING ACTION FROM:
action 2, numVisits=830956, meanQ=10.137632, numObservations: 5
action 1, numVisits=52, meanQ=8.049148, numObservations: 4
action 5, numVisits=5, meanQ=4.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.560062 0.880651 0.662411 0.12808 0.0760261 0.283487 0.0397226 0.211631 0.586572 0.86487 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 498
Initial state: 0 0.540342 0.886931 0.748551 0.80586 0.699522 0.870028 0.833322 0.997715 0.569383 0.196218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 864469 episodes
GETTING ACTION FROM:
action 5, numVisits=864459, meanQ=10.243038, numObservations: 4
action 1, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 0 0.540342 0.886931 0.748551 0.80586 0.699522 0.870028 0.833322 0.997715 0.569383 0.196218 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=249202, meanQ=13.409170, numObservations: 3
action 3, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1197917 episodes
GETTING ACTION FROM:
action 1, numVisits=1447119, meanQ=12.336263, numObservations: 3
action 3, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.540342 0.886931 0.748551 0.80586 0.699522 0.870028 0.833322 0.997715 0.569383 0.196218 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 499
Initial state: 0 0.563185 0.89098 0.498345 0.735106 0.946224 0.977291 0.501992 0.0426324 0.660584 0.897297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 619563 episodes
GETTING ACTION FROM:
action 0, numVisits=619556, meanQ=13.243019, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.563185 0.89098 0.498345 0.735106 0.946224 0.977291 0.501992 0.0426324 0.660584 0.897297 w: 1
Observation: 0 0 0.925772 0 0.807138 0 0.960933 0 0.0852628 0 0.829077 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=72310, meanQ=17.629050, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 946395 episodes
GETTING ACTION FROM:
action 1, numVisits=1018691, meanQ=11.811576, numObservations: 5
action 2, numVisits=17, meanQ=9.634124, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.563185 0.89098 0.498345 0.735106 0.946224 0.977291 0.501992 0.0426324 0.660584 0.897297 w: 1
Observation: 5 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 500
Initial state: 0 0.593144 0.847338 0.391784 0.499803 0.884379 0.807119 0.430392 0.510251 0.561675 0.832127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 864940 episodes
GETTING ACTION FROM:
action 4, numVisits=864934, meanQ=10.223104, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 4
Next state: 0 0.593144 0.847338 0.391784 0.499803 0.884379 0.807119 0.430392 0.510251 0.561675 0.832127 w: 1
Observation: 2 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=214407, meanQ=13.454272, numObservations: 4
action 2, numVisits=18, meanQ=8.986117, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1181586 episodes
GETTING ACTION FROM:
action 3, numVisits=1395993, meanQ=12.126658, numObservations: 4
action 2, numVisits=18, meanQ=8.986117, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.593144 0.847338 0.391784 0.499803 0.884379 0.807119 0.430392 0.510251 0.561675 0.832127 w: 1
Observation: 7 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
