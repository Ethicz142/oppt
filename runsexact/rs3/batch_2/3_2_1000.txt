Run # 1
Initial state: 0 0.663835 0.894768 0.965888 0.365228 0.55494 0.896114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214155 episodes
GETTING ACTION FROM:
action 3, numVisits=214149, meanQ=17.693925, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.663835 0.894768 0.965888 0.365228 0.55494 0.896114 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.14894 0.169454 0.593735 0.871219 0.688909 0.803085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229466 episodes
GETTING ACTION FROM:
action 2, numVisits=229450, meanQ=17.872111, numObservations: 3
action 1, numVisits=13, meanQ=11.767692, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.14894 0.169454 0.593735 0.871219 0.688909 0.803085 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.12147 0.684978 0.632985 0.883584 0.576958 0.814964 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225127 episodes
GETTING ACTION FROM:
action 1, numVisits=225123, meanQ=17.631224, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.12147 0.684978 0.632985 0.883584 0.576958 0.814964 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31681, meanQ=23.245253, numObservations: 5
action 2, numVisits=35, meanQ=21.628003, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288480 episodes
GETTING ACTION FROM:
action 3, numVisits=319692, meanQ=19.345565, numObservations: 5
action 2, numVisits=504, meanQ=19.031826, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.12147 0.684978 0.632985 0.883584 0.576958 0.814964 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 4
Initial state: 0 0.390871 0.542734 0.539131 0.868254 0.555953 0.812742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220508 episodes
GETTING ACTION FROM:
action 2, numVisits=220504, meanQ=17.595764, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.390871 0.542734 0.539131 0.868254 0.555953 0.812742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=16459, meanQ=15.171613, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 274209 episodes
GETTING ACTION FROM:
action 1, numVisits=83623, meanQ=18.811215, numObservations: 4
action 0, numVisits=207046, meanQ=3.971968, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.390871 0.542734 0.539131 0.868254 0.555953 0.812742 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 5
Initial state: 0 0.672184 0.819097 0.762568 0.205726 0.529793 0.818497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227488 episodes
GETTING ACTION FROM:
action 3, numVisits=227484, meanQ=17.806979, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.672184 0.819097 0.762568 0.205726 0.529793 0.818497 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.588316 0.896832 0.639146 0.859274 0.240225 0.0167032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 233206 episodes
GETTING ACTION FROM:
action 1, numVisits=233202, meanQ=17.854490, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.588316 0.896832 0.639146 0.859274 0.240225 0.0167032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.614239 0.802923 0.533217 0.217092 0.642415 0.886047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230735 episodes
GETTING ACTION FROM:
action 1, numVisits=230698, meanQ=17.740474, numObservations: 3
action 2, numVisits=22, meanQ=15.363641, numObservations: 3
action 3, numVisits=13, meanQ=14.460000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.614239 0.802923 0.533217 0.217092 0.642415 0.886047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 8
Initial state: 0 0.575892 0.867751 0.123367 0.521841 0.528955 0.858077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228258 episodes
GETTING ACTION FROM:
action 2, numVisits=228251, meanQ=17.879027, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.575892 0.867751 0.123367 0.521841 0.528955 0.858077 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25869, meanQ=23.492940, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287128 episodes
GETTING ACTION FROM:
action 1, numVisits=312997, meanQ=18.765692, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.575892 0.867751 0.123367 0.521841 0.528955 0.858077 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 9
Initial state: 0 0.695134 0.897418 0.387323 0.444667 0.515834 0.803727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223755 episodes
GETTING ACTION FROM:
action 2, numVisits=223751, meanQ=18.137038, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.695134 0.897418 0.387323 0.444667 0.515834 0.803727 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25849, meanQ=23.473655, numObservations: 3
action 3, numVisits=6, meanQ=19.498333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281808 episodes
GETTING ACTION FROM:
action 1, numVisits=307651, meanQ=19.391036, numObservations: 5
action 3, numVisits=12, meanQ=15.915833, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.695134 0.897418 0.387323 0.444667 0.515834 0.803727 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 10
Initial state: 0 0.911989 0.677521 0.63331 0.895504 0.593676 0.846484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225149 episodes
GETTING ACTION FROM:
action 3, numVisits=225139, meanQ=17.812726, numObservations: 3
action 1, numVisits=7, meanQ=10.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.911989 0.677521 0.63331 0.895504 0.593676 0.846484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.185088 0.454699 0.521478 0.811881 0.516645 0.893795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223671 episodes
GETTING ACTION FROM:
action 2, numVisits=223665, meanQ=17.712353, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.185088 0.454699 0.521478 0.811881 0.516645 0.893795 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 12
Initial state: 0 0.5127 0.871804 0.60929 0.887205 0.902297 0.304912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221925 episodes
GETTING ACTION FROM:
action 1, numVisits=221921, meanQ=17.870292, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.5127 0.871804 0.60929 0.887205 0.902297 0.304912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 13
Initial state: 0 0.587457 0.810224 0.701549 0.447334 0.68411 0.850515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221692 episodes
GETTING ACTION FROM:
action 3, numVisits=221675, meanQ=17.821034, numObservations: 4
action 2, numVisits=13, meanQ=14.921546, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.587457 0.810224 0.701549 0.447334 0.68411 0.850515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 14
Initial state: 0 0.655252 0.846623 0.681448 0.85614 0.106181 0.240995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228763 episodes
GETTING ACTION FROM:
action 2, numVisits=228759, meanQ=17.848025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.655252 0.846623 0.681448 0.85614 0.106181 0.240995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=17031, meanQ=18.768835, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 262436 episodes
GETTING ACTION FROM:
action 2, numVisits=279467, meanQ=17.438016, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.655252 0.846623 0.681448 0.85614 0.106181 0.240995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 15
Initial state: 0 0.534276 0.871416 0.459823 0.972688 0.683481 0.815734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215708 episodes
GETTING ACTION FROM:
action 1, numVisits=215704, meanQ=17.946429, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.534276 0.871416 0.459823 0.972688 0.683481 0.815734 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=14043, meanQ=19.586027, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 262095 episodes
GETTING ACTION FROM:
action 2, numVisits=106764, meanQ=18.759279, numObservations: 4
action -1, numVisits=169373, meanQ=3.912834, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.534276 0.871416 0.459823 0.972688 0.683481 0.815734 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=103, meanQ=20.537382, numObservations: 4
action 2, numVisits=4, meanQ=15.250000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292213 episodes
GETTING ACTION FROM:
action 3, numVisits=292314, meanQ=18.610140, numObservations: 4
action 2, numVisits=6, meanQ=12.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.534276 0.871416 0.459823 0.972688 0.683481 0.815734 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 16
Initial state: 0 0.67185 0.870143 0.44942 0.043876 0.669559 0.857497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222618 episodes
GETTING ACTION FROM:
action 3, numVisits=222608, meanQ=18.019101, numObservations: 5
action 1, numVisits=7, meanQ=10.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.67185 0.870143 0.44942 0.043876 0.669559 0.857497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 17
Initial state: 0 0.682232 0.881909 0.529292 0.607553 0.612408 0.815378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223157 episodes
GETTING ACTION FROM:
action 2, numVisits=223152, meanQ=17.756277, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.682232 0.881909 0.529292 0.607553 0.612408 0.815378 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 18
Initial state: 0 0.15246 0.00867914 0.531589 0.814344 0.62193 0.882134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222235 episodes
GETTING ACTION FROM:
action 3, numVisits=222231, meanQ=17.886119, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.15246 0.00867914 0.531589 0.814344 0.62193 0.882134 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.148075 0.568791 0.508647 0.884981 0.545421 0.865812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 210560 episodes
GETTING ACTION FROM:
action 1, numVisits=210556, meanQ=17.376980, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.148075 0.568791 0.508647 0.884981 0.545421 0.865812 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=29613, meanQ=20.998430, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 264941 episodes
GETTING ACTION FROM:
action -1, numVisits=294554, meanQ=4.945167, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.148075 0.568791 0.508647 0.884981 0.545421 0.865812 w: 1
Observation: 0 0.211471 0 0.607276 0 0.463432 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=91623, meanQ=21.737163, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286354 episodes
GETTING ACTION FROM:
action 3, numVisits=377977, meanQ=19.180767, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.148075 0.568791 0.508647 0.884981 0.545421 0.865812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 20
Initial state: 0 0.597475 0.838152 0.501896 0.827575 0.412034 0.402132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223185 episodes
GETTING ACTION FROM:
action 1, numVisits=223177, meanQ=17.836204, numObservations: 4
action 2, numVisits=5, meanQ=10.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.597475 0.838152 0.501896 0.827575 0.412034 0.402132 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.162019 0.85695 0.681371 0.840345 0.646328 0.821142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219773 episodes
GETTING ACTION FROM:
action 3, numVisits=219757, meanQ=17.679003, numObservations: 5
action 1, numVisits=9, meanQ=11.774456, numObservations: 4
action 2, numVisits=5, meanQ=11.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.162019 0.85695 0.681371 0.840345 0.646328 0.821142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.631834 0.898517 0.383469 0.572852 0.500464 0.829287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225577 episodes
GETTING ACTION FROM:
action 3, numVisits=225571, meanQ=17.888257, numObservations: 3
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.631834 0.898517 0.383469 0.572852 0.500464 0.829287 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.659888 0.802086 0.571771 0.815077 0.208585 0.961562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220257 episodes
GETTING ACTION FROM:
action 1, numVisits=220253, meanQ=17.695287, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.659888 0.802086 0.571771 0.815077 0.208585 0.961562 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 24
Initial state: 0 0.56419 0.844282 0.682328 0.825151 0.924951 0.715349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153654 episodes
GETTING ACTION FROM:
action -1, numVisits=153650, meanQ=15.900087, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.56419 0.844282 0.682328 0.825151 0.924951 0.715349 w: 1
Observation: 0 0.635851 0 0.751861 0 0.979546 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=153638, meanQ=18.095328, numObservations: 4
action 3, numVisits=8, meanQ=11.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 249065 episodes
GETTING ACTION FROM:
action 2, numVisits=402703, meanQ=18.358790, numObservations: 4
action 3, numVisits=8, meanQ=11.873750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.56419 0.844282 0.682328 0.825151 0.924951 0.715349 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 25
Initial state: 0 0.14117 0.782061 0.688933 0.888151 0.624765 0.839616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221414 episodes
GETTING ACTION FROM:
action 3, numVisits=221407, meanQ=17.840692, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 1, numVisits=3, meanQ=4.670033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.14117 0.782061 0.688933 0.888151 0.624765 0.839616 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.611811 0.819658 0.343624 0.747943 0.675492 0.831007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223099 episodes
GETTING ACTION FROM:
action 3, numVisits=223078, meanQ=18.123155, numObservations: 4
action 1, numVisits=17, meanQ=10.985300, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.611811 0.819658 0.343624 0.747943 0.675492 0.831007 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.678036 0.474382 0.543191 0.855198 0.667878 0.851691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222563 episodes
GETTING ACTION FROM:
action 2, numVisits=222559, meanQ=17.753447, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.678036 0.474382 0.543191 0.855198 0.667878 0.851691 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.547491 0.886143 0.215295 0.508186 0.620935 0.877566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223544 episodes
GETTING ACTION FROM:
action 1, numVisits=223538, meanQ=17.760118, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.547491 0.886143 0.215295 0.508186 0.620935 0.877566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.568678 0.0947142 0.589438 0.858534 0.511825 0.829556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223094 episodes
GETTING ACTION FROM:
action 1, numVisits=223083, meanQ=17.864530, numObservations: 5
action 3, numVisits=7, meanQ=10.141429, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.568678 0.0947142 0.589438 0.858534 0.511825 0.829556 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.548522 0.815115 0.876233 0.948779 0.519993 0.806684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218821 episodes
GETTING ACTION FROM:
action 3, numVisits=218812, meanQ=17.834561, numObservations: 5
action 2, numVisits=6, meanQ=13.665000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.548522 0.815115 0.876233 0.948779 0.519993 0.806684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 31
Initial state: 0 0.695162 0.860638 0.28199 0.997642 0.548579 0.801286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222992 episodes
GETTING ACTION FROM:
action 3, numVisits=222985, meanQ=17.834198, numObservations: 4
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.695162 0.860638 0.28199 0.997642 0.548579 0.801286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16494, meanQ=18.708153, numObservations: 3
action 1, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 271450 episodes
GETTING ACTION FROM:
action 3, numVisits=287944, meanQ=17.549534, numObservations: 3
action 1, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.695162 0.860638 0.28199 0.997642 0.548579 0.801286 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 32
Initial state: 0 0.489678 0.948584 0.592161 0.898121 0.60777 0.810387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226460 episodes
GETTING ACTION FROM:
action 2, numVisits=226456, meanQ=17.844843, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.489678 0.948584 0.592161 0.898121 0.60777 0.810387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 33
Initial state: 0 0.581446 0.815041 0.514004 0.814071 0.178514 0.745308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222784 episodes
GETTING ACTION FROM:
action 3, numVisits=222780, meanQ=17.691988, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.581446 0.815041 0.514004 0.814071 0.178514 0.745308 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31375, meanQ=23.204517, numObservations: 4
action 2, numVisits=15, meanQ=20.134007, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282659 episodes
GETTING ACTION FROM:
action 1, numVisits=311201, meanQ=19.068347, numObservations: 4
action 2, numVisits=2848, meanQ=18.945862, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.581446 0.815041 0.514004 0.814071 0.178514 0.745308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 34
Initial state: 0 0.695246 0.829236 0.548868 0.523327 0.626617 0.812485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220999 episodes
GETTING ACTION FROM:
action 1, numVisits=220990, meanQ=18.080742, numObservations: 5
action 3, numVisits=5, meanQ=11.598000, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.695246 0.829236 0.548868 0.523327 0.626617 0.812485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 35
Initial state: 0 0.656015 0.835565 0.0590132 0.397397 0.627602 0.822142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218739 episodes
GETTING ACTION FROM:
action 2, numVisits=218540, meanQ=17.855375, numObservations: 4
action 1, numVisits=189, meanQ=16.677152, numObservations: 5
action 3, numVisits=8, meanQ=12.376262, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.656015 0.835565 0.0590132 0.397397 0.627602 0.822142 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=35860, meanQ=23.140806, numObservations: 3
action 1, numVisits=7, meanQ=20.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291347 episodes
GETTING ACTION FROM:
action 3, numVisits=327112, meanQ=19.065442, numObservations: 3
action 1, numVisits=102, meanQ=18.323333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.656015 0.835565 0.0590132 0.397397 0.627602 0.822142 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 36
Initial state: 0 0.128685 0.22064 0.586545 0.802481 0.531196 0.878749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221717 episodes
GETTING ACTION FROM:
action 1, numVisits=221712, meanQ=17.877460, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.128685 0.22064 0.586545 0.802481 0.531196 0.878749 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31305, meanQ=23.265057, numObservations: 5
action 2, numVisits=6, meanQ=19.498333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 280385 episodes
GETTING ACTION FROM:
action 3, numVisits=311660, meanQ=19.850821, numObservations: 5
action 2, numVisits=36, meanQ=18.388611, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.128685 0.22064 0.586545 0.802481 0.531196 0.878749 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=930, meanQ=22.415291, numObservations: 3
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 296599 episodes
GETTING ACTION FROM:
action 3, numVisits=297525, meanQ=18.671436, numObservations: 3
action 2, numVisits=7, meanQ=15.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.128685 0.22064 0.586545 0.802481 0.531196 0.878749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 37
Initial state: 0 0.592592 0.847463 0.619614 0.874538 0.162386 0.218067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220964 episodes
GETTING ACTION FROM:
action 1, numVisits=220956, meanQ=17.838824, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.592592 0.847463 0.619614 0.874538 0.162386 0.218067 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 38
Initial state: 0 0.502541 0.802959 0.505979 0.884536 0.134349 0.0691632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224775 episodes
GETTING ACTION FROM:
action 3, numVisits=224761, meanQ=17.919114, numObservations: 4
action 1, numVisits=10, meanQ=12.198010, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.502541 0.802959 0.505979 0.884536 0.134349 0.0691632 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=36861, meanQ=23.198362, numObservations: 4
action 1, numVisits=5, meanQ=18.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286502 episodes
GETTING ACTION FROM:
action 2, numVisits=323362, meanQ=19.570128, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.502541 0.802959 0.505979 0.884536 0.134349 0.0691632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 39
Initial state: 0 0.553597 0.833549 0.543341 0.838476 0.230343 0.53094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223363 episodes
GETTING ACTION FROM:
action 2, numVisits=223349, meanQ=17.833889, numObservations: 4
action 3, numVisits=5, meanQ=13.196000, numObservations: 2
action 1, numVisits=7, meanQ=10.998586, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.553597 0.833549 0.543341 0.838476 0.230343 0.53094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 40
Initial state: 0 0.519221 0.836855 0.847319 0.00840863 0.547163 0.849778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222740 episodes
GETTING ACTION FROM:
action 1, numVisits=222735, meanQ=18.080658, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.519221 0.836855 0.847319 0.00840863 0.547163 0.849778 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 41
Initial state: 0 0.623656 0.855134 0.715606 0.955529 0.697105 0.873342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225283 episodes
GETTING ACTION FROM:
action 2, numVisits=225277, meanQ=17.839670, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.623656 0.855134 0.715606 0.955529 0.697105 0.873342 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 42
Initial state: 0 0.303505 0.824661 0.612727 0.80651 0.604517 0.881827 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152871 episodes
GETTING ACTION FROM:
action 0, numVisits=152866, meanQ=15.702281, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.303505 0.824661 0.612727 0.80651 0.604517 0.881827 w: 1
Observation: 0 0 0.812616 0 0.782455 0 0.801573 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=152835, meanQ=17.902602, numObservations: 5
action 1, numVisits=27, meanQ=11.739648, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 244991 episodes
GETTING ACTION FROM:
action 3, numVisits=397826, meanQ=18.068997, numObservations: 5
action 1, numVisits=27, meanQ=11.739648, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.303505 0.824661 0.612727 0.80651 0.604517 0.881827 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=24860, meanQ=18.880407, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 269775 episodes
GETTING ACTION FROM:
action 3, numVisits=294635, meanQ=17.841120, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.303505 0.824661 0.612727 0.80651 0.604517 0.881827 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 43
Initial state: 0 0.651642 0.890729 0.174719 0.173245 0.69508 0.862612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221085 episodes
GETTING ACTION FROM:
action 1, numVisits=221076, meanQ=17.821576, numObservations: 5
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.651642 0.890729 0.174719 0.173245 0.69508 0.862612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 44
Initial state: 0 0.374729 0.418633 0.536059 0.873109 0.681491 0.884976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221730 episodes
GETTING ACTION FROM:
action 1, numVisits=221726, meanQ=17.838868, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.374729 0.418633 0.536059 0.873109 0.681491 0.884976 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31403, meanQ=23.228640, numObservations: 4
action 3, numVisits=8, meanQ=20.623750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287149 episodes
GETTING ACTION FROM:
action 3, numVisits=86299, meanQ=19.195232, numObservations: 3
action 2, numVisits=232261, meanQ=18.965788, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.374729 0.418633 0.536059 0.873109 0.681491 0.884976 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 45
Initial state: 0 0.0365641 0.574014 0.512306 0.827503 0.566869 0.897504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222484 episodes
GETTING ACTION FROM:
action 1, numVisits=222468, meanQ=17.710768, numObservations: 4
action 2, numVisits=13, meanQ=12.076931, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0365641 0.574014 0.512306 0.827503 0.566869 0.897504 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36272, meanQ=23.212593, numObservations: 5
action 2, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282528 episodes
GETTING ACTION FROM:
action 3, numVisits=318795, meanQ=19.007181, numObservations: 5
action 2, numVisits=8, meanQ=16.248750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0365641 0.574014 0.512306 0.827503 0.566869 0.897504 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 46
Initial state: 0 0.465569 0.293515 0.626505 0.838516 0.551687 0.893838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220725 episodes
GETTING ACTION FROM:
action 3, numVisits=220714, meanQ=17.733417, numObservations: 5
action 1, numVisits=8, meanQ=11.873750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.465569 0.293515 0.626505 0.838516 0.551687 0.893838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 47
Initial state: 0 0.615968 0.820422 0.677806 0.862189 0.700127 0.537631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219916 episodes
GETTING ACTION FROM:
action 3, numVisits=219905, meanQ=17.705774, numObservations: 5
action 1, numVisits=7, meanQ=12.140014, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.615968 0.820422 0.677806 0.862189 0.700127 0.537631 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 48
Initial state: 0 0.661354 0.850472 0.676918 0.873725 0.489368 0.0509848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224705 episodes
GETTING ACTION FROM:
action 1, numVisits=224700, meanQ=17.807428, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.661354 0.850472 0.676918 0.873725 0.489368 0.0509848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 49
Initial state: 0 0.337072 0.100708 0.676112 0.842411 0.600658 0.894328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216144 episodes
GETTING ACTION FROM:
action 3, numVisits=216129, meanQ=17.663703, numObservations: 4
action 1, numVisits=12, meanQ=11.248342, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.337072 0.100708 0.676112 0.842411 0.600658 0.894328 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 50
Initial state: 0 0.200805 0.282682 0.560762 0.857508 0.578067 0.86117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228488 episodes
GETTING ACTION FROM:
action 2, numVisits=228484, meanQ=17.914534, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.200805 0.282682 0.560762 0.857508 0.578067 0.86117 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 51
Initial state: 0 0.57085 0.861194 0.406717 0.575736 0.656216 0.893809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223636 episodes
GETTING ACTION FROM:
action 2, numVisits=223631, meanQ=17.699877, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.57085 0.861194 0.406717 0.575736 0.656216 0.893809 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31269, meanQ=23.156394, numObservations: 4
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285160 episodes
GETTING ACTION FROM:
action 3, numVisits=316429, meanQ=19.380129, numObservations: 4
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.57085 0.861194 0.406717 0.575736 0.656216 0.893809 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 52
Initial state: 0 0.693498 0.812306 0.864586 0.0855354 0.64226 0.858604 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222189 episodes
GETTING ACTION FROM:
action 3, numVisits=222155, meanQ=17.827980, numObservations: 5
action 1, numVisits=31, meanQ=16.455161, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.693498 0.812306 0.864586 0.0855354 0.64226 0.858604 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 53
Initial state: 0 0.538341 0.870493 0.427811 0.944896 0.667086 0.873749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221849 episodes
GETTING ACTION FROM:
action 1, numVisits=221843, meanQ=17.846315, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.538341 0.870493 0.427811 0.944896 0.667086 0.873749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 54
Initial state: 0 0.535122 0.849532 0.491239 0.30765 0.655356 0.854937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227574 episodes
GETTING ACTION FROM:
action 2, numVisits=227568, meanQ=17.691957, numObservations: 3
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.535122 0.849532 0.491239 0.30765 0.655356 0.854937 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37568, meanQ=23.131614, numObservations: 3
action 1, numVisits=47, meanQ=21.616600, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289829 episodes
GETTING ACTION FROM:
action 3, numVisits=326906, meanQ=19.710549, numObservations: 3
action 1, numVisits=538, meanQ=19.411222, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.535122 0.849532 0.491239 0.30765 0.655356 0.854937 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 55
Initial state: 0 0.389025 0.90469 0.565183 0.834401 0.604522 0.826314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222140 episodes
GETTING ACTION FROM:
action 2, numVisits=222135, meanQ=17.757946, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.389025 0.90469 0.565183 0.834401 0.604522 0.826314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 56
Initial state: 0 0.18198 0.354124 0.637933 0.840731 0.545827 0.868147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223909 episodes
GETTING ACTION FROM:
action 1, numVisits=223905, meanQ=17.819212, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.18198 0.354124 0.637933 0.840731 0.545827 0.868147 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=37054, meanQ=23.186966, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287974 episodes
GETTING ACTION FROM:
action 2, numVisits=325028, meanQ=19.319998, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.18198 0.354124 0.637933 0.840731 0.545827 0.868147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7996, meanQ=21.320441, numObservations: 4
action 2, numVisits=12, meanQ=19.498333, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 290916 episodes
GETTING ACTION FROM:
action 3, numVisits=298886, meanQ=19.163026, numObservations: 4
action 2, numVisits=38, meanQ=17.973158, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.18198 0.354124 0.637933 0.840731 0.545827 0.868147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 57
Initial state: 0 0.654008 0.886964 0.663561 0.886618 0.360194 0.764049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220638 episodes
GETTING ACTION FROM:
action 3, numVisits=220630, meanQ=17.715251, numObservations: 5
action 1, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.654008 0.886964 0.663561 0.886618 0.360194 0.764049 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25072, meanQ=23.506732, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286357 episodes
GETTING ACTION FROM:
action 1, numVisits=311429, meanQ=18.753073, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.654008 0.886964 0.663561 0.886618 0.360194 0.764049 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 58
Initial state: 0 0.617404 0.844578 0.0785396 0.156551 0.606423 0.850457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225625 episodes
GETTING ACTION FROM:
action 1, numVisits=225620, meanQ=17.755181, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.617404 0.844578 0.0785396 0.156551 0.606423 0.850457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 59
Initial state: 0 0.527475 0.836388 0.866016 0.11911 0.643623 0.811918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221324 episodes
GETTING ACTION FROM:
action 1, numVisits=221320, meanQ=17.776165, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.527475 0.836388 0.866016 0.11911 0.643623 0.811918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 60
Initial state: 0 0.630489 0.876106 0.585677 0.851037 0.485092 0.584881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224373 episodes
GETTING ACTION FROM:
action 1, numVisits=224369, meanQ=17.815378, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.630489 0.876106 0.585677 0.851037 0.485092 0.584881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 61
Initial state: 0 0.570084 0.881879 0.684772 0.834673 0.0407334 0.394307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223886 episodes
GETTING ACTION FROM:
action 3, numVisits=223882, meanQ=17.715720, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.570084 0.881879 0.684772 0.834673 0.0407334 0.394307 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11188, meanQ=22.251843, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283414 episodes
GETTING ACTION FROM:
action 1, numVisits=294602, meanQ=19.181465, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.570084 0.881879 0.684772 0.834673 0.0407334 0.394307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 62
Initial state: 0 0.636138 0.804372 0.52797 0.807413 0.610373 0.408089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223848 episodes
GETTING ACTION FROM:
action 1, numVisits=223842, meanQ=17.848567, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.636138 0.804372 0.52797 0.807413 0.610373 0.408089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 63
Initial state: 0 0.65591 0.836761 0.555778 0.846675 0.472711 0.967597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221755 episodes
GETTING ACTION FROM:
action 1, numVisits=221747, meanQ=17.754957, numObservations: 5
action 3, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.65591 0.836761 0.555778 0.846675 0.472711 0.967597 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 64
Initial state: 0 0.510654 0.887827 0.691155 0.875701 0.0463562 0.768596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223803 episodes
GETTING ACTION FROM:
action 3, numVisits=223799, meanQ=17.720339, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.510654 0.887827 0.691155 0.875701 0.0463562 0.768596 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 65
Initial state: 0 0.760375 0.419774 0.681938 0.8131 0.662141 0.828196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223541 episodes
GETTING ACTION FROM:
action 3, numVisits=223537, meanQ=17.777324, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.760375 0.419774 0.681938 0.8131 0.662141 0.828196 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16765, meanQ=17.316868, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 287581 episodes
GETTING ACTION FROM:
action 1, numVisits=304346, meanQ=18.619830, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.760375 0.419774 0.681938 0.8131 0.662141 0.828196 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 66
Initial state: 0 0.617905 0.839901 0.582656 0.899977 0.383573 0.934701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218943 episodes
GETTING ACTION FROM:
action 1, numVisits=218933, meanQ=17.620969, numObservations: 4
action 2, numVisits=7, meanQ=11.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.617905 0.839901 0.582656 0.899977 0.383573 0.934701 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16405, meanQ=17.202037, numObservations: 3
action 1, numVisits=37, meanQ=11.055151, numObservations: 3
action 2, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 286804 episodes
GETTING ACTION FROM:
action 3, numVisits=303209, meanQ=18.646202, numObservations: 3
action 1, numVisits=37, meanQ=11.055151, numObservations: 3
action 2, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.617905 0.839901 0.582656 0.899977 0.383573 0.934701 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=6583, meanQ=20.284195, numObservations: 3
action 2, numVisits=205, meanQ=16.998229, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 291409 episodes
GETTING ACTION FROM:
action 3, numVisits=297992, meanQ=18.105216, numObservations: 3
action 2, numVisits=205, meanQ=16.998229, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.617905 0.839901 0.582656 0.899977 0.383573 0.934701 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 0, numVisits=2127, meanQ=17.672149, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 288729 episodes
GETTING ACTION FROM:
action 3, numVisits=269863, meanQ=16.807388, numObservations: 5
action 0, numVisits=20989, meanQ=0.376066, numObservations: 1
action -1, numVisits=7, meanQ=-2.001414, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.617905 0.839901 0.582656 0.899977 0.383573 0.934701 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 67
Initial state: 0 0.568981 0.172097 0.597672 0.804825 0.673046 0.841898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223171 episodes
GETTING ACTION FROM:
action 2, numVisits=223159, meanQ=17.780050, numObservations: 4
action 3, numVisits=6, meanQ=13.665000, numObservations: 3
action 1, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.568981 0.172097 0.597672 0.804825 0.673046 0.841898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 68
Initial state: 0 0.565409 0.890074 0.0207186 0.453609 0.582448 0.848863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224928 episodes
GETTING ACTION FROM:
action 2, numVisits=224923, meanQ=17.861904, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.565409 0.890074 0.0207186 0.453609 0.582448 0.848863 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25755, meanQ=23.471117, numObservations: 3
action 1, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283751 episodes
GETTING ACTION FROM:
action 3, numVisits=309477, meanQ=19.233284, numObservations: 5
action 1, numVisits=33, meanQ=17.878485, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.565409 0.890074 0.0207186 0.453609 0.582448 0.848863 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 69
Initial state: 0 0.577453 0.898611 0.547427 0.87096 0.511568 0.00773976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224415 episodes
GETTING ACTION FROM:
action 2, numVisits=224409, meanQ=17.707537, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.577453 0.898611 0.547427 0.87096 0.511568 0.00773976 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 70
Initial state: 0 0.0421673 0.738612 0.541418 0.851887 0.659797 0.87087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217119 episodes
GETTING ACTION FROM:
action 2, numVisits=217101, meanQ=18.123695, numObservations: 5
action 1, numVisits=15, meanQ=9.668020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0421673 0.738612 0.541418 0.851887 0.659797 0.87087 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 71
Initial state: 0 0.604795 0.857387 0.942221 0.0769857 0.550605 0.864849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223497 episodes
GETTING ACTION FROM:
action 2, numVisits=223492, meanQ=17.820360, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.604795 0.857387 0.942221 0.0769857 0.550605 0.864849 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 72
Initial state: 0 0.964026 0.340898 0.678728 0.810805 0.644079 0.818395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223092 episodes
GETTING ACTION FROM:
action 3, numVisits=223088, meanQ=17.892410, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.964026 0.340898 0.678728 0.810805 0.644079 0.818395 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 73
Initial state: 0 0.557946 0.873688 0.668765 0.881863 0.781836 0.00965503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222815 episodes
GETTING ACTION FROM:
action 3, numVisits=222811, meanQ=17.847151, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.557946 0.873688 0.668765 0.881863 0.781836 0.00965503 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 74
Initial state: 0 0.697361 0.888176 0.697665 0.867574 0.106686 0.0957859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221171 episodes
GETTING ACTION FROM:
action 2, numVisits=221166, meanQ=17.746565, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.697361 0.888176 0.697665 0.867574 0.106686 0.0957859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 75
Initial state: 0 0.525776 0.843084 0.668619 0.879395 0.949281 0.670617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154648 episodes
GETTING ACTION FROM:
action -1, numVisits=154644, meanQ=15.684640, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.525776 0.843084 0.668619 0.879395 0.949281 0.670617 w: 1
Observation: 0 0.436213 0 0.747818 0 0.869881 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154637, meanQ=17.876593, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 249204 episodes
GETTING ACTION FROM:
action 2, numVisits=403841, meanQ=18.020118, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.525776 0.843084 0.668619 0.879395 0.949281 0.670617 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 76
Initial state: 0 0.534297 0.864195 0.0845226 0.177353 0.661255 0.870857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224828 episodes
GETTING ACTION FROM:
action 1, numVisits=224823, meanQ=17.821950, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.534297 0.864195 0.0845226 0.177353 0.661255 0.870857 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 77
Initial state: 0 0.641441 0.859999 0.0462505 0.379284 0.647773 0.89818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223428 episodes
GETTING ACTION FROM:
action 2, numVisits=223422, meanQ=17.673193, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.641441 0.859999 0.0462505 0.379284 0.647773 0.89818 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=36698, meanQ=23.134086, numObservations: 4
action 3, numVisits=16, meanQ=20.499381, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286841 episodes
GETTING ACTION FROM:
action 1, numVisits=323536, meanQ=19.415340, numObservations: 4
action 3, numVisits=19, meanQ=17.683695, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.641441 0.859999 0.0462505 0.379284 0.647773 0.89818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 78
Initial state: 0 0.605768 0.894495 0.535911 0.876973 0.173919 0.549577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 209731 episodes
GETTING ACTION FROM:
action 3, numVisits=209726, meanQ=17.598812, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.605768 0.894495 0.535911 0.876973 0.173919 0.549577 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=23960, meanQ=21.169968, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 262001 episodes
GETTING ACTION FROM:
action 0, numVisits=285961, meanQ=5.023795, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.605768 0.894495 0.535911 0.876973 0.173919 0.549577 w: 1
Observation: 0 0 0.895954 0 0.866152 0 0.453672 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=89016, meanQ=22.174250, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286443 episodes
GETTING ACTION FROM:
action 2, numVisits=375459, meanQ=19.863782, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.605768 0.894495 0.535911 0.876973 0.173919 0.549577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 79
Initial state: 0 0.519693 0.865072 0.541734 0.914311 0.603747 0.878812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221429 episodes
GETTING ACTION FROM:
action 1, numVisits=221404, meanQ=17.753523, numObservations: 5
action 2, numVisits=21, meanQ=13.464290, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.519693 0.865072 0.541734 0.914311 0.603747 0.878812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 80
Initial state: 0 0.591074 0.808116 0.533265 0.861083 0.0177171 0.595858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224349 episodes
GETTING ACTION FROM:
action 1, numVisits=224345, meanQ=17.834771, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.591074 0.808116 0.533265 0.861083 0.0177171 0.595858 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 81
Initial state: 0 0.602374 0.891257 0.655036 0.897585 0.150161 0.0377675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223469 episodes
GETTING ACTION FROM:
action 2, numVisits=223463, meanQ=17.813492, numObservations: 5
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.602374 0.891257 0.655036 0.897585 0.150161 0.0377675 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 82
Initial state: 0 0.600664 0.85429 0.66618 0.139423 0.625189 0.844442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224182 episodes
GETTING ACTION FROM:
action 1, numVisits=224138, meanQ=17.747904, numObservations: 4
action 2, numVisits=41, meanQ=15.982200, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.600664 0.85429 0.66618 0.139423 0.625189 0.844442 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 83
Initial state: 0 0.562814 0.874432 0.52742 0.85304 0.960722 0.24345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222058 episodes
GETTING ACTION FROM:
action 3, numVisits=222050, meanQ=17.776852, numObservations: 5
action 1, numVisits=5, meanQ=6.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.562814 0.874432 0.52742 0.85304 0.960722 0.24345 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 84
Initial state: 0 0.120092 0.527564 0.508017 0.882905 0.566598 0.868715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227886 episodes
GETTING ACTION FROM:
action 2, numVisits=227882, meanQ=17.849026, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.120092 0.527564 0.508017 0.882905 0.566598 0.868715 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 85
Initial state: 0 0.518436 0.880289 0.316374 0.596908 0.63164 0.84173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214212 episodes
GETTING ACTION FROM:
action 3, numVisits=214208, meanQ=17.570878, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.518436 0.880289 0.316374 0.596908 0.63164 0.84173 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 86
Initial state: 0 0.569135 0.883651 0.379109 0.0551638 0.670904 0.827192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221622 episodes
GETTING ACTION FROM:
action 2, numVisits=221608, meanQ=17.734034, numObservations: 5
action 1, numVisits=10, meanQ=14.299000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.569135 0.883651 0.379109 0.0551638 0.670904 0.827192 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30835, meanQ=23.237543, numObservations: 4
action 1, numVisits=4, meanQ=17.247500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287238 episodes
GETTING ACTION FROM:
action 3, numVisits=318072, meanQ=19.372718, numObservations: 4
action 1, numVisits=5, meanQ=12.798020, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.569135 0.883651 0.379109 0.0551638 0.670904 0.827192 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 87
Initial state: 0 0.0161984 0.143831 0.505312 0.835195 0.514612 0.893467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224498 episodes
GETTING ACTION FROM:
action 2, numVisits=224489, meanQ=18.115253, numObservations: 4
action 1, numVisits=6, meanQ=7.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0161984 0.143831 0.505312 0.835195 0.514612 0.893467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 88
Initial state: 0 0.599628 0.869432 0.537903 0.874032 0.865378 0.0180971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221004 episodes
GETTING ACTION FROM:
action 3, numVisits=220999, meanQ=17.738098, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.599628 0.869432 0.537903 0.874032 0.865378 0.0180971 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 89
Initial state: 0 0.593333 0.869295 0.0426622 0.225021 0.616172 0.847461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220656 episodes
GETTING ACTION FROM:
action 1, numVisits=220649, meanQ=17.696639, numObservations: 5
action 3, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.593333 0.869295 0.0426622 0.225021 0.616172 0.847461 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 90
Initial state: 0 0.543658 0.840486 0.066955 0.000568723 0.625423 0.800231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222762 episodes
GETTING ACTION FROM:
action 1, numVisits=222757, meanQ=17.751920, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.543658 0.840486 0.066955 0.000568723 0.625423 0.800231 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16361, meanQ=17.474556, numObservations: 3
action 1, numVisits=10, meanQ=14.299000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290502 episodes
GETTING ACTION FROM:
action 2, numVisits=306863, meanQ=18.150646, numObservations: 3
action 1, numVisits=10, meanQ=14.299000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.543658 0.840486 0.066955 0.000568723 0.625423 0.800231 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 91
Initial state: 0 0.386374 0.131829 0.514061 0.883334 0.652792 0.866871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223378 episodes
GETTING ACTION FROM:
action 2, numVisits=223374, meanQ=17.749546, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.386374 0.131829 0.514061 0.883334 0.652792 0.866871 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 92
Initial state: 0 0.694294 0.892933 0.878647 0.302653 0.637124 0.849713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222990 episodes
GETTING ACTION FROM:
action 1, numVisits=222986, meanQ=17.872652, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.694294 0.892933 0.878647 0.302653 0.637124 0.849713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 93
Initial state: 0 0.554985 0.818701 0.693102 0.834048 0.0535884 0.592454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225254 episodes
GETTING ACTION FROM:
action 2, numVisits=225250, meanQ=17.808136, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.554985 0.818701 0.693102 0.834048 0.0535884 0.592454 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 94
Initial state: 0 0.529457 0.828492 0.683823 0.899555 0.0762782 0.0963838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224334 episodes
GETTING ACTION FROM:
action 1, numVisits=224330, meanQ=18.088068, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.529457 0.828492 0.683823 0.899555 0.0762782 0.0963838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 95
Initial state: 0 0.516161 0.859927 0.634521 0.820491 0.803615 0.102626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221906 episodes
GETTING ACTION FROM:
action 1, numVisits=221902, meanQ=17.760889, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.516161 0.859927 0.634521 0.820491 0.803615 0.102626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 96
Initial state: 0 0.667446 0.819954 0.515398 0.807286 0.195826 0.0977641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224608 episodes
GETTING ACTION FROM:
action 1, numVisits=224603, meanQ=17.735202, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.667446 0.819954 0.515398 0.807286 0.195826 0.0977641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 97
Initial state: 0 0.654675 0.836934 0.624848 0.899508 0.73587 0.661319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222183 episodes
GETTING ACTION FROM:
action 3, numVisits=222162, meanQ=17.837867, numObservations: 5
action 1, numVisits=14, meanQ=15.141429, numObservations: 4
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.654675 0.836934 0.624848 0.899508 0.73587 0.661319 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 98
Initial state: 0 0.573182 0.873496 0.521457 0.85769 0.0165358 0.359846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224194 episodes
GETTING ACTION FROM:
action 3, numVisits=224190, meanQ=17.877257, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.573182 0.873496 0.521457 0.85769 0.0165358 0.359846 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=37065, meanQ=23.149302, numObservations: 4
action 1, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285613 episodes
GETTING ACTION FROM:
action 2, numVisits=322676, meanQ=18.964505, numObservations: 4
action 1, numVisits=5, meanQ=12.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.573182 0.873496 0.521457 0.85769 0.0165358 0.359846 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 99
Initial state: 0 0.632921 0.87186 0.973657 0.200064 0.674752 0.888286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224001 episodes
GETTING ACTION FROM:
action 1, numVisits=223990, meanQ=17.747065, numObservations: 4
action 2, numVisits=8, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.632921 0.87186 0.973657 0.200064 0.674752 0.888286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 100
Initial state: 0 0.626322 0.898991 0.509402 0.813788 0.214467 0.673463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222213 episodes
GETTING ACTION FROM:
action 1, numVisits=222201, meanQ=17.845551, numObservations: 5
action 3, numVisits=8, meanQ=13.375012, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.626322 0.898991 0.509402 0.813788 0.214467 0.673463 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 101
Initial state: 0 0.883688 0.124604 0.584139 0.870707 0.655716 0.8659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215709 episodes
GETTING ACTION FROM:
action 1, numVisits=215705, meanQ=17.699731, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.883688 0.124604 0.584139 0.870707 0.655716 0.8659 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 102
Initial state: 0 0.602235 0.823849 0.697314 0.090223 0.574703 0.886748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218404 episodes
GETTING ACTION FROM:
action 2, numVisits=218386, meanQ=17.802643, numObservations: 4
action 3, numVisits=14, meanQ=15.267150, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.602235 0.823849 0.697314 0.090223 0.574703 0.886748 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 103
Initial state: 0 0.604627 0.805762 0.61646 0.8266 0.872841 0.137517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225793 episodes
GETTING ACTION FROM:
action 2, numVisits=225787, meanQ=17.751170, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.604627 0.805762 0.61646 0.8266 0.872841 0.137517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 104
Initial state: 0 0.6987 0.865439 0.611506 0.896246 0.977864 0.0212381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221245 episodes
GETTING ACTION FROM:
action 2, numVisits=221204, meanQ=17.727239, numObservations: 5
action 1, numVisits=14, meanQ=15.409286, numObservations: 3
action 3, numVisits=25, meanQ=15.059604, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.6987 0.865439 0.611506 0.896246 0.977864 0.0212381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 105
Initial state: 0 0.100998 0.686507 0.612267 0.812859 0.66842 0.834812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221615 episodes
GETTING ACTION FROM:
action 3, numVisits=221611, meanQ=17.750451, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.100998 0.686507 0.612267 0.812859 0.66842 0.834812 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 106
Initial state: 0 0.644804 0.866103 0.0301014 0.353196 0.586212 0.864851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224867 episodes
GETTING ACTION FROM:
action 2, numVisits=224862, meanQ=17.746543, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.644804 0.866103 0.0301014 0.353196 0.586212 0.864851 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=36794, meanQ=23.207481, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284407 episodes
GETTING ACTION FROM:
action 1, numVisits=321201, meanQ=19.492725, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.644804 0.866103 0.0301014 0.353196 0.586212 0.864851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 107
Initial state: 0 0.553588 0.831772 0.316896 0.385554 0.604231 0.859477 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227029 episodes
GETTING ACTION FROM:
action 2, numVisits=227003, meanQ=17.800641, numObservations: 3
action 3, numVisits=19, meanQ=13.683689, numObservations: 3
action 1, numVisits=5, meanQ=13.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.553588 0.831772 0.316896 0.385554 0.604231 0.859477 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37181, meanQ=23.163606, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290493 episodes
GETTING ACTION FROM:
action 3, numVisits=327674, meanQ=19.604659, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.553588 0.831772 0.316896 0.385554 0.604231 0.859477 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 108
Initial state: 0 0.686264 0.855397 0.286951 0.954008 0.595341 0.888595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153651 episodes
GETTING ACTION FROM:
action -1, numVisits=153646, meanQ=15.544703, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.686264 0.855397 0.286951 0.954008 0.595341 0.888595 w: 1
Observation: 0 0.636671 0 0.241724 0 0.68504 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153617, meanQ=17.745178, numObservations: 4
action 3, numVisits=16, meanQ=11.365625, numObservations: 2
action 2, numVisits=10, meanQ=11.201010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 247567 episodes
GETTING ACTION FROM:
action 1, numVisits=401184, meanQ=17.717182, numObservations: 4
action 3, numVisits=16, meanQ=11.365625, numObservations: 2
action 2, numVisits=10, meanQ=11.201010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.686264 0.855397 0.286951 0.954008 0.595341 0.888595 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 109
Initial state: 0 0.433801 0.472513 0.648479 0.871231 0.506258 0.83509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220604 episodes
GETTING ACTION FROM:
action 2, numVisits=220599, meanQ=17.735845, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.433801 0.472513 0.648479 0.871231 0.506258 0.83509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 110
Initial state: 0 0.502042 0.892061 0.275988 0.820058 0.652197 0.835438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221737 episodes
GETTING ACTION FROM:
action 3, numVisits=221733, meanQ=17.788268, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.502042 0.892061 0.275988 0.820058 0.652197 0.835438 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 111
Initial state: 0 0.86755 0.603596 0.513281 0.842117 0.54137 0.829265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223118 episodes
GETTING ACTION FROM:
action 2, numVisits=223110, meanQ=17.738397, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.86755 0.603596 0.513281 0.842117 0.54137 0.829265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 112
Initial state: 0 0.613591 0.889635 0.915863 0.640676 0.695662 0.884393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222545 episodes
GETTING ACTION FROM:
action 1, numVisits=222535, meanQ=17.908089, numObservations: 5
action 2, numVisits=7, meanQ=5.677143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.613591 0.889635 0.915863 0.640676 0.695662 0.884393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 113
Initial state: 0 0.64788 0.814205 0.922779 0.76758 0.662426 0.818946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216345 episodes
GETTING ACTION FROM:
action 3, numVisits=216339, meanQ=17.796589, numObservations: 5
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.64788 0.814205 0.922779 0.76758 0.662426 0.818946 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 114
Initial state: 0 0.896241 0.169943 0.687508 0.848468 0.607937 0.80355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155096 episodes
GETTING ACTION FROM:
action -1, numVisits=155092, meanQ=15.573600, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.896241 0.169943 0.687508 0.848468 0.607937 0.80355 w: 1
Observation: 0 0.933798 0 0.74952 0 0.691265 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=155063, meanQ=17.793323, numObservations: 3
action 1, numVisits=14, meanQ=11.767857, numObservations: 3
action 3, numVisits=12, meanQ=10.082500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 250314 episodes
GETTING ACTION FROM:
action 2, numVisits=405377, meanQ=17.949872, numObservations: 3
action 1, numVisits=14, meanQ=11.767857, numObservations: 3
action 3, numVisits=12, meanQ=10.082500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.896241 0.169943 0.687508 0.848468 0.607937 0.80355 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 115
Initial state: 0 0.64553 0.806157 0.601584 0.82479 0.146808 0.505039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220550 episodes
GETTING ACTION FROM:
action 3, numVisits=220538, meanQ=17.769204, numObservations: 4
action 2, numVisits=9, meanQ=14.108889, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.64553 0.806157 0.601584 0.82479 0.146808 0.505039 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25129, meanQ=23.499802, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285010 episodes
GETTING ACTION FROM:
action 2, numVisits=310139, meanQ=19.019481, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.64553 0.806157 0.601584 0.82479 0.146808 0.505039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 116
Initial state: 0 0.732952 0.997561 0.588992 0.822928 0.664576 0.800196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222063 episodes
GETTING ACTION FROM:
action 3, numVisits=222040, meanQ=17.857928, numObservations: 4
action 2, numVisits=19, meanQ=14.527384, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.732952 0.997561 0.588992 0.822928 0.664576 0.800196 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 117
Initial state: 0 0.678258 0.852793 0.625406 0.883295 0.408225 0.750042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223533 episodes
GETTING ACTION FROM:
action 3, numVisits=223529, meanQ=17.761358, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.678258 0.852793 0.625406 0.883295 0.408225 0.750042 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25621, meanQ=23.447522, numObservations: 3
action 1, numVisits=32, meanQ=21.343444, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287040 episodes
GETTING ACTION FROM:
action 2, numVisits=312422, meanQ=18.944192, numObservations: 4
action 1, numVisits=271, meanQ=18.513065, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.678258 0.852793 0.625406 0.883295 0.408225 0.750042 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 118
Initial state: 0 0.56746 0.854336 0.274972 0.377271 0.544997 0.87921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223644 episodes
GETTING ACTION FROM:
action 3, numVisits=223630, meanQ=17.804896, numObservations: 3
action 2, numVisits=10, meanQ=15.098000, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.56746 0.854336 0.274972 0.377271 0.544997 0.87921 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 119
Initial state: 0 0.720837 0.636967 0.614258 0.840956 0.516186 0.845469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223420 episodes
GETTING ACTION FROM:
action 3, numVisits=223414, meanQ=17.765998, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.720837 0.636967 0.614258 0.840956 0.516186 0.845469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 120
Initial state: 0 0.568454 0.856921 0.503501 0.838004 0.0217455 0.437039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221071 episodes
GETTING ACTION FROM:
action 3, numVisits=221066, meanQ=17.848113, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.568454 0.856921 0.503501 0.838004 0.0217455 0.437039 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5128, meanQ=22.350581, numObservations: 3
action 2, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292105 episodes
GETTING ACTION FROM:
action 1, numVisits=297212, meanQ=18.680691, numObservations: 3
action 2, numVisits=24, meanQ=17.041250, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.568454 0.856921 0.503501 0.838004 0.0217455 0.437039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 121
Initial state: 0 0.687043 0.849529 0.214151 0.291129 0.546313 0.801121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219710 episodes
GETTING ACTION FROM:
action 3, numVisits=219703, meanQ=17.764636, numObservations: 5
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.687043 0.849529 0.214151 0.291129 0.546313 0.801121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 122
Initial state: 0 0.602657 0.871276 0.432748 0.845695 0.584164 0.854723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226262 episodes
GETTING ACTION FROM:
action 3, numVisits=226258, meanQ=17.863359, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.602657 0.871276 0.432748 0.845695 0.584164 0.854723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 123
Initial state: 0 0.558517 0.890707 0.582857 0.803605 0.4421 0.919176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222931 episodes
GETTING ACTION FROM:
action 1, numVisits=222917, meanQ=17.797843, numObservations: 4
action 2, numVisits=10, meanQ=12.198010, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.558517 0.890707 0.582857 0.803605 0.4421 0.919176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 124
Initial state: 0 0.682526 0.830989 0.61508 0.802365 0.547378 0.159201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226687 episodes
GETTING ACTION FROM:
action 1, numVisits=226682, meanQ=17.859215, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.682526 0.830989 0.61508 0.802365 0.547378 0.159201 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 125
Initial state: 0 0.718209 0.0604889 0.655424 0.854478 0.578654 0.841284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223227 episodes
GETTING ACTION FROM:
action 3, numVisits=223223, meanQ=17.919079, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.718209 0.0604889 0.655424 0.854478 0.578654 0.841284 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 126
Initial state: 0 0.675483 0.859363 0.857462 0.489556 0.561803 0.838764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220352 episodes
GETTING ACTION FROM:
action 3, numVisits=220346, meanQ=17.703776, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.675483 0.859363 0.857462 0.489556 0.561803 0.838764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 127
Initial state: 0 0.590239 0.859136 0.114313 0.19778 0.650191 0.812147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219970 episodes
GETTING ACTION FROM:
action 3, numVisits=219965, meanQ=17.794747, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.590239 0.859136 0.114313 0.19778 0.650191 0.812147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 128
Initial state: 0 0.482159 0.884135 0.546592 0.837824 0.699901 0.812199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224521 episodes
GETTING ACTION FROM:
action 3, numVisits=224516, meanQ=17.868611, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.482159 0.884135 0.546592 0.837824 0.699901 0.812199 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16568, meanQ=18.718014, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 263470 episodes
GETTING ACTION FROM:
action 3, numVisits=280038, meanQ=17.715297, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.482159 0.884135 0.546592 0.837824 0.699901 0.812199 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 129
Initial state: 0 0.515728 0.875008 0.566877 0.0780192 0.505316 0.8795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221766 episodes
GETTING ACTION FROM:
action 2, numVisits=221740, meanQ=17.813614, numObservations: 5
action 3, numVisits=10, meanQ=10.375000, numObservations: 4
action 1, numVisits=14, meanQ=9.828571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.515728 0.875008 0.566877 0.0780192 0.505316 0.8795 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 130
Initial state: 0 0.51438 0.831307 0.467308 0.849636 0.623817 0.896305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223849 episodes
GETTING ACTION FROM:
action 1, numVisits=223845, meanQ=17.850439, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.51438 0.831307 0.467308 0.849636 0.623817 0.896305 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 131
Initial state: 0 0.0174616 0.683465 0.620589 0.818969 0.690283 0.812202 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225649 episodes
GETTING ACTION FROM:
action 1, numVisits=225644, meanQ=17.846330, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0174616 0.683465 0.620589 0.818969 0.690283 0.812202 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=37148, meanQ=23.098402, numObservations: 4
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287795 episodes
GETTING ACTION FROM:
action 2, numVisits=324943, meanQ=19.119591, numObservations: 4
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0174616 0.683465 0.620589 0.818969 0.690283 0.812202 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 132
Initial state: 0 0.634253 0.824665 0.777522 0.709237 0.624065 0.894032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221542 episodes
GETTING ACTION FROM:
action 3, numVisits=221538, meanQ=17.824145, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.634253 0.824665 0.777522 0.709237 0.624065 0.894032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 133
Initial state: 0 0.599255 0.892754 0.525095 0.877829 0.139688 0.987017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220938 episodes
GETTING ACTION FROM:
action 3, numVisits=220926, meanQ=17.799479, numObservations: 5
action 2, numVisits=9, meanQ=12.750000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.599255 0.892754 0.525095 0.877829 0.139688 0.987017 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16301, meanQ=18.602984, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 262830 episodes
GETTING ACTION FROM:
action 3, numVisits=279131, meanQ=18.315756, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.599255 0.892754 0.525095 0.877829 0.139688 0.987017 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3210, meanQ=22.576922, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 297344 episodes
GETTING ACTION FROM:
action 1, numVisits=300554, meanQ=18.997569, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.599255 0.892754 0.525095 0.877829 0.139688 0.987017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 134
Initial state: 0 0.672377 0.828067 0.623689 0.684198 0.511308 0.856527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222974 episodes
GETTING ACTION FROM:
action 2, numVisits=222970, meanQ=17.876819, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.672377 0.828067 0.623689 0.684198 0.511308 0.856527 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 135
Initial state: 0 0.0560353 0.57504 0.641877 0.866879 0.601048 0.835483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223758 episodes
GETTING ACTION FROM:
action 3, numVisits=223747, meanQ=17.875510, numObservations: 4
action 2, numVisits=6, meanQ=6.500000, numObservations: 1
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0560353 0.57504 0.641877 0.866879 0.601048 0.835483 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 136
Initial state: 0 0.167533 0.684774 0.67359 0.832418 0.658183 0.835589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222778 episodes
GETTING ACTION FROM:
action 1, numVisits=222762, meanQ=17.814499, numObservations: 5
action 3, numVisits=13, meanQ=8.770008, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.167533 0.684774 0.67359 0.832418 0.658183 0.835589 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25504, meanQ=23.453575, numObservations: 3
action 3, numVisits=6, meanQ=19.498333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292419 episodes
GETTING ACTION FROM:
action 2, numVisits=317913, meanQ=19.801978, numObservations: 3
action 3, numVisits=16, meanQ=17.936875, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.167533 0.684774 0.67359 0.832418 0.658183 0.835589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 137
Initial state: 0 0.555129 0.894926 0.515689 0.840537 0.051084 0.408154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221377 episodes
GETTING ACTION FROM:
action 3, numVisits=221370, meanQ=17.752132, numObservations: 5
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.555129 0.894926 0.515689 0.840537 0.051084 0.408154 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25076, meanQ=23.503997, numObservations: 3
action 1, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285770 episodes
GETTING ACTION FROM:
action 2, numVisits=310846, meanQ=19.148203, numObservations: 4
action 1, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.555129 0.894926 0.515689 0.840537 0.051084 0.408154 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 138
Initial state: 0 0.607275 0.821603 0.0500681 0.573007 0.502536 0.825505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223263 episodes
GETTING ACTION FROM:
action 3, numVisits=223257, meanQ=17.756376, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.607275 0.821603 0.0500681 0.573007 0.502536 0.825505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 139
Initial state: 0 0.665872 0.849045 0.617086 0.856027 0.155234 0.817069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223614 episodes
GETTING ACTION FROM:
action 1, numVisits=223608, meanQ=17.814770, numObservations: 4
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.665872 0.849045 0.617086 0.856027 0.155234 0.817069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 140
Initial state: 0 0.688 0.892581 0.586028 0.842784 0.0965143 0.00860895 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226160 episodes
GETTING ACTION FROM:
action 1, numVisits=226156, meanQ=17.734937, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.688 0.892581 0.586028 0.842784 0.0965143 0.00860895 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 141
Initial state: 0 0.139075 0.932563 0.587548 0.868689 0.62261 0.830326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223221 episodes
GETTING ACTION FROM:
action 2, numVisits=223217, meanQ=17.744907, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.139075 0.932563 0.587548 0.868689 0.62261 0.830326 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 142
Initial state: 0 0.543289 0.871914 0.571528 0.882903 0.148727 0.074531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219021 episodes
GETTING ACTION FROM:
action 3, numVisits=219005, meanQ=17.881385, numObservations: 5
action 2, numVisits=9, meanQ=8.332244, numObservations: 4
action 1, numVisits=5, meanQ=6.196000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.543289 0.871914 0.571528 0.882903 0.148727 0.074531 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=24835, meanQ=23.514904, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 289555 episodes
GETTING ACTION FROM:
action 2, numVisits=314390, meanQ=19.032324, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.543289 0.871914 0.571528 0.882903 0.148727 0.074531 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 143
Initial state: 0 0.0541406 0.885325 0.623043 0.829109 0.592356 0.854746 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223508 episodes
GETTING ACTION FROM:
action 2, numVisits=223504, meanQ=17.740387, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0541406 0.885325 0.623043 0.829109 0.592356 0.854746 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=36729, meanQ=23.163744, numObservations: 4
action 3, numVisits=4, meanQ=17.247500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286151 episodes
GETTING ACTION FROM:
action 1, numVisits=322876, meanQ=19.543621, numObservations: 4
action 3, numVisits=8, meanQ=16.248750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0541406 0.885325 0.623043 0.829109 0.592356 0.854746 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7052, meanQ=23.169054, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 293937 episodes
GETTING ACTION FROM:
action 3, numVisits=300989, meanQ=19.636444, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0541406 0.885325 0.623043 0.829109 0.592356 0.854746 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 144
Initial state: 0 0.677636 0.833755 0.625293 0.864517 0.393399 0.457182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221577 episodes
GETTING ACTION FROM:
action 3, numVisits=221573, meanQ=17.726515, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.677636 0.833755 0.625293 0.864517 0.393399 0.457182 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25423, meanQ=23.473696, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286013 episodes
GETTING ACTION FROM:
action 1, numVisits=311436, meanQ=18.912834, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.677636 0.833755 0.625293 0.864517 0.393399 0.457182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 145
Initial state: 0 0.683188 0.845762 0.724159 0.593628 0.60696 0.810512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223045 episodes
GETTING ACTION FROM:
action 2, numVisits=223040, meanQ=17.869887, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.683188 0.845762 0.724159 0.593628 0.60696 0.810512 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 146
Initial state: 0 0.336228 0.0239517 0.56071 0.868446 0.624072 0.816635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224422 episodes
GETTING ACTION FROM:
action 2, numVisits=224412, meanQ=17.722671, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.336228 0.0239517 0.56071 0.868446 0.624072 0.816635 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 147
Initial state: 0 0.683003 0.883138 0.579822 0.83455 0.468448 0.863455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222865 episodes
GETTING ACTION FROM:
action 1, numVisits=222861, meanQ=17.721092, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.683003 0.883138 0.579822 0.83455 0.468448 0.863455 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 148
Initial state: 0 0.12856 0.632776 0.642586 0.873615 0.647916 0.858494 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223659 episodes
GETTING ACTION FROM:
action 2, numVisits=223654, meanQ=17.794058, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.12856 0.632776 0.642586 0.873615 0.647916 0.858494 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 149
Initial state: 0 0.510562 0.845187 0.539268 0.823008 0.897786 0.870334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153704 episodes
GETTING ACTION FROM:
action 0, numVisits=153699, meanQ=15.536651, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.510562 0.845187 0.539268 0.823008 0.897786 0.870334 w: 1
Observation: 0 0 0.804384 0 0.849435 0 0.896381 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=153692, meanQ=17.787671, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 247094 episodes
GETTING ACTION FROM:
action 2, numVisits=400786, meanQ=17.819246, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.510562 0.845187 0.539268 0.823008 0.897786 0.870334 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 150
Initial state: 0 0.569975 0.899418 0.209164 0.0946425 0.603776 0.828441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222022 episodes
GETTING ACTION FROM:
action 3, numVisits=222017, meanQ=17.794181, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.569975 0.899418 0.209164 0.0946425 0.603776 0.828441 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 151
Initial state: 0 0.617811 0.864252 0.616796 0.845759 0.175634 0.991503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221472 episodes
GETTING ACTION FROM:
action 2, numVisits=221465, meanQ=17.833132, numObservations: 5
action 1, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.617811 0.864252 0.616796 0.845759 0.175634 0.991503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 152
Initial state: 0 0.57281 0.850049 0.511434 0.841525 0.386605 0.443662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222241 episodes
GETTING ACTION FROM:
action 2, numVisits=222233, meanQ=17.756535, numObservations: 4
action 1, numVisits=5, meanQ=12.348000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.57281 0.850049 0.511434 0.841525 0.386605 0.443662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 153
Initial state: 0 0.0951869 0.0755394 0.580766 0.824969 0.531225 0.874487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221386 episodes
GETTING ACTION FROM:
action 1, numVisits=221375, meanQ=17.732303, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action 3, numVisits=5, meanQ=5.418000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.0951869 0.0755394 0.580766 0.824969 0.531225 0.874487 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31146, meanQ=23.271195, numObservations: 4
action 3, numVisits=19, meanQ=19.735263, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285681 episodes
GETTING ACTION FROM:
action 2, numVisits=316821, meanQ=19.371295, numObservations: 4
action 3, numVisits=25, meanQ=17.958800, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0951869 0.0755394 0.580766 0.824969 0.531225 0.874487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 154
Initial state: 0 0.505725 0.11731 0.696978 0.891117 0.565996 0.868783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222296 episodes
GETTING ACTION FROM:
action 3, numVisits=222290, meanQ=17.796815, numObservations: 5
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.505725 0.11731 0.696978 0.891117 0.565996 0.868783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 155
Initial state: 0 0.625226 0.886398 0.594354 0.802442 0.185599 0.503037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223258 episodes
GETTING ACTION FROM:
action 2, numVisits=223251, meanQ=17.835316, numObservations: 4
action 1, numVisits=4, meanQ=3.245025, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.625226 0.886398 0.594354 0.802442 0.185599 0.503037 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 156
Initial state: 0 0.614334 0.86692 0.397077 0.280058 0.512303 0.803944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220016 episodes
GETTING ACTION FROM:
action 3, numVisits=219979, meanQ=17.806909, numObservations: 5
action 2, numVisits=30, meanQ=14.834003, numObservations: 3
action 1, numVisits=5, meanQ=10.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.614334 0.86692 0.397077 0.280058 0.512303 0.803944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 157
Initial state: 0 0.571592 0.878154 0.513482 0.877458 0.659548 0.159121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228207 episodes
GETTING ACTION FROM:
action 2, numVisits=228203, meanQ=17.748781, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.571592 0.878154 0.513482 0.877458 0.659548 0.159121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 158
Initial state: 0 0.690037 0.897281 0.737676 0.505944 0.63186 0.890953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226713 episodes
GETTING ACTION FROM:
action 2, numVisits=226701, meanQ=17.830563, numObservations: 3
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action 3, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.690037 0.897281 0.737676 0.505944 0.63186 0.890953 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 159
Initial state: 0 0.607321 0.851028 0.656363 0.871096 0.258214 0.800756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225119 episodes
GETTING ACTION FROM:
action 3, numVisits=225114, meanQ=17.847705, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.607321 0.851028 0.656363 0.871096 0.258214 0.800756 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 160
Initial state: 0 0.598407 0.886046 0.682087 0.846036 0.332655 0.986134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224159 episodes
GETTING ACTION FROM:
action 1, numVisits=224147, meanQ=17.704124, numObservations: 4
action 2, numVisits=6, meanQ=13.665000, numObservations: 2
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.598407 0.886046 0.682087 0.846036 0.332655 0.986134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 161
Initial state: 0 0.692242 0.830313 0.579297 0.856072 0.997742 0.969596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223219 episodes
GETTING ACTION FROM:
action 2, numVisits=223207, meanQ=17.879673, numObservations: 5
action 3, numVisits=9, meanQ=13.221111, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.692242 0.830313 0.579297 0.856072 0.997742 0.969596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 162
Initial state: 0 0.568458 0.853706 0.539413 0.873338 0.164375 0.901864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222242 episodes
GETTING ACTION FROM:
action 3, numVisits=222166, meanQ=17.810280, numObservations: 4
action 2, numVisits=72, meanQ=16.497785, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.568458 0.853706 0.539413 0.873338 0.164375 0.901864 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16248, meanQ=17.604012, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 281900 episodes
GETTING ACTION FROM:
action 2, numVisits=298148, meanQ=18.648318, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.568458 0.853706 0.539413 0.873338 0.164375 0.901864 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 163
Initial state: 0 0.692976 0.151103 0.699858 0.898861 0.660987 0.883233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222433 episodes
GETTING ACTION FROM:
action 3, numVisits=222428, meanQ=17.813333, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.692976 0.151103 0.699858 0.898861 0.660987 0.883233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 164
Initial state: 0 0.649307 0.890729 0.676589 0.47939 0.681501 0.891662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223854 episodes
GETTING ACTION FROM:
action 3, numVisits=223850, meanQ=17.873406, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.649307 0.890729 0.676589 0.47939 0.681501 0.891662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 165
Initial state: 0 0.671562 0.896181 0.529357 0.848258 0.927263 0.731846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222416 episodes
GETTING ACTION FROM:
action 1, numVisits=222409, meanQ=17.806998, numObservations: 5
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.671562 0.896181 0.529357 0.848258 0.927263 0.731846 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 166
Initial state: 0 0.509911 0.815287 0.62633 0.887723 0.663367 0.345159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223746 episodes
GETTING ACTION FROM:
action 3, numVisits=223742, meanQ=17.793031, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.509911 0.815287 0.62633 0.887723 0.663367 0.345159 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 167
Initial state: 0 0.433234 0.767299 0.684775 0.846627 0.548847 0.858854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225372 episodes
GETTING ACTION FROM:
action 3, numVisits=225367, meanQ=17.746494, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.433234 0.767299 0.684775 0.846627 0.548847 0.858854 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 168
Initial state: 0 0.617896 0.856959 0.560712 0.825582 0.432125 0.654689 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224618 episodes
GETTING ACTION FROM:
action 3, numVisits=224611, meanQ=17.749028, numObservations: 4
action 1, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.617896 0.856959 0.560712 0.825582 0.432125 0.654689 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=36701, meanQ=23.186044, numObservations: 4
action 2, numVisits=7, meanQ=20.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282854 episodes
GETTING ACTION FROM:
action 1, numVisits=319310, meanQ=19.429670, numObservations: 4
action 2, numVisits=252, meanQ=18.973612, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.617896 0.856959 0.560712 0.825582 0.432125 0.654689 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 169
Initial state: 0 0.576012 0.825429 0.571778 0.893978 0.154407 0.854067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156000 episodes
GETTING ACTION FROM:
action -1, numVisits=155993, meanQ=15.469959, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.576012 0.825429 0.571778 0.893978 0.154407 0.854067 w: 1
Observation: 0 0.672073 0 0.663173 0 0.177094 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=155987, meanQ=17.674965, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 252977 episodes
GETTING ACTION FROM:
action 1, numVisits=408964, meanQ=17.780531, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.576012 0.825429 0.571778 0.893978 0.154407 0.854067 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 170
Initial state: 0 0.608599 0.846441 0.973907 0.612121 0.597731 0.807929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224674 episodes
GETTING ACTION FROM:
action 2, numVisits=224663, meanQ=17.884807, numObservations: 4
action 1, numVisits=8, meanQ=9.496250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.608599 0.846441 0.973907 0.612121 0.597731 0.807929 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 171
Initial state: 0 0.043802 0.749167 0.623926 0.86626 0.587014 0.851011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225268 episodes
GETTING ACTION FROM:
action 1, numVisits=225264, meanQ=17.897581, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.043802 0.749167 0.623926 0.86626 0.587014 0.851011 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36886, meanQ=23.172740, numObservations: 4
action 2, numVisits=43, meanQ=20.766749, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283606 episodes
GETTING ACTION FROM:
action 3, numVisits=320478, meanQ=19.785733, numObservations: 4
action 2, numVisits=57, meanQ=18.630881, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.043802 0.749167 0.623926 0.86626 0.587014 0.851011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 172
Initial state: 0 0.669188 0.876687 0.492093 0.197922 0.504119 0.819771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220717 episodes
GETTING ACTION FROM:
action 3, numVisits=220707, meanQ=17.798194, numObservations: 5
action 2, numVisits=7, meanQ=10.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.669188 0.876687 0.492093 0.197922 0.504119 0.819771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 173
Initial state: 0 0.597836 0.872305 0.725351 0.726578 0.55577 0.869132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221474 episodes
GETTING ACTION FROM:
action 1, numVisits=221467, meanQ=18.097011, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.597836 0.872305 0.725351 0.726578 0.55577 0.869132 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 174
Initial state: 0 0.689413 0.893561 0.638875 0.887477 0.0934206 0.0191747 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223471 episodes
GETTING ACTION FROM:
action 1, numVisits=223456, meanQ=17.856610, numObservations: 5
action 3, numVisits=11, meanQ=13.451818, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.689413 0.893561 0.638875 0.887477 0.0934206 0.0191747 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 175
Initial state: 0 0.673398 0.82728 0.669214 0.893036 0.434731 0.78859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227257 episodes
GETTING ACTION FROM:
action 3, numVisits=227243, meanQ=17.805933, numObservations: 3
action 1, numVisits=11, meanQ=13.270918, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.673398 0.82728 0.669214 0.893036 0.434731 0.78859 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=36797, meanQ=23.145365, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288478 episodes
GETTING ACTION FROM:
action 2, numVisits=325275, meanQ=19.020782, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.673398 0.82728 0.669214 0.893036 0.434731 0.78859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 176
Initial state: 0 0.915274 0.44406 0.517333 0.830319 0.668812 0.824267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214188 episodes
GETTING ACTION FROM:
action 3, numVisits=214182, meanQ=17.661168, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.915274 0.44406 0.517333 0.830319 0.668812 0.824267 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 177
Initial state: 0 0.221394 0.458386 0.549361 0.878586 0.556498 0.839067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224283 episodes
GETTING ACTION FROM:
action 2, numVisits=224279, meanQ=17.883443, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.221394 0.458386 0.549361 0.878586 0.556498 0.839067 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 178
Initial state: 0 0.515068 0.801007 0.668429 0.857961 0.339325 0.308907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223225 episodes
GETTING ACTION FROM:
action 3, numVisits=223209, meanQ=17.830764, numObservations: 4
action 2, numVisits=12, meanQ=10.895008, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.515068 0.801007 0.668429 0.857961 0.339325 0.308907 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 179
Initial state: 0 0.511627 0.804762 0.641728 0.838954 0.731044 0.753718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223363 episodes
GETTING ACTION FROM:
action 2, numVisits=223359, meanQ=17.767003, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.511627 0.804762 0.641728 0.838954 0.731044 0.753718 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 180
Initial state: 0 0.607248 0.881142 0.547278 0.88293 0.491201 0.341774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224323 episodes
GETTING ACTION FROM:
action 2, numVisits=224319, meanQ=17.769451, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.607248 0.881142 0.547278 0.88293 0.491201 0.341774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 181
Initial state: 0 0.566451 0.880115 0.575579 0.881324 0.795748 0.384825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222713 episodes
GETTING ACTION FROM:
action 2, numVisits=222708, meanQ=17.827840, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.566451 0.880115 0.575579 0.881324 0.795748 0.384825 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 182
Initial state: 0 0.677912 0.818799 0.0356869 0.274307 0.531303 0.813143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223671 episodes
GETTING ACTION FROM:
action 1, numVisits=223663, meanQ=17.719263, numObservations: 4
action 2, numVisits=4, meanQ=10.495000, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.677912 0.818799 0.0356869 0.274307 0.531303 0.813143 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 183
Initial state: 0 0.698237 0.887772 0.268601 0.3241 0.546295 0.887682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221422 episodes
GETTING ACTION FROM:
action 3, numVisits=221416, meanQ=17.822208, numObservations: 5
action 1, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.698237 0.887772 0.268601 0.3241 0.546295 0.887682 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 184
Initial state: 0 0.114419 0.767059 0.56777 0.820567 0.554281 0.869887 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222804 episodes
GETTING ACTION FROM:
action 1, numVisits=222794, meanQ=18.115727, numObservations: 5
action 3, numVisits=6, meanQ=13.665000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.114419 0.767059 0.56777 0.820567 0.554281 0.869887 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25205, meanQ=23.477064, numObservations: 3
action 2, numVisits=13, meanQ=19.844615, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284715 episodes
GETTING ACTION FROM:
action 3, numVisits=309903, meanQ=19.105156, numObservations: 4
action 2, numVisits=30, meanQ=17.666670, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.114419 0.767059 0.56777 0.820567 0.554281 0.869887 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 185
Initial state: 0 0.623095 0.802627 0.986665 0.107305 0.615026 0.823143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221574 episodes
GETTING ACTION FROM:
action 2, numVisits=221565, meanQ=17.719357, numObservations: 5
action 3, numVisits=5, meanQ=10.000000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.623095 0.802627 0.986665 0.107305 0.615026 0.823143 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 186
Initial state: 0 0.307553 0.738182 0.636992 0.871215 0.65268 0.884928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223630 episodes
GETTING ACTION FROM:
action 2, numVisits=223625, meanQ=17.717140, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.307553 0.738182 0.636992 0.871215 0.65268 0.884928 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 187
Initial state: 0 0.645957 0.883307 0.568277 0.871686 0.983614 0.049871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221516 episodes
GETTING ACTION FROM:
action 2, numVisits=221483, meanQ=17.747497, numObservations: 5
action 3, numVisits=18, meanQ=11.602228, numObservations: 4
action 1, numVisits=13, meanQ=11.441538, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.645957 0.883307 0.568277 0.871686 0.983614 0.049871 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 188
Initial state: 0 0.537836 0.827569 0.0687323 0.735863 0.554242 0.811107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221210 episodes
GETTING ACTION FROM:
action 1, numVisits=221203, meanQ=17.752529, numObservations: 5
action 2, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.537836 0.827569 0.0687323 0.735863 0.554242 0.811107 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 189
Initial state: 0 0.481964 0.944479 0.677718 0.898417 0.638636 0.844249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226532 episodes
GETTING ACTION FROM:
action 1, numVisits=226525, meanQ=17.874682, numObservations: 3
action 3, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.481964 0.944479 0.677718 0.898417 0.638636 0.844249 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16819, meanQ=18.567624, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 265143 episodes
GETTING ACTION FROM:
action 1, numVisits=281962, meanQ=17.660604, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.481964 0.944479 0.677718 0.898417 0.638636 0.844249 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=783, meanQ=19.748779, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 273366 episodes
GETTING ACTION FROM:
action 1, numVisits=274149, meanQ=17.165590, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.481964 0.944479 0.677718 0.898417 0.638636 0.844249 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 190
Initial state: 0 0.513106 0.887865 0.67302 0.893199 0.513011 0.578134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225491 episodes
GETTING ACTION FROM:
action 2, numVisits=225483, meanQ=18.072786, numObservations: 4
action 3, numVisits=5, meanQ=12.798020, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.513106 0.887865 0.67302 0.893199 0.513011 0.578134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 191
Initial state: 0 0.676913 0.803118 0.653933 0.850865 0.251927 0.406558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224775 episodes
GETTING ACTION FROM:
action 2, numVisits=224771, meanQ=17.757758, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.676913 0.803118 0.653933 0.850865 0.251927 0.406558 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 192
Initial state: 0 0.541461 0.71505 0.52072 0.804891 0.505776 0.895738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220469 episodes
GETTING ACTION FROM:
action 3, numVisits=220459, meanQ=17.861657, numObservations: 5
action 2, numVisits=7, meanQ=15.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.541461 0.71505 0.52072 0.804891 0.505776 0.895738 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 193
Initial state: 0 0.589398 0.824729 0.636487 0.883929 0.718849 0.151306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223951 episodes
GETTING ACTION FROM:
action 3, numVisits=223947, meanQ=17.778131, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.589398 0.824729 0.636487 0.883929 0.718849 0.151306 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 194
Initial state: 0 0.63338 0.840598 0.593241 0.85864 0.714163 0.119868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222969 episodes
GETTING ACTION FROM:
action 2, numVisits=222961, meanQ=17.804392, numObservations: 4
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.63338 0.840598 0.593241 0.85864 0.714163 0.119868 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 195
Initial state: 0 0.64478 0.843781 0.512627 0.816439 0.960128 0.323919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224631 episodes
GETTING ACTION FROM:
action 1, numVisits=224616, meanQ=17.860990, numObservations: 4
action 3, numVisits=11, meanQ=13.816382, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.64478 0.843781 0.512627 0.816439 0.960128 0.323919 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 196
Initial state: 0 0.471534 0.664821 0.606806 0.896324 0.513649 0.828241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221903 episodes
GETTING ACTION FROM:
action 2, numVisits=221898, meanQ=17.820987, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.471534 0.664821 0.606806 0.896324 0.513649 0.828241 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 197
Initial state: 0 0.633494 0.897805 0.64232 0.853222 0.494051 0.695029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225286 episodes
GETTING ACTION FROM:
action 2, numVisits=225278, meanQ=17.722774, numObservations: 3
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.633494 0.897805 0.64232 0.853222 0.494051 0.695029 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16765, meanQ=17.305417, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 283425 episodes
GETTING ACTION FROM:
action 1, numVisits=300190, meanQ=18.453727, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.633494 0.897805 0.64232 0.853222 0.494051 0.695029 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 198
Initial state: 0 0.538589 0.845562 0.0746012 0.277332 0.500774 0.805263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221340 episodes
GETTING ACTION FROM:
action 2, numVisits=221307, meanQ=17.705211, numObservations: 5
action 3, numVisits=26, meanQ=12.152704, numObservations: 5
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.538589 0.845562 0.0746012 0.277332 0.500774 0.805263 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25124, meanQ=23.491898, numObservations: 3
action 1, numVisits=6, meanQ=9.833350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289841 episodes
GETTING ACTION FROM:
action 3, numVisits=314965, meanQ=19.132792, numObservations: 3
action 1, numVisits=6, meanQ=9.833350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.538589 0.845562 0.0746012 0.277332 0.500774 0.805263 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 199
Initial state: 0 0.45151 0.468543 0.502205 0.856259 0.606554 0.812694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224890 episodes
GETTING ACTION FROM:
action 2, numVisits=224877, meanQ=17.940124, numObservations: 5
action 3, numVisits=10, meanQ=10.799000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.45151 0.468543 0.502205 0.856259 0.606554 0.812694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 200
Initial state: 0 0.632078 0.816215 0.538081 0.811165 0.639517 0.23252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227157 episodes
GETTING ACTION FROM:
action 1, numVisits=227153, meanQ=17.821470, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.632078 0.816215 0.538081 0.811165 0.639517 0.23252 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 201
Initial state: 0 0.505438 0.838571 0.549957 0.816479 0.192667 0.247173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224010 episodes
GETTING ACTION FROM:
action 2, numVisits=223997, meanQ=17.698241, numObservations: 4
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action 1, numVisits=7, meanQ=9.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.505438 0.838571 0.549957 0.816479 0.192667 0.247173 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 202
Initial state: 0 0.626283 0.881865 0.210281 0.589426 0.543577 0.849408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220811 episodes
GETTING ACTION FROM:
action 3, numVisits=220804, meanQ=17.732996, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.626283 0.881865 0.210281 0.589426 0.543577 0.849408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 203
Initial state: 0 0.652098 0.818877 0.0983012 0.255312 0.669342 0.884901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222602 episodes
GETTING ACTION FROM:
action 1, numVisits=222598, meanQ=17.716526, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.652098 0.818877 0.0983012 0.255312 0.669342 0.884901 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2213, meanQ=17.078737, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 283806 episodes
GETTING ACTION FROM:
action 3, numVisits=286019, meanQ=19.036811, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.652098 0.818877 0.0983012 0.255312 0.669342 0.884901 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 204
Initial state: 0 0.59065 0.880853 0.559582 0.893622 0.690312 0.133648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220818 episodes
GETTING ACTION FROM:
action 2, numVisits=220789, meanQ=17.720818, numObservations: 5
action 1, numVisits=25, meanQ=15.814804, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.59065 0.880853 0.559582 0.893622 0.690312 0.133648 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 205
Initial state: 0 0.546807 0.894825 0.566752 0.882178 0.479634 0.313346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219055 episodes
GETTING ACTION FROM:
action 3, numVisits=219051, meanQ=17.822932, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.546807 0.894825 0.566752 0.882178 0.479634 0.313346 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30787, meanQ=23.243931, numObservations: 5
action 2, numVisits=13, meanQ=19.691546, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282768 episodes
GETTING ACTION FROM:
action 1, numVisits=313551, meanQ=19.159410, numObservations: 5
action 2, numVisits=17, meanQ=16.587653, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.546807 0.894825 0.566752 0.882178 0.479634 0.313346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 206
Initial state: 0 0.587229 0.813174 0.583112 0.299616 0.644764 0.836812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223640 episodes
GETTING ACTION FROM:
action 1, numVisits=223623, meanQ=17.874981, numObservations: 4
action 3, numVisits=14, meanQ=15.141429, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.587229 0.813174 0.583112 0.299616 0.644764 0.836812 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 207
Initial state: 0 0.636472 0.807344 0.86208 0.317657 0.53303 0.866361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223896 episodes
GETTING ACTION FROM:
action 2, numVisits=223883, meanQ=17.738284, numObservations: 4
action 1, numVisits=10, meanQ=9.298020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.636472 0.807344 0.86208 0.317657 0.53303 0.866361 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 208
Initial state: 0 0.667079 0.801001 0.215809 0.404572 0.681627 0.847256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222551 episodes
GETTING ACTION FROM:
action 2, numVisits=222547, meanQ=17.659873, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.667079 0.801001 0.215809 0.404572 0.681627 0.847256 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30991, meanQ=23.193624, numObservations: 4
action 1, numVisits=37, meanQ=20.188657, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 283539 episodes
GETTING ACTION FROM:
action 3, numVisits=314514, meanQ=19.272163, numObservations: 4
action 1, numVisits=53, meanQ=18.188119, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.667079 0.801001 0.215809 0.404572 0.681627 0.847256 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 209
Initial state: 0 0.123402 0.563673 0.658167 0.89354 0.626277 0.858927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224079 episodes
GETTING ACTION FROM:
action 2, numVisits=224073, meanQ=17.864112, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.123402 0.563673 0.658167 0.89354 0.626277 0.858927 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16650, meanQ=18.609773, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 264749 episodes
GETTING ACTION FROM:
action 2, numVisits=281399, meanQ=17.102003, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.123402 0.563673 0.658167 0.89354 0.626277 0.858927 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 210
Initial state: 0 0.545304 0.868276 0.591991 0.834079 0.682371 0.795197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225469 episodes
GETTING ACTION FROM:
action 2, numVisits=225453, meanQ=17.825141, numObservations: 3
action 1, numVisits=13, meanQ=11.468462, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.545304 0.868276 0.591991 0.834079 0.682371 0.795197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 211
Initial state: 0 0.4607 0.72144 0.687093 0.822987 0.550321 0.816702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227718 episodes
GETTING ACTION FROM:
action 2, numVisits=227713, meanQ=17.740134, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.4607 0.72144 0.687093 0.822987 0.550321 0.816702 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37299, meanQ=23.170805, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286310 episodes
GETTING ACTION FROM:
action 3, numVisits=323609, meanQ=18.987776, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.4607 0.72144 0.687093 0.822987 0.550321 0.816702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 212
Initial state: 0 0.955044 0.917137 0.629017 0.872911 0.55078 0.836751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223293 episodes
GETTING ACTION FROM:
action 2, numVisits=223285, meanQ=17.735849, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.955044 0.917137 0.629017 0.872911 0.55078 0.836751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 213
Initial state: 0 0.663925 0.85551 0.67371 0.892355 0.229732 0.312828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222762 episodes
GETTING ACTION FROM:
action 2, numVisits=222758, meanQ=17.793963, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.663925 0.85551 0.67371 0.892355 0.229732 0.312828 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 214
Initial state: 0 0.239647 0.0300292 0.539387 0.869619 0.511764 0.810967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224408 episodes
GETTING ACTION FROM:
action 2, numVisits=224402, meanQ=17.828630, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.239647 0.0300292 0.539387 0.869619 0.511764 0.810967 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 215
Initial state: 0 0.510788 0.883937 0.635842 0.879228 0.392587 0.426085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222680 episodes
GETTING ACTION FROM:
action 1, numVisits=222676, meanQ=17.732085, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.510788 0.883937 0.635842 0.879228 0.392587 0.426085 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 216
Initial state: 0 0.193716 0.0180998 0.578696 0.862183 0.572209 0.81201 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224415 episodes
GETTING ACTION FROM:
action 3, numVisits=224411, meanQ=17.865607, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.193716 0.0180998 0.578696 0.862183 0.572209 0.81201 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16713, meanQ=18.578091, numObservations: 3
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 265854 episodes
GETTING ACTION FROM:
action 3, numVisits=282567, meanQ=17.066700, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.193716 0.0180998 0.578696 0.862183 0.572209 0.81201 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 217
Initial state: 0 0.593394 0.888788 0.67013 0.827782 0.284368 0.342628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 207296 episodes
GETTING ACTION FROM:
action 3, numVisits=207285, meanQ=17.453660, numObservations: 5
action 2, numVisits=6, meanQ=7.183333, numObservations: 3
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.593394 0.888788 0.67013 0.827782 0.284368 0.342628 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=28606, meanQ=20.724577, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 258662 episodes
GETTING ACTION FROM:
action 0, numVisits=287268, meanQ=5.013841, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.593394 0.888788 0.67013 0.827782 0.284368 0.342628 w: 1
Observation: 0 0 0.937386 0 0.8791 0 0.361175 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=66611, meanQ=23.274668, numObservations: 4
action 2, numVisits=112, meanQ=21.629559, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284588 episodes
GETTING ACTION FROM:
action 1, numVisits=351052, meanQ=19.877125, numObservations: 4
action 2, numVisits=259, meanQ=19.416336, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.593394 0.888788 0.67013 0.827782 0.284368 0.342628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5424
Run # 218
Initial state: 0 0.550409 0.849847 0.759082 0.769454 0.592581 0.850268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227874 episodes
GETTING ACTION FROM:
action 2, numVisits=227870, meanQ=17.834436, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.550409 0.849847 0.759082 0.769454 0.592581 0.850268 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16423, meanQ=18.514586, numObservations: 4
action 1, numVisits=25, meanQ=14.471604, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 262467 episodes
GETTING ACTION FROM:
action 2, numVisits=278890, meanQ=17.407563, numObservations: 4
action 1, numVisits=25, meanQ=14.471604, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.550409 0.849847 0.759082 0.769454 0.592581 0.850268 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6861, meanQ=18.665510, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 273310 episodes
GETTING ACTION FROM:
action 2, numVisits=280171, meanQ=16.814835, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.550409 0.849847 0.759082 0.769454 0.592581 0.850268 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 219
Initial state: 0 0.588371 0.823905 0.362876 0.159786 0.677259 0.874612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223915 episodes
GETTING ACTION FROM:
action 1, numVisits=223910, meanQ=17.852430, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.588371 0.823905 0.362876 0.159786 0.677259 0.874612 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 220
Initial state: 0 0.6405 0.871246 0.532457 0.873574 0.368397 0.476843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222952 episodes
GETTING ACTION FROM:
action 2, numVisits=222939, meanQ=17.795904, numObservations: 4
action 3, numVisits=9, meanQ=13.637778, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.6405 0.871246 0.532457 0.873574 0.368397 0.476843 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 221
Initial state: 0 0.166063 0.0407154 0.629351 0.858715 0.641427 0.814567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226282 episodes
GETTING ACTION FROM:
action 3, numVisits=226278, meanQ=17.772876, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.166063 0.0407154 0.629351 0.858715 0.641427 0.814567 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 222
Initial state: 0 0.564173 0.883143 0.504059 0.805888 0.889928 0.109553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223123 episodes
GETTING ACTION FROM:
action 1, numVisits=223109, meanQ=17.700535, numObservations: 4
action 3, numVisits=9, meanQ=10.886678, numObservations: 3
action 2, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.564173 0.883143 0.504059 0.805888 0.889928 0.109553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 223
Initial state: 0 0.585576 0.884728 0.538408 0.878035 0.79741 0.394078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153463 episodes
GETTING ACTION FROM:
action 0, numVisits=153458, meanQ=15.550994, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.585576 0.884728 0.538408 0.878035 0.79741 0.394078 w: 1
Observation: 0 0 0.876098 0 0.921846 0 0.366775 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153452, meanQ=17.756320, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 242890 episodes
GETTING ACTION FROM:
action 1, numVisits=396342, meanQ=17.883292, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.585576 0.884728 0.538408 0.878035 0.79741 0.394078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 224
Initial state: 0 0.294439 0.132863 0.615387 0.849116 0.559594 0.815574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226268 episodes
GETTING ACTION FROM:
action 1, numVisits=226262, meanQ=17.799717, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.294439 0.132863 0.615387 0.849116 0.559594 0.815574 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=36728, meanQ=23.145018, numObservations: 4
action 3, numVisits=6, meanQ=19.498333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284347 episodes
GETTING ACTION FROM:
action 2, numVisits=321067, meanQ=19.804896, numObservations: 4
action 3, numVisits=14, meanQ=17.641429, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.294439 0.132863 0.615387 0.849116 0.559594 0.815574 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 225
Initial state: 0 0.51215 0.884256 0.676703 0.507892 0.562431 0.899123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217656 episodes
GETTING ACTION FROM:
action 2, numVisits=217652, meanQ=17.568714, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.51215 0.884256 0.676703 0.507892 0.562431 0.899123 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 226
Initial state: 0 0.653405 0.803426 0.50098 0.763372 0.676878 0.859123 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224466 episodes
GETTING ACTION FROM:
action 1, numVisits=224457, meanQ=17.739955, numObservations: 4
action 2, numVisits=6, meanQ=13.016667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.653405 0.803426 0.50098 0.763372 0.676878 0.859123 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 227
Initial state: 0 0.424927 0.59426 0.644536 0.859085 0.573669 0.89037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220828 episodes
GETTING ACTION FROM:
action 3, numVisits=220824, meanQ=17.740177, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.424927 0.59426 0.644536 0.859085 0.573669 0.89037 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 228
Initial state: 0 0.598518 0.813315 0.187214 0.411891 0.556091 0.822223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221038 episodes
GETTING ACTION FROM:
action 3, numVisits=221031, meanQ=17.719317, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.598518 0.813315 0.187214 0.411891 0.556091 0.822223 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 229
Initial state: 0 0.558849 0.804122 0.99471 0.314711 0.556235 0.887919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223361 episodes
GETTING ACTION FROM:
action 1, numVisits=223356, meanQ=17.818939, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.558849 0.804122 0.99471 0.314711 0.556235 0.887919 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 230
Initial state: 0 0.567346 0.801787 0.655988 0.850029 0.894877 0.854046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223643 episodes
GETTING ACTION FROM:
action 3, numVisits=223636, meanQ=17.874002, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.567346 0.801787 0.655988 0.850029 0.894877 0.854046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 231
Initial state: 0 0.603095 0.834657 0.342779 0.285613 0.594777 0.8018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223459 episodes
GETTING ACTION FROM:
action 2, numVisits=223455, meanQ=17.760025, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.603095 0.834657 0.342779 0.285613 0.594777 0.8018 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5312, meanQ=22.361073, numObservations: 4
action 3, numVisits=13, meanQ=19.844615, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285272 episodes
GETTING ACTION FROM:
action 1, numVisits=290499, meanQ=18.876696, numObservations: 4
action 3, numVisits=98, meanQ=18.168163, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.603095 0.834657 0.342779 0.285613 0.594777 0.8018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=5321, meanQ=20.488250, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290467 episodes
GETTING ACTION FROM:
action 3, numVisits=295788, meanQ=19.060602, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.603095 0.834657 0.342779 0.285613 0.594777 0.8018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 232
Initial state: 0 0.560306 0.806373 0.69943 0.862223 0.399626 0.0195225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225354 episodes
GETTING ACTION FROM:
action 2, numVisits=225350, meanQ=17.687377, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.560306 0.806373 0.69943 0.862223 0.399626 0.0195225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 233
Initial state: 0 0.618956 0.891406 0.720266 0.718003 0.671968 0.887571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216894 episodes
GETTING ACTION FROM:
action 2, numVisits=216889, meanQ=17.740387, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.618956 0.891406 0.720266 0.718003 0.671968 0.887571 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 234
Initial state: 0 0.562734 0.80114 0.230533 0.722438 0.608185 0.864161 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223185 episodes
GETTING ACTION FROM:
action 2, numVisits=223174, meanQ=17.788731, numObservations: 4
action 1, numVisits=7, meanQ=11.857157, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.562734 0.80114 0.230533 0.722438 0.608185 0.864161 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31725, meanQ=23.263027, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282580 episodes
GETTING ACTION FROM:
action 3, numVisits=314305, meanQ=19.481230, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.562734 0.80114 0.230533 0.722438 0.608185 0.864161 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 235
Initial state: 0 0.645813 0.83328 0.585869 0.85237 0.294026 0.593978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222538 episodes
GETTING ACTION FROM:
action 3, numVisits=222527, meanQ=17.775349, numObservations: 4
action 1, numVisits=8, meanQ=8.001262, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.645813 0.83328 0.585869 0.85237 0.294026 0.593978 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25485, meanQ=23.490774, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 282526 episodes
GETTING ACTION FROM:
action 2, numVisits=308011, meanQ=19.356548, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.645813 0.83328 0.585869 0.85237 0.294026 0.593978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 236
Initial state: 0 0.551522 0.881725 0.524702 0.866333 0.657639 0.0365724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225422 episodes
GETTING ACTION FROM:
action 2, numVisits=225418, meanQ=17.734278, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.551522 0.881725 0.524702 0.866333 0.657639 0.0365724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 237
Initial state: 0 0.561997 0.837218 0.991175 0.183242 0.626301 0.839089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221072 episodes
GETTING ACTION FROM:
action 3, numVisits=221065, meanQ=17.694099, numObservations: 5
action 1, numVisits=4, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.561997 0.837218 0.991175 0.183242 0.626301 0.839089 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 238
Initial state: 0 0.525367 0.822727 0.926829 0.177066 0.515707 0.858756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224975 episodes
GETTING ACTION FROM:
action 2, numVisits=224970, meanQ=17.769340, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.525367 0.822727 0.926829 0.177066 0.515707 0.858756 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 239
Initial state: 0 0.640623 0.796835 0.691932 0.814627 0.685282 0.832219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224239 episodes
GETTING ACTION FROM:
action 3, numVisits=224226, meanQ=17.863237, numObservations: 4
action 2, numVisits=10, meanQ=10.799000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.640623 0.796835 0.691932 0.814627 0.685282 0.832219 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 240
Initial state: 0 0.698631 0.892786 0.829447 0.59436 0.546116 0.879903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220007 episodes
GETTING ACTION FROM:
action 3, numVisits=219999, meanQ=17.684290, numObservations: 5
action 2, numVisits=4, meanQ=10.495000, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.698631 0.892786 0.829447 0.59436 0.546116 0.879903 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 241
Initial state: 0 0.605238 0.834433 0.779128 0.389928 0.612378 0.82843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219678 episodes
GETTING ACTION FROM:
action 3, numVisits=219665, meanQ=17.728603, numObservations: 4
action 2, numVisits=10, meanQ=11.549000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.605238 0.834433 0.779128 0.389928 0.612378 0.82843 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 242
Initial state: 0 0.258813 0.488327 0.578072 0.871495 0.579445 0.882182 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223236 episodes
GETTING ACTION FROM:
action 1, numVisits=223232, meanQ=17.824196, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.258813 0.488327 0.578072 0.871495 0.579445 0.882182 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36672, meanQ=23.181496, numObservations: 4
action 2, numVisits=9, meanQ=20.998889, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283328 episodes
GETTING ACTION FROM:
action 3, numVisits=319815, meanQ=19.261747, numObservations: 4
action 2, numVisits=194, meanQ=18.688196, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.258813 0.488327 0.578072 0.871495 0.579445 0.882182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=8159, meanQ=22.187355, numObservations: 4
action 2, numVisits=16, meanQ=18.436250, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 287835 episodes
GETTING ACTION FROM:
action 3, numVisits=295948, meanQ=18.457306, numObservations: 4
action 2, numVisits=62, meanQ=17.483548, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.258813 0.488327 0.578072 0.871495 0.579445 0.882182 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 243
Initial state: 0 0.68131 0.852459 0.672963 0.89243 0.691956 0.603165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224686 episodes
GETTING ACTION FROM:
action 1, numVisits=224682, meanQ=17.848922, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.68131 0.852459 0.672963 0.89243 0.691956 0.603165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 244
Initial state: 0 0.593611 0.800636 0.629235 0.635146 0.581494 0.857799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222217 episodes
GETTING ACTION FROM:
action 3, numVisits=222208, meanQ=17.835743, numObservations: 5
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.593611 0.800636 0.629235 0.635146 0.581494 0.857799 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 245
Initial state: 0 0.922018 0.216681 0.652144 0.830563 0.692157 0.807074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224087 episodes
GETTING ACTION FROM:
action 2, numVisits=224081, meanQ=17.730229, numObservations: 4
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.922018 0.216681 0.652144 0.830563 0.692157 0.807074 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 246
Initial state: 0 0.585999 0.872237 0.596056 0.846554 0.849124 0.555036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226705 episodes
GETTING ACTION FROM:
action 2, numVisits=226687, meanQ=17.754268, numObservations: 3
action 1, numVisits=15, meanQ=11.465340, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.585999 0.872237 0.596056 0.846554 0.849124 0.555036 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 247
Initial state: 0 0.176809 0.0984299 0.565927 0.850689 0.605427 0.86944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221056 episodes
GETTING ACTION FROM:
action 3, numVisits=221052, meanQ=17.856857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.176809 0.0984299 0.565927 0.850689 0.605427 0.86944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 248
Initial state: 0 0.537462 0.803265 0.685525 0.849522 0.752582 0.196061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223378 episodes
GETTING ACTION FROM:
action 3, numVisits=223369, meanQ=17.811564, numObservations: 4
action 1, numVisits=6, meanQ=10.163350, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.537462 0.803265 0.685525 0.849522 0.752582 0.196061 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 249
Initial state: 0 0.643867 0.740346 0.522693 0.880731 0.645909 0.804766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222736 episodes
GETTING ACTION FROM:
action 2, numVisits=222731, meanQ=17.814306, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.643867 0.740346 0.522693 0.880731 0.645909 0.804766 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 250
Initial state: 0 0.743365 0.748895 0.503276 0.822406 0.647646 0.885456 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224617 episodes
GETTING ACTION FROM:
action 3, numVisits=224613, meanQ=17.886773, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.743365 0.748895 0.503276 0.822406 0.647646 0.885456 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 251
Initial state: 0 0.615941 0.850372 0.861692 0.233612 0.649435 0.853109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223067 episodes
GETTING ACTION FROM:
action 2, numVisits=223063, meanQ=17.742724, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.615941 0.850372 0.861692 0.233612 0.649435 0.853109 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 252
Initial state: 0 0.636012 0.818144 0.865162 0.426425 0.675473 0.808903 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221818 episodes
GETTING ACTION FROM:
action 2, numVisits=221813, meanQ=17.828971, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.636012 0.818144 0.865162 0.426425 0.675473 0.808903 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 253
Initial state: 0 0.851878 0.107665 0.628628 0.86695 0.688525 0.827178 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226132 episodes
GETTING ACTION FROM:
action 1, numVisits=226124, meanQ=17.822029, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=9.502525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.851878 0.107665 0.628628 0.86695 0.688525 0.827178 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 254
Initial state: 0 0.0718906 0.885147 0.534281 0.842076 0.536738 0.858369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224760 episodes
GETTING ACTION FROM:
action 3, numVisits=224754, meanQ=17.880733, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.0718906 0.885147 0.534281 0.842076 0.536738 0.858369 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 255
Initial state: 0 0.806894 0.14039 0.67954 0.805365 0.642242 0.831511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221522 episodes
GETTING ACTION FROM:
action 1, numVisits=221518, meanQ=17.715968, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.806894 0.14039 0.67954 0.805365 0.642242 0.831511 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 256
Initial state: 0 0.0961777 0.0987027 0.526196 0.837176 0.528434 0.835447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219486 episodes
GETTING ACTION FROM:
action 3, numVisits=219482, meanQ=17.705439, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0961777 0.0987027 0.526196 0.837176 0.528434 0.835447 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 257
Initial state: 0 0.621128 0.661072 0.604043 0.887192 0.528132 0.856696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225764 episodes
GETTING ACTION FROM:
action 2, numVisits=225760, meanQ=17.735083, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.621128 0.661072 0.604043 0.887192 0.528132 0.856696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 258
Initial state: 0 0.527983 0.805085 0.59716 0.83379 0.21474 0.530837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153311 episodes
GETTING ACTION FROM:
action -1, numVisits=153307, meanQ=15.541789, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.527983 0.805085 0.59716 0.83379 0.21474 0.530837 w: 1
Observation: 0 0.497945 0 0.581553 0 0.156317 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=153287, meanQ=17.763533, numObservations: 5
action 3, numVisits=10, meanQ=11.598000, numObservations: 2
action 1, numVisits=7, meanQ=10.998586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 240820 episodes
GETTING ACTION FROM:
action 2, numVisits=394107, meanQ=17.929952, numObservations: 5
action 3, numVisits=10, meanQ=11.598000, numObservations: 2
action 1, numVisits=7, meanQ=10.998586, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.527983 0.805085 0.59716 0.83379 0.21474 0.530837 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 259
Initial state: 0 0.28521 0.884223 0.574982 0.816534 0.691625 0.817134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222300 episodes
GETTING ACTION FROM:
action 1, numVisits=222292, meanQ=17.793638, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 3, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.28521 0.884223 0.574982 0.816534 0.691625 0.817134 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 260
Initial state: 0 0.528728 0.814015 0.762416 0.785196 0.583438 0.898352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225316 episodes
GETTING ACTION FROM:
action 1, numVisits=225312, meanQ=17.837781, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.528728 0.814015 0.762416 0.785196 0.583438 0.898352 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 261
Initial state: 0 0.63467 0.876288 0.548736 0.853967 0.234277 0.0456097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153876 episodes
GETTING ACTION FROM:
action -1, numVisits=153869, meanQ=15.638897, numObservations: 1
action 2, numVisits=4, meanQ=-0.252500, numObservations: 3
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.63467 0.876288 0.548736 0.853967 0.234277 0.0456097 w: 1
Observation: 0 0.682696 0 0.635278 0 0.185525 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153862, meanQ=17.802355, numObservations: 5
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 242460 episodes
GETTING ACTION FROM:
action 3, numVisits=396322, meanQ=17.623245, numObservations: 5
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.63467 0.876288 0.548736 0.853967 0.234277 0.0456097 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=57731, meanQ=23.299250, numObservations: 5
action 2, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282576 episodes
GETTING ACTION FROM:
action 1, numVisits=340307, meanQ=19.587864, numObservations: 5
action 2, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.63467 0.876288 0.548736 0.853967 0.234277 0.0456097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 262
Initial state: 0 0.640493 0.802978 0.582092 0.817336 0.218023 0.331984 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225753 episodes
GETTING ACTION FROM:
action 1, numVisits=225746, meanQ=17.767191, numObservations: 3
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.640493 0.802978 0.582092 0.817336 0.218023 0.331984 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 263
Initial state: 0 0.631593 0.808779 0.844895 0.0795137 0.565345 0.874785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223183 episodes
GETTING ACTION FROM:
action 1, numVisits=223179, meanQ=17.755142, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.631593 0.808779 0.844895 0.0795137 0.565345 0.874785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 264
Initial state: 0 0.612156 0.861388 0.614291 0.819425 0.635373 0.615344 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224358 episodes
GETTING ACTION FROM:
action 1, numVisits=224352, meanQ=17.816779, numObservations: 4
action 3, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.612156 0.861388 0.614291 0.819425 0.635373 0.615344 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 265
Initial state: 0 0.982752 0.613833 0.567862 0.804011 0.625126 0.895991 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225158 episodes
GETTING ACTION FROM:
action 2, numVisits=225154, meanQ=17.855869, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.982752 0.613833 0.567862 0.804011 0.625126 0.895991 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 266
Initial state: 0 0.272695 0.0787792 0.668971 0.808734 0.557816 0.878093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222592 episodes
GETTING ACTION FROM:
action 2, numVisits=222586, meanQ=17.728631, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.272695 0.0787792 0.668971 0.808734 0.557816 0.878093 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 267
Initial state: 0 0.401396 0.154157 0.528749 0.874543 0.639973 0.806631 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224833 episodes
GETTING ACTION FROM:
action 1, numVisits=224828, meanQ=17.766016, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.401396 0.154157 0.528749 0.874543 0.639973 0.806631 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=36821, meanQ=23.158029, numObservations: 4
action 3, numVisits=17, meanQ=20.588829, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288367 episodes
GETTING ACTION FROM:
action 2, numVisits=325178, meanQ=19.058003, numObservations: 4
action 3, numVisits=27, meanQ=16.962967, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.401396 0.154157 0.528749 0.874543 0.639973 0.806631 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 268
Initial state: 0 0.620229 0.851136 0.261654 0.253581 0.570273 0.895931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220611 episodes
GETTING ACTION FROM:
action 1, numVisits=220604, meanQ=17.717108, numObservations: 5
action 3, numVisits=3, meanQ=12.333333, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.620229 0.851136 0.261654 0.253581 0.570273 0.895931 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 269
Initial state: 0 0.576618 0.850079 0.502787 0.804311 0.0343686 0.24715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220261 episodes
GETTING ACTION FROM:
action 3, numVisits=220254, meanQ=17.751491, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.576618 0.850079 0.502787 0.804311 0.0343686 0.24715 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=36022, meanQ=23.140678, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 287956 episodes
GETTING ACTION FROM:
action 1, numVisits=323978, meanQ=19.487575, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.576618 0.850079 0.502787 0.804311 0.0343686 0.24715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 270
Initial state: 0 0.563091 0.857646 0.700494 0.714459 0.52279 0.893131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220013 episodes
GETTING ACTION FROM:
action 3, numVisits=220003, meanQ=17.678087, numObservations: 5
action 2, numVisits=5, meanQ=7.000020, numObservations: 2
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.563091 0.857646 0.700494 0.714459 0.52279 0.893131 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=2197, meanQ=18.810418, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 262437 episodes
GETTING ACTION FROM:
action 3, numVisits=264634, meanQ=17.025585, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.563091 0.857646 0.700494 0.714459 0.52279 0.893131 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3652, meanQ=17.892568, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 272376 episodes
GETTING ACTION FROM:
action 3, numVisits=276028, meanQ=16.217550, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.563091 0.857646 0.700494 0.714459 0.52279 0.893131 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 271
Initial state: 0 0.258295 0.223975 0.53529 0.87621 0.515135 0.879336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225486 episodes
GETTING ACTION FROM:
action 2, numVisits=225475, meanQ=17.854520, numObservations: 3
action 3, numVisits=7, meanQ=11.282857, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.258295 0.223975 0.53529 0.87621 0.515135 0.879336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 272
Initial state: 0 0.496539 0.293937 0.65841 0.880504 0.672189 0.817122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215126 episodes
GETTING ACTION FROM:
action 3, numVisits=215122, meanQ=17.533006, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.496539 0.293937 0.65841 0.880504 0.672189 0.817122 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 273
Initial state: 0 0.548187 0.864293 0.799579 0.503564 0.697651 0.823309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224901 episodes
GETTING ACTION FROM:
action 1, numVisits=224894, meanQ=17.726318, numObservations: 3
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.548187 0.864293 0.799579 0.503564 0.697651 0.823309 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 274
Initial state: 0 0.0641752 0.570336 0.631478 0.841208 0.690849 0.834174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214333 episodes
GETTING ACTION FROM:
action 2, numVisits=214307, meanQ=17.558699, numObservations: 5
action 1, numVisits=18, meanQ=14.331678, numObservations: 4
action 3, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0641752 0.570336 0.631478 0.841208 0.690849 0.834174 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 275
Initial state: 0 0.590144 0.802522 0.920501 0.664307 0.542006 0.807445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 209976 episodes
GETTING ACTION FROM:
action 3, numVisits=209972, meanQ=17.694456, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.590144 0.802522 0.920501 0.664307 0.542006 0.807445 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 276
Initial state: 0 0.632049 0.889089 0.0155128 0.783167 0.553423 0.859696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220802 episodes
GETTING ACTION FROM:
action 3, numVisits=220798, meanQ=17.794792, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.632049 0.889089 0.0155128 0.783167 0.553423 0.859696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 277
Initial state: 0 0.855666 0.702745 0.590358 0.847486 0.596487 0.826564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 210361 episodes
GETTING ACTION FROM:
action 2, numVisits=210357, meanQ=17.384794, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.855666 0.702745 0.590358 0.847486 0.596487 0.826564 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 278
Initial state: 0 0.527827 0.823362 0.17353 0.0263076 0.699623 0.804889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214228 episodes
GETTING ACTION FROM:
action 3, numVisits=214216, meanQ=17.696885, numObservations: 4
action 2, numVisits=9, meanQ=6.777789, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.527827 0.823362 0.17353 0.0263076 0.699623 0.804889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=16011, meanQ=16.651969, numObservations: 1
action 1, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 263171 episodes
GETTING ACTION FROM:
action 2, numVisits=137536, meanQ=18.851515, numObservations: 4
action 0, numVisits=141647, meanQ=3.859673, numObservations: 1
action 1, numVisits=4, meanQ=-0.252500, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.527827 0.823362 0.17353 0.0263076 0.699623 0.804889 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 279
Initial state: 0 0.648401 0.843267 0.541741 0.870176 0.954289 0.504504 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226971 episodes
GETTING ACTION FROM:
action 1, numVisits=226967, meanQ=17.865631, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.648401 0.843267 0.541741 0.870176 0.954289 0.504504 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 280
Initial state: 0 0.652577 0.895311 0.324747 0.303195 0.564939 0.891543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222372 episodes
GETTING ACTION FROM:
action 3, numVisits=222366, meanQ=17.726014, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.652577 0.895311 0.324747 0.303195 0.564939 0.891543 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 281
Initial state: 0 0.219788 0.342834 0.587497 0.881267 0.584501 0.810416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224588 episodes
GETTING ACTION FROM:
action 1, numVisits=224574, meanQ=17.776307, numObservations: 4
action 3, numVisits=11, meanQ=10.634564, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.219788 0.342834 0.587497 0.881267 0.584501 0.810416 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 282
Initial state: 0 0.656656 0.869234 0.643691 0.809116 0.425894 0.25926 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223820 episodes
GETTING ACTION FROM:
action 2, numVisits=223816, meanQ=17.827882, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.656656 0.869234 0.643691 0.809116 0.425894 0.25926 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 283
Initial state: 0 0.521699 0.870136 0.531976 0.802923 0.822082 0.143476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224809 episodes
GETTING ACTION FROM:
action 2, numVisits=224805, meanQ=17.763386, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.521699 0.870136 0.531976 0.802923 0.822082 0.143476 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 284
Initial state: 0 0.875398 0.700391 0.549814 0.803205 0.613664 0.821016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221507 episodes
GETTING ACTION FROM:
action 3, numVisits=221503, meanQ=17.810933, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.875398 0.700391 0.549814 0.803205 0.613664 0.821016 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 285
Initial state: 0 0.215332 0.080231 0.521146 0.885593 0.512201 0.853586 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222212 episodes
GETTING ACTION FROM:
action 1, numVisits=222205, meanQ=17.708910, numObservations: 5
action 2, numVisits=4, meanQ=9.502525, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.215332 0.080231 0.521146 0.885593 0.512201 0.853586 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30827, meanQ=23.308915, numObservations: 4
action 3, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289846 episodes
GETTING ACTION FROM:
action 2, numVisits=320672, meanQ=18.745106, numObservations: 4
action 3, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.215332 0.080231 0.521146 0.885593 0.512201 0.853586 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 286
Initial state: 0 0.442958 0.0567915 0.610182 0.861995 0.653959 0.809002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221218 episodes
GETTING ACTION FROM:
action 3, numVisits=221209, meanQ=17.766645, numObservations: 5
action 1, numVisits=4, meanQ=10.495000, numObservations: 3
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.442958 0.0567915 0.610182 0.861995 0.653959 0.809002 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 287
Initial state: 0 0.599832 0.395326 0.520921 0.893146 0.514351 0.839078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223745 episodes
GETTING ACTION FROM:
action 1, numVisits=223741, meanQ=17.784557, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.599832 0.395326 0.520921 0.893146 0.514351 0.839078 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 288
Initial state: 0 0.535322 0.822847 0.918404 0.998205 0.597403 0.839029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226032 episodes
GETTING ACTION FROM:
action 2, numVisits=226028, meanQ=17.862955, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.535322 0.822847 0.918404 0.998205 0.597403 0.839029 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 289
Initial state: 0 0.483056 0.0375289 0.668941 0.822833 0.553192 0.847524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 210051 episodes
GETTING ACTION FROM:
action 3, numVisits=210039, meanQ=17.346857, numObservations: 3
action 1, numVisits=9, meanQ=9.056678, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.483056 0.0375289 0.668941 0.822833 0.553192 0.847524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 290
Initial state: 0 0.654175 0.601881 0.658829 0.826157 0.685375 0.848536 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220683 episodes
GETTING ACTION FROM:
action 3, numVisits=220668, meanQ=17.812041, numObservations: 4
action 2, numVisits=5, meanQ=13.196000, numObservations: 2
action 1, numVisits=8, meanQ=12.872500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.654175 0.601881 0.658829 0.826157 0.685375 0.848536 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 291
Initial state: 0 0.642452 0.824819 0.53989 0.838204 0.914869 0.380833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223511 episodes
GETTING ACTION FROM:
action 3, numVisits=223505, meanQ=17.792797, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.642452 0.824819 0.53989 0.838204 0.914869 0.380833 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 292
Initial state: 0 0.861123 0.750837 0.519375 0.846166 0.632756 0.817797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224339 episodes
GETTING ACTION FROM:
action 2, numVisits=224331, meanQ=17.873808, numObservations: 4
action 1, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.861123 0.750837 0.519375 0.846166 0.632756 0.817797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 293
Initial state: 0 0.646392 0.801072 0.420919 0.958423 0.502013 0.843617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224552 episodes
GETTING ACTION FROM:
action 2, numVisits=224548, meanQ=17.760633, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.646392 0.801072 0.420919 0.958423 0.502013 0.843617 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16200, meanQ=17.441791, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 280297 episodes
GETTING ACTION FROM:
action 3, numVisits=296497, meanQ=18.708931, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.646392 0.801072 0.420919 0.958423 0.502013 0.843617 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 294
Initial state: 0 0.488515 0.338827 0.696366 0.821367 0.575031 0.858057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224372 episodes
GETTING ACTION FROM:
action 3, numVisits=224366, meanQ=17.912633, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.488515 0.338827 0.696366 0.821367 0.575031 0.858057 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 295
Initial state: 0 0.0373832 0.415667 0.507625 0.856047 0.55855 0.86622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225698 episodes
GETTING ACTION FROM:
action 1, numVisits=225694, meanQ=17.796894, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0373832 0.415667 0.507625 0.856047 0.55855 0.86622 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=37092, meanQ=23.193704, numObservations: 3
action 3, numVisits=5, meanQ=17.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291351 episodes
GETTING ACTION FROM:
action 2, numVisits=328441, meanQ=19.482165, numObservations: 3
action 3, numVisits=7, meanQ=14.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0373832 0.415667 0.507625 0.856047 0.55855 0.86622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 296
Initial state: 0 0.125316 0.498207 0.577669 0.896335 0.550281 0.827676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223342 episodes
GETTING ACTION FROM:
action 1, numVisits=223337, meanQ=17.806602, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.125316 0.498207 0.577669 0.896335 0.550281 0.827676 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31259, meanQ=23.230757, numObservations: 5
action 2, numVisits=18, meanQ=20.338889, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282366 episodes
GETTING ACTION FROM:
action 3, numVisits=313610, meanQ=19.047261, numObservations: 5
action 2, numVisits=33, meanQ=17.760606, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.125316 0.498207 0.577669 0.896335 0.550281 0.827676 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 297
Initial state: 0 0.611213 0.867021 0.045833 0.105881 0.642293 0.830188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221231 episodes
GETTING ACTION FROM:
action 3, numVisits=221225, meanQ=17.701297, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.611213 0.867021 0.045833 0.105881 0.642293 0.830188 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 298
Initial state: 0 0.552979 0.860362 0.0663536 0.959133 0.690263 0.842096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154057 episodes
GETTING ACTION FROM:
action -1, numVisits=154052, meanQ=15.640250, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.552979 0.860362 0.0663536 0.959133 0.690263 0.842096 w: 1
Observation: 0 0.625492 0 0.0451636 0 0.775527 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154034, meanQ=17.826185, numObservations: 4
action 1, numVisits=9, meanQ=13.887789, numObservations: 4
action 3, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 248733 episodes
GETTING ACTION FROM:
action 2, numVisits=402767, meanQ=17.650550, numObservations: 4
action 1, numVisits=9, meanQ=13.887789, numObservations: 4
action 3, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.552979 0.860362 0.0663536 0.959133 0.690263 0.842096 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 299
Initial state: 0 0.533621 0.85784 0.472494 0.734759 0.509723 0.8871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222896 episodes
GETTING ACTION FROM:
action 3, numVisits=222890, meanQ=17.741039, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.533621 0.85784 0.472494 0.734759 0.509723 0.8871 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 300
Initial state: 0 0.458745 0.661624 0.558944 0.863324 0.549831 0.826219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224857 episodes
GETTING ACTION FROM:
action 1, numVisits=224853, meanQ=17.829475, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.458745 0.661624 0.558944 0.863324 0.549831 0.826219 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25541, meanQ=23.494636, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284430 episodes
GETTING ACTION FROM:
action 2, numVisits=309971, meanQ=19.054391, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.458745 0.661624 0.558944 0.863324 0.549831 0.826219 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7081, meanQ=21.757363, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291541 episodes
GETTING ACTION FROM:
action 3, numVisits=298622, meanQ=18.853656, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.458745 0.661624 0.558944 0.863324 0.549831 0.826219 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 301
Initial state: 0 0.626325 0.878644 0.587242 0.834685 0.911214 0.925968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221644 episodes
GETTING ACTION FROM:
action 1, numVisits=221638, meanQ=17.859125, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.626325 0.878644 0.587242 0.834685 0.911214 0.925968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 302
Initial state: 0 0.0672466 0.639007 0.581633 0.888457 0.625838 0.847836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224003 episodes
GETTING ACTION FROM:
action 1, numVisits=223999, meanQ=17.737706, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0672466 0.639007 0.581633 0.888457 0.625838 0.847836 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=36248, meanQ=23.155418, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284407 episodes
GETTING ACTION FROM:
action 2, numVisits=320655, meanQ=19.314722, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0672466 0.639007 0.581633 0.888457 0.625838 0.847836 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 303
Initial state: 0 0.690031 0.853822 0.586049 0.87488 0.257468 0.292255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224472 episodes
GETTING ACTION FROM:
action 1, numVisits=224461, meanQ=17.742217, numObservations: 4
action 2, numVisits=8, meanQ=9.247512, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.690031 0.853822 0.586049 0.87488 0.257468 0.292255 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 304
Initial state: 0 0.109651 0.64042 0.623645 0.815331 0.661724 0.808314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223079 episodes
GETTING ACTION FROM:
action 2, numVisits=223049, meanQ=17.834949, numObservations: 4
action 1, numVisits=23, meanQ=14.380439, numObservations: 4
action 3, numVisits=5, meanQ=13.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.109651 0.64042 0.623645 0.815331 0.661724 0.808314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 305
Initial state: 0 0.374478 0.0485218 0.528754 0.849895 0.57037 0.829217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222458 episodes
GETTING ACTION FROM:
action 1, numVisits=222454, meanQ=18.134311, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.374478 0.0485218 0.528754 0.849895 0.57037 0.829217 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25736, meanQ=23.506697, numObservations: 3
action 2, numVisits=7, meanQ=20.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285491 episodes
GETTING ACTION FROM:
action 3, numVisits=311223, meanQ=19.191607, numObservations: 4
action 2, numVisits=11, meanQ=15.907273, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.374478 0.0485218 0.528754 0.849895 0.57037 0.829217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 306
Initial state: 0 0.699711 0.845379 0.993361 0.673847 0.502403 0.827794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220271 episodes
GETTING ACTION FROM:
action 3, numVisits=220240, meanQ=17.712799, numObservations: 4
action 2, numVisits=27, meanQ=13.369637, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.699711 0.845379 0.993361 0.673847 0.502403 0.827794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 307
Initial state: 0 0.436771 0.439125 0.654961 0.836865 0.596015 0.840607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220654 episodes
GETTING ACTION FROM:
action 3, numVisits=220649, meanQ=17.771001, numObservations: 5
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.436771 0.439125 0.654961 0.836865 0.596015 0.840607 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 308
Initial state: 0 0.466869 0.651456 0.534414 0.829673 0.59949 0.811628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220960 episodes
GETTING ACTION FROM:
action 3, numVisits=220955, meanQ=17.843374, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.466869 0.651456 0.534414 0.829673 0.59949 0.811628 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 309
Initial state: 0 0.566538 0.874692 0.503207 0.898631 0.844968 0.216845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223834 episodes
GETTING ACTION FROM:
action 2, numVisits=223829, meanQ=17.723798, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.566538 0.874692 0.503207 0.898631 0.844968 0.216845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 310
Initial state: 0 0.694749 0.850274 0.770227 0.607914 0.566783 0.853821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224823 episodes
GETTING ACTION FROM:
action 1, numVisits=224812, meanQ=17.809691, numObservations: 4
action 3, numVisits=4, meanQ=10.495000, numObservations: 4
action 2, numVisits=5, meanQ=10.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.694749 0.850274 0.770227 0.607914 0.566783 0.853821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 311
Initial state: 0 0.649974 0.802001 0.872806 0.953112 0.551221 0.875983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221937 episodes
GETTING ACTION FROM:
action 1, numVisits=221930, meanQ=17.811695, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.649974 0.802001 0.872806 0.953112 0.551221 0.875983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 312
Initial state: 0 0.751728 0.184079 0.539054 0.861462 0.631169 0.8263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224164 episodes
GETTING ACTION FROM:
action 3, numVisits=224157, meanQ=18.120417, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.751728 0.184079 0.539054 0.861462 0.631169 0.8263 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 313
Initial state: 0 0.213535 0.283287 0.672326 0.82395 0.596774 0.860379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221833 episodes
GETTING ACTION FROM:
action 2, numVisits=221828, meanQ=17.843300, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.213535 0.283287 0.672326 0.82395 0.596774 0.860379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 314
Initial state: 0 0.989117 0.945105 0.636227 0.883313 0.692112 0.838507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223213 episodes
GETTING ACTION FROM:
action 2, numVisits=223208, meanQ=17.771498, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.989117 0.945105 0.636227 0.883313 0.692112 0.838507 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 315
Initial state: 0 0.534902 0.649436 0.564018 0.894048 0.591836 0.827367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222260 episodes
GETTING ACTION FROM:
action 1, numVisits=222247, meanQ=17.721374, numObservations: 5
action 3, numVisits=4, meanQ=10.495000, numObservations: 3
action 2, numVisits=7, meanQ=10.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.534902 0.649436 0.564018 0.894048 0.591836 0.827367 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 316
Initial state: 0 0.542198 0.822261 0.38763 0.322987 0.61546 0.88163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221614 episodes
GETTING ACTION FROM:
action 3, numVisits=221610, meanQ=17.814876, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.542198 0.822261 0.38763 0.322987 0.61546 0.88163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 317
Initial state: 0 0.676673 0.831204 0.788606 0.327402 0.699035 0.894821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222343 episodes
GETTING ACTION FROM:
action 3, numVisits=222339, meanQ=17.720089, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.676673 0.831204 0.788606 0.327402 0.699035 0.894821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 318
Initial state: 0 0.627107 0.821556 0.418008 0.280583 0.624832 0.81527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218618 episodes
GETTING ACTION FROM:
action 2, numVisits=218605, meanQ=17.561272, numObservations: 3
action 1, numVisits=9, meanQ=10.666678, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.627107 0.821556 0.418008 0.280583 0.624832 0.81527 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=35882, meanQ=23.152758, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 279302 episodes
GETTING ACTION FROM:
action 3, numVisits=315184, meanQ=19.678704, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.627107 0.821556 0.418008 0.280583 0.624832 0.81527 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 319
Initial state: 0 0.199057 0.383707 0.60159 0.883175 0.657605 0.87146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221020 episodes
GETTING ACTION FROM:
action 2, numVisits=220994, meanQ=17.729971, numObservations: 5
action 3, numVisits=22, meanQ=15.363641, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.199057 0.383707 0.60159 0.883175 0.657605 0.87146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 320
Initial state: 0 0.00797297 0.436771 0.556122 0.871575 0.684029 0.842498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222482 episodes
GETTING ACTION FROM:
action 3, numVisits=222475, meanQ=17.838605, numObservations: 4
action 1, numVisits=4, meanQ=1.745000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.00797297 0.436771 0.556122 0.871575 0.684029 0.842498 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 321
Initial state: 0 0.529261 0.826872 0.209241 0.651216 0.646996 0.886688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152383 episodes
GETTING ACTION FROM:
action -1, numVisits=152378, meanQ=15.567782, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.529261 0.826872 0.209241 0.651216 0.646996 0.886688 w: 1
Observation: 0 0.493563 0 0.152653 0 0.588254 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=152363, meanQ=17.763506, numObservations: 5
action 2, numVisits=11, meanQ=11.999091, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 241768 episodes
GETTING ACTION FROM:
action 3, numVisits=394131, meanQ=17.686616, numObservations: 5
action 2, numVisits=11, meanQ=11.999091, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.529261 0.826872 0.209241 0.651216 0.646996 0.886688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 322
Initial state: 0 0.617698 0.839866 0.671397 0.821305 0.371324 0.79592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221293 episodes
GETTING ACTION FROM:
action 2, numVisits=221289, meanQ=17.782649, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.617698 0.839866 0.671397 0.821305 0.371324 0.79592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 323
Initial state: 0 0.693976 0.806188 0.854509 0.861363 0.608647 0.80489 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221460 episodes
GETTING ACTION FROM:
action 3, numVisits=221452, meanQ=17.941523, numObservations: 5
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.693976 0.806188 0.854509 0.861363 0.608647 0.80489 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=13874, meanQ=18.882897, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 262145 episodes
GETTING ACTION FROM:
action 3, numVisits=276019, meanQ=17.946370, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.693976 0.806188 0.854509 0.861363 0.608647 0.80489 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 324
Initial state: 0 0.111376 0.647821 0.661766 0.833959 0.637519 0.830497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223945 episodes
GETTING ACTION FROM:
action 3, numVisits=223941, meanQ=17.814133, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.111376 0.647821 0.661766 0.833959 0.637519 0.830497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 325
Initial state: 0 0.19115 0.111998 0.519228 0.860606 0.590428 0.835773 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224137 episodes
GETTING ACTION FROM:
action 3, numVisits=224123, meanQ=17.862529, numObservations: 4
action 2, numVisits=9, meanQ=13.667789, numObservations: 3
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.19115 0.111998 0.519228 0.860606 0.590428 0.835773 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 326
Initial state: 0 0.212769 0.900796 0.502859 0.888456 0.67509 0.800864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220514 episodes
GETTING ACTION FROM:
action 3, numVisits=220510, meanQ=17.741425, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.212769 0.900796 0.502859 0.888456 0.67509 0.800864 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 327
Initial state: 0 0.509307 0.860321 0.424518 0.411137 0.618691 0.896777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223354 episodes
GETTING ACTION FROM:
action 2, numVisits=223163, meanQ=17.733474, numObservations: 4
action 1, numVisits=187, meanQ=17.213900, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.509307 0.860321 0.424518 0.411137 0.618691 0.896777 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36822, meanQ=23.130055, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287664 episodes
GETTING ACTION FROM:
action 3, numVisits=324486, meanQ=19.615326, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.509307 0.860321 0.424518 0.411137 0.618691 0.896777 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 328
Initial state: 0 0.617762 0.864033 0.692168 0.815527 0.0867795 0.652918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223217 episodes
GETTING ACTION FROM:
action 1, numVisits=223205, meanQ=17.817368, numObservations: 4
action 2, numVisits=8, meanQ=8.248763, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.617762 0.864033 0.692168 0.815527 0.0867795 0.652918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 329
Initial state: 0 0.179422 0.750303 0.605349 0.848408 0.625528 0.837017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223166 episodes
GETTING ACTION FROM:
action 1, numVisits=223161, meanQ=17.760181, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.179422 0.750303 0.605349 0.848408 0.625528 0.837017 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31195, meanQ=23.271336, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284687 episodes
GETTING ACTION FROM:
action 2, numVisits=315882, meanQ=19.145388, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.179422 0.750303 0.605349 0.848408 0.625528 0.837017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 330
Initial state: 0 0.614733 0.812149 0.252779 0.738639 0.675174 0.82579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220390 episodes
GETTING ACTION FROM:
action 3, numVisits=220382, meanQ=17.672090, numObservations: 5
action 1, numVisits=5, meanQ=13.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.614733 0.812149 0.252779 0.738639 0.675174 0.82579 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 331
Initial state: 0 0.636445 0.883875 0.561927 0.807433 0.827741 0.695719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224591 episodes
GETTING ACTION FROM:
action 1, numVisits=224568, meanQ=17.861183, numObservations: 4
action 2, numVisits=14, meanQ=13.640721, numObservations: 3
action 3, numVisits=7, meanQ=12.424286, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.636445 0.883875 0.561927 0.807433 0.827741 0.695719 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 332
Initial state: 0 0.677105 0.837641 0.693778 0.84263 0.454209 0.348338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223386 episodes
GETTING ACTION FROM:
action 1, numVisits=223378, meanQ=17.729051, numObservations: 4
action 3, numVisits=4, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.677105 0.837641 0.693778 0.84263 0.454209 0.348338 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 333
Initial state: 0 0.552443 0.800714 0.680184 0.491708 0.655194 0.899366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224649 episodes
GETTING ACTION FROM:
action 1, numVisits=224643, meanQ=18.094319, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.552443 0.800714 0.680184 0.491708 0.655194 0.899366 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 334
Initial state: 0 0.693883 0.82433 0.956642 0.0692804 0.53168 0.898034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224325 episodes
GETTING ACTION FROM:
action 1, numVisits=224320, meanQ=17.866914, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.693883 0.82433 0.956642 0.0692804 0.53168 0.898034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 335
Initial state: 0 0.373925 0.903298 0.582984 0.861295 0.558885 0.899753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221366 episodes
GETTING ACTION FROM:
action 1, numVisits=221343, meanQ=17.782436, numObservations: 5
action 3, numVisits=20, meanQ=8.075515, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.373925 0.903298 0.582984 0.861295 0.558885 0.899753 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 336
Initial state: 0 0.567814 0.830059 0.333739 0.380739 0.55285 0.832032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225582 episodes
GETTING ACTION FROM:
action 1, numVisits=225576, meanQ=18.096655, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.567814 0.830059 0.333739 0.380739 0.55285 0.832032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 337
Initial state: 0 0.522047 0.830444 0.983209 0.493272 0.634212 0.812374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159748 episodes
GETTING ACTION FROM:
action 0, numVisits=159741, meanQ=20.391457, numObservations: 3
action -1, numVisits=3, meanQ=-3.656600, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.522047 0.830444 0.983209 0.493272 0.634212 0.812374 w: 1
Observation: 0 0 0.906551 0 0.472566 0 0.774722 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=51372, meanQ=22.879632, numObservations: 4
action 3, numVisits=4, meanQ=17.247500, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 244880 episodes
GETTING ACTION FROM:
action 1, numVisits=296250, meanQ=19.062388, numObservations: 4
action 3, numVisits=6, meanQ=14.996667, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.522047 0.830444 0.983209 0.493272 0.634212 0.812374 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 338
Initial state: 0 0.0517218 0.498471 0.532122 0.838477 0.673606 0.80251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222654 episodes
GETTING ACTION FROM:
action 2, numVisits=222642, meanQ=17.852452, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 1, numVisits=6, meanQ=7.831667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.0517218 0.498471 0.532122 0.838477 0.673606 0.80251 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 339
Initial state: 0 0.566546 0.81249 0.670488 0.851198 0.074694 0.360732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223546 episodes
GETTING ACTION FROM:
action 2, numVisits=223533, meanQ=17.806860, numObservations: 4
action 3, numVisits=8, meanQ=13.375012, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.566546 0.81249 0.670488 0.851198 0.074694 0.360732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 340
Initial state: 0 0.660114 0.898941 0.181331 0.722627 0.576977 0.859153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223023 episodes
GETTING ACTION FROM:
action 3, numVisits=223000, meanQ=17.818935, numObservations: 4
action 2, numVisits=16, meanQ=7.498750, numObservations: 3
action 1, numVisits=5, meanQ=5.798020, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.660114 0.898941 0.181331 0.722627 0.576977 0.859153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 341
Initial state: 0 0.658457 0.855069 0.413802 0.900757 0.651821 0.870517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222967 episodes
GETTING ACTION FROM:
action 1, numVisits=222963, meanQ=17.854379, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.658457 0.855069 0.413802 0.900757 0.651821 0.870517 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 342
Initial state: 0 0.503932 0.846442 0.657829 0.167276 0.62531 0.810266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215588 episodes
GETTING ACTION FROM:
action 3, numVisits=215582, meanQ=17.909279, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.503932 0.846442 0.657829 0.167276 0.62531 0.810266 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=13934, meanQ=19.627215, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 260203 episodes
GETTING ACTION FROM:
action 1, numVisits=47258, meanQ=18.988315, numObservations: 4
action -1, numVisits=226880, meanQ=3.998684, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.503932 0.846442 0.657829 0.167276 0.62531 0.810266 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 343
Initial state: 0 0.673955 0.810776 0.231553 0.930252 0.616122 0.880206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222074 episodes
GETTING ACTION FROM:
action 1, numVisits=222070, meanQ=17.840491, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.673955 0.810776 0.231553 0.930252 0.616122 0.880206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 344
Initial state: 0 0.533003 0.814314 0.954018 0.447721 0.641067 0.884679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224266 episodes
GETTING ACTION FROM:
action 1, numVisits=224260, meanQ=17.752930, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.533003 0.814314 0.954018 0.447721 0.641067 0.884679 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 345
Initial state: 0 0.654713 0.876219 0.0535936 0.296434 0.671816 0.800932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221731 episodes
GETTING ACTION FROM:
action 1, numVisits=221727, meanQ=17.750655, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.654713 0.876219 0.0535936 0.296434 0.671816 0.800932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 346
Initial state: 0 0.497339 0.257451 0.590244 0.845137 0.643518 0.862309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221406 episodes
GETTING ACTION FROM:
action 3, numVisits=221401, meanQ=17.717785, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.497339 0.257451 0.590244 0.845137 0.643518 0.862309 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 347
Initial state: 0 0.700118 0.0115967 0.525681 0.813037 0.637892 0.823892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223608 episodes
GETTING ACTION FROM:
action 1, numVisits=223603, meanQ=17.807758, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.700118 0.0115967 0.525681 0.813037 0.637892 0.823892 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 348
Initial state: 0 0.573414 0.845437 0.529945 0.864445 0.6435 0.142484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223195 episodes
GETTING ACTION FROM:
action 3, numVisits=223185, meanQ=17.741356, numObservations: 4
action 2, numVisits=7, meanQ=5.392871, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.573414 0.845437 0.529945 0.864445 0.6435 0.142484 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 349
Initial state: 0 0.55575 0.800052 0.315433 0.234758 0.504265 0.803357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222938 episodes
GETTING ACTION FROM:
action 1, numVisits=222931, meanQ=17.847218, numObservations: 5
action 3, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.55575 0.800052 0.315433 0.234758 0.504265 0.803357 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 350
Initial state: 0 0.600238 0.802751 0.440154 0.526278 0.527929 0.847879 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221879 episodes
GETTING ACTION FROM:
action 1, numVisits=221875, meanQ=17.825547, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600238 0.802751 0.440154 0.526278 0.527929 0.847879 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 351
Initial state: 0 0.686724 0.806927 0.691548 0.849509 0.448626 0.243757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222899 episodes
GETTING ACTION FROM:
action 2, numVisits=222895, meanQ=17.735568, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.686724 0.806927 0.691548 0.849509 0.448626 0.243757 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 352
Initial state: 0 0.574408 0.842275 0.576482 0.864216 0.461252 0.411457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222983 episodes
GETTING ACTION FROM:
action 2, numVisits=222970, meanQ=17.767409, numObservations: 4
action 1, numVisits=4, meanQ=10.495000, numObservations: 2
action 3, numVisits=7, meanQ=10.141429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.574408 0.842275 0.576482 0.864216 0.461252 0.411457 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 353
Initial state: 0 0.596887 0.833364 0.148384 0.83803 0.673892 0.879339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223319 episodes
GETTING ACTION FROM:
action 3, numVisits=223315, meanQ=17.764687, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.596887 0.833364 0.148384 0.83803 0.673892 0.879339 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 354
Initial state: 0 0.652191 0.839706 0.371358 0.77634 0.569852 0.839686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220538 episodes
GETTING ACTION FROM:
action 1, numVisits=220529, meanQ=17.753373, numObservations: 5
action 2, numVisits=6, meanQ=10.495000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.652191 0.839706 0.371358 0.77634 0.569852 0.839686 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 355
Initial state: 0 0.675451 0.838167 0.502117 0.804177 0.319318 0.254907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226209 episodes
GETTING ACTION FROM:
action 1, numVisits=226202, meanQ=17.815983, numObservations: 3
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.675451 0.838167 0.502117 0.804177 0.319318 0.254907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 356
Initial state: 0 0.103659 0.305955 0.579196 0.807954 0.572395 0.876714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221033 episodes
GETTING ACTION FROM:
action 2, numVisits=221021, meanQ=17.767047, numObservations: 5
action 3, numVisits=8, meanQ=12.623762, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.103659 0.305955 0.579196 0.807954 0.572395 0.876714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 357
Initial state: 0 0.428172 0.0486625 0.644914 0.836885 0.521323 0.859901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223467 episodes
GETTING ACTION FROM:
action 3, numVisits=223463, meanQ=17.828037, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.428172 0.0486625 0.644914 0.836885 0.521323 0.859901 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 358
Initial state: 0 0.130345 0.124683 0.508875 0.887799 0.509631 0.898223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223402 episodes
GETTING ACTION FROM:
action 1, numVisits=223398, meanQ=17.730234, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.130345 0.124683 0.508875 0.887799 0.509631 0.898223 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25369, meanQ=23.496217, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291616 episodes
GETTING ACTION FROM:
action 2, numVisits=316985, meanQ=19.479942, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.130345 0.124683 0.508875 0.887799 0.509631 0.898223 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 359
Initial state: 0 0.612401 0.849522 0.676536 0.862496 0.510005 0.790137 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224249 episodes
GETTING ACTION FROM:
action 3, numVisits=224203, meanQ=17.902544, numObservations: 4
action 2, numVisits=41, meanQ=14.969278, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.612401 0.849522 0.676536 0.862496 0.510005 0.790137 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 360
Initial state: 0 0.52276 0.84666 0.698084 0.802547 0.29659 0.923726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225596 episodes
GETTING ACTION FROM:
action 1, numVisits=225581, meanQ=17.795221, numObservations: 4
action 3, numVisits=12, meanQ=8.666683, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.52276 0.84666 0.698084 0.802547 0.29659 0.923726 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 361
Initial state: 0 0.685791 0.844387 0.95181 0.726782 0.698054 0.832753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221229 episodes
GETTING ACTION FROM:
action 1, numVisits=221225, meanQ=17.724110, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.685791 0.844387 0.95181 0.726782 0.698054 0.832753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 362
Initial state: 0 0.966975 0.32298 0.593532 0.851268 0.538563 0.86367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224326 episodes
GETTING ACTION FROM:
action 1, numVisits=224315, meanQ=17.718528, numObservations: 4
action 3, numVisits=8, meanQ=12.872500, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.966975 0.32298 0.593532 0.851268 0.538563 0.86367 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 363
Initial state: 0 0.696729 0.884322 0.884347 0.174018 0.620499 0.894701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223150 episodes
GETTING ACTION FROM:
action 2, numVisits=223143, meanQ=17.726851, numObservations: 4
action 1, numVisits=4, meanQ=9.502525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.696729 0.884322 0.884347 0.174018 0.620499 0.894701 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 364
Initial state: 0 0.587329 0.88912 0.502437 0.861738 0.310718 0.626574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218825 episodes
GETTING ACTION FROM:
action 1, numVisits=218812, meanQ=17.742563, numObservations: 5
action 3, numVisits=10, meanQ=10.799000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.587329 0.88912 0.502437 0.861738 0.310718 0.626574 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 365
Initial state: 0 0.52804 0.879753 0.659005 0.672282 0.530973 0.880575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153445 episodes
GETTING ACTION FROM:
action -1, numVisits=153439, meanQ=15.503150, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.52804 0.879753 0.659005 0.672282 0.530973 0.880575 w: 1
Observation: 0 0.604777 0 0.652375 0 0.465943 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=153433, meanQ=17.724815, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 243230 episodes
GETTING ACTION FROM:
action 2, numVisits=396663, meanQ=17.843509, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.52804 0.879753 0.659005 0.672282 0.530973 0.880575 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 366
Initial state: 0 0.684832 0.842614 0.225929 0.118869 0.650247 0.825169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224727 episodes
GETTING ACTION FROM:
action 3, numVisits=224721, meanQ=17.820885, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.684832 0.842614 0.225929 0.118869 0.650247 0.825169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16885, meanQ=18.612195, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 262714 episodes
GETTING ACTION FROM:
action 3, numVisits=279599, meanQ=17.347126, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.684832 0.842614 0.225929 0.118869 0.650247 0.825169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6841, meanQ=20.346846, numObservations: 3
action 1, numVisits=4, meanQ=15.250000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 295365 episodes
GETTING ACTION FROM:
action 2, numVisits=302206, meanQ=19.087360, numObservations: 3
action 1, numVisits=4, meanQ=15.250000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.684832 0.842614 0.225929 0.118869 0.650247 0.825169 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1654, meanQ=21.179222, numObservations: 3
action 1, numVisits=5, meanQ=18.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 295703 episodes
GETTING ACTION FROM:
action 3, numVisits=297356, meanQ=19.162927, numObservations: 3
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.684832 0.842614 0.225929 0.118869 0.650247 0.825169 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 367
Initial state: 0 0.694781 0.894758 0.49461 0.17376 0.656923 0.831548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222561 episodes
GETTING ACTION FROM:
action 2, numVisits=222551, meanQ=17.737698, numObservations: 4
action 3, numVisits=6, meanQ=14.665017, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.694781 0.894758 0.49461 0.17376 0.656923 0.831548 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=36324, meanQ=23.141416, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286991 episodes
GETTING ACTION FROM:
action 1, numVisits=323315, meanQ=19.646213, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.694781 0.894758 0.49461 0.17376 0.656923 0.831548 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 368
Initial state: 0 0.601791 0.832923 0.527067 0.842576 0.0160359 0.810687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223445 episodes
GETTING ACTION FROM:
action 3, numVisits=223440, meanQ=17.817932, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.601791 0.832923 0.527067 0.842576 0.0160359 0.810687 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16582, meanQ=18.666193, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 259446 episodes
GETTING ACTION FROM:
action 3, numVisits=276028, meanQ=17.820396, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.601791 0.832923 0.527067 0.842576 0.0160359 0.810687 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=8914, meanQ=23.195414, numObservations: 5
action 1, numVisits=5, meanQ=18.598000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 288138 episodes
GETTING ACTION FROM:
action 2, numVisits=297047, meanQ=19.013053, numObservations: 5
action 1, numVisits=10, meanQ=14.299000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.601791 0.832923 0.527067 0.842576 0.0160359 0.810687 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 369
Initial state: 0 0.69939 0.836466 0.085101 0.483017 0.585415 0.896288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223773 episodes
GETTING ACTION FROM:
action 2, numVisits=223751, meanQ=17.847400, numObservations: 4
action 3, numVisits=10, meanQ=11.399010, numObservations: 3
action 1, numVisits=10, meanQ=9.298020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 2 0.69939 0.836466 0.085101 0.483017 0.585415 0.896288 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 370
Initial state: 0 0.695847 0.856014 0.847209 0.169777 0.692403 0.896541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221298 episodes
GETTING ACTION FROM:
action 3, numVisits=221291, meanQ=17.734394, numObservations: 5
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.695847 0.856014 0.847209 0.169777 0.692403 0.896541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 371
Initial state: 0 0.3552 0.179986 0.620876 0.837804 0.685035 0.881301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222115 episodes
GETTING ACTION FROM:
action 2, numVisits=222111, meanQ=17.741026, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.3552 0.179986 0.620876 0.837804 0.685035 0.881301 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 372
Initial state: 0 0.806534 0.310718 0.581574 0.842733 0.685539 0.883796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159880 episodes
GETTING ACTION FROM:
action 0, numVisits=159875, meanQ=19.234846, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.806534 0.310718 0.581574 0.842733 0.685539 0.883796 w: 1
Observation: 0 0 0.32307 0 0.910809 0 0.891409 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=35752, meanQ=23.451557, numObservations: 5
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 244341 episodes
GETTING ACTION FROM:
action 3, numVisits=280092, meanQ=18.582419, numObservations: 5
action 2, numVisits=4, meanQ=8.497500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.806534 0.310718 0.581574 0.842733 0.685539 0.883796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 373
Initial state: 0 0.641232 0.8871 0.557694 0.832228 0.361777 0.843401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225647 episodes
GETTING ACTION FROM:
action 1, numVisits=225642, meanQ=17.748940, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.641232 0.8871 0.557694 0.832228 0.361777 0.843401 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 374
Initial state: 0 0.200968 0.81634 0.53247 0.874092 0.510594 0.877713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152908 episodes
GETTING ACTION FROM:
action 0, numVisits=152900, meanQ=15.820982, numObservations: 1
action 1, numVisits=4, meanQ=-1.225000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.200968 0.81634 0.53247 0.874092 0.510594 0.877713 w: 1
Observation: 0 0 0.718773 0 0.841139 0 0.939473 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=152895, meanQ=18.055319, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 241378 episodes
GETTING ACTION FROM:
action 3, numVisits=394273, meanQ=17.874701, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.200968 0.81634 0.53247 0.874092 0.510594 0.877713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 375
Initial state: 0 0.618325 0.875018 0.556909 0.439478 0.525452 0.81279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225032 episodes
GETTING ACTION FROM:
action 3, numVisits=225027, meanQ=17.743813, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.618325 0.875018 0.556909 0.439478 0.525452 0.81279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 376
Initial state: 0 0.324576 0.738977 0.650262 0.884427 0.580055 0.811698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224907 episodes
GETTING ACTION FROM:
action 2, numVisits=224899, meanQ=17.870535, numObservations: 4
action 3, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.324576 0.738977 0.650262 0.884427 0.580055 0.811698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 377
Initial state: 0 0.514725 0.835023 0.621913 0.898575 0.458975 0.312881 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153678 episodes
GETTING ACTION FROM:
action -1, numVisits=153674, meanQ=15.506319, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.514725 0.835023 0.621913 0.898575 0.458975 0.312881 w: 1
Observation: 0 0.551461 0 0.704632 0 0.466426 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153664, meanQ=17.697067, numObservations: 5
action 2, numVisits=5, meanQ=13.196000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 241271 episodes
GETTING ACTION FROM:
action 1, numVisits=394935, meanQ=17.844648, numObservations: 5
action 2, numVisits=5, meanQ=13.196000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.514725 0.835023 0.621913 0.898575 0.458975 0.312881 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3444, meanQ=19.254623, numObservations: 3
action 2, numVisits=4, meanQ=9.997525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 265237 episodes
GETTING ACTION FROM:
action 1, numVisits=268681, meanQ=17.186883, numObservations: 4
action 2, numVisits=4, meanQ=9.997525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.514725 0.835023 0.621913 0.898575 0.458975 0.312881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=3248, meanQ=19.089867, numObservations: 4
action 2, numVisits=10, meanQ=14.899010, numObservations: 2
action 1, numVisits=9, meanQ=13.637778, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 288950 episodes
GETTING ACTION FROM:
action 3, numVisits=292198, meanQ=18.857952, numObservations: 4
action 2, numVisits=10, meanQ=14.899010, numObservations: 2
action 1, numVisits=9, meanQ=13.637778, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.514725 0.835023 0.621913 0.898575 0.458975 0.312881 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=804, meanQ=22.855864, numObservations: 3
action 1, numVisits=23, meanQ=20.131748, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 294775 episodes
GETTING ACTION FROM:
action 2, numVisits=295500, meanQ=18.751290, numObservations: 4
action 1, numVisits=102, meanQ=17.980688, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.514725 0.835023 0.621913 0.898575 0.458975 0.312881 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9.29271
Run # 378
Initial state: 0 0.585903 0.878425 0.924782 0.901446 0.617045 0.812271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224802 episodes
GETTING ACTION FROM:
action 1, numVisits=224797, meanQ=17.822437, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.585903 0.878425 0.924782 0.901446 0.617045 0.812271 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16734, meanQ=18.511552, numObservations: 3
action 3, numVisits=10, meanQ=11.350010, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 265138 episodes
GETTING ACTION FROM:
action 1, numVisits=281872, meanQ=16.980338, numObservations: 4
action 3, numVisits=10, meanQ=11.350010, numObservations: 2
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.585903 0.878425 0.924782 0.901446 0.617045 0.812271 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 379
Initial state: 0 0.586582 0.800525 0.403962 0.205766 0.684548 0.877056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222509 episodes
GETTING ACTION FROM:
action 1, numVisits=222505, meanQ=17.721388, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.586582 0.800525 0.403962 0.205766 0.684548 0.877056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 380
Initial state: 0 0.588658 0.839452 0.317856 0.437152 0.578873 0.827666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223008 episodes
GETTING ACTION FROM:
action 3, numVisits=223000, meanQ=17.861737, numObservations: 5
action 1, numVisits=5, meanQ=11.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.588658 0.839452 0.317856 0.437152 0.578873 0.827666 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 381
Initial state: 0 0.614412 0.814401 0.531095 0.860965 0.805721 0.421553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 213466 episodes
GETTING ACTION FROM:
action 3, numVisits=213457, meanQ=17.540170, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action 1, numVisits=5, meanQ=10.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.614412 0.814401 0.531095 0.860965 0.805721 0.421553 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 382
Initial state: 0 0.801441 0.904583 0.577472 0.880957 0.646059 0.812738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225059 episodes
GETTING ACTION FROM:
action 2, numVisits=225047, meanQ=17.869245, numObservations: 4
action 3, numVisits=9, meanQ=14.108889, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.801441 0.904583 0.577472 0.880957 0.646059 0.812738 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 383
Initial state: 0 0.951993 0.796452 0.544297 0.808851 0.665105 0.841793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221312 episodes
GETTING ACTION FROM:
action 1, numVisits=221307, meanQ=17.715143, numObservations: 5
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.951993 0.796452 0.544297 0.808851 0.665105 0.841793 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 384
Initial state: 0 0.815285 0.930051 0.683321 0.890492 0.562471 0.819396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225275 episodes
GETTING ACTION FROM:
action 1, numVisits=225270, meanQ=17.863551, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.815285 0.930051 0.683321 0.890492 0.562471 0.819396 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 385
Initial state: 0 0.588083 0.855377 0.624957 0.825725 0.202366 0.782331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152849 episodes
GETTING ACTION FROM:
action 0, numVisits=152844, meanQ=15.565019, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.588083 0.855377 0.624957 0.825725 0.202366 0.782331 w: 1
Observation: 0 0 0.814422 0 0.872745 0 0.837762 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=152834, meanQ=17.789550, numObservations: 5
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 244148 episodes
GETTING ACTION FROM:
action 2, numVisits=396982, meanQ=17.771042, numObservations: 5
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.588083 0.855377 0.624957 0.825725 0.202366 0.782331 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 386
Initial state: 0 0.591407 0.892206 0.0980934 0.250107 0.675728 0.880753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225024 episodes
GETTING ACTION FROM:
action 2, numVisits=225018, meanQ=17.765898, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.591407 0.892206 0.0980934 0.250107 0.675728 0.880753 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31502, meanQ=23.253808, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284232 episodes
GETTING ACTION FROM:
action 3, numVisits=315734, meanQ=18.595497, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.591407 0.892206 0.0980934 0.250107 0.675728 0.880753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 387
Initial state: 0 0.627918 0.813742 0.539899 0.281893 0.521445 0.811001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153548 episodes
GETTING ACTION FROM:
action 0, numVisits=153543, meanQ=15.866213, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.627918 0.813742 0.539899 0.281893 0.521445 0.811001 w: 1
Observation: 0 0 0.756738 0 0.322871 0 0.79518 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153525, meanQ=18.073645, numObservations: 5
action 3, numVisits=14, meanQ=13.212143, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 243304 episodes
GETTING ACTION FROM:
action 1, numVisits=396829, meanQ=18.055361, numObservations: 5
action 3, numVisits=14, meanQ=13.212143, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.627918 0.813742 0.539899 0.281893 0.521445 0.811001 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 388
Initial state: 0 0.559839 0.834673 0.391654 0.546483 0.690271 0.890378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214527 episodes
GETTING ACTION FROM:
action 1, numVisits=214522, meanQ=17.579265, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.559839 0.834673 0.391654 0.546483 0.690271 0.890378 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 389
Initial state: 0 0.0143501 0.415779 0.684158 0.892113 0.613017 0.805275 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222760 episodes
GETTING ACTION FROM:
action 1, numVisits=222745, meanQ=17.724474, numObservations: 4
action 3, numVisits=11, meanQ=8.817273, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.0143501 0.415779 0.684158 0.892113 0.613017 0.805275 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 390
Initial state: 0 0.533265 0.865465 0.808671 0.668549 0.507942 0.840674 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222954 episodes
GETTING ACTION FROM:
action 3, numVisits=222946, meanQ=17.799126, numObservations: 4
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.533265 0.865465 0.808671 0.668549 0.507942 0.840674 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 391
Initial state: 0 0.536839 0.846055 0.559008 0.0203399 0.585905 0.81322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225717 episodes
GETTING ACTION FROM:
action 1, numVisits=225705, meanQ=17.737810, numObservations: 3
action 2, numVisits=8, meanQ=13.871250, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.536839 0.846055 0.559008 0.0203399 0.585905 0.81322 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16764, meanQ=17.309491, numObservations: 4
action 1, numVisits=8, meanQ=10.875000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284599 episodes
GETTING ACTION FROM:
action 3, numVisits=301363, meanQ=18.381945, numObservations: 4
action 1, numVisits=8, meanQ=10.875000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.536839 0.846055 0.559008 0.0203399 0.585905 0.81322 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 392
Initial state: 0 0.500097 0.881659 0.205209 0.0548598 0.50278 0.848899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223603 episodes
GETTING ACTION FROM:
action 1, numVisits=223596, meanQ=17.793779, numObservations: 4
action 2, numVisits=4, meanQ=9.502525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.500097 0.881659 0.205209 0.0548598 0.50278 0.848899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 393
Initial state: 0 0.671809 0.843244 0.27813 0.50641 0.692797 0.81983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224014 episodes
GETTING ACTION FROM:
action 1, numVisits=224008, meanQ=17.871755, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.671809 0.843244 0.27813 0.50641 0.692797 0.81983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16514, meanQ=18.766674, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 262095 episodes
GETTING ACTION FROM:
action 1, numVisits=278609, meanQ=17.454343, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.671809 0.843244 0.27813 0.50641 0.692797 0.81983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 394
Initial state: 0 0.637035 0.872614 0.784577 0.632739 0.566363 0.824034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223825 episodes
GETTING ACTION FROM:
action 2, numVisits=223817, meanQ=17.785405, numObservations: 4
action 3, numVisits=5, meanQ=5.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.637035 0.872614 0.784577 0.632739 0.566363 0.824034 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16962, meanQ=17.266775, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283685 episodes
GETTING ACTION FROM:
action 3, numVisits=300647, meanQ=18.324366, numObservations: 4
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.637035 0.872614 0.784577 0.632739 0.566363 0.824034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 395
Initial state: 0 0.074328 0.243047 0.612295 0.875245 0.524647 0.808826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225668 episodes
GETTING ACTION FROM:
action 3, numVisits=225664, meanQ=17.795221, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.074328 0.243047 0.612295 0.875245 0.524647 0.808826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 396
Initial state: 0 0.972756 0.63506 0.69523 0.817646 0.500595 0.847649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222694 episodes
GETTING ACTION FROM:
action 3, numVisits=222689, meanQ=17.896393, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.972756 0.63506 0.69523 0.817646 0.500595 0.847649 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 397
Initial state: 0 0.61131 0.857092 0.60318 0.882706 0.376083 0.961362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217180 episodes
GETTING ACTION FROM:
action 2, numVisits=217173, meanQ=17.832306, numObservations: 5
action 3, numVisits=3, meanQ=12.333333, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.61131 0.857092 0.60318 0.882706 0.376083 0.961362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 398
Initial state: 0 0.310281 0.406527 0.500571 0.803925 0.653119 0.885474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221977 episodes
GETTING ACTION FROM:
action 3, numVisits=221969, meanQ=17.851983, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.310281 0.406527 0.500571 0.803925 0.653119 0.885474 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 399
Initial state: 0 0.659246 0.86065 0.0221908 0.777144 0.509965 0.825224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225238 episodes
GETTING ACTION FROM:
action 3, numVisits=225234, meanQ=17.901362, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.659246 0.86065 0.0221908 0.777144 0.509965 0.825224 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 400
Initial state: 0 0.257884 0.575113 0.599601 0.833211 0.551154 0.800535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222973 episodes
GETTING ACTION FROM:
action 2, numVisits=222966, meanQ=17.822552, numObservations: 5
action 3, numVisits=4, meanQ=3.245025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.257884 0.575113 0.599601 0.833211 0.551154 0.800535 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 401
Initial state: 0 0.586754 0.827073 0.298688 0.000717489 0.569901 0.814189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215644 episodes
GETTING ACTION FROM:
action 3, numVisits=215638, meanQ=17.899580, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.586754 0.827073 0.298688 0.000717489 0.569901 0.814189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 402
Initial state: 0 0.585636 0.851887 0.658982 0.834029 0.413732 0.578337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154920 episodes
GETTING ACTION FROM:
action -1, numVisits=154916, meanQ=15.700367, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.585636 0.851887 0.658982 0.834029 0.413732 0.578337 w: 1
Observation: 0 0.521089 0 0.586633 0 0.505386 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=154909, meanQ=17.862437, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 247303 episodes
GETTING ACTION FROM:
action 1, numVisits=402212, meanQ=17.614158, numObservations: 4
action 2, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.585636 0.851887 0.658982 0.834029 0.413732 0.578337 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 21.76
Run # 403
Initial state: 0 0.907696 0.288449 0.554941 0.820261 0.64497 0.845196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223019 episodes
GETTING ACTION FROM:
action 2, numVisits=223010, meanQ=17.854774, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action 3, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.907696 0.288449 0.554941 0.820261 0.64497 0.845196 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 404
Initial state: 0 0.547391 0.838748 0.353231 0.509203 0.615668 0.866785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224090 episodes
GETTING ACTION FROM:
action 1, numVisits=224086, meanQ=17.744479, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.547391 0.838748 0.353231 0.509203 0.615668 0.866785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 405
Initial state: 0 0.577741 0.899244 0.688141 0.843973 0.77606 0.55323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223330 episodes
GETTING ACTION FROM:
action 3, numVisits=223316, meanQ=17.818732, numObservations: 4
action 1, numVisits=6, meanQ=9.163333, numObservations: 3
action 2, numVisits=6, meanQ=7.831667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.577741 0.899244 0.688141 0.843973 0.77606 0.55323 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16666, meanQ=18.603188, numObservations: 3
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 260646 episodes
GETTING ACTION FROM:
action 3, numVisits=277312, meanQ=17.476513, numObservations: 4
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.577741 0.899244 0.688141 0.843973 0.77606 0.55323 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 406
Initial state: 0 0.589347 0.848536 0.154975 0.403915 0.639954 0.863727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228215 episodes
GETTING ACTION FROM:
action 2, numVisits=228211, meanQ=17.809352, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.589347 0.848536 0.154975 0.403915 0.639954 0.863727 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=37276, meanQ=23.144413, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 287056 episodes
GETTING ACTION FROM:
action 1, numVisits=324332, meanQ=19.047904, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.589347 0.848536 0.154975 0.403915 0.639954 0.863727 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 407
Initial state: 0 0.645601 0.851139 0.0513511 0.0806261 0.675115 0.821007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224010 episodes
GETTING ACTION FROM:
action 2, numVisits=223996, meanQ=17.850521, numObservations: 4
action 3, numVisits=10, meanQ=11.598000, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 0 0.645601 0.851139 0.0513511 0.0806261 0.675115 0.821007 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31340, meanQ=23.240916, numObservations: 4
action 3, numVisits=21, meanQ=18.760481, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286530 episodes
GETTING ACTION FROM:
action 1, numVisits=317862, meanQ=19.428518, numObservations: 4
action 3, numVisits=29, meanQ=17.792072, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.645601 0.851139 0.0513511 0.0806261 0.675115 0.821007 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 408
Initial state: 0 0.559316 0.600389 0.577289 0.858011 0.522111 0.809488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222595 episodes
GETTING ACTION FROM:
action 3, numVisits=222588, meanQ=17.770470, numObservations: 4
action 2, numVisits=4, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.559316 0.600389 0.577289 0.858011 0.522111 0.809488 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 409
Initial state: 0 0.622703 0.811521 0.609464 0.822973 0.123699 0.279947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223678 episodes
GETTING ACTION FROM:
action 3, numVisits=223671, meanQ=17.844815, numObservations: 4
action 1, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.622703 0.811521 0.609464 0.822973 0.123699 0.279947 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=36652, meanQ=23.153271, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284243 episodes
GETTING ACTION FROM:
action 2, numVisits=320895, meanQ=19.379658, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.622703 0.811521 0.609464 0.822973 0.123699 0.279947 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 410
Initial state: 0 0.647519 0.898051 0.289037 0.511967 0.598442 0.848065 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224822 episodes
GETTING ACTION FROM:
action 1, numVisits=224818, meanQ=17.845340, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.647519 0.898051 0.289037 0.511967 0.598442 0.848065 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 411
Initial state: 0 0.557237 0.814702 0.588695 0.0525094 0.695812 0.862269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223993 episodes
GETTING ACTION FROM:
action 1, numVisits=223989, meanQ=17.737869, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.557237 0.814702 0.588695 0.0525094 0.695812 0.862269 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 412
Initial state: 0 0.76835 0.386628 0.678534 0.856239 0.684639 0.898405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224054 episodes
GETTING ACTION FROM:
action 1, numVisits=224050, meanQ=17.837277, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.76835 0.386628 0.678534 0.856239 0.684639 0.898405 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 413
Initial state: 0 0.544856 0.88403 0.249569 0.189374 0.661065 0.817247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223349 episodes
GETTING ACTION FROM:
action 2, numVisits=223345, meanQ=17.826465, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.544856 0.88403 0.249569 0.189374 0.661065 0.817247 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31258, meanQ=23.319236, numObservations: 4
action 1, numVisits=8, meanQ=20.623750, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 286289 episodes
GETTING ACTION FROM:
action 3, numVisits=317534, meanQ=19.496685, numObservations: 4
action 1, numVisits=21, meanQ=17.713810, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.544856 0.88403 0.249569 0.189374 0.661065 0.817247 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7786, meanQ=22.491325, numObservations: 4
action 1, numVisits=7, meanQ=20.141429, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 291414 episodes
GETTING ACTION FROM:
action 3, numVisits=299176, meanQ=18.848708, numObservations: 4
action 1, numVisits=31, meanQ=17.483548, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.544856 0.88403 0.249569 0.189374 0.661065 0.817247 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 414
Initial state: 0 0.347859 0.934792 0.643843 0.860553 0.503136 0.831915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226532 episodes
GETTING ACTION FROM:
action 1, numVisits=226521, meanQ=17.852488, numObservations: 3
action 3, numVisits=7, meanQ=9.535714, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.347859 0.934792 0.643843 0.860553 0.503136 0.831915 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 415
Initial state: 0 0.694827 0.883927 0.645056 0.845125 0.624138 0.580993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222547 episodes
GETTING ACTION FROM:
action 1, numVisits=222540, meanQ=17.866526, numObservations: 5
action 2, numVisits=4, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.694827 0.883927 0.645056 0.845125 0.624138 0.580993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 416
Initial state: 0 0.599875 0.876337 0.642142 0.840829 0.449523 0.393664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222581 episodes
GETTING ACTION FROM:
action 2, numVisits=222570, meanQ=18.159777, numObservations: 5
action 3, numVisits=7, meanQ=9.000000, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.599875 0.876337 0.642142 0.840829 0.449523 0.393664 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 417
Initial state: 0 0.565969 0.821425 0.825208 0.630862 0.607815 0.896677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225817 episodes
GETTING ACTION FROM:
action 1, numVisits=225813, meanQ=17.769806, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.565969 0.821425 0.825208 0.630862 0.607815 0.896677 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 418
Initial state: 0 0.69834 0.803546 0.602478 0.801914 0.526118 0.0202866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224020 episodes
GETTING ACTION FROM:
action 2, numVisits=224013, meanQ=17.685775, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.69834 0.803546 0.602478 0.801914 0.526118 0.0202866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 419
Initial state: 0 0.929595 0.904151 0.618292 0.884425 0.58232 0.850425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224108 episodes
GETTING ACTION FROM:
action 3, numVisits=224104, meanQ=17.857014, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.929595 0.904151 0.618292 0.884425 0.58232 0.850425 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 420
Initial state: 0 0.0764073 0.364124 0.697999 0.858249 0.669523 0.897558 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225316 episodes
GETTING ACTION FROM:
action 2, numVisits=225312, meanQ=17.749279, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0764073 0.364124 0.697999 0.858249 0.669523 0.897558 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 421
Initial state: 0 0.229275 0.055426 0.514094 0.83127 0.591999 0.892851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222231 episodes
GETTING ACTION FROM:
action 2, numVisits=222222, meanQ=17.784312, numObservations: 4
action 1, numVisits=6, meanQ=13.665000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.229275 0.055426 0.514094 0.83127 0.591999 0.892851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 422
Initial state: 0 0.115038 0.00359746 0.502632 0.829727 0.502873 0.833745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221530 episodes
GETTING ACTION FROM:
action 3, numVisits=221507, meanQ=18.071077, numObservations: 5
action 1, numVisits=20, meanQ=10.799000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.115038 0.00359746 0.502632 0.829727 0.502873 0.833745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 423
Initial state: 0 0.661694 0.854108 0.565326 0.847259 0.168964 0.73748 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220501 episodes
GETTING ACTION FROM:
action 2, numVisits=220474, meanQ=17.712725, numObservations: 5
action 3, numVisits=24, meanQ=14.771679, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.661694 0.854108 0.565326 0.847259 0.168964 0.73748 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 424
Initial state: 0 0.97464 0.0089033 0.685244 0.879342 0.500272 0.895981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225831 episodes
GETTING ACTION FROM:
action 3, numVisits=225822, meanQ=17.837179, numObservations: 3
action 2, numVisits=6, meanQ=12.333333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.97464 0.0089033 0.685244 0.879342 0.500272 0.895981 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 425
Initial state: 0 0.632507 0.817229 0.542289 0.880257 0.861288 0.14751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225961 episodes
GETTING ACTION FROM:
action 2, numVisits=225949, meanQ=17.870837, numObservations: 3
action 1, numVisits=9, meanQ=10.666678, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.632507 0.817229 0.542289 0.880257 0.861288 0.14751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 426
Initial state: 0 0.158481 0.148752 0.67939 0.874975 0.551405 0.805229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225143 episodes
GETTING ACTION FROM:
action 1, numVisits=225139, meanQ=17.827803, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.158481 0.148752 0.67939 0.874975 0.551405 0.805229 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25587, meanQ=23.467797, numObservations: 3
action 3, numVisits=12, meanQ=19.332508, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284234 episodes
GETTING ACTION FROM:
action 2, numVisits=309496, meanQ=18.680389, numObservations: 4
action 3, numVisits=337, meanQ=18.291782, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.158481 0.148752 0.67939 0.874975 0.551405 0.805229 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 427
Initial state: 0 0.678736 0.87816 0.70377 0.583268 0.617641 0.878076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223932 episodes
GETTING ACTION FROM:
action 3, numVisits=223927, meanQ=17.733469, numObservations: 4
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.678736 0.87816 0.70377 0.583268 0.617641 0.878076 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 428
Initial state: 0 0.542702 0.828603 0.699499 0.814721 0.0421351 0.565962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226748 episodes
GETTING ACTION FROM:
action 2, numVisits=226743, meanQ=17.870679, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.542702 0.828603 0.699499 0.814721 0.0421351 0.565962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 429
Initial state: 0 0.868233 0.0611141 0.519832 0.836703 0.612479 0.880567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221335 episodes
GETTING ACTION FROM:
action 1, numVisits=221329, meanQ=17.725652, numObservations: 5
action 2, numVisits=3, meanQ=5.330033, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.868233 0.0611141 0.519832 0.836703 0.612479 0.880567 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 430
Initial state: 0 0.19153 0.762073 0.512776 0.841534 0.627988 0.858664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222221 episodes
GETTING ACTION FROM:
action 2, numVisits=222194, meanQ=18.104721, numObservations: 5
action 1, numVisits=24, meanQ=12.623762, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.19153 0.762073 0.512776 0.841534 0.627988 0.858664 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 431
Initial state: 0 0.638001 0.833358 0.560624 0.883109 0.857488 0.391444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222412 episodes
GETTING ACTION FROM:
action 3, numVisits=222392, meanQ=17.712814, numObservations: 4
action 2, numVisits=17, meanQ=15.507059, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.638001 0.833358 0.560624 0.883109 0.857488 0.391444 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 432
Initial state: 0 0.882149 0.700519 0.658889 0.8283 0.694817 0.854735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221838 episodes
GETTING ACTION FROM:
action 3, numVisits=221831, meanQ=17.730957, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.882149 0.700519 0.658889 0.8283 0.694817 0.854735 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 433
Initial state: 0 0.578071 0.84794 0.511648 0.837697 0.0524396 0.0847163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220509 episodes
GETTING ACTION FROM:
action 2, numVisits=220505, meanQ=17.680338, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.578071 0.84794 0.511648 0.837697 0.0524396 0.0847163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16500, meanQ=17.468513, numObservations: 4
action 1, numVisits=7, meanQ=10.645729, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 283775 episodes
GETTING ACTION FROM:
action 3, numVisits=300275, meanQ=18.727852, numObservations: 4
action 1, numVisits=7, meanQ=10.645729, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.578071 0.84794 0.511648 0.837697 0.0524396 0.0847163 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=5504, meanQ=23.394265, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 294857 episodes
GETTING ACTION FROM:
action 2, numVisits=300361, meanQ=18.508303, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.578071 0.84794 0.511648 0.837697 0.0524396 0.0847163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=1162, meanQ=21.605988, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 299811 episodes
GETTING ACTION FROM:
action 2, numVisits=300973, meanQ=18.164271, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.578071 0.84794 0.511648 0.837697 0.0524396 0.0847163 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 434
Initial state: 0 0.606746 0.822055 0.422162 0.169024 0.65255 0.802965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222022 episodes
GETTING ACTION FROM:
action 2, numVisits=222016, meanQ=17.762703, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.606746 0.822055 0.422162 0.169024 0.65255 0.802965 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25401, meanQ=23.452813, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286512 episodes
GETTING ACTION FROM:
action 3, numVisits=311913, meanQ=19.016817, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.606746 0.822055 0.422162 0.169024 0.65255 0.802965 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 435
Initial state: 0 0.448351 0.552115 0.676019 0.896667 0.646215 0.846869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221291 episodes
GETTING ACTION FROM:
action 2, numVisits=221271, meanQ=17.742785, numObservations: 5
action 1, numVisits=11, meanQ=12.725455, numObservations: 3
action 3, numVisits=7, meanQ=12.140014, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.448351 0.552115 0.676019 0.896667 0.646215 0.846869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 436
Initial state: 0 0.678277 0.872914 0.0583062 0.308765 0.616405 0.837258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220435 episodes
GETTING ACTION FROM:
action 3, numVisits=220430, meanQ=17.712303, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.678277 0.872914 0.0583062 0.308765 0.616405 0.837258 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 437
Initial state: 0 0.695989 0.888532 0.518187 0.89744 0.421995 0.548713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219869 episodes
GETTING ACTION FROM:
action 3, numVisits=219859, meanQ=17.742640, numObservations: 5
action 2, numVisits=7, meanQ=11.282857, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.695989 0.888532 0.518187 0.89744 0.421995 0.548713 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=25126, meanQ=23.490198, numObservations: 3
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282533 episodes
GETTING ACTION FROM:
action 2, numVisits=307659, meanQ=19.243821, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.695989 0.888532 0.518187 0.89744 0.421995 0.548713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=7139, meanQ=22.711862, numObservations: 4
action 1, numVisits=23, meanQ=20.390439, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291856 episodes
GETTING ACTION FROM:
action 1, numVisits=267407, meanQ=19.309505, numObservations: 3
action 2, numVisits=31611, meanQ=19.240354, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.695989 0.888532 0.518187 0.89744 0.421995 0.548713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 438
Initial state: 0 0.655942 0.833216 0.566048 0.887928 0.144247 0.779936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223425 episodes
GETTING ACTION FROM:
action 1, numVisits=223405, meanQ=17.762194, numObservations: 4
action 3, numVisits=13, meanQ=6.692315, numObservations: 3
action 2, numVisits=5, meanQ=4.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.655942 0.833216 0.566048 0.887928 0.144247 0.779936 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 439
Initial state: 0 0.99044 0.560923 0.579902 0.895692 0.658252 0.801556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 209144 episodes
GETTING ACTION FROM:
action 2, numVisits=209140, meanQ=17.450152, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.99044 0.560923 0.579902 0.895692 0.658252 0.801556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 440
Initial state: 0 0.602772 0.882744 0.71311 0.381208 0.609679 0.814781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220717 episodes
GETTING ACTION FROM:
action 3, numVisits=220713, meanQ=17.699370, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.602772 0.882744 0.71311 0.381208 0.609679 0.814781 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16646, meanQ=17.337778, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 286615 episodes
GETTING ACTION FROM:
action 2, numVisits=303261, meanQ=18.197626, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.602772 0.882744 0.71311 0.381208 0.609679 0.814781 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 441
Initial state: 0 0.170152 0.743431 0.613824 0.84329 0.558674 0.89392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222423 episodes
GETTING ACTION FROM:
action 2, numVisits=222414, meanQ=17.742571, numObservations: 5
action 3, numVisits=6, meanQ=9.163333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.170152 0.743431 0.613824 0.84329 0.558674 0.89392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 442
Initial state: 0 0.594687 0.823734 0.666198 0.883423 0.111405 0.0227549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225139 episodes
GETTING ACTION FROM:
action 2, numVisits=225135, meanQ=17.780501, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.594687 0.823734 0.666198 0.883423 0.111405 0.0227549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 443
Initial state: 0 0.512965 0.157868 0.529601 0.833615 0.518918 0.848451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224455 episodes
GETTING ACTION FROM:
action 1, numVisits=224436, meanQ=17.794351, numObservations: 4
action 2, numVisits=16, meanQ=11.630625, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.512965 0.157868 0.529601 0.833615 0.518918 0.848451 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 444
Initial state: 0 0.324466 0.251128 0.503489 0.821248 0.546834 0.89715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224258 episodes
GETTING ACTION FROM:
action 2, numVisits=224252, meanQ=17.712672, numObservations: 4
action 1, numVisits=3, meanQ=5.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.324466 0.251128 0.503489 0.821248 0.546834 0.89715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 445
Initial state: 0 0.747914 0.904799 0.514342 0.842863 0.670389 0.844056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220736 episodes
GETTING ACTION FROM:
action 2, numVisits=220725, meanQ=17.705629, numObservations: 4
action 3, numVisits=7, meanQ=11.282857, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.747914 0.904799 0.514342 0.842863 0.670389 0.844056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 446
Initial state: 0 0.687442 0.824209 0.618251 0.825484 0.109715 0.903621 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221819 episodes
GETTING ACTION FROM:
action 2, numVisits=221810, meanQ=18.092106, numObservations: 5
action 1, numVisits=6, meanQ=7.831667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.687442 0.824209 0.618251 0.825484 0.109715 0.903621 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 447
Initial state: 0 0.61674 0.841528 0.679332 0.816507 0.622894 0.435067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226204 episodes
GETTING ACTION FROM:
action 1, numVisits=226200, meanQ=17.692528, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.61674 0.841528 0.679332 0.816507 0.622894 0.435067 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 448
Initial state: 0 0.392272 0.628017 0.672188 0.880307 0.525347 0.845373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223606 episodes
GETTING ACTION FROM:
action 2, numVisits=223599, meanQ=17.827449, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.392272 0.628017 0.672188 0.880307 0.525347 0.845373 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 449
Initial state: 0 0.576749 0.80733 0.468906 0.234794 0.559805 0.830163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221100 episodes
GETTING ACTION FROM:
action 1, numVisits=221091, meanQ=17.714493, numObservations: 5
action 3, numVisits=3, meanQ=12.333333, numObservations: 1
action 2, numVisits=4, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.576749 0.80733 0.468906 0.234794 0.559805 0.830163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 450
Initial state: 0 0.629301 0.882413 0.612558 0.867416 0.0830206 0.545932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222712 episodes
GETTING ACTION FROM:
action 3, numVisits=222706, meanQ=18.162412, numObservations: 5
action 2, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.629301 0.882413 0.612558 0.867416 0.0830206 0.545932 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25434, meanQ=23.511330, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284272 episodes
GETTING ACTION FROM:
action 1, numVisits=309706, meanQ=18.897124, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.629301 0.882413 0.612558 0.867416 0.0830206 0.545932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 451
Initial state: 0 0.190251 0.218422 0.534795 0.843217 0.589024 0.882062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153651 episodes
GETTING ACTION FROM:
action -1, numVisits=153647, meanQ=15.669688, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: -1
Next state: 0 0.190251 0.218422 0.534795 0.843217 0.589024 0.882062 w: 1
Observation: 0 0.250295 0 0.553952 0 0.492611 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153637, meanQ=17.835010, numObservations: 5
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 246786 episodes
GETTING ACTION FROM:
action 1, numVisits=400423, meanQ=17.717961, numObservations: 5
action 2, numVisits=5, meanQ=11.598000, numObservations: 3
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 0 0.190251 0.218422 0.534795 0.843217 0.589024 0.882062 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=9440, meanQ=22.376144, numObservations: 4
action 3, numVisits=3, meanQ=14.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289418 episodes
GETTING ACTION FROM:
action 2, numVisits=298858, meanQ=19.435309, numObservations: 4
action 3, numVisits=3, meanQ=14.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.190251 0.218422 0.534795 0.843217 0.589024 0.882062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 452
Initial state: 0 0.096803 0.868967 0.513023 0.846896 0.692668 0.858914 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220674 episodes
GETTING ACTION FROM:
action 3, numVisits=220662, meanQ=17.752334, numObservations: 5
action 2, numVisits=9, meanQ=13.221111, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.096803 0.868967 0.513023 0.846896 0.692668 0.858914 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 453
Initial state: 0 0.994485 0.455919 0.573785 0.888472 0.61019 0.845857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224929 episodes
GETTING ACTION FROM:
action 1, numVisits=224925, meanQ=17.767785, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.994485 0.455919 0.573785 0.888472 0.61019 0.845857 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 454
Initial state: 0 0.590465 0.8958 0.285151 0.671014 0.594428 0.865512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222270 episodes
GETTING ACTION FROM:
action 2, numVisits=222266, meanQ=17.746063, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.590465 0.8958 0.285151 0.671014 0.594428 0.865512 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31361, meanQ=23.196100, numObservations: 3
action 1, numVisits=13, meanQ=19.691546, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287914 episodes
GETTING ACTION FROM:
action 3, numVisits=319211, meanQ=19.027180, numObservations: 3
action 1, numVisits=77, meanQ=18.181432, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.590465 0.8958 0.285151 0.671014 0.594428 0.865512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 455
Initial state: 0 0.579186 0.882121 0.0929067 0.958937 0.536356 0.897572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222350 episodes
GETTING ACTION FROM:
action 3, numVisits=222346, meanQ=17.856421, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.579186 0.882121 0.0929067 0.958937 0.536356 0.897572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 456
Initial state: 0 0.551482 0.865766 0.678822 0.868849 0.855773 0.873831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224133 episodes
GETTING ACTION FROM:
action 2, numVisits=224105, meanQ=17.856832, numObservations: 5
action 3, numVisits=25, meanQ=10.540004, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.551482 0.865766 0.678822 0.868849 0.855773 0.873831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 457
Initial state: 0 0.254685 0.293197 0.523053 0.877709 0.65628 0.834277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222788 episodes
GETTING ACTION FROM:
action 1, numVisits=222784, meanQ=17.825572, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.254685 0.293197 0.523053 0.877709 0.65628 0.834277 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25352, meanQ=23.507071, numObservations: 3
action 2, numVisits=3, meanQ=14.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282249 episodes
GETTING ACTION FROM:
action 3, numVisits=307599, meanQ=19.014070, numObservations: 5
action 2, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.254685 0.293197 0.523053 0.877709 0.65628 0.834277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 458
Initial state: 0 0.455472 0.735116 0.649393 0.816587 0.65106 0.895471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154482 episodes
GETTING ACTION FROM:
action -1, numVisits=154478, meanQ=15.459749, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.455472 0.735116 0.649393 0.816587 0.65106 0.895471 w: 1
Observation: 0 0.486146 0 0.614266 0 0.693512 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=154462, meanQ=17.677133, numObservations: 4
action 1, numVisits=12, meanQ=11.248342, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 245336 episodes
GETTING ACTION FROM:
action 3, numVisits=399798, meanQ=17.670018, numObservations: 4
action 1, numVisits=12, meanQ=11.248342, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.455472 0.735116 0.649393 0.816587 0.65106 0.895471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=30623, meanQ=17.495671, numObservations: 5
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action 3, numVisits=5, meanQ=11.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 279370 episodes
GETTING ACTION FROM:
action 2, numVisits=309993, meanQ=18.465741, numObservations: 5
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action 3, numVisits=5, meanQ=11.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.455472 0.735116 0.649393 0.816587 0.65106 0.895471 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 459
Initial state: 0 0.143758 0.838028 0.525317 0.869949 0.594935 0.850931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220722 episodes
GETTING ACTION FROM:
action 1, numVisits=220715, meanQ=17.674941, numObservations: 5
action 2, numVisits=3, meanQ=12.333333, numObservations: 1
action 3, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.143758 0.838028 0.525317 0.869949 0.594935 0.850931 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 460
Initial state: 0 0.476416 0.751336 0.659873 0.848302 0.66215 0.857216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220159 episodes
GETTING ACTION FROM:
action 3, numVisits=220148, meanQ=17.826705, numObservations: 5
action 2, numVisits=8, meanQ=9.247512, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.476416 0.751336 0.659873 0.848302 0.66215 0.857216 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 461
Initial state: 0 0.568537 0.850943 0.795145 0.687584 0.652175 0.897416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225479 episodes
GETTING ACTION FROM:
action 2, numVisits=225475, meanQ=17.835763, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.568537 0.850943 0.795145 0.687584 0.652175 0.897416 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 462
Initial state: 0 0.881876 0.612571 0.679332 0.819725 0.560632 0.804596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223846 episodes
GETTING ACTION FROM:
action 2, numVisits=223840, meanQ=17.680049, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.881876 0.612571 0.679332 0.819725 0.560632 0.804596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 463
Initial state: 0 0.993996 0.236702 0.644826 0.887408 0.570494 0.846682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224053 episodes
GETTING ACTION FROM:
action 3, numVisits=224049, meanQ=17.835030, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.993996 0.236702 0.644826 0.887408 0.570494 0.846682 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 464
Initial state: 0 0.792467 0.788652 0.638827 0.895317 0.569972 0.896999 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226628 episodes
GETTING ACTION FROM:
action 1, numVisits=226606, meanQ=17.830759, numObservations: 3
action 2, numVisits=15, meanQ=15.849340, numObservations: 3
action 3, numVisits=5, meanQ=11.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.792467 0.788652 0.638827 0.895317 0.569972 0.896999 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 465
Initial state: 0 0.580233 0.897486 0.522615 0.872662 0.925353 0.803696 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222772 episodes
GETTING ACTION FROM:
action 2, numVisits=222748, meanQ=17.774106, numObservations: 4
action 3, numVisits=20, meanQ=15.100510, numObservations: 4
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.580233 0.897486 0.522615 0.872662 0.925353 0.803696 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 466
Initial state: 0 0.400522 0.486941 0.525972 0.841614 0.530409 0.82695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223228 episodes
GETTING ACTION FROM:
action 2, numVisits=223211, meanQ=17.712472, numObservations: 4
action 3, numVisits=12, meanQ=11.248342, numObservations: 5
action 1, numVisits=3, meanQ=5.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.400522 0.486941 0.525972 0.841614 0.530409 0.82695 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 467
Initial state: 0 0.600477 0.857694 0.615075 0.825987 0.464051 0.369645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221409 episodes
GETTING ACTION FROM:
action 3, numVisits=221404, meanQ=17.766224, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.600477 0.857694 0.615075 0.825987 0.464051 0.369645 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5322, meanQ=22.363302, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284564 episodes
GETTING ACTION FROM:
action 1, numVisits=289886, meanQ=18.485081, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600477 0.857694 0.615075 0.825987 0.464051 0.369645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 468
Initial state: 0 0.521134 0.852972 0.752222 0.668334 0.587128 0.897702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222455 episodes
GETTING ACTION FROM:
action 1, numVisits=222433, meanQ=17.803236, numObservations: 5
action 3, numVisits=18, meanQ=15.388344, numObservations: 3
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.521134 0.852972 0.752222 0.668334 0.587128 0.897702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 469
Initial state: 0 0.522519 0.806025 0.137582 0.099057 0.651762 0.807663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224690 episodes
GETTING ACTION FROM:
action 3, numVisits=224681, meanQ=17.900493, numObservations: 4
action 1, numVisits=3, meanQ=12.333333, numObservations: 2
action 2, numVisits=4, meanQ=8.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.522519 0.806025 0.137582 0.099057 0.651762 0.807663 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 470
Initial state: 0 0.584496 0.836578 0.557269 0.887559 0.192065 0.0569189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221251 episodes
GETTING ACTION FROM:
action 2, numVisits=221243, meanQ=17.701881, numObservations: 5
action 1, numVisits=5, meanQ=12.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.584496 0.836578 0.557269 0.887559 0.192065 0.0569189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 471
Initial state: 0 0.991958 0.711234 0.661811 0.845166 0.592889 0.806263 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224652 episodes
GETTING ACTION FROM:
action 1, numVisits=224639, meanQ=17.716615, numObservations: 4
action 3, numVisits=10, meanQ=11.201010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.991958 0.711234 0.661811 0.845166 0.592889 0.806263 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 472
Initial state: 0 0.885818 0.791501 0.659931 0.832693 0.539383 0.819892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224795 episodes
GETTING ACTION FROM:
action 2, numVisits=224782, meanQ=17.817818, numObservations: 3
action 3, numVisits=6, meanQ=12.958333, numObservations: 3
action 1, numVisits=5, meanQ=12.798020, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 2
Next state: 1 0.885818 0.791501 0.659931 0.832693 0.539383 0.819892 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 473
Initial state: 0 0.534416 0.824782 0.0758738 0.1153 0.561912 0.875251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223218 episodes
GETTING ACTION FROM:
action 1, numVisits=223214, meanQ=17.854825, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.534416 0.824782 0.0758738 0.1153 0.561912 0.875251 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 474
Initial state: 0 0.355225 0.199638 0.678514 0.839618 0.58634 0.809266 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222218 episodes
GETTING ACTION FROM:
action 1, numVisits=222211, meanQ=17.727694, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.355225 0.199638 0.678514 0.839618 0.58634 0.809266 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=10959, meanQ=22.394276, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286017 episodes
GETTING ACTION FROM:
action 2, numVisits=296976, meanQ=19.158664, numObservations: 5
action 3, numVisits=3, meanQ=14.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.355225 0.199638 0.678514 0.839618 0.58634 0.809266 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 475
Initial state: 0 0.554893 0.892946 0.5926 0.864051 0.436122 0.0315384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221776 episodes
GETTING ACTION FROM:
action 3, numVisits=221772, meanQ=17.782647, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.554893 0.892946 0.5926 0.864051 0.436122 0.0315384 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30876, meanQ=23.252267, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286515 episodes
GETTING ACTION FROM:
action 1, numVisits=317391, meanQ=19.423546, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.554893 0.892946 0.5926 0.864051 0.436122 0.0315384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 476
Initial state: 0 0.491214 0.700689 0.588903 0.843365 0.680328 0.837851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221512 episodes
GETTING ACTION FROM:
action 3, numVisits=221507, meanQ=17.767744, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.491214 0.700689 0.588903 0.843365 0.680328 0.837851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 477
Initial state: 0 0.198751 0.829897 0.635297 0.872783 0.664626 0.891375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222840 episodes
GETTING ACTION FROM:
action 2, numVisits=222836, meanQ=17.886130, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.198751 0.829897 0.635297 0.872783 0.664626 0.891375 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 478
Initial state: 0 0.912364 0.412457 0.63143 0.839037 0.648629 0.886451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223510 episodes
GETTING ACTION FROM:
action 2, numVisits=223506, meanQ=17.746384, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.912364 0.412457 0.63143 0.839037 0.648629 0.886451 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16957, meanQ=17.326418, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 272663 episodes
GETTING ACTION FROM:
action 1, numVisits=289620, meanQ=19.083780, numObservations: 5
action 3, numVisits=4, meanQ=8.497500, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 2 0.912364 0.412457 0.63143 0.839037 0.648629 0.886451 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 479
Initial state: 0 0.689991 0.816926 0.748685 0.617866 0.658799 0.895324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226181 episodes
GETTING ACTION FROM:
action 1, numVisits=226177, meanQ=17.842866, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.689991 0.816926 0.748685 0.617866 0.658799 0.895324 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 480
Initial state: 0 0.622433 0.850929 0.228015 0.5257 0.54128 0.86451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223690 episodes
GETTING ACTION FROM:
action 1, numVisits=223682, meanQ=17.775258, numObservations: 4
action 3, numVisits=5, meanQ=7.794000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.622433 0.850929 0.228015 0.5257 0.54128 0.86451 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 481
Initial state: 0 0.584563 0.879268 0.645864 0.893284 0.336876 0.527886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222356 episodes
GETTING ACTION FROM:
action 1, numVisits=222352, meanQ=17.756602, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.584563 0.879268 0.645864 0.893284 0.336876 0.527886 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 482
Initial state: 0 0.591352 0.809017 0.257931 0.193802 0.684809 0.881037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222053 episodes
GETTING ACTION FROM:
action 1, numVisits=222049, meanQ=17.713067, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.591352 0.809017 0.257931 0.193802 0.684809 0.881037 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 483
Initial state: 0 0.659422 0.862209 0.454509 0.568425 0.509745 0.848338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223540 episodes
GETTING ACTION FROM:
action 1, numVisits=223536, meanQ=17.754929, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.659422 0.862209 0.454509 0.568425 0.509745 0.848338 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 484
Initial state: 0 0.654005 0.885468 0.658781 0.870989 0.736485 0.344682 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224654 episodes
GETTING ACTION FROM:
action 1, numVisits=224649, meanQ=17.813350, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.654005 0.885468 0.658781 0.870989 0.736485 0.344682 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 485
Initial state: 0 0.620302 0.809726 0.640952 0.818356 0.429639 0.257332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 210558 episodes
GETTING ACTION FROM:
action 2, numVisits=210553, meanQ=17.805584, numObservations: 5
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.620302 0.809726 0.640952 0.818356 0.429639 0.257332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 486
Initial state: 0 0.673326 0.858131 0.655769 0.878192 0.72892 0.253069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153912 episodes
GETTING ACTION FROM:
action -1, numVisits=153906, meanQ=15.523951, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.673326 0.858131 0.655769 0.878192 0.72892 0.253069 w: 1
Observation: 0 0.692269 0 0.673463 0 0.826229 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153900, meanQ=17.806175, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 246063 episodes
GETTING ACTION FROM:
action 3, numVisits=399963, meanQ=18.150845, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.673326 0.858131 0.655769 0.878192 0.72892 0.253069 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 487
Initial state: 0 0.643385 0.868471 0.651107 0.887343 0.121616 0.865955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224262 episodes
GETTING ACTION FROM:
action 1, numVisits=224256, meanQ=17.756356, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.643385 0.868471 0.651107 0.887343 0.121616 0.865955 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 488
Initial state: 0 0.724878 0.360483 0.659113 0.805979 0.609608 0.862933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223278 episodes
GETTING ACTION FROM:
action 3, numVisits=223274, meanQ=17.862799, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.724878 0.360483 0.659113 0.805979 0.609608 0.862933 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 489
Initial state: 0 0.533532 0.865851 0.260266 0.485883 0.535722 0.823653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222521 episodes
GETTING ACTION FROM:
action 1, numVisits=222517, meanQ=17.851369, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.533532 0.865851 0.260266 0.485883 0.535722 0.823653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16532, meanQ=18.885495, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 266406 episodes
GETTING ACTION FROM:
action 1, numVisits=282938, meanQ=17.159179, numObservations: 4
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.533532 0.865851 0.260266 0.485883 0.535722 0.823653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 490
Initial state: 0 0.569302 0.815165 0.63242 0.824184 0.882894 0.179371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223279 episodes
GETTING ACTION FROM:
action 2, numVisits=223275, meanQ=17.751259, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.569302 0.815165 0.63242 0.824184 0.882894 0.179371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16110, meanQ=18.558942, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 262349 episodes
GETTING ACTION FROM:
action 2, numVisits=278459, meanQ=17.328411, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.569302 0.815165 0.63242 0.824184 0.882894 0.179371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 491
Initial state: 0 0.517962 0.818218 0.513337 0.870849 0.290385 0.21974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220612 episodes
GETTING ACTION FROM:
action 3, numVisits=220596, meanQ=17.732173, numObservations: 4
action 2, numVisits=13, meanQ=14.306931, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.517962 0.818218 0.513337 0.870849 0.290385 0.21974 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 492
Initial state: 0 0.658988 0.873336 0.159793 0.481385 0.510763 0.83288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222679 episodes
GETTING ACTION FROM:
action 2, numVisits=222665, meanQ=17.791805, numObservations: 4
action 1, numVisits=11, meanQ=7.088182, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.658988 0.873336 0.159793 0.481385 0.510763 0.83288 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31347, meanQ=23.272189, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284052 episodes
GETTING ACTION FROM:
action 1, numVisits=315399, meanQ=19.376849, numObservations: 5
action 3, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.658988 0.873336 0.159793 0.481385 0.510763 0.83288 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 493
Initial state: 0 0.633281 0.876934 0.691394 0.813336 0.718919 0.35246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220816 episodes
GETTING ACTION FROM:
action 3, numVisits=220804, meanQ=17.760898, numObservations: 5
action 2, numVisits=8, meanQ=12.872500, numObservations: 2
action 1, numVisits=2, meanQ=10.495000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 2 0.633281 0.876934 0.691394 0.813336 0.718919 0.35246 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 494
Initial state: 0 0.618125 0.821326 0.655944 0.848498 0.22913 0.927542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153904 episodes
GETTING ACTION FROM:
action -1, numVisits=153900, meanQ=15.571194, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.618125 0.821326 0.655944 0.848498 0.22913 0.927542 w: 1
Observation: 0 0.646761 0 0.623209 0 0.24406 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153890, meanQ=17.743048, numObservations: 5
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 243387 episodes
GETTING ACTION FROM:
action 3, numVisits=397277, meanQ=17.933684, numObservations: 5
action 1, numVisits=6, meanQ=13.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.618125 0.821326 0.655944 0.848498 0.22913 0.927542 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=29595, meanQ=17.304634, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287040 episodes
GETTING ACTION FROM:
action 2, numVisits=316635, meanQ=18.729790, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.618125 0.821326 0.655944 0.848498 0.22913 0.927542 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 17.5624
Run # 495
Initial state: 0 0.317319 0.152578 0.60211 0.854711 0.670963 0.858371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220668 episodes
GETTING ACTION FROM:
action 3, numVisits=220660, meanQ=17.834627, numObservations: 5
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action 1, numVisits=4, meanQ=8.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 0 0.317319 0.152578 0.60211 0.854711 0.670963 0.858371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16553, meanQ=18.748518, numObservations: 3
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 263667 episodes
GETTING ACTION FROM:
action 3, numVisits=280220, meanQ=16.472609, numObservations: 4
action 2, numVisits=2, meanQ=10.495000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.317319 0.152578 0.60211 0.854711 0.670963 0.858371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 496
Initial state: 0 0.0189469 0.844839 0.547692 0.815177 0.573096 0.814329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223299 episodes
GETTING ACTION FROM:
action 2, numVisits=223290, meanQ=17.700097, numObservations: 4
action 1, numVisits=6, meanQ=9.163333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0189469 0.844839 0.547692 0.815177 0.573096 0.814329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 497
Initial state: 0 0.61175 0.831196 0.162653 0.0830611 0.58673 0.863382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224458 episodes
GETTING ACTION FROM:
action 1, numVisits=224445, meanQ=17.745320, numObservations: 4
action 2, numVisits=10, meanQ=11.598000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.61175 0.831196 0.162653 0.0830611 0.58673 0.863382 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 498
Initial state: 0 0.63689 0.856655 0.120147 0.914665 0.672567 0.889047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219469 episodes
GETTING ACTION FROM:
action 3, numVisits=219436, meanQ=17.702580, numObservations: 5
action 2, numVisits=30, meanQ=13.651003, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.63689 0.856655 0.120147 0.914665 0.672567 0.889047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 499
Initial state: 0 0.568681 0.859316 0.625358 0.836273 0.129512 0.549944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226069 episodes
GETTING ACTION FROM:
action 3, numVisits=226065, meanQ=17.857500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.568681 0.859316 0.625358 0.836273 0.129512 0.549944 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=37160, meanQ=23.174601, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289309 episodes
GETTING ACTION FROM:
action 1, numVisits=326469, meanQ=18.823021, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.568681 0.859316 0.625358 0.836273 0.129512 0.549944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 500
Initial state: 0 0.6264 0.826977 0.66016 0.817214 0.711478 0.981242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221218 episodes
GETTING ACTION FROM:
action 3, numVisits=221212, meanQ=17.850401, numObservations: 5
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.6264 0.826977 0.66016 0.817214 0.711478 0.981242 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
