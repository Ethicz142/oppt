Run # 1
Initial state: 0 0.53768 0.818495 0.903326 0.554298 0.565098 0.803885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 209921 episodes
GETTING ACTION FROM:
action 3, numVisits=209826, meanQ=4.947743, numObservations: 5
action 0, numVisits=63, meanQ=4.064380, numObservations: 1
action -1, numVisits=28, meanQ=3.527573, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.53768 0.818495 0.903326 0.554298 0.565098 0.803885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.682213 0.871951 0.184219 0.475319 0.625731 0.832102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225756 episodes
GETTING ACTION FROM:
action 3, numVisits=225749, meanQ=4.951555, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.682213 0.871951 0.184219 0.475319 0.625731 0.832102 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.405715 0.64649 0.620931 0.893299 0.555544 0.881176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228448 episodes
GETTING ACTION FROM:
action 2, numVisits=228429, meanQ=5.138923, numObservations: 4
action -1, numVisits=15, meanQ=3.236503, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.405715 0.64649 0.620931 0.893299 0.555544 0.881176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.118637 0.0103219 0.649996 0.858738 0.658004 0.839609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224121 episodes
GETTING ACTION FROM:
action 2, numVisits=224074, meanQ=4.998477, numObservations: 5
action 0, numVisits=41, meanQ=3.890672, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.118637 0.0103219 0.649996 0.858738 0.658004 0.839609 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 5
Initial state: 0 0.569057 0.841798 0.796251 0.00787808 0.649573 0.89866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224100 episodes
GETTING ACTION FROM:
action 3, numVisits=224044, meanQ=5.026754, numObservations: 5
action -1, numVisits=43, meanQ=3.937516, numObservations: 1
action 1, numVisits=10, meanQ=2.598000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.569057 0.841798 0.796251 0.00787808 0.649573 0.89866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.506493 0.8181 0.517666 0.886121 0.614538 0.0326309 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 211435 episodes
GETTING ACTION FROM:
action 2, numVisits=211426, meanQ=4.707509, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.506493 0.8181 0.517666 0.886121 0.614538 0.0326309 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.555393 0.887194 0.115601 0.109403 0.532676 0.820736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156341 episodes
GETTING ACTION FROM:
action -1, numVisits=156334, meanQ=2.935307, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.555393 0.887194 0.115601 0.109403 0.532676 0.820736 w: 1
Observation: 0 0.634535 0 0.0560397 0 0.462686 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=156283, meanQ=4.996842, numObservations: 3
action -1, numVisits=45, meanQ=3.961139, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 254733 episodes
GETTING ACTION FROM:
action 1, numVisits=411016, meanQ=5.045826, numObservations: 3
action -1, numVisits=45, meanQ=3.961139, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.555393 0.887194 0.115601 0.109403 0.532676 0.820736 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=30998, meanQ=5.521397, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 259364 episodes
GETTING ACTION FROM:
action 1, numVisits=290360, meanQ=5.004600, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.555393 0.887194 0.115601 0.109403 0.532676 0.820736 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 8
Initial state: 0 0.93146 0.470305 0.576655 0.806387 0.646729 0.850509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222231 episodes
GETTING ACTION FROM:
action 2, numVisits=222225, meanQ=5.043241, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.93146 0.470305 0.576655 0.806387 0.646729 0.850509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.35715 0.786247 0.573754 0.87017 0.644353 0.820223 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224673 episodes
GETTING ACTION FROM:
action 1, numVisits=224604, meanQ=4.922196, numObservations: 5
action -1, numVisits=31, meanQ=3.641076, numObservations: 1
action 0, numVisits=20, meanQ=3.319408, numObservations: 1
action 3, numVisits=16, meanQ=2.873756, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 0 0.35715 0.786247 0.573754 0.87017 0.644353 0.820223 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30829, meanQ=8.396821, numObservations: 4
action 2, numVisits=305, meanQ=8.058358, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287825 episodes
GETTING ACTION FROM:
action 3, numVisits=316506, meanQ=6.397014, numObservations: 4
action 2, numVisits=2453, meanQ=6.264904, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.35715 0.786247 0.573754 0.87017 0.644353 0.820223 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 10
Initial state: 0 0.589285 0.812436 0.580292 0.841818 0.234754 0.725129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224825 episodes
GETTING ACTION FROM:
action 1, numVisits=224818, meanQ=4.915432, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.589285 0.812436 0.580292 0.841818 0.234754 0.725129 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.549623 0.861953 0.918114 0.626509 0.667028 0.804823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154808 episodes
GETTING ACTION FROM:
action 0, numVisits=154140, meanQ=2.894776, numObservations: 1
action -1, numVisits=663, meanQ=1.404008, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.549623 0.861953 0.918114 0.626509 0.667028 0.804823 w: 1
Observation: 0 0 0.918766 0 0.58028 0 0.785938 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=154108, meanQ=4.957071, numObservations: 5
action 0, numVisits=21, meanQ=3.401980, numObservations: 1
action 1, numVisits=5, meanQ=1.780000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 244046 episodes
GETTING ACTION FROM:
action 2, numVisits=398154, meanQ=5.058719, numObservations: 5
action 0, numVisits=21, meanQ=3.401980, numObservations: 1
action 1, numVisits=5, meanQ=1.780000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.549623 0.861953 0.918114 0.626509 0.667028 0.804823 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 12
Initial state: 0 0.692504 0.853624 0.670704 0.962301 0.568101 0.862323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225584 episodes
GETTING ACTION FROM:
action 3, numVisits=225499, meanQ=5.030838, numObservations: 4
action 1, numVisits=80, meanQ=2.580678, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.692504 0.853624 0.670704 0.962301 0.568101 0.862323 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.688074 0.856416 0.687258 0.249754 0.680975 0.824072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224165 episodes
GETTING ACTION FROM:
action 2, numVisits=224114, meanQ=4.922975, numObservations: 4
action 3, numVisits=25, meanQ=3.478812, numObservations: 4
action 0, numVisits=23, meanQ=3.461626, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.688074 0.856416 0.687258 0.249754 0.680975 0.824072 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31088, meanQ=8.422596, numObservations: 4
action 3, numVisits=103, meanQ=7.808253, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288076 episodes
GETTING ACTION FROM:
action 1, numVisits=318684, meanQ=6.189538, numObservations: 4
action 3, numVisits=583, meanQ=5.889606, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.688074 0.856416 0.687258 0.249754 0.680975 0.824072 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 14
Initial state: 0 0.595386 0.892573 0.292358 0.398229 0.569551 0.871097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217188 episodes
GETTING ACTION FROM:
action 1, numVisits=217074, meanQ=4.843848, numObservations: 5
action -1, numVisits=81, meanQ=4.073881, numObservations: 1
action 0, numVisits=22, meanQ=3.320966, numObservations: 1
action 2, numVisits=10, meanQ=1.799000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.595386 0.892573 0.292358 0.398229 0.569551 0.871097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=16374, meanQ=3.436495, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 283885 episodes
GETTING ACTION FROM:
action 2, numVisits=282806, meanQ=5.742198, numObservations: 5
action 0, numVisits=17454, meanQ=3.193174, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.595386 0.892573 0.292358 0.398229 0.569551 0.871097 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1855, meanQ=7.708328, numObservations: 5
action 1, numVisits=7, meanQ=4.427143, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292552 episodes
GETTING ACTION FROM:
action 3, numVisits=294403, meanQ=6.081059, numObservations: 5
action 1, numVisits=11, meanQ=3.545464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.595386 0.892573 0.292358 0.398229 0.569551 0.871097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=1111, meanQ=7.694617, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292717 episodes
GETTING ACTION FROM:
action 3, numVisits=293824, meanQ=5.218522, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.595386 0.892573 0.292358 0.398229 0.569551 0.871097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 15
Initial state: 0 0.574812 0.87423 0.0206931 0.258026 0.612431 0.835945 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226493 episodes
GETTING ACTION FROM:
action 1, numVisits=226487, meanQ=5.003224, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.574812 0.87423 0.0206931 0.258026 0.612431 0.835945 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.699179 0.862672 0.439083 0.0847532 0.6565 0.845013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223790 episodes
GETTING ACTION FROM:
action 2, numVisits=223233, meanQ=4.946116, numObservations: 5
action 3, numVisits=544, meanQ=4.654382, numObservations: 5
action 1, numVisits=9, meanQ=2.553344, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.699179 0.862672 0.439083 0.0847532 0.6565 0.845013 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25567, meanQ=8.424585, numObservations: 4
action 3, numVisits=5590, meanQ=8.380812, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288360 episodes
GETTING ACTION FROM:
action 1, numVisits=294373, meanQ=6.355836, numObservations: 4
action 3, numVisits=25144, meanQ=6.322672, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.699179 0.862672 0.439083 0.0847532 0.6565 0.845013 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 17
Initial state: 0 0.669651 0.805981 0.816648 0.762371 0.506782 0.861441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225443 episodes
GETTING ACTION FROM:
action 3, numVisits=225368, meanQ=5.012321, numObservations: 5
action -1, numVisits=35, meanQ=3.825264, numObservations: 1
action 2, numVisits=35, meanQ=3.683437, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.669651 0.805981 0.816648 0.762371 0.506782 0.861441 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.525391 0.871838 0.801691 0.825773 0.572319 0.857476 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229206 episodes
GETTING ACTION FROM:
action 2, numVisits=229092, meanQ=4.974950, numObservations: 3
action -1, numVisits=78, meanQ=4.179865, numObservations: 1
action 0, numVisits=22, meanQ=3.447770, numObservations: 1
action 1, numVisits=13, meanQ=2.997715, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.525391 0.871838 0.801691 0.825773 0.572319 0.857476 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.605555 0.854549 0.584114 0.885125 0.00467702 0.2549 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228856 episodes
GETTING ACTION FROM:
action 2, numVisits=228850, meanQ=5.021493, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.605555 0.854549 0.584114 0.885125 0.00467702 0.2549 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 20
Initial state: 0 0.672819 0.894539 0.136337 0.255625 0.529174 0.815393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217814 episodes
GETTING ACTION FROM:
action 3, numVisits=217701, meanQ=4.818238, numObservations: 4
action 0, numVisits=108, meanQ=4.153980, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.672819 0.894539 0.136337 0.255625 0.529174 0.815393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.531978 0.879957 0.833253 0.943063 0.548539 0.897407 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230321 episodes
GETTING ACTION FROM:
action 1, numVisits=230139, meanQ=4.925540, numObservations: 3
action -1, numVisits=177, meanQ=4.404072, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.531978 0.879957 0.833253 0.943063 0.548539 0.897407 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 22
Initial state: 0 0.623575 0.839553 0.783638 0.49211 0.593936 0.80166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226839 episodes
GETTING ACTION FROM:
action 1, numVisits=226733, meanQ=5.015119, numObservations: 4
action 0, numVisits=65, meanQ=4.147775, numObservations: 1
action -1, numVisits=22, meanQ=3.516265, numObservations: 1
action 3, numVisits=15, meanQ=2.866000, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action: 1
Next state: 1 0.623575 0.839553 0.783638 0.49211 0.593936 0.80166 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.178946 0.142563 0.533588 0.836734 0.522069 0.891194 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220264 episodes
GETTING ACTION FROM:
action 1, numVisits=220221, meanQ=4.997975, numObservations: 5
action -1, numVisits=34, meanQ=3.770230, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.178946 0.142563 0.533588 0.836734 0.522069 0.891194 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30625, meanQ=8.420749, numObservations: 4
action 2, numVisits=12, meanQ=5.831675, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 280198 episodes
GETTING ACTION FROM:
action 3, numVisits=310808, meanQ=5.967881, numObservations: 4
action 2, numVisits=25, meanQ=4.279204, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.178946 0.142563 0.533588 0.836734 0.522069 0.891194 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 24
Initial state: 0 0.612683 0.801663 0.160946 0.969414 0.526833 0.849044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222439 episodes
GETTING ACTION FROM:
action 3, numVisits=222331, meanQ=5.061358, numObservations: 3
action -1, numVisits=64, meanQ=4.187097, numObservations: 1
action 0, numVisits=42, meanQ=3.967380, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.612683 0.801663 0.160946 0.969414 0.526833 0.849044 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 25
Initial state: 0 0.644282 0.871275 0.817991 0.336412 0.6501 0.840165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218599 episodes
GETTING ACTION FROM:
action 2, numVisits=208253, meanQ=5.024478, numObservations: 4
action -1, numVisits=10340, meanQ=3.011067, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.644282 0.871275 0.817991 0.336412 0.6501 0.840165 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.653944 0.895864 0.522266 0.883759 0.597179 0.0912878 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 147716 episodes
GETTING ACTION FROM:
action 0, numVisits=147697, meanQ=2.740586, numObservations: 1
action 2, numVisits=12, meanQ=0.665850, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 0
Next state: 0 0.653944 0.895864 0.522266 0.883759 0.597179 0.0912878 w: 1
Observation: 0 0 0.897793 0 0.860191 0 0.116867 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=147604, meanQ=4.811281, numObservations: 5
action 0, numVisits=88, meanQ=4.057455, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 234245 episodes
GETTING ACTION FROM:
action 3, numVisits=381849, meanQ=4.952507, numObservations: 5
action 0, numVisits=88, meanQ=4.057455, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.653944 0.895864 0.522266 0.883759 0.597179 0.0912878 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=18516, meanQ=5.732612, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 256175 episodes
GETTING ACTION FROM:
action 0, numVisits=274680, meanQ=0.239680, numObservations: 1
action -1, numVisits=9, meanQ=-2.223300, numObservations: 1
action 3, numVisits=4, meanQ=-4.002500, numObservations: 3
action 1, numVisits=3, meanQ=-5.673333, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.653944 0.895864 0.522266 0.883759 0.597179 0.0912878 w: 1
Observation: 0 0 0.970494 0 0.812402 0 0.185294 
Immediate reward: -2
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=82660, meanQ=7.287697, numObservations: 4
action 2, numVisits=34, meanQ=5.935000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 280246 episodes
GETTING ACTION FROM:
action 1, numVisits=362407, meanQ=6.217495, numObservations: 4
action 2, numVisits=533, meanQ=5.904966, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.653944 0.895864 0.522266 0.883759 0.597179 0.0912878 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.812491
Run # 27
Initial state: 0 0.619039 0.844438 0.206841 0.435994 0.523162 0.827873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221238 episodes
GETTING ACTION FROM:
action 3, numVisits=220630, meanQ=4.944305, numObservations: 4
action -1, numVisits=465, meanQ=3.189004, numObservations: 1
action 1, numVisits=140, meanQ=2.981225, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.619039 0.844438 0.206841 0.435994 0.523162 0.827873 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 28
Initial state: 0 0.139615 0.723416 0.577068 0.808183 0.504029 0.865235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219405 episodes
GETTING ACTION FROM:
action 1, numVisits=217313, meanQ=5.001918, numObservations: 5
action 2, numVisits=2086, meanQ=4.849578, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.139615 0.723416 0.577068 0.808183 0.504029 0.865235 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30282, meanQ=8.399526, numObservations: 5
action 2, numVisits=3, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 277285 episodes
GETTING ACTION FROM:
action 3, numVisits=307450, meanQ=6.364938, numObservations: 5
action 2, numVisits=120, meanQ=5.633167, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.139615 0.723416 0.577068 0.808183 0.504029 0.865235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 29
Initial state: 0 0.580523 0.824329 0.53517 0.813993 0.739759 0.581007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224581 episodes
GETTING ACTION FROM:
action 3, numVisits=224536, meanQ=5.025698, numObservations: 3
action 0, numVisits=20, meanQ=3.416975, numObservations: 1
action 1, numVisits=17, meanQ=2.881176, numObservations: 4
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.580523 0.824329 0.53517 0.813993 0.739759 0.581007 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 30
Initial state: 0 0.605596 0.890241 0.365441 0.915021 0.665503 0.8007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222517 episodes
GETTING ACTION FROM:
action 1, numVisits=222506, meanQ=5.012164, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.605596 0.890241 0.365441 0.915021 0.665503 0.8007 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1865, meanQ=4.853401, numObservations: 4
action 3, numVisits=18, meanQ=1.665567, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281723 episodes
GETTING ACTION FROM:
action 2, numVisits=283588, meanQ=5.889572, numObservations: 4
action 3, numVisits=18, meanQ=1.665567, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.605596 0.890241 0.365441 0.915021 0.665503 0.8007 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 31
Initial state: 0 0.606159 0.868437 0.776029 0.912944 0.510269 0.845135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219986 episodes
GETTING ACTION FROM:
action 3, numVisits=219976, meanQ=5.015752, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.606159 0.868437 0.776029 0.912944 0.510269 0.845135 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.578277 0.879622 0.527932 0.88055 0.537386 0.92737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221086 episodes
GETTING ACTION FROM:
action 3, numVisits=221025, meanQ=4.937194, numObservations: 4
action -1, numVisits=57, meanQ=4.016525, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.578277 0.879622 0.527932 0.88055 0.537386 0.92737 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.712322 0.438971 0.544639 0.812025 0.623616 0.858165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214308 episodes
GETTING ACTION FROM:
action 3, numVisits=214260, meanQ=4.856909, numObservations: 4
action 0, numVisits=30, meanQ=3.571802, numObservations: 1
action 1, numVisits=15, meanQ=2.465340, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.712322 0.438971 0.544639 0.812025 0.623616 0.858165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 34
Initial state: 0 0.627503 0.844746 0.692128 0.886345 0.585405 0.780634 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151385 episodes
GETTING ACTION FROM:
action 0, numVisits=151283, meanQ=2.949383, numObservations: 1
action -1, numVisits=76, meanQ=2.170086, numObservations: 1
action 2, numVisits=20, meanQ=0.798510, numObservations: 4
action 1, numVisits=4, meanQ=-2.005000, numObservations: 3
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 0
Next state: 0 0.627503 0.844746 0.692128 0.886345 0.585405 0.780634 w: 1
Observation: 0 0 0.911385 0 0.861717 0 0.799116 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=151206, meanQ=4.993986, numObservations: 5
action -1, numVisits=72, meanQ=4.179611, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 241518 episodes
GETTING ACTION FROM:
action 3, numVisits=392724, meanQ=5.113096, numObservations: 5
action -1, numVisits=72, meanQ=4.179611, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.627503 0.844746 0.692128 0.886345 0.585405 0.780634 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 35
Initial state: 0 0.785621 0.0740647 0.645415 0.825968 0.515499 0.84901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224656 episodes
GETTING ACTION FROM:
action 1, numVisits=221672, meanQ=4.997231, numObservations: 3
action 2, numVisits=2928, meanQ=4.864955, numObservations: 4
action 0, numVisits=28, meanQ=3.661754, numObservations: 1
action -1, numVisits=22, meanQ=3.443791, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action: 1
Next state: 2 0.785621 0.0740647 0.645415 0.825968 0.515499 0.84901 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 36
Initial state: 0 0.661317 0.817471 0.520397 0.144425 0.530959 0.85542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219751 episodes
GETTING ACTION FROM:
action 2, numVisits=219678, meanQ=4.940170, numObservations: 4
action 0, numVisits=52, meanQ=3.881598, numObservations: 1
action -1, numVisits=12, meanQ=2.805666, numObservations: 1
action 3, numVisits=8, meanQ=1.987500, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.661317 0.817471 0.520397 0.144425 0.530959 0.85542 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 37
Initial state: 0 0.516826 0.894005 0.623889 0.81004 0.618292 0.408353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 201733 episodes
GETTING ACTION FROM:
action 3, numVisits=201695, meanQ=4.922323, numObservations: 4
action 0, numVisits=31, meanQ=3.611374, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.516826 0.894005 0.623889 0.81004 0.618292 0.408353 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=33061, meanQ=8.321930, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283432 episodes
GETTING ACTION FROM:
action 1, numVisits=316493, meanQ=6.365347, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.516826 0.894005 0.623889 0.81004 0.618292 0.408353 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 38
Initial state: 0 0.0220609 0.952852 0.51903 0.827491 0.599043 0.887236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223109 episodes
GETTING ACTION FROM:
action 2, numVisits=222986, meanQ=4.957118, numObservations: 3
action -1, numVisits=78, meanQ=4.173513, numObservations: 1
action 0, numVisits=23, meanQ=3.488515, numObservations: 1
action 3, numVisits=20, meanQ=2.885005, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.0220609 0.952852 0.51903 0.827491 0.599043 0.887236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.420164 0.634718 0.649138 0.885556 0.623229 0.867665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220827 episodes
GETTING ACTION FROM:
action 1, numVisits=220759, meanQ=5.016589, numObservations: 4
action 0, numVisits=54, meanQ=4.041038, numObservations: 1
action 3, numVisits=11, meanQ=2.808182, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.420164 0.634718 0.649138 0.885556 0.623229 0.867665 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 40
Initial state: 0 0.947779 0.460443 0.626052 0.815185 0.661291 0.854311 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217521 episodes
GETTING ACTION FROM:
action 2, numVisits=217515, meanQ=4.929443, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.947779 0.460443 0.626052 0.815185 0.661291 0.854311 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.794181 0.148689 0.589528 0.85799 0.649986 0.833371 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221656 episodes
GETTING ACTION FROM:
action 2, numVisits=221592, meanQ=4.938612, numObservations: 4
action -1, numVisits=33, meanQ=3.714785, numObservations: 1
action 1, numVisits=28, meanQ=2.632864, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.794181 0.148689 0.589528 0.85799 0.649986 0.833371 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 42
Initial state: 0 0.81661 0.345167 0.60373 0.893936 0.610442 0.877203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228365 episodes
GETTING ACTION FROM:
action 2, numVisits=228352, meanQ=4.928936, numObservations: 3
action 3, numVisits=8, meanQ=2.235013, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.81661 0.345167 0.60373 0.893936 0.610442 0.877203 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.747404 0.522028 0.571673 0.895821 0.679118 0.889823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223884 episodes
GETTING ACTION FROM:
action 3, numVisits=223806, meanQ=5.021747, numObservations: 5
action 0, numVisits=73, meanQ=4.195843, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.747404 0.522028 0.571673 0.895821 0.679118 0.889823 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.0872817 0.670738 0.535357 0.816363 0.673364 0.873007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218346 episodes
GETTING ACTION FROM:
action 1, numVisits=218149, meanQ=4.876914, numObservations: 5
action -1, numVisits=165, meanQ=4.337818, numObservations: 1
action 3, numVisits=27, meanQ=3.362963, numObservations: 3
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0872817 0.670738 0.535357 0.816363 0.673364 0.873007 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30217, meanQ=8.410771, numObservations: 4
action 3, numVisits=15, meanQ=6.465340, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289494 episodes
GETTING ACTION FROM:
action 2, numVisits=318840, meanQ=6.020689, numObservations: 4
action 3, numVisits=884, meanQ=5.778625, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0872817 0.670738 0.535357 0.816363 0.673364 0.873007 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 45
Initial state: 0 0.570127 0.85282 0.00267706 0.128177 0.56209 0.843853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223985 episodes
GETTING ACTION FROM:
action 2, numVisits=223922, meanQ=4.951309, numObservations: 5
action 0, numVisits=57, meanQ=4.012767, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.570127 0.85282 0.00267706 0.128177 0.56209 0.843853 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5502, meanQ=7.802178, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284621 episodes
GETTING ACTION FROM:
action 3, numVisits=290085, meanQ=6.057536, numObservations: 5
action 2, numVisits=38, meanQ=4.882105, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.570127 0.85282 0.00267706 0.128177 0.56209 0.843853 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 46
Initial state: 0 0.90636 0.0334417 0.631919 0.847695 0.598456 0.87659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227971 episodes
GETTING ACTION FROM:
action 1, numVisits=227964, meanQ=5.151010, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.90636 0.0334417 0.631919 0.847695 0.598456 0.87659 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 47
Initial state: 0 0.586279 0.839777 0.601526 0.853728 0.069821 0.676185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224495 episodes
GETTING ACTION FROM:
action 1, numVisits=224489, meanQ=4.974897, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.586279 0.839777 0.601526 0.853728 0.069821 0.676185 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.600433 0.892149 0.115401 0.48537 0.634759 0.866853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224215 episodes
GETTING ACTION FROM:
action 2, numVisits=224144, meanQ=5.123490, numObservations: 5
action -1, numVisits=41, meanQ=4.032319, numObservations: 1
action 3, numVisits=27, meanQ=3.369274, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.600433 0.892149 0.115401 0.48537 0.634759 0.866853 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25579, meanQ=8.516836, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287851 episodes
GETTING ACTION FROM:
action 1, numVisits=313430, meanQ=6.101722, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600433 0.892149 0.115401 0.48537 0.634759 0.866853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 49
Initial state: 0 0.58042 0.899991 0.57666 0.899301 0.855819 0.316818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154762 episodes
GETTING ACTION FROM:
action -1, numVisits=144452, meanQ=2.971261, numObservations: 1
action 0, numVisits=10302, meanQ=2.921323, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action: -1
Next state: 0 0.58042 0.899991 0.57666 0.899301 0.855819 0.316818 w: 1
Observation: 0 0.555285 0 0.499367 0 0.887982 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=144431, meanQ=5.015207, numObservations: 4
action 1, numVisits=10, meanQ=2.189000, numObservations: 3
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 246630 episodes
GETTING ACTION FROM:
action 3, numVisits=391061, meanQ=5.121303, numObservations: 4
action 1, numVisits=10, meanQ=2.189000, numObservations: 3
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.58042 0.899991 0.57666 0.899301 0.855819 0.316818 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 50
Initial state: 0 0.817281 0.252433 0.641818 0.838081 0.658103 0.841936 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227412 episodes
GETTING ACTION FROM:
action 2, numVisits=227315, meanQ=5.017246, numObservations: 4
action -1, numVisits=88, meanQ=4.279044, numObservations: 1
action 1, numVisits=5, meanQ=-0.597980, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.817281 0.252433 0.641818 0.838081 0.658103 0.841936 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 51
Initial state: 0 0.656838 0.208456 0.551075 0.855995 0.556156 0.88039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224833 episodes
GETTING ACTION FROM:
action 3, numVisits=224811, meanQ=4.999305, numObservations: 5
action 1, numVisits=17, meanQ=2.647653, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.656838 0.208456 0.551075 0.855995 0.556156 0.88039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.676078 0.889758 0.552465 0.818368 0.715385 0.956841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227697 episodes
GETTING ACTION FROM:
action 2, numVisits=227564, meanQ=5.015969, numObservations: 3
action 0, numVisits=119, meanQ=4.330216, numObservations: 1
action 1, numVisits=8, meanQ=2.498750, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.676078 0.889758 0.552465 0.818368 0.715385 0.956841 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 53
Initial state: 0 0.147535 0.815887 0.691558 0.808828 0.639714 0.869889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226884 episodes
GETTING ACTION FROM:
action 2, numVisits=226827, meanQ=5.211784, numObservations: 5
action 3, numVisits=52, meanQ=3.301927, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.147535 0.815887 0.691558 0.808828 0.639714 0.869889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.513684 0.835521 0.0363608 0.67392 0.549386 0.842756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220830 episodes
GETTING ACTION FROM:
action 2, numVisits=220748, meanQ=4.841930, numObservations: 4
action -1, numVisits=50, meanQ=3.847067, numObservations: 1
action 1, numVisits=15, meanQ=2.598000, numObservations: 3
action 3, numVisits=15, meanQ=2.585333, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.513684 0.835521 0.0363608 0.67392 0.549386 0.842756 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30443, meanQ=8.351653, numObservations: 3
action 3, numVisits=32, meanQ=7.184694, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292618 episodes
GETTING ACTION FROM:
action 1, numVisits=323032, meanQ=6.264483, numObservations: 3
action 3, numVisits=61, meanQ=5.096889, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.513684 0.835521 0.0363608 0.67392 0.549386 0.842756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=8304, meanQ=7.199277, numObservations: 4
action 1, numVisits=5, meanQ=3.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 295748 episodes
GETTING ACTION FROM:
action 3, numVisits=304049, meanQ=6.119572, numObservations: 4
action 1, numVisits=8, meanQ=3.001263, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.513684 0.835521 0.0363608 0.67392 0.549386 0.842756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 55
Initial state: 0 0.662312 0.862224 0.276646 0.0878901 0.635552 0.837157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225114 episodes
GETTING ACTION FROM:
action 1, numVisits=225084, meanQ=4.957722, numObservations: 4
action 3, numVisits=25, meanQ=3.479204, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.662312 0.862224 0.276646 0.0878901 0.635552 0.837157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.0927967 0.574283 0.528959 0.885894 0.582133 0.853932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228060 episodes
GETTING ACTION FROM:
action 3, numVisits=228053, meanQ=5.018003, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0927967 0.574283 0.528959 0.885894 0.582133 0.853932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 57
Initial state: 0 0.596281 0.817992 0.252291 0.523438 0.58009 0.894754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227419 episodes
GETTING ACTION FROM:
action 2, numVisits=227386, meanQ=4.943300, numObservations: 3
action 1, numVisits=13, meanQ=2.836923, numObservations: 4
action 3, numVisits=16, meanQ=2.738125, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.596281 0.817992 0.252291 0.523438 0.58009 0.894754 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37379, meanQ=8.354787, numObservations: 3
action 1, numVisits=9, meanQ=6.110011, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 293244 episodes
GETTING ACTION FROM:
action 3, numVisits=330582, meanQ=6.088280, numObservations: 3
action 1, numVisits=48, meanQ=4.999587, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.596281 0.817992 0.252291 0.523438 0.58009 0.894754 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 58
Initial state: 0 0.650947 0.859873 0.568608 0.849168 0.391047 0.320535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229051 episodes
GETTING ACTION FROM:
action 1, numVisits=229042, meanQ=4.984159, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.650947 0.859873 0.568608 0.849168 0.391047 0.320535 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.527681 0.885272 0.481398 0.485888 0.591746 0.885838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220658 episodes
GETTING ACTION FROM:
action 3, numVisits=209652, meanQ=4.991783, numObservations: 4
action -1, numVisits=10328, meanQ=3.031196, numObservations: 1
action 0, numVisits=667, meanQ=2.854653, numObservations: 1
action 2, numVisits=8, meanQ=0.748763, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 3
Next state: 1 0.527681 0.885272 0.481398 0.485888 0.591746 0.885838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.62541 0.24012 0.631414 0.831862 0.640367 0.897515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225058 episodes
GETTING ACTION FROM:
action 2, numVisits=225049, meanQ=5.049673, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.62541 0.24012 0.631414 0.831862 0.640367 0.897515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.848091 0.0618229 0.520077 0.837872 0.535466 0.81617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217491 episodes
GETTING ACTION FROM:
action 2, numVisits=217485, meanQ=4.838678, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.848091 0.0618229 0.520077 0.837872 0.535466 0.81617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=16199, meanQ=3.431852, numObservations: 1
action 3, numVisits=9, meanQ=0.998889, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289482 episodes
GETTING ACTION FROM:
action 1, numVisits=288443, meanQ=6.161380, numObservations: 4
action -1, numVisits=17239, meanQ=3.189025, numObservations: 1
action 3, numVisits=9, meanQ=0.998889, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.848091 0.0618229 0.520077 0.837872 0.535466 0.81617 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 62
Initial state: 0 0.716685 0.94876 0.697561 0.841869 0.61841 0.819126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225161 episodes
GETTING ACTION FROM:
action 2, numVisits=224989, meanQ=4.982988, numObservations: 5
action 3, numVisits=102, meanQ=4.253225, numObservations: 3
action -1, numVisits=48, meanQ=3.963972, numObservations: 1
action 0, numVisits=18, meanQ=3.337649, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.716685 0.94876 0.697561 0.841869 0.61841 0.819126 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.301375 0.756406 0.670408 0.805015 0.53809 0.885437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226725 episodes
GETTING ACTION FROM:
action 3, numVisits=226715, meanQ=4.950076, numObservations: 4
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 3
Next state: 1 0.301375 0.756406 0.670408 0.805015 0.53809 0.885437 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.643015 0.831653 0.603823 0.284346 0.60372 0.893485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223829 episodes
GETTING ACTION FROM:
action 2, numVisits=223752, meanQ=4.922948, numObservations: 5
action 0, numVisits=64, meanQ=4.050352, numObservations: 1
action 1, numVisits=9, meanQ=1.886667, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.643015 0.831653 0.603823 0.284346 0.60372 0.893485 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31236, meanQ=8.424924, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288233 episodes
GETTING ACTION FROM:
action 3, numVisits=319469, meanQ=6.255656, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.643015 0.831653 0.603823 0.284346 0.60372 0.893485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 65
Initial state: 0 0.609267 0.870561 0.543298 0.883298 0.489867 0.0585839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224113 episodes
GETTING ACTION FROM:
action 2, numVisits=224072, meanQ=5.025723, numObservations: 5
action 1, numVisits=25, meanQ=3.308004, numObservations: 4
action 3, numVisits=12, meanQ=2.823342, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.609267 0.870561 0.543298 0.883298 0.489867 0.0585839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16846, meanQ=5.581462, numObservations: 4
action 1, numVisits=9, meanQ=3.221111, numObservations: 3
action 3, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 283416 episodes
GETTING ACTION FROM:
action 3, numVisits=274473, meanQ=5.710458, numObservations: 5
action 2, numVisits=25792, meanQ=5.408569, numObservations: 4
action 1, numVisits=9, meanQ=3.221111, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 0 0.609267 0.870561 0.543298 0.883298 0.489867 0.0585839 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=3981, meanQ=8.333483, numObservations: 4
action 2, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 296077 episodes
GETTING ACTION FROM:
action 1, numVisits=299075, meanQ=6.178908, numObservations: 4
action 2, numVisits=986, meanQ=5.957779, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.609267 0.870561 0.543298 0.883298 0.489867 0.0585839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 66
Initial state: 0 0.929802 0.730519 0.518817 0.895137 0.526331 0.89665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229339 episodes
GETTING ACTION FROM:
action 2, numVisits=229261, meanQ=5.013286, numObservations: 3
action 0, numVisits=59, meanQ=4.097461, numObservations: 1
action 1, numVisits=16, meanQ=2.750006, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.929802 0.730519 0.518817 0.895137 0.526331 0.89665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.83385 0.671634 0.699907 0.892795 0.629167 0.824166 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228171 episodes
GETTING ACTION FROM:
action 2, numVisits=228153, meanQ=5.000346, numObservations: 3
action 1, numVisits=10, meanQ=2.399010, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.83385 0.671634 0.699907 0.892795 0.629167 0.824166 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.634411 0.8561 0.54323 0.843829 0.147654 0.0264944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224553 episodes
GETTING ACTION FROM:
action 1, numVisits=224547, meanQ=5.180301, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.634411 0.8561 0.54323 0.843829 0.147654 0.0264944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.584157 0.824349 0.691194 0.812187 0.109715 0.0533198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224352 episodes
GETTING ACTION FROM:
action 2, numVisits=224307, meanQ=4.964481, numObservations: 5
action 0, numVisits=38, meanQ=3.832111, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.584157 0.824349 0.691194 0.812187 0.109715 0.0533198 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.599396 0.0850125 0.532386 0.823622 0.605223 0.817541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 209912 episodes
GETTING ACTION FROM:
action 2, numVisits=209678, meanQ=4.720883, numObservations: 5
action 3, numVisits=196, meanQ=4.225680, numObservations: 4
action 0, numVisits=35, meanQ=3.547734, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.599396 0.0850125 0.532386 0.823622 0.605223 0.817541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=15841, meanQ=1.555107, numObservations: 1
action 1, numVisits=15, meanQ=-0.465980, numObservations: 3
action 3, numVisits=8, meanQ=-0.999987, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 282072 episodes
GETTING ACTION FROM:
action 3, numVisits=279436, meanQ=5.550728, numObservations: 5
action 0, numVisits=18484, meanQ=1.170432, numObservations: 1
action 1, numVisits=15, meanQ=-0.465980, numObservations: 3
action -1, numVisits=4, meanQ=-2.252450, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.599396 0.0850125 0.532386 0.823622 0.605223 0.817541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 71
Initial state: 0 0.577159 0.813001 0.129172 0.1641 0.544632 0.887198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226410 episodes
GETTING ACTION FROM:
action 1, numVisits=226364, meanQ=5.000452, numObservations: 4
action 0, numVisits=42, meanQ=3.890594, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.577159 0.813001 0.129172 0.1641 0.544632 0.887198 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 72
Initial state: 0 0.57753 0.805607 0.556551 0.851631 0.701823 0.13691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155400 episodes
GETTING ACTION FROM:
action -1, numVisits=155387, meanQ=2.848596, numObservations: 1
action 1, numVisits=7, meanQ=-0.429986, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.57753 0.805607 0.556551 0.851631 0.701823 0.13691 w: 1
Observation: 0 0.509543 0 0.484305 0 0.800181 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=155359, meanQ=4.917989, numObservations: 4
action 3, numVisits=13, meanQ=2.836923, numObservations: 3
action 1, numVisits=10, meanQ=2.598000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 245730 episodes
GETTING ACTION FROM:
action 2, numVisits=401088, meanQ=4.835360, numObservations: 4
action 3, numVisits=13, meanQ=2.836923, numObservations: 3
action 1, numVisits=11, meanQ=1.907282, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.57753 0.805607 0.556551 0.851631 0.701823 0.13691 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 73
Initial state: 0 0.515685 0.88035 0.779108 0.0296429 0.521818 0.863127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154927 episodes
GETTING ACTION FROM:
action 0, numVisits=154917, meanQ=2.928186, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 0
Next state: 0 0.515685 0.88035 0.779108 0.0296429 0.521818 0.863127 w: 1
Observation: 0 0 0.789458 0 0.0507831 0 0.834463 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=154736, meanQ=4.951806, numObservations: 5
action 3, numVisits=97, meanQ=4.242577, numObservations: 3
action -1, numVisits=80, meanQ=4.185329, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 244140 episodes
GETTING ACTION FROM:
action 1, numVisits=398871, meanQ=4.941788, numObservations: 5
action -1, numVisits=83, meanQ=4.158535, numObservations: 1
action 3, numVisits=99, meanQ=4.136667, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.515685 0.88035 0.779108 0.0296429 0.521818 0.863127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 74
Initial state: 0 0.539111 0.805705 0.538469 0.864551 0.157358 0.489234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226496 episodes
GETTING ACTION FROM:
action 2, numVisits=226482, meanQ=5.014960, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.539111 0.805705 0.538469 0.864551 0.157358 0.489234 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.680307 0.828393 0.816343 0.76981 0.635098 0.845855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218832 episodes
GETTING ACTION FROM:
action 3, numVisits=218826, meanQ=4.831606, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.680307 0.828393 0.816343 0.76981 0.635098 0.845855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.332724 0.499028 0.501398 0.886935 0.617791 0.856493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219763 episodes
GETTING ACTION FROM:
action 3, numVisits=219640, meanQ=5.031737, numObservations: 4
action 2, numVisits=57, meanQ=4.078428, numObservations: 3
action 1, numVisits=62, meanQ=4.011776, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.332724 0.499028 0.501398 0.886935 0.617791 0.856493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 77
Initial state: 0 0.684254 0.812423 0.625443 0.841739 0.772316 0.00292892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225403 episodes
GETTING ACTION FROM:
action 2, numVisits=225270, meanQ=4.982988, numObservations: 4
action 0, numVisits=90, meanQ=4.250846, numObservations: 1
action -1, numVisits=36, meanQ=3.823052, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.684254 0.812423 0.625443 0.841739 0.772316 0.00292892 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.907767 0.359731 0.65735 0.80759 0.574745 0.861392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225612 episodes
GETTING ACTION FROM:
action 3, numVisits=225605, meanQ=4.944099, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.907767 0.359731 0.65735 0.80759 0.574745 0.861392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.672475 0.898462 0.593743 0.823671 0.399413 0.560047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222573 episodes
GETTING ACTION FROM:
action 2, numVisits=222561, meanQ=5.022037, numObservations: 5
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.672475 0.898462 0.593743 0.823671 0.399413 0.560047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.515225 0.596128 0.650876 0.8078 0.584847 0.857179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227246 episodes
GETTING ACTION FROM:
action 1, numVisits=227232, meanQ=4.957852, numObservations: 3
action 3, numVisits=9, meanQ=2.333344, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.515225 0.596128 0.650876 0.8078 0.584847 0.857179 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 81
Initial state: 0 0.533156 0.845172 0.557315 0.424278 0.676496 0.889911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228417 episodes
GETTING ACTION FROM:
action 2, numVisits=228359, meanQ=5.170443, numObservations: 4
action -1, numVisits=33, meanQ=3.935026, numObservations: 1
action 1, numVisits=22, meanQ=3.251377, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.533156 0.845172 0.557315 0.424278 0.676496 0.889911 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 82
Initial state: 0 0.551829 0.859023 0.633452 0.866461 0.811655 0.720899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230268 episodes
GETTING ACTION FROM:
action 2, numVisits=230073, meanQ=4.929120, numObservations: 3
action -1, numVisits=101, meanQ=4.234760, numObservations: 1
action 0, numVisits=64, meanQ=4.054398, numObservations: 1
action 1, numVisits=29, meanQ=3.343800, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.551829 0.859023 0.633452 0.866461 0.811655 0.720899 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.584932 0.853295 0.520542 0.855298 0.785557 0.409293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225108 episodes
GETTING ACTION FROM:
action 1, numVisits=225060, meanQ=5.031387, numObservations: 5
action -1, numVisits=28, meanQ=3.701229, numObservations: 1
action 0, numVisits=11, meanQ=2.890000, numObservations: 1
action 2, numVisits=8, meanQ=0.997500, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.584932 0.853295 0.520542 0.855298 0.785557 0.409293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.744583 0.448021 0.670071 0.803272 0.57397 0.809754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225595 episodes
GETTING ACTION FROM:
action 2, numVisits=225534, meanQ=4.921533, numObservations: 4
action 0, numVisits=52, meanQ=3.915512, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.744583 0.448021 0.670071 0.803272 0.57397 0.809754 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.772029 0.336812 0.56517 0.882914 0.510826 0.844822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156606 episodes
GETTING ACTION FROM:
action 0, numVisits=155640, meanQ=2.971802, numObservations: 1
action -1, numVisits=959, meanQ=2.765883, numObservations: 1
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.772029 0.336812 0.56517 0.882914 0.510826 0.844822 w: 1
Observation: 0 0 0.249221 0 0.965514 0 0.827608 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=155604, meanQ=4.988471, numObservations: 4
action 2, numVisits=30, meanQ=3.061347, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 252070 episodes
GETTING ACTION FROM:
action 1, numVisits=407674, meanQ=5.048731, numObservations: 4
action 2, numVisits=30, meanQ=3.061347, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.772029 0.336812 0.56517 0.882914 0.510826 0.844822 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 86
Initial state: 0 0.619454 0.840173 0.503358 0.833986 0.782339 0.686291 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223467 episodes
GETTING ACTION FROM:
action 3, numVisits=223369, meanQ=4.968805, numObservations: 5
action 0, numVisits=87, meanQ=4.210601, numObservations: 1
action 1, numVisits=8, meanQ=0.997500, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.619454 0.840173 0.503358 0.833986 0.782339 0.686291 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 87
Initial state: 0 0.547371 0.863396 0.173204 0.587997 0.527188 0.814632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229229 episodes
GETTING ACTION FROM:
action 3, numVisits=229075, meanQ=4.946818, numObservations: 3
action -1, numVisits=150, meanQ=4.379348, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.547371 0.863396 0.173204 0.587997 0.527188 0.814632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.680497 0.816047 0.590916 0.801994 0.657974 0.725736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226446 episodes
GETTING ACTION FROM:
action 1, numVisits=225112, meanQ=4.960332, numObservations: 4
action 2, numVisits=1283, meanQ=4.752391, numObservations: 5
action 0, numVisits=48, meanQ=3.955714, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.680497 0.816047 0.590916 0.801994 0.657974 0.725736 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.0531618 0.286282 0.587843 0.867844 0.669369 0.889619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219434 episodes
GETTING ACTION FROM:
action 2, numVisits=219214, meanQ=5.006623, numObservations: 4
action 0, numVisits=198, meanQ=4.498028, numObservations: 1
action -1, numVisits=18, meanQ=3.300492, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 1 0.0531618 0.286282 0.587843 0.867844 0.669369 0.889619 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.517792 0.801368 0.659446 0.85223 0.0336875 0.632399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 190305 episodes
GETTING ACTION FROM:
action 1, numVisits=111154, meanQ=4.991855, numObservations: 5
action -1, numVisits=44928, meanQ=3.001719, numObservations: 1
action 0, numVisits=34220, meanQ=2.927735, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.517792 0.801368 0.659446 0.85223 0.0336875 0.632399 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=884, meanQ=4.857433, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289429 episodes
GETTING ACTION FROM:
action 3, numVisits=290310, meanQ=5.639785, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.517792 0.801368 0.659446 0.85223 0.0336875 0.632399 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3143, meanQ=8.537339, numObservations: 3
action 1, numVisits=3, meanQ=4.996667, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 298964 episodes
GETTING ACTION FROM:
action 2, numVisits=302106, meanQ=6.250274, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.517792 0.801368 0.659446 0.85223 0.0336875 0.632399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 91
Initial state: 0 0.210269 0.771002 0.655427 0.879103 0.61193 0.883042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226699 episodes
GETTING ACTION FROM:
action 2, numVisits=145777, meanQ=5.006475, numObservations: 4
action 3, numVisits=80871, meanQ=4.982778, numObservations: 4
action -1, numVisits=48, meanQ=4.002622, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.210269 0.771002 0.655427 0.879103 0.61193 0.883042 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.054122 0.782017 0.677506 0.82694 0.696881 0.897083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226302 episodes
GETTING ACTION FROM:
action 1, numVisits=226138, meanQ=4.976564, numObservations: 4
action 0, numVisits=103, meanQ=4.278192, numObservations: 1
action 3, numVisits=58, meanQ=3.982762, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.054122 0.782017 0.677506 0.82694 0.696881 0.897083 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37027, meanQ=8.315289, numObservations: 3
action 2, numVisits=6, meanQ=4.665017, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290021 episodes
GETTING ACTION FROM:
action 3, numVisits=326995, meanQ=6.224946, numObservations: 3
action 2, numVisits=59, meanQ=5.100002, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.054122 0.782017 0.677506 0.82694 0.696881 0.897083 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 93
Initial state: 0 0.536835 0.838571 0.417855 0.240616 0.6513 0.826531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156333 episodes
GETTING ACTION FROM:
action -1, numVisits=156317, meanQ=2.952042, numObservations: 1
action 2, numVisits=10, meanQ=0.598000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.536835 0.838571 0.417855 0.240616 0.6513 0.826531 w: 1
Observation: 0 0.451196 0 0.323579 0 0.610179 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=156305, meanQ=4.975597, numObservations: 3
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 248945 episodes
GETTING ACTION FROM:
action 2, numVisits=405250, meanQ=5.023811, numObservations: 3
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.536835 0.838571 0.417855 0.240616 0.6513 0.826531 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=67123, meanQ=8.329316, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 287440 episodes
GETTING ACTION FROM:
action 1, numVisits=354563, meanQ=6.452598, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.536835 0.838571 0.417855 0.240616 0.6513 0.826531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 94
Initial state: 0 0.618153 0.893806 0.589531 0.809007 0.0299079 0.11687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223934 episodes
GETTING ACTION FROM:
action 1, numVisits=220654, meanQ=4.959224, numObservations: 5
action -1, numVisits=3238, meanQ=2.762474, numObservations: 1
action 2, numVisits=37, meanQ=1.810546, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 1
Next state: 1 0.618153 0.893806 0.589531 0.809007 0.0299079 0.11687 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.641732 0.805622 0.233767 0.0896528 0.528849 0.843294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219044 episodes
GETTING ACTION FROM:
action 3, numVisits=219020, meanQ=5.013689, numObservations: 4
action 0, numVisits=19, meanQ=3.248713, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.641732 0.805622 0.233767 0.0896528 0.528849 0.843294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.592863 0.805324 0.653484 0.854585 0.81175 0.562784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225151 episodes
GETTING ACTION FROM:
action 1, numVisits=225144, meanQ=5.142055, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.592863 0.805324 0.653484 0.854585 0.81175 0.562784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.612585 0.813159 0.590781 0.848185 0.273734 0.0610564 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156820 episodes
GETTING ACTION FROM:
action -1, numVisits=145937, meanQ=2.980440, numObservations: 1
action 0, numVisits=10878, meanQ=2.878912, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.612585 0.813159 0.590781 0.848185 0.273734 0.0610564 w: 1
Observation: 0 0.587791 0 0.591745 0 0.356304 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=145928, meanQ=5.032172, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 248808 episodes
GETTING ACTION FROM:
action 1, numVisits=394736, meanQ=4.948495, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.612585 0.813159 0.590781 0.848185 0.273734 0.0610564 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=30595, meanQ=5.400241, numObservations: 3
action 2, numVisits=14, meanQ=1.150014, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 266406 episodes
GETTING ACTION FROM:
action 1, numVisits=297001, meanQ=5.354207, numObservations: 3
action 2, numVisits=14, meanQ=1.150014, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.612585 0.813159 0.590781 0.848185 0.273734 0.0610564 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 98
Initial state: 0 0.64024 0.804339 0.632687 0.83673 0.785334 0.842921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164635 episodes
GETTING ACTION FROM:
action 0, numVisits=153668, meanQ=5.876187, numObservations: 3
action 3, numVisits=10926, meanQ=5.029610, numObservations: 3
action -1, numVisits=30, meanQ=3.901343, numObservations: 1
action 1, numVisits=10, meanQ=3.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.64024 0.804339 0.632687 0.83673 0.785334 0.842921 w: 1
Observation: 0 0 0.749982 0 0.851231 0 0.790358 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=56212, meanQ=7.888843, numObservations: 4
action 1, numVisits=12, meanQ=2.498342, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 249339 episodes
GETTING ACTION FROM:
action 2, numVisits=305510, meanQ=5.479180, numObservations: 4
action -1, numVisits=41, meanQ=4.348842, numObservations: 1
action 1, numVisits=12, meanQ=2.498342, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.64024 0.804339 0.632687 0.83673 0.785334 0.842921 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 99
Initial state: 0 0.561965 0.846117 0.565048 0.867545 0.839518 0.143109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228206 episodes
GETTING ACTION FROM:
action 3, numVisits=228145, meanQ=4.931998, numObservations: 3
action 1, numVisits=33, meanQ=3.484861, numObservations: 3
action 0, numVisits=19, meanQ=3.262549, numObservations: 1
action 2, numVisits=7, meanQ=0.428571, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.561965 0.846117 0.565048 0.867545 0.839518 0.143109 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 100
Initial state: 0 0.277241 0.185085 0.689224 0.843264 0.601839 0.854241 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225299 episodes
GETTING ACTION FROM:
action 3, numVisits=225236, meanQ=5.012635, numObservations: 5
action -1, numVisits=40, meanQ=3.846248, numObservations: 1
action 1, numVisits=20, meanQ=3.390000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.277241 0.185085 0.689224 0.843264 0.601839 0.854241 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16878, meanQ=5.524444, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 266655 episodes
GETTING ACTION FROM:
action 3, numVisits=283531, meanQ=5.103203, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.277241 0.185085 0.689224 0.843264 0.601839 0.854241 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 101
Initial state: 0 0.525056 0.822649 0.759327 0.506208 0.604053 0.820551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228144 episodes
GETTING ACTION FROM:
action 2, numVisits=227943, meanQ=5.003006, numObservations: 4
action -1, numVisits=191, meanQ=4.499382, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.525056 0.822649 0.759327 0.506208 0.604053 0.820551 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 102
Initial state: 0 0.624823 0.886441 0.995979 0.590196 0.537388 0.886573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226333 episodes
GETTING ACTION FROM:
action 2, numVisits=226326, meanQ=5.021884, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.624823 0.886441 0.995979 0.590196 0.537388 0.886573 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 103
Initial state: 0 0.695545 0.830714 0.677834 0.880546 0.195636 0.665569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224321 episodes
GETTING ACTION FROM:
action 3, numVisits=224238, meanQ=4.992782, numObservations: 5
action -1, numVisits=79, meanQ=4.203061, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.695545 0.830714 0.677834 0.880546 0.195636 0.665569 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11296, meanQ=7.890967, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289284 episodes
GETTING ACTION FROM:
action 2, numVisits=300578, meanQ=6.027643, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.695545 0.830714 0.677834 0.880546 0.195636 0.665569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 104
Initial state: 0 0.508813 0.867305 0.314453 0.825501 0.517182 0.877656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225192 episodes
GETTING ACTION FROM:
action 3, numVisits=224571, meanQ=4.982626, numObservations: 4
action 2, numVisits=552, meanQ=4.659872, numObservations: 4
action 0, numVisits=46, meanQ=3.950963, numObservations: 1
action 1, numVisits=21, meanQ=3.090957, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.508813 0.867305 0.314453 0.825501 0.517182 0.877656 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.116835 0.488641 0.571518 0.86525 0.584475 0.80592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225975 episodes
GETTING ACTION FROM:
action 3, numVisits=225958, meanQ=4.931690, numObservations: 4
action 1, numVisits=11, meanQ=2.081818, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.116835 0.488641 0.571518 0.86525 0.584475 0.80592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.999003 0.230624 0.619632 0.820368 0.672498 0.886002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 231026 episodes
GETTING ACTION FROM:
action 1, numVisits=231020, meanQ=5.005993, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.999003 0.230624 0.619632 0.820368 0.672498 0.886002 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 107
Initial state: 0 0.531772 0.824693 0.563284 0.897359 0.899843 0.161732 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225131 episodes
GETTING ACTION FROM:
action 2, numVisits=225118, meanQ=5.032411, numObservations: 4
action 1, numVisits=7, meanQ=2.144300, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.531772 0.824693 0.563284 0.897359 0.899843 0.161732 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.606863 0.849254 0.50971 0.873603 0.410854 0.0134046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215005 episodes
GETTING ACTION FROM:
action 1, numVisits=214999, meanQ=4.868220, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.606863 0.849254 0.50971 0.873603 0.410854 0.0134046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.994963 0.296187 0.62933 0.846773 0.639481 0.893627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224265 episodes
GETTING ACTION FROM:
action 1, numVisits=224251, meanQ=4.970493, numObservations: 5
action 3, numVisits=9, meanQ=0.998889, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.994963 0.296187 0.62933 0.846773 0.639481 0.893627 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 110
Initial state: 0 0.592127 0.884059 0.64781 0.82371 0.122946 0.365517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221881 episodes
GETTING ACTION FROM:
action 3, numVisits=221805, meanQ=5.032187, numObservations: 5
action 2, numVisits=69, meanQ=3.974933, numObservations: 4
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.592127 0.884059 0.64781 0.82371 0.122946 0.365517 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30938, meanQ=8.409786, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288639 episodes
GETTING ACTION FROM:
action 2, numVisits=319576, meanQ=6.367997, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.592127 0.884059 0.64781 0.82371 0.122946 0.365517 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 111
Initial state: 0 0.0773595 0.994062 0.666208 0.803509 0.676948 0.874274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229825 episodes
GETTING ACTION FROM:
action 1, numVisits=229730, meanQ=4.964623, numObservations: 3
action 2, numVisits=76, meanQ=3.945819, numObservations: 4
action 3, numVisits=15, meanQ=3.126000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.0773595 0.994062 0.666208 0.803509 0.676948 0.874274 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.353676 0.32363 0.652876 0.814826 0.618666 0.842106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227023 episodes
GETTING ACTION FROM:
action 3, numVisits=227017, meanQ=5.012882, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.353676 0.32363 0.652876 0.814826 0.618666 0.842106 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.65971 0.802291 0.604234 0.891639 0.860548 0.149219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218638 episodes
GETTING ACTION FROM:
action 1, numVisits=218611, meanQ=4.861521, numObservations: 4
action 0, numVisits=20, meanQ=3.161883, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.65971 0.802291 0.604234 0.891639 0.860548 0.149219 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.503801 0.0775606 0.637085 0.880337 0.501007 0.850547 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227506 episodes
GETTING ACTION FROM:
action 1, numVisits=227378, meanQ=5.174885, numObservations: 4
action 3, numVisits=116, meanQ=4.437357, numObservations: 3
action 2, numVisits=8, meanQ=2.498750, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.503801 0.0775606 0.637085 0.880337 0.501007 0.850547 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=12965, meanQ=7.956178, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284110 episodes
GETTING ACTION FROM:
action 2, numVisits=297073, meanQ=5.926029, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.503801 0.0775606 0.637085 0.880337 0.501007 0.850547 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 115
Initial state: 0 0.688727 0.800137 0.176905 0.120681 0.675566 0.899832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219126 episodes
GETTING ACTION FROM:
action 1, numVisits=219091, meanQ=4.852205, numObservations: 4
action -1, numVisits=27, meanQ=3.444472, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.688727 0.800137 0.176905 0.120681 0.675566 0.899832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 116
Initial state: 0 0.750308 0.528382 0.529786 0.88392 0.699147 0.823523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216353 episodes
GETTING ACTION FROM:
action 3, numVisits=216304, meanQ=4.916642, numObservations: 4
action 1, numVisits=44, meanQ=3.584550, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.750308 0.528382 0.529786 0.88392 0.699147 0.823523 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.625173 0.839994 0.564022 0.815346 0.938386 0.137012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215616 episodes
GETTING ACTION FROM:
action 1, numVisits=215556, meanQ=4.851202, numObservations: 5
action 0, numVisits=47, meanQ=3.810191, numObservations: 1
action -1, numVisits=10, meanQ=2.485195, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.625173 0.839994 0.564022 0.815346 0.938386 0.137012 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 118
Initial state: 0 0.63008 0.864855 0.663148 0.877611 0.864275 0.517233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223625 episodes
GETTING ACTION FROM:
action 3, numVisits=223584, meanQ=4.952886, numObservations: 4
action 0, numVisits=23, meanQ=3.478290, numObservations: 1
action 2, numVisits=9, meanQ=2.320000, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.63008 0.864855 0.663148 0.877611 0.864275 0.517233 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 119
Initial state: 0 0.657053 0.831156 0.693942 0.801317 0.387206 0.960387 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223750 episodes
GETTING ACTION FROM:
action 3, numVisits=223729, meanQ=5.055877, numObservations: 4
action 2, numVisits=11, meanQ=2.088182, numObservations: 4
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.657053 0.831156 0.693942 0.801317 0.387206 0.960387 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4298, meanQ=7.029127, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289006 episodes
GETTING ACTION FROM:
action 1, numVisits=293302, meanQ=5.887438, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.657053 0.831156 0.693942 0.801317 0.387206 0.960387 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 120
Initial state: 0 0.597737 0.819205 0.585883 0.2989 0.686489 0.801342 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223572 episodes
GETTING ACTION FROM:
action 1, numVisits=223562, meanQ=5.000318, numObservations: 5
action 3, numVisits=5, meanQ=-0.622000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.597737 0.819205 0.585883 0.2989 0.686489 0.801342 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 121
Initial state: 0 0.125383 0.230496 0.693607 0.829449 0.64023 0.831591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221866 episodes
GETTING ACTION FROM:
action 3, numVisits=221790, meanQ=4.962560, numObservations: 5
action 0, numVisits=69, meanQ=4.008230, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.125383 0.230496 0.693607 0.829449 0.64023 0.831591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 122
Initial state: 0 0.667146 0.848471 0.400329 0.925317 0.557542 0.837348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 124812 episodes
GETTING ACTION FROM:
action -1, numVisits=124805, meanQ=3.834102, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.667146 0.848471 0.400329 0.925317 0.557542 0.837348 w: 1
Observation: 0 0.735427 0 0.47295 0 0.532737 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=114486, meanQ=5.975447, numObservations: 3
action 3, numVisits=10256, meanQ=5.009679, numObservations: 4
action 1, numVisits=59, meanQ=3.904410, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 172266 episodes
GETTING ACTION FROM:
action 0, numVisits=286752, meanQ=5.977480, numObservations: 3
action 3, numVisits=10256, meanQ=5.009679, numObservations: 4
action 1, numVisits=59, meanQ=3.904410, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.667146 0.848471 0.400329 0.925317 0.557542 0.837348 w: 1
Observation: 0 0 0.921403 0 0.845068 0 0.875338 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=41715, meanQ=8.219401, numObservations: 4
action 3, numVisits=48203, meanQ=8.217179, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 247080 episodes
GETTING ACTION FROM:
action 1, numVisits=188157, meanQ=6.038018, numObservations: 4
action 3, numVisits=148839, meanQ=6.036242, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.667146 0.848471 0.400329 0.925317 0.557542 0.837348 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 123
Initial state: 0 0.685913 0.831715 0.745006 0.114666 0.641149 0.857439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225265 episodes
GETTING ACTION FROM:
action 3, numVisits=218203, meanQ=4.987104, numObservations: 5
action 1, numVisits=7057, meanQ=4.868842, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.685913 0.831715 0.745006 0.114666 0.641149 0.857439 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.0441522 0.0870399 0.63729 0.829259 0.660095 0.81743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 208358 episodes
GETTING ACTION FROM:
action 3, numVisits=173947, meanQ=4.966407, numObservations: 5
action 0, numVisits=34285, meanQ=2.916516, numObservations: 1
action -1, numVisits=122, meanQ=2.364346, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0441522 0.0870399 0.63729 0.829259 0.660095 0.81743 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.644762 0.83825 0.0797891 0.0537184 0.585041 0.895657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226202 episodes
GETTING ACTION FROM:
action 3, numVisits=226195, meanQ=4.932490, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.644762 0.83825 0.0797891 0.0537184 0.585041 0.895657 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 126
Initial state: 0 0.574176 0.88731 0.714913 0.395767 0.690573 0.896841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228645 episodes
GETTING ACTION FROM:
action 1, numVisits=228468, meanQ=4.961862, numObservations: 3
action 0, numVisits=170, meanQ=4.434547, numObservations: 1
action 3, numVisits=4, meanQ=-0.007500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.574176 0.88731 0.714913 0.395767 0.690573 0.896841 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1913, meanQ=4.737688, numObservations: 4
action 3, numVisits=42, meanQ=3.752390, numObservations: 4
action 1, numVisits=9, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 290622 episodes
GETTING ACTION FROM:
action 2, numVisits=292533, meanQ=6.067551, numObservations: 4
action 3, numVisits=42, meanQ=3.752390, numObservations: 4
action 1, numVisits=9, meanQ=2.333333, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 2 0.574176 0.88731 0.714913 0.395767 0.690573 0.896841 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 127
Initial state: 0 0.677118 0.814805 0.702557 0.0568729 0.515372 0.870831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224788 episodes
GETTING ACTION FROM:
action 2, numVisits=224739, meanQ=4.908500, numObservations: 5
action -1, numVisits=35, meanQ=3.722782, numObservations: 1
action 3, numVisits=10, meanQ=2.598000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.677118 0.814805 0.702557 0.0568729 0.515372 0.870831 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 128
Initial state: 0 0.87487 0.496088 0.635303 0.898602 0.674905 0.877111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226826 episodes
GETTING ACTION FROM:
action 2, numVisits=226766, meanQ=4.948856, numObservations: 4
action -1, numVisits=51, meanQ=3.946251, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.87487 0.496088 0.635303 0.898602 0.674905 0.877111 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 129
Initial state: 0 0.565715 0.865488 0.952561 0.149384 0.523083 0.844234 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217137 episodes
GETTING ACTION FROM:
action 2, numVisits=217108, meanQ=4.897554, numObservations: 5
action 1, numVisits=21, meanQ=2.037398, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.565715 0.865488 0.952561 0.149384 0.523083 0.844234 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 130
Initial state: 0 0.599738 0.894531 0.0388391 0.407109 0.60495 0.897361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223099 episodes
GETTING ACTION FROM:
action 2, numVisits=222996, meanQ=5.032395, numObservations: 3
action -1, numVisits=99, meanQ=4.248616, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.599738 0.894531 0.0388391 0.407109 0.60495 0.897361 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36320, meanQ=8.376103, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289369 episodes
GETTING ACTION FROM:
action 3, numVisits=325689, meanQ=6.159551, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.599738 0.894531 0.0388391 0.407109 0.60495 0.897361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 131
Initial state: 0 0.756573 0.261811 0.62775 0.864028 0.685492 0.819157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157015 episodes
GETTING ACTION FROM:
action -1, numVisits=156994, meanQ=2.891157, numObservations: 1
action 2, numVisits=14, meanQ=0.857157, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-2.005000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.756573 0.261811 0.62775 0.864028 0.685492 0.819157 w: 1
Observation: 0 0.761083 0 0.645603 0 0.589541 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=156965, meanQ=4.962739, numObservations: 3
action 3, numVisits=23, meanQ=2.999135, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 246682 episodes
GETTING ACTION FROM:
action 2, numVisits=403647, meanQ=5.209032, numObservations: 3
action 3, numVisits=23, meanQ=2.999135, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.756573 0.261811 0.62775 0.864028 0.685492 0.819157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=29998, meanQ=4.443271, numObservations: 4
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 284777 episodes
GETTING ACTION FROM:
action 1, numVisits=314775, meanQ=5.202866, numObservations: 4
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.756573 0.261811 0.62775 0.864028 0.685492 0.819157 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 132
Initial state: 0 0.950748 0.230637 0.587839 0.880878 0.658356 0.865247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219420 episodes
GETTING ACTION FROM:
action 3, numVisits=219291, meanQ=4.870213, numObservations: 4
action -1, numVisits=68, meanQ=4.014072, numObservations: 1
action 0, numVisits=59, meanQ=3.956748, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.950748 0.230637 0.587839 0.880878 0.658356 0.865247 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.558042 0.884282 0.635796 0.871293 0.959201 0.25619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226498 episodes
GETTING ACTION FROM:
action 1, numVisits=226492, meanQ=4.929485, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.558042 0.884282 0.635796 0.871293 0.959201 0.25619 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 134
Initial state: 0 0.0567682 0.467912 0.61357 0.887249 0.523719 0.844627 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226125 episodes
GETTING ACTION FROM:
action 3, numVisits=226017, meanQ=4.950739, numObservations: 4
action 0, numVisits=55, meanQ=3.979412, numObservations: 1
action -1, numVisits=25, meanQ=3.525683, numObservations: 1
action 2, numVisits=21, meanQ=2.886676, numObservations: 3
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action: 3
Next state: 1 0.0567682 0.467912 0.61357 0.887249 0.523719 0.844627 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.99476 0.58723 0.639066 0.812325 0.549174 0.883657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221085 episodes
GETTING ACTION FROM:
action 2, numVisits=221069, meanQ=4.911044, numObservations: 5
action 1, numVisits=10, meanQ=1.997010, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.99476 0.58723 0.639066 0.812325 0.549174 0.883657 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 136
Initial state: 0 0.349715 0.505881 0.657595 0.867866 0.684579 0.892004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224478 episodes
GETTING ACTION FROM:
action 3, numVisits=224240, meanQ=4.955397, numObservations: 5
action -1, numVisits=184, meanQ=4.435811, numObservations: 1
action 0, numVisits=49, meanQ=3.966360, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.349715 0.505881 0.657595 0.867866 0.684579 0.892004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.597968 0.894093 0.927814 0.270226 0.615317 0.854852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220063 episodes
GETTING ACTION FROM:
action 1, numVisits=219942, meanQ=4.873806, numObservations: 4
action -1, numVisits=111, meanQ=4.138271, numObservations: 1
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.597968 0.894093 0.927814 0.270226 0.615317 0.854852 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.632038 0.959642 0.66538 0.868703 0.687234 0.869325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226347 episodes
GETTING ACTION FROM:
action 3, numVisits=223790, meanQ=5.007282, numObservations: 4
action 1, numVisits=2552, meanQ=4.862850, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.632038 0.959642 0.66538 0.868703 0.687234 0.869325 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.834292 0.416251 0.628578 0.836729 0.509346 0.829821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223679 episodes
GETTING ACTION FROM:
action 1, numVisits=223670, meanQ=4.970426, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.834292 0.416251 0.628578 0.836729 0.509346 0.829821 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 140
Initial state: 0 0.582324 0.859826 0.544777 0.848627 0.818593 0.413231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214849 episodes
GETTING ACTION FROM:
action 1, numVisits=186276, meanQ=5.022376, numObservations: 3
action -1, numVisits=27962, meanQ=2.987576, numObservations: 1
action 0, numVisits=597, meanQ=2.763278, numObservations: 1
action 2, numVisits=10, meanQ=0.598000, numObservations: 4
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action: 1
Next state: 1 0.582324 0.859826 0.544777 0.848627 0.818593 0.413231 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.569986 0.158454 0.607498 0.894545 0.500512 0.813471 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224845 episodes
GETTING ACTION FROM:
action 1, numVisits=224824, meanQ=4.991588, numObservations: 5
action -1, numVisits=17, meanQ=3.282485, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.569986 0.158454 0.607498 0.894545 0.500512 0.813471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16820, meanQ=5.530406, numObservations: 3
action 2, numVisits=15, meanQ=3.534013, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 266392 episodes
GETTING ACTION FROM:
action 1, numVisits=283197, meanQ=5.228351, numObservations: 3
action 2, numVisits=28, meanQ=3.785364, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.569986 0.158454 0.607498 0.894545 0.500512 0.813471 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=37758, meanQ=8.501103, numObservations: 5
action 3, numVisits=23, meanQ=5.782617, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 291846 episodes
GETTING ACTION FROM:
action 2, numVisits=329584, meanQ=6.249177, numObservations: 5
action 3, numVisits=43, meanQ=5.139307, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.569986 0.158454 0.607498 0.894545 0.500512 0.813471 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 142
Initial state: 0 0.56236 0.842833 0.667008 0.811397 0.403309 0.157998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220648 episodes
GETTING ACTION FROM:
action 2, numVisits=220640, meanQ=4.888293, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.56236 0.842833 0.667008 0.811397 0.403309 0.157998 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.644664 0.84725 0.689461 0.852742 0.318032 0.339417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226686 episodes
GETTING ACTION FROM:
action 3, numVisits=226664, meanQ=5.024215, numObservations: 4
action 1, numVisits=17, meanQ=3.234124, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.644664 0.84725 0.689461 0.852742 0.318032 0.339417 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=11194, meanQ=7.867308, numObservations: 3
action 2, numVisits=9, meanQ=5.443333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292820 episodes
GETTING ACTION FROM:
action 1, numVisits=304003, meanQ=6.009054, numObservations: 3
action 2, numVisits=18, meanQ=3.888333, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.644664 0.84725 0.689461 0.852742 0.318032 0.339417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 144
Initial state: 0 0.745643 0.913103 0.582063 0.821141 0.634454 0.854515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227533 episodes
GETTING ACTION FROM:
action 3, numVisits=227413, meanQ=5.046225, numObservations: 4
action 0, numVisits=64, meanQ=4.172435, numObservations: 2
action 1, numVisits=45, meanQ=3.924676, numObservations: 4
action 2, numVisits=9, meanQ=2.553344, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.745643 0.913103 0.582063 0.821141 0.634454 0.854515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 145
Initial state: 0 0.651656 0.838941 0.604529 0.844 0.296304 0.551918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224574 episodes
GETTING ACTION FROM:
action 2, numVisits=224454, meanQ=5.004298, numObservations: 5
action 1, numVisits=62, meanQ=4.071927, numObservations: 4
action 0, numVisits=55, meanQ=4.070911, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.651656 0.838941 0.604529 0.844 0.296304 0.551918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.283804 0.124248 0.688806 0.827664 0.685255 0.888217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227787 episodes
GETTING ACTION FROM:
action 2, numVisits=227781, meanQ=4.990471, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.283804 0.124248 0.688806 0.827664 0.685255 0.888217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.128461 0.570265 0.677187 0.884407 0.60541 0.87812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 211201 episodes
GETTING ACTION FROM:
action 2, numVisits=211115, meanQ=4.722371, numObservations: 4
action 0, numVisits=79, meanQ=3.682826, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.128461 0.570265 0.677187 0.884407 0.60541 0.87812 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.587551 0.819463 0.839508 0.642818 0.522675 0.853222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227880 episodes
GETTING ACTION FROM:
action 1, numVisits=227874, meanQ=5.163915, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.587551 0.819463 0.839508 0.642818 0.522675 0.853222 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 149
Initial state: 0 0.520862 0.852039 0.706571 0.569992 0.654023 0.842397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224543 episodes
GETTING ACTION FROM:
action 1, numVisits=224532, meanQ=4.938749, numObservations: 4
action 2, numVisits=6, meanQ=-1.648317, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.520862 0.852039 0.706571 0.569992 0.654023 0.842397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.0567312 0.161727 0.659829 0.817316 0.568986 0.887889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227140 episodes
GETTING ACTION FROM:
action 1, numVisits=227116, meanQ=5.033571, numObservations: 4
action -1, numVisits=19, meanQ=3.333874, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0567312 0.161727 0.659829 0.817316 0.568986 0.887889 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=37381, meanQ=8.356894, numObservations: 4
action 3, numVisits=15, meanQ=6.200680, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289378 episodes
GETTING ACTION FROM:
action 2, numVisits=326754, meanQ=6.231194, numObservations: 4
action 3, numVisits=20, meanQ=4.200515, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0567312 0.161727 0.659829 0.817316 0.568986 0.887889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 151
Initial state: 0 0.329154 0.309121 0.635071 0.895369 0.659204 0.835303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225011 episodes
GETTING ACTION FROM:
action 3, numVisits=224979, meanQ=5.002023, numObservations: 5
action 0, numVisits=28, meanQ=3.614092, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.329154 0.309121 0.635071 0.895369 0.659204 0.835303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.648799 0.897448 0.539173 0.85673 0.00257912 0.0694336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225246 episodes
GETTING ACTION FROM:
action 1, numVisits=219407, meanQ=4.949502, numObservations: 4
action -1, numVisits=5831, meanQ=2.802646, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.648799 0.897448 0.539173 0.85673 0.00257912 0.0694336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.621345 0.824663 0.803711 0.417853 0.598855 0.814602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227406 episodes
GETTING ACTION FROM:
action 1, numVisits=227380, meanQ=4.960858, numObservations: 4
action -1, numVisits=20, meanQ=3.397184, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.621345 0.824663 0.803711 0.417853 0.598855 0.814602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.639606 0.846618 0.501115 0.848968 0.627133 0.938143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229320 episodes
GETTING ACTION FROM:
action 2, numVisits=229242, meanQ=4.972053, numObservations: 3
action -1, numVisits=71, meanQ=4.129988, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.639606 0.846618 0.501115 0.848968 0.627133 0.938143 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.762004 0.515891 0.618646 0.824165 0.604026 0.837883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221689 episodes
GETTING ACTION FROM:
action 3, numVisits=215649, meanQ=4.934960, numObservations: 5
action 0, numVisits=6029, meanQ=2.815214, numObservations: 1
action 1, numVisits=7, meanQ=0.428586, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 3
Next state: 1 0.762004 0.515891 0.618646 0.824165 0.604026 0.837883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.544774 0.00727961 0.613977 0.800943 0.5856 0.821659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224882 episodes
GETTING ACTION FROM:
action 1, numVisits=224846, meanQ=5.011447, numObservations: 5
action 0, numVisits=31, meanQ=3.727442, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.544774 0.00727961 0.613977 0.800943 0.5856 0.821659 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 157
Initial state: 0 0.531073 0.878167 0.598876 0.899388 0.0473928 0.445111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227460 episodes
GETTING ACTION FROM:
action 2, numVisits=227373, meanQ=4.994339, numObservations: 4
action -1, numVisits=64, meanQ=4.127304, numObservations: 1
action 0, numVisits=20, meanQ=3.395978, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.531073 0.878167 0.598876 0.899388 0.0473928 0.445111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.444469 0.344928 0.636375 0.824433 0.616178 0.873821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219195 episodes
GETTING ACTION FROM:
action 2, numVisits=219188, meanQ=4.955990, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.444469 0.344928 0.636375 0.824433 0.616178 0.873821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.701372 0.59125 0.63622 0.894369 0.528379 0.83328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226664 episodes
GETTING ACTION FROM:
action 2, numVisits=226601, meanQ=4.995474, numObservations: 4
action -1, numVisits=38, meanQ=3.781408, numObservations: 1
action 1, numVisits=22, meanQ=2.635918, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.701372 0.59125 0.63622 0.894369 0.528379 0.83328 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.695396 0.863912 0.699348 0.845969 0.764405 0.0318831 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223975 episodes
GETTING ACTION FROM:
action 2, numVisits=214921, meanQ=5.049255, numObservations: 3
action 0, numVisits=9049, meanQ=2.963403, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.695396 0.863912 0.699348 0.845969 0.764405 0.0318831 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 161
Initial state: 0 0.623304 0.801343 0.558763 0.874444 0.806574 0.611542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215401 episodes
GETTING ACTION FROM:
action 1, numVisits=215395, meanQ=4.863575, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.623304 0.801343 0.558763 0.874444 0.806574 0.611542 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.609932 0.847576 0.425375 0.412955 0.662846 0.810225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225842 episodes
GETTING ACTION FROM:
action 3, numVisits=225833, meanQ=5.005527, numObservations: 3
action 1, numVisits=4, meanQ=-0.504975, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.609932 0.847576 0.425375 0.412955 0.662846 0.810225 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.670484 0.896708 0.696733 0.829706 0.201919 0.769409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226987 episodes
GETTING ACTION FROM:
action 2, numVisits=226767, meanQ=5.030479, numObservations: 4
action -1, numVisits=184, meanQ=4.519570, numObservations: 1
action 0, numVisits=23, meanQ=3.579266, numObservations: 1
action 1, numVisits=10, meanQ=2.399010, numObservations: 3
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action: 2
Next state: 1 0.670484 0.896708 0.696733 0.829706 0.201919 0.769409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.560832 0.879681 0.63855 0.805565 0.088601 0.91357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228634 episodes
GETTING ACTION FROM:
action 2, numVisits=228568, meanQ=4.991869, numObservations: 3
action 3, numVisits=61, meanQ=3.055251, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.560832 0.879681 0.63855 0.805565 0.088601 0.91357 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.538606 0.858694 0.428981 0.593581 0.550716 0.85851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 164331 episodes
GETTING ACTION FROM:
action 2, numVisits=26337, meanQ=4.963052, numObservations: 3
action 0, numVisits=137988, meanQ=2.916705, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-2.966667, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.538606 0.858694 0.428981 0.593581 0.550716 0.85851 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=4335, meanQ=8.334491, numObservations: 3
action 1, numVisits=20, meanQ=7.000005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292006 episodes
GETTING ACTION FROM:
action 3, numVisits=296228, meanQ=5.860997, numObservations: 3
action 1, numVisits=131, meanQ=5.242215, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.538606 0.858694 0.428981 0.593581 0.550716 0.85851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 166
Initial state: 0 0.532709 0.22767 0.574387 0.827478 0.637111 0.810374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223696 episodes
GETTING ACTION FROM:
action 3, numVisits=197244, meanQ=5.029333, numObservations: 5
action 2, numVisits=26418, meanQ=4.898327, numObservations: 5
action 0, numVisits=31, meanQ=3.726087, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.532709 0.22767 0.574387 0.827478 0.637111 0.810374 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.575459 0.818121 0.543325 0.115355 0.633483 0.855846 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226012 episodes
GETTING ACTION FROM:
action 2, numVisits=225956, meanQ=5.023659, numObservations: 5
action -1, numVisits=50, meanQ=4.030076, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.575459 0.818121 0.543325 0.115355 0.633483 0.855846 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 168
Initial state: 0 0.27669 0.566348 0.658676 0.814793 0.686548 0.823699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 162599 episodes
GETTING ACTION FROM:
action 0, numVisits=162553, meanQ=5.700508, numObservations: 2
action 1, numVisits=41, meanQ=2.117327, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.27669 0.566348 0.658676 0.814793 0.686548 0.823699 w: 1
Observation: 0 0 0.601806 0 0.779607 0 0.728343 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=119177, meanQ=7.608587, numObservations: 4
action 3, numVisits=11, meanQ=4.271818, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 251591 episodes
GETTING ACTION FROM:
action 2, numVisits=370765, meanQ=6.036526, numObservations: 4
action 3, numVisits=12, meanQ=3.499175, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.27669 0.566348 0.658676 0.814793 0.686548 0.823699 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=3639, meanQ=6.227519, numObservations: 3
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 270668 episodes
GETTING ACTION FROM:
action 2, numVisits=274305, meanQ=5.418460, numObservations: 3
action 3, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.27669 0.566348 0.658676 0.814793 0.686548 0.823699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 169
Initial state: 0 0.334548 0.77457 0.590439 0.840422 0.565133 0.87059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228837 episodes
GETTING ACTION FROM:
action 1, numVisits=228420, meanQ=4.929715, numObservations: 3
action 2, numVisits=408, meanQ=4.543526, numObservations: 5
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.334548 0.77457 0.590439 0.840422 0.565133 0.87059 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37314, meanQ=8.328593, numObservations: 5
action 2, numVisits=69, meanQ=7.576668, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 283248 episodes
GETTING ACTION FROM:
action 3, numVisits=320169, meanQ=6.411699, numObservations: 5
action 2, numVisits=462, meanQ=6.089526, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.334548 0.77457 0.590439 0.840422 0.565133 0.87059 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 170
Initial state: 0 0.603505 0.80976 0.535805 0.874943 0.0401247 0.260124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224998 episodes
GETTING ACTION FROM:
action 1, numVisits=224988, meanQ=4.927674, numObservations: 5
action 2, numVisits=4, meanQ=-0.504975, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.603505 0.80976 0.535805 0.874943 0.0401247 0.260124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 171
Initial state: 0 0.612049 0.821976 0.958322 0.0314366 0.529718 0.800122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226078 episodes
GETTING ACTION FROM:
action 3, numVisits=226070, meanQ=4.978266, numObservations: 4
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.612049 0.821976 0.958322 0.0314366 0.529718 0.800122 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.582281 0.857207 0.532976 0.805632 0.803545 0.0194215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226990 episodes
GETTING ACTION FROM:
action 1, numVisits=226974, meanQ=4.977590, numObservations: 4
action 2, numVisits=10, meanQ=2.189000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.582281 0.857207 0.532976 0.805632 0.803545 0.0194215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.543622 0.885405 0.500984 0.889142 0.888162 0.162299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217746 episodes
GETTING ACTION FROM:
action 3, numVisits=217203, meanQ=4.782870, numObservations: 4
action 0, numVisits=531, meanQ=1.787938, numObservations: 1
action 1, numVisits=4, meanQ=-1.002450, numObservations: 2
action 2, numVisits=6, meanQ=-2.001650, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.543622 0.885405 0.500984 0.889142 0.888162 0.162299 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=16047, meanQ=2.618359, numObservations: 1
action -1, numVisits=52, meanQ=1.710056, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 286411 episodes
GETTING ACTION FROM:
action 1, numVisits=278525, meanQ=5.946515, numObservations: 5
action 0, numVisits=23911, meanQ=1.440061, numObservations: 1
action -1, numVisits=76, meanQ=0.731187, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.543622 0.885405 0.500984 0.889142 0.888162 0.162299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4951, meanQ=7.295118, numObservations: 4
action 2, numVisits=82, meanQ=6.104149, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 297228 episodes
GETTING ACTION FROM:
action 2, numVisits=243066, meanQ=6.091133, numObservations: 4
action 1, numVisits=59195, meanQ=5.788727, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.543622 0.885405 0.500984 0.889142 0.888162 0.162299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 174
Initial state: 0 0.600947 0.827815 0.712541 0.700219 0.504429 0.886737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228406 episodes
GETTING ACTION FROM:
action 2, numVisits=228153, meanQ=4.967379, numObservations: 3
action 1, numVisits=132, meanQ=4.225871, numObservations: 4
action 0, numVisits=74, meanQ=4.155521, numObservations: 1
action -1, numVisits=46, meanQ=3.943555, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.600947 0.827815 0.712541 0.700219 0.504429 0.886737 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 175
Initial state: 0 0.626229 0.807264 0.337845 0.0709103 0.61075 0.893214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223332 episodes
GETTING ACTION FROM:
action 2, numVisits=223323, meanQ=4.925163, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.626229 0.807264 0.337845 0.0709103 0.61075 0.893214 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30907, meanQ=8.410335, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283942 episodes
GETTING ACTION FROM:
action 3, numVisits=314849, meanQ=6.222957, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.626229 0.807264 0.337845 0.0709103 0.61075 0.893214 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 176
Initial state: 0 0.776876 0.194399 0.538658 0.823572 0.662681 0.808989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219608 episodes
GETTING ACTION FROM:
action 1, numVisits=208312, meanQ=4.962275, numObservations: 5
action -1, numVisits=11285, meanQ=3.042230, numObservations: 1
action 2, numVisits=8, meanQ=0.501263, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.776876 0.194399 0.538658 0.823572 0.662681 0.808989 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 177
Initial state: 0 0.564302 0.821518 0.86741 0.515313 0.541748 0.865151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229055 episodes
GETTING ACTION FROM:
action 1, numVisits=229049, meanQ=5.015979, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.564302 0.821518 0.86741 0.515313 0.541748 0.865151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 178
Initial state: 0 0.486816 0.646867 0.571465 0.80766 0.540173 0.826253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218674 episodes
GETTING ACTION FROM:
action 2, numVisits=218631, meanQ=4.857122, numObservations: 4
action 0, numVisits=38, meanQ=3.691413, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.486816 0.646867 0.571465 0.80766 0.540173 0.826253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.590543 0.890962 0.575038 0.822868 0.798808 0.0487487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228246 episodes
GETTING ACTION FROM:
action 1, numVisits=228060, meanQ=4.948254, numObservations: 3
action 0, numVisits=95, meanQ=4.238509, numObservations: 1
action -1, numVisits=89, meanQ=4.206230, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.590543 0.890962 0.575038 0.822868 0.798808 0.0487487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.394697 0.251613 0.687749 0.812771 0.68278 0.865905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217669 episodes
GETTING ACTION FROM:
action 1, numVisits=217609, meanQ=4.845561, numObservations: 5
action 2, numVisits=34, meanQ=3.528544, numObservations: 3
action 3, numVisits=22, meanQ=3.176818, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.394697 0.251613 0.687749 0.812771 0.68278 0.865905 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30198, meanQ=8.402344, numObservations: 4
action 2, numVisits=84, meanQ=7.709648, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284140 episodes
GETTING ACTION FROM:
action 2, numVisits=75365, meanQ=6.196453, numObservations: 3
action 3, numVisits=239057, meanQ=6.180142, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.394697 0.251613 0.687749 0.812771 0.68278 0.865905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 181
Initial state: 0 0.871168 0.338092 0.627682 0.84346 0.507074 0.806938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223151 episodes
GETTING ACTION FROM:
action 1, numVisits=223139, meanQ=5.009380, numObservations: 5
action 2, numVisits=7, meanQ=0.428586, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.871168 0.338092 0.627682 0.84346 0.507074 0.806938 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 182
Initial state: 0 0.645828 0.802374 0.751771 0.536806 0.541858 0.8653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228743 episodes
GETTING ACTION FROM:
action 1, numVisits=228703, meanQ=4.960715, numObservations: 3
action -1, numVisits=36, meanQ=3.751268, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.645828 0.802374 0.751771 0.536806 0.541858 0.8653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.396132 0.533019 0.697194 0.800465 0.542915 0.800507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225048 episodes
GETTING ACTION FROM:
action 1, numVisits=225041, meanQ=5.035963, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.396132 0.533019 0.697194 0.800465 0.542915 0.800507 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 184
Initial state: 0 0.0317149 0.581931 0.575639 0.841569 0.563255 0.884119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224496 episodes
GETTING ACTION FROM:
action 3, numVisits=224402, meanQ=4.979754, numObservations: 5
action -1, numVisits=62, meanQ=4.084040, numObservations: 1
action 2, numVisits=26, meanQ=3.145777, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.0317149 0.581931 0.575639 0.841569 0.563255 0.884119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 185
Initial state: 0 0.0628626 0.786586 0.525251 0.832777 0.548208 0.851823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225695 episodes
GETTING ACTION FROM:
action 2, numVisits=225683, meanQ=4.941289, numObservations: 4
action 1, numVisits=7, meanQ=2.144300, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0628626 0.786586 0.525251 0.832777 0.548208 0.851823 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 186
Initial state: 0 0.567559 0.84325 0.477214 0.223647 0.68589 0.819729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227468 episodes
GETTING ACTION FROM:
action 2, numVisits=227387, meanQ=5.062971, numObservations: 5
action -1, numVisits=77, meanQ=4.257076, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.567559 0.84325 0.477214 0.223647 0.68589 0.819729 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=13385, meanQ=8.538729, numObservations: 3
action 3, numVisits=12616, meanQ=8.533401, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285195 episodes
GETTING ACTION FROM:
action 3, numVisits=243706, meanQ=6.281209, numObservations: 4
action 1, numVisits=67490, meanQ=6.267945, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.567559 0.84325 0.477214 0.223647 0.68589 0.819729 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 187
Initial state: 0 0.51136 0.841631 0.595538 0.856623 0.0553663 0.724919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223543 episodes
GETTING ACTION FROM:
action 1, numVisits=223536, meanQ=4.949806, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.51136 0.841631 0.595538 0.856623 0.0553663 0.724919 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.528749 0.854442 0.651252 0.851049 0.463161 0.964923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 230456 episodes
GETTING ACTION FROM:
action 1, numVisits=230450, meanQ=4.981259, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.528749 0.854442 0.651252 0.851049 0.463161 0.964923 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.665921 0.841391 0.714094 0.763324 0.696735 0.884481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226312 episodes
GETTING ACTION FROM:
action 2, numVisits=226197, meanQ=4.987293, numObservations: 4
action -1, numVisits=107, meanQ=4.037970, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.665921 0.841391 0.714094 0.763324 0.696735 0.884481 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 190
Initial state: 0 0.516784 0.801149 0.641388 0.857474 0.881451 0.22238 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225932 episodes
GETTING ACTION FROM:
action 2, numVisits=225809, meanQ=4.980043, numObservations: 4
action 0, numVisits=111, meanQ=4.323132, numObservations: 1
action 1, numVisits=9, meanQ=1.886667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.516784 0.801149 0.641388 0.857474 0.881451 0.22238 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.83369 0.777209 0.53451 0.849114 0.646374 0.892778 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224247 episodes
GETTING ACTION FROM:
action 1, numVisits=224234, meanQ=4.900439, numObservations: 4
action 2, numVisits=8, meanQ=1.500000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.83369 0.777209 0.53451 0.849114 0.646374 0.892778 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 192
Initial state: 0 0.793685 0.0119232 0.502041 0.804001 0.605199 0.819006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224544 episodes
GETTING ACTION FROM:
action 2, numVisits=224537, meanQ=5.141254, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.793685 0.0119232 0.502041 0.804001 0.605199 0.819006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.681497 0.858721 0.375835 0.415368 0.579186 0.896764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227076 episodes
GETTING ACTION FROM:
action 1, numVisits=226992, meanQ=5.008522, numObservations: 4
action -1, numVisits=46, meanQ=3.965361, numObservations: 1
action 0, numVisits=36, meanQ=3.839707, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.681497 0.858721 0.375835 0.415368 0.579186 0.896764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 194
Initial state: 0 0.295467 0.380241 0.675516 0.811888 0.594158 0.837947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219859 episodes
GETTING ACTION FROM:
action 1, numVisits=219823, meanQ=4.927001, numObservations: 5
action 2, numVisits=31, meanQ=3.506777, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.295467 0.380241 0.675516 0.811888 0.594158 0.837947 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30738, meanQ=8.386232, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 288869 episodes
GETTING ACTION FROM:
action 2, numVisits=319607, meanQ=6.193972, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.295467 0.380241 0.675516 0.811888 0.594158 0.837947 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 195
Initial state: 0 0.580638 0.859931 0.535137 0.839127 0.781499 0.765904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224152 episodes
GETTING ACTION FROM:
action 3, numVisits=223981, meanQ=4.970678, numObservations: 4
action 0, numVisits=122, meanQ=4.339901, numObservations: 1
action -1, numVisits=46, meanQ=3.895118, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.580638 0.859931 0.535137 0.839127 0.781499 0.765904 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 196
Initial state: 0 0.895215 0.484717 0.670725 0.889311 0.664134 0.837393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224346 episodes
GETTING ACTION FROM:
action 3, numVisits=224290, meanQ=4.954203, numObservations: 5
action -1, numVisits=49, meanQ=3.953707, numObservations: 1
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.895215 0.484717 0.670725 0.889311 0.664134 0.837393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 197
Initial state: 0 0.65379 0.861687 0.15172 0.175786 0.607294 0.804108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227897 episodes
GETTING ACTION FROM:
action 2, numVisits=227879, meanQ=4.948957, numObservations: 3
action 1, numVisits=12, meanQ=1.832508, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.65379 0.861687 0.15172 0.175786 0.607294 0.804108 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=21133, meanQ=8.346485, numObservations: 4
action 3, numVisits=16617, meanQ=8.343082, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286704 episodes
GETTING ACTION FROM:
action 3, numVisits=208146, meanQ=6.326100, numObservations: 4
action 1, numVisits=116308, meanQ=6.321053, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.65379 0.861687 0.15172 0.175786 0.607294 0.804108 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 198
Initial state: 0 0.014348 0.304947 0.607081 0.866502 0.695711 0.807688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224991 episodes
GETTING ACTION FROM:
action 2, numVisits=224979, meanQ=5.013011, numObservations: 5
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.014348 0.304947 0.607081 0.866502 0.695711 0.807688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 199
Initial state: 0 0.5257 0.827634 0.605104 0.808093 0.348233 0.209288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219459 episodes
GETTING ACTION FROM:
action 1, numVisits=219433, meanQ=4.870780, numObservations: 4
action -1, numVisits=22, meanQ=3.331716, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.5257 0.827634 0.605104 0.808093 0.348233 0.209288 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.621715 0.811037 0.610315 0.867695 0.291007 0.0456589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223122 episodes
GETTING ACTION FROM:
action 2, numVisits=223066, meanQ=4.958000, numObservations: 3
action 3, numVisits=50, meanQ=3.905608, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.621715 0.811037 0.610315 0.867695 0.291007 0.0456589 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 201
Initial state: 0 0.679304 0.841302 0.910426 0.472355 0.59272 0.852845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224248 episodes
GETTING ACTION FROM:
action 3, numVisits=224236, meanQ=4.906299, numObservations: 4
action 2, numVisits=7, meanQ=-1.287143, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.679304 0.841302 0.910426 0.472355 0.59272 0.852845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.508107 0.367687 0.620831 0.81395 0.559518 0.866552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225786 episodes
GETTING ACTION FROM:
action 2, numVisits=225777, meanQ=5.014603, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.508107 0.367687 0.620831 0.81395 0.559518 0.866552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.608172 0.844827 0.199372 0.68414 0.536796 0.874736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221430 episodes
GETTING ACTION FROM:
action 1, numVisits=221326, meanQ=4.963286, numObservations: 5
action 0, numVisits=89, meanQ=4.184159, numObservations: 1
action 2, numVisits=11, meanQ=2.452745, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.608172 0.844827 0.199372 0.68414 0.536796 0.874736 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.150919 0.094201 0.593365 0.84361 0.642378 0.813598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215132 episodes
GETTING ACTION FROM:
action 1, numVisits=215104, meanQ=5.004032, numObservations: 5
action 2, numVisits=23, meanQ=3.260009, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.150919 0.094201 0.593365 0.84361 0.642378 0.813598 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 205
Initial state: 0 0.134185 0.305028 0.690073 0.83283 0.662403 0.868818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222682 episodes
GETTING ACTION FROM:
action 3, numVisits=222651, meanQ=5.037793, numObservations: 5
action -1, numVisits=17, meanQ=3.246890, numObservations: 1
action 1, numVisits=8, meanQ=1.500013, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.134185 0.305028 0.690073 0.83283 0.662403 0.868818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.538469 0.87529 0.553663 0.875626 0.679872 0.702313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223195 episodes
GETTING ACTION FROM:
action 3, numVisits=223158, meanQ=4.946952, numObservations: 5
action -1, numVisits=19, meanQ=3.291996, numObservations: 1
action 2, numVisits=15, meanQ=2.866000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.538469 0.87529 0.553663 0.875626 0.679872 0.702313 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=18099, meanQ=8.406610, numObservations: 5
action 1, numVisits=13101, meanQ=8.394535, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286056 episodes
GETTING ACTION FROM:
action 2, numVisits=181960, meanQ=6.193396, numObservations: 5
action 1, numVisits=135296, meanQ=6.188812, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.538469 0.87529 0.553663 0.875626 0.679872 0.702313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 207
Initial state: 0 0.688515 0.866051 0.79067 0.855299 0.602442 0.83031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217962 episodes
GETTING ACTION FROM:
action 3, numVisits=217953, meanQ=4.978698, numObservations: 5
action 1, numVisits=4, meanQ=-1.002450, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.688515 0.866051 0.79067 0.855299 0.602442 0.83031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 208
Initial state: 0 0.591907 0.818635 0.882853 0.468577 0.577117 0.838007 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224535 episodes
GETTING ACTION FROM:
action 1, numVisits=224529, meanQ=4.942355, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.591907 0.818635 0.882853 0.468577 0.577117 0.838007 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.596218 0.815191 0.973717 0.66279 0.56362 0.833611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219714 episodes
GETTING ACTION FROM:
action 3, numVisits=219704, meanQ=4.904731, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.596218 0.815191 0.973717 0.66279 0.56362 0.833611 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.541102 0.800681 0.590146 0.863515 0.188069 0.306225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226117 episodes
GETTING ACTION FROM:
action 2, numVisits=226077, meanQ=4.978562, numObservations: 4
action 0, numVisits=17, meanQ=3.267125, numObservations: 1
action -1, numVisits=16, meanQ=3.192058, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.541102 0.800681 0.590146 0.863515 0.188069 0.306225 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.597836 0.898756 0.949816 0.680975 0.653213 0.856199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156443 episodes
GETTING ACTION FROM:
action -1, numVisits=156433, meanQ=2.938970, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.597836 0.898756 0.949816 0.680975 0.653213 0.856199 w: 1
Observation: 0 0.563109 0 1 0 0.715835 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=156345, meanQ=5.027329, numObservations: 4
action -1, numVisits=79, meanQ=4.226396, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 247857 episodes
GETTING ACTION FROM:
action 2, numVisits=404202, meanQ=5.176256, numObservations: 4
action -1, numVisits=79, meanQ=4.226396, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.597836 0.898756 0.949816 0.680975 0.653213 0.856199 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=30348, meanQ=5.649651, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 266648 episodes
GETTING ACTION FROM:
action 2, numVisits=296996, meanQ=5.356001, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.597836 0.898756 0.949816 0.680975 0.653213 0.856199 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 212
Initial state: 0 0.504651 0.818798 0.567869 0.863883 0.81901 0.702186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 199559 episodes
GETTING ACTION FROM:
action 0, numVisits=61166, meanQ=5.784496, numObservations: 3
action 2, numVisits=138381, meanQ=4.933832, numObservations: 5
action 3, numVisits=9, meanQ=1.886667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.504651 0.818798 0.567869 0.863883 0.81901 0.702186 w: 1
Observation: 0 0 0.899481 0 0.887435 0 0.661911 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=33785, meanQ=7.519511, numObservations: 4
action 1, numVisits=4, meanQ=4.000000, numObservations: 2
action 3, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 248072 episodes
GETTING ACTION FROM:
action 2, numVisits=281785, meanQ=5.517604, numObservations: 4
action 0, numVisits=57, meanQ=4.569862, numObservations: 1
action 1, numVisits=17, meanQ=3.587071, numObservations: 4
action 3, numVisits=7, meanQ=2.711429, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.504651 0.818798 0.567869 0.863883 0.81901 0.702186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 213
Initial state: 0 0.579599 0.86951 0.604315 0.823376 0.966553 0.895552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227246 episodes
GETTING ACTION FROM:
action 1, numVisits=227239, meanQ=5.041560, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.579599 0.86951 0.604315 0.823376 0.966553 0.895552 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5489, meanQ=7.792810, numObservations: 4
action 3, numVisits=9, meanQ=5.876667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287940 episodes
GETTING ACTION FROM:
action 2, numVisits=293424, meanQ=6.067696, numObservations: 4
action 3, numVisits=12, meanQ=3.324167, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.579599 0.86951 0.604315 0.823376 0.966553 0.895552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 214
Initial state: 0 0.664158 0.807638 0.68747 0.825671 0.21852 0.00367573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224291 episodes
GETTING ACTION FROM:
action 1, numVisits=224285, meanQ=4.990973, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.664158 0.807638 0.68747 0.825671 0.21852 0.00367573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.560636 0.885181 0.506948 0.808007 0.8195 0.150758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223787 episodes
GETTING ACTION FROM:
action 2, numVisits=223687, meanQ=5.006495, numObservations: 5
action 0, numVisits=96, meanQ=4.299819, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.560636 0.885181 0.506948 0.808007 0.8195 0.150758 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 216
Initial state: 0 0.511862 0.878632 0.0650786 0.317194 0.622427 0.859889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221120 episodes
GETTING ACTION FROM:
action 1, numVisits=220924, meanQ=4.858970, numObservations: 3
action -1, numVisits=154, meanQ=4.294392, numObservations: 1
action 2, numVisits=39, meanQ=3.409495, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.511862 0.878632 0.0650786 0.317194 0.622427 0.859889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.673572 0.848418 0.610433 0.328626 0.54609 0.847742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156887 episodes
GETTING ACTION FROM:
action -1, numVisits=156880, meanQ=2.995855, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.673572 0.848418 0.610433 0.328626 0.54609 0.847742 w: 1
Observation: 0 0.699178 0 0.585002 0 0.491837 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=156823, meanQ=5.028361, numObservations: 4
action -1, numVisits=44, meanQ=3.974687, numObservations: 1
action 1, numVisits=9, meanQ=2.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 245763 episodes
GETTING ACTION FROM:
action 3, numVisits=402580, meanQ=4.900429, numObservations: 4
action -1, numVisits=50, meanQ=3.877234, numObservations: 1
action 1, numVisits=9, meanQ=2.333333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.673572 0.848418 0.610433 0.328626 0.54609 0.847742 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 218
Initial state: 0 0.498426 0.0536634 0.63089 0.818871 0.667686 0.845596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152695 episodes
GETTING ACTION FROM:
action -1, numVisits=152687, meanQ=2.888928, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-2.966667, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.498426 0.0536634 0.63089 0.818871 0.667686 0.845596 w: 1
Observation: 0 0.419977 0 0.533104 0 0.630968 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=152570, meanQ=4.936836, numObservations: 4
action 2, numVisits=111, meanQ=4.273520, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 238319 episodes
GETTING ACTION FROM:
action 3, numVisits=390882, meanQ=4.886286, numObservations: 4
action 2, numVisits=118, meanQ=4.180260, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.498426 0.0536634 0.63089 0.818871 0.667686 0.845596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 219
Initial state: 0 0.583223 0.87947 0.719246 0.7226 0.594891 0.883734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225250 episodes
GETTING ACTION FROM:
action 1, numVisits=225146, meanQ=4.937508, numObservations: 4
action 0, numVisits=99, meanQ=4.236513, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.583223 0.87947 0.719246 0.7226 0.594891 0.883734 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=17140, meanQ=4.696241, numObservations: 4
action 0, numVisits=40, meanQ=3.729539, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 281293 episodes
GETTING ACTION FROM:
action 2, numVisits=298433, meanQ=6.130922, numObservations: 4
action 0, numVisits=40, meanQ=3.729539, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.583223 0.87947 0.719246 0.7226 0.594891 0.883734 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 220
Initial state: 0 0.238541 0.362947 0.572383 0.887899 0.619631 0.804649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227122 episodes
GETTING ACTION FROM:
action 2, numVisits=227116, meanQ=4.937781, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.238541 0.362947 0.572383 0.887899 0.619631 0.804649 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 221
Initial state: 0 0.876998 0.743103 0.597745 0.849467 0.671918 0.844493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222688 episodes
GETTING ACTION FROM:
action 3, numVisits=222668, meanQ=5.024502, numObservations: 3
action 1, numVisits=15, meanQ=0.719333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.876998 0.743103 0.597745 0.849467 0.671918 0.844493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=10933, meanQ=5.438549, numObservations: 2
action 2, numVisits=5856, meanQ=4.805197, numObservations: 5
action -1, numVisits=26, meanQ=3.654038, numObservations: 1
action 3, numVisits=25, meanQ=3.555608, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282890 episodes
GETTING ACTION FROM:
action 2, numVisits=287464, meanQ=6.331412, numObservations: 5
action 0, numVisits=12215, meanQ=4.825638, numObservations: 2
action -1, numVisits=26, meanQ=3.654038, numObservations: 1
action 3, numVisits=25, meanQ=3.555608, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.876998 0.743103 0.597745 0.849467 0.671918 0.844493 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 222
Initial state: 0 0.589875 0.890626 0.76899 0.763453 0.530002 0.868039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225163 episodes
GETTING ACTION FROM:
action 3, numVisits=225042, meanQ=4.962765, numObservations: 4
action 2, numVisits=115, meanQ=3.576957, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.589875 0.890626 0.76899 0.763453 0.530002 0.868039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.0420802 0.443014 0.609653 0.853913 0.628294 0.841857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222424 episodes
GETTING ACTION FROM:
action 3, numVisits=222418, meanQ=4.938283, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0420802 0.443014 0.609653 0.853913 0.628294 0.841857 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=17121, meanQ=4.654221, numObservations: 5
action -1, numVisits=44, meanQ=3.665456, numObservations: 1
action 1, numVisits=19, meanQ=3.104737, numObservations: 3
action 3, numVisits=20, meanQ=2.996510, numObservations: 2
action 0, numVisits=13, meanQ=2.772320, numObservations: 1
Sampled 282511 episodes
GETTING ACTION FROM:
action 2, numVisits=299632, meanQ=6.026825, numObservations: 5
action -1, numVisits=44, meanQ=3.665456, numObservations: 1
action 1, numVisits=19, meanQ=3.104737, numObservations: 3
action 3, numVisits=20, meanQ=2.996510, numObservations: 2
action 0, numVisits=13, meanQ=2.772320, numObservations: 1
action: 2
Next state: 1 0.0420802 0.443014 0.609653 0.853913 0.628294 0.841857 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 224
Initial state: 0 0.725411 0.844096 0.631478 0.831076 0.535458 0.831382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226967 episodes
GETTING ACTION FROM:
action 1, numVisits=226961, meanQ=5.040192, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.725411 0.844096 0.631478 0.831076 0.535458 0.831382 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.609848 0.858308 0.547199 0.85394 0.856255 0.726093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220972 episodes
GETTING ACTION FROM:
action 3, numVisits=220849, meanQ=4.877358, numObservations: 3
action -1, numVisits=101, meanQ=4.163858, numObservations: 1
action 2, numVisits=19, meanQ=2.879474, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.609848 0.858308 0.547199 0.85394 0.856255 0.726093 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 226
Initial state: 0 0.683097 0.81001 0.0448643 0.172554 0.524336 0.887061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222924 episodes
GETTING ACTION FROM:
action 1, numVisits=222124, meanQ=4.937052, numObservations: 5
action 0, numVisits=596, meanQ=3.371593, numObservations: 1
action -1, numVisits=138, meanQ=3.141284, numObservations: 1
action 3, numVisits=45, meanQ=2.363113, numObservations: 4
action 2, numVisits=21, meanQ=2.129524, numObservations: 3
action: 1
Next state: 1 0.683097 0.81001 0.0448643 0.172554 0.524336 0.887061 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.180137 0.723176 0.536645 0.859432 0.606045 0.823029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225449 episodes
GETTING ACTION FROM:
action 1, numVisits=225394, meanQ=5.005855, numObservations: 4
action 0, numVisits=39, meanQ=3.859511, numObservations: 1
action 2, numVisits=12, meanQ=1.992508, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.180137 0.723176 0.536645 0.859432 0.606045 0.823029 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26123, meanQ=8.543686, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290678 episodes
GETTING ACTION FROM:
action 3, numVisits=316794, meanQ=6.068608, numObservations: 3
action 2, numVisits=7, meanQ=2.711429, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.180137 0.723176 0.536645 0.859432 0.606045 0.823029 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 228
Initial state: 0 0.546811 0.819326 0.379729 0.0588812 0.56788 0.811885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219620 episodes
GETTING ACTION FROM:
action 3, numVisits=219611, meanQ=4.927472, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.546811 0.819326 0.379729 0.0588812 0.56788 0.811885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 229
Initial state: 0 0.199223 0.06761 0.568028 0.876412 0.539669 0.891366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224053 episodes
GETTING ACTION FROM:
action 1, numVisits=223949, meanQ=4.962706, numObservations: 5
action 3, numVisits=95, meanQ=4.246476, numObservations: 3
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.199223 0.06761 0.568028 0.876412 0.539669 0.891366 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=11136, meanQ=7.897249, numObservations: 4
action 3, numVisits=39, meanQ=6.584623, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289417 episodes
GETTING ACTION FROM:
action 2, numVisits=287116, meanQ=6.120343, numObservations: 4
action 3, numVisits=13476, meanQ=6.070991, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.199223 0.06761 0.568028 0.876412 0.539669 0.891366 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 230
Initial state: 0 0.678544 0.805082 0.679658 0.815614 0.781637 0.904654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219310 episodes
GETTING ACTION FROM:
action 2, numVisits=219257, meanQ=4.826998, numObservations: 4
action -1, numVisits=39, meanQ=3.715328, numObservations: 1
action 3, numVisits=11, meanQ=2.453636, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.678544 0.805082 0.679658 0.815614 0.781637 0.904654 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.553713 0.811981 0.513927 0.898942 0.494464 0.010957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216385 episodes
GETTING ACTION FROM:
action 2, numVisits=205590, meanQ=4.866554, numObservations: 4
action -1, numVisits=10768, meanQ=3.026144, numObservations: 1
action 3, numVisits=24, meanQ=1.832925, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.553713 0.811981 0.513927 0.898942 0.494464 0.010957 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.526037 0.873386 0.591924 0.844836 0.896636 0.804517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224158 episodes
GETTING ACTION FROM:
action 3, numVisits=224150, meanQ=5.004044, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.526037 0.873386 0.591924 0.844836 0.896636 0.804517 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.762076 0.408915 0.652292 0.879277 0.618314 0.899235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222103 episodes
GETTING ACTION FROM:
action 3, numVisits=222042, meanQ=4.994930, numObservations: 5
action -1, numVisits=54, meanQ=4.034332, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.762076 0.408915 0.652292 0.879277 0.618314 0.899235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.896412 0.294326 0.563513 0.878246 0.53375 0.824468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221886 episodes
GETTING ACTION FROM:
action 3, numVisits=221865, meanQ=4.948024, numObservations: 5
action 2, numVisits=16, meanQ=2.997512, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.896412 0.294326 0.563513 0.878246 0.53375 0.824468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.65116 0.856054 0.414226 0.991408 0.628037 0.865589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223307 episodes
GETTING ACTION FROM:
action 3, numVisits=223258, meanQ=4.957934, numObservations: 5
action 0, numVisits=36, meanQ=3.788672, numObservations: 1
action 1, numVisits=10, meanQ=1.799000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.65116 0.856054 0.414226 0.991408 0.628037 0.865589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.514455 0.873712 0.131595 0.00431006 0.558331 0.85501 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229058 episodes
GETTING ACTION FROM:
action 3, numVisits=229030, meanQ=5.010513, numObservations: 3
action -1, numVisits=24, meanQ=3.525263, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.514455 0.873712 0.131595 0.00431006 0.558331 0.85501 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=17301, meanQ=5.577967, numObservations: 4
action 1, numVisits=54, meanQ=3.841857, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 264175 episodes
GETTING ACTION FROM:
action 3, numVisits=281474, meanQ=4.882576, numObservations: 4
action 1, numVisits=54, meanQ=3.841857, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.514455 0.873712 0.131595 0.00431006 0.558331 0.85501 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 237
Initial state: 0 0.618796 0.809026 0.620008 0.801949 0.713532 0.175325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 174470 episodes
GETTING ACTION FROM:
action 2, numVisits=65240, meanQ=4.952982, numObservations: 4
action 0, numVisits=109224, meanQ=3.218654, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.618796 0.809026 0.620008 0.801949 0.713532 0.175325 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.00623634 0.945343 0.64861 0.840873 0.59169 0.832122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229940 episodes
GETTING ACTION FROM:
action 2, numVisits=229776, meanQ=5.005803, numObservations: 3
action 0, numVisits=84, meanQ=4.241540, numObservations: 1
action -1, numVisits=75, meanQ=4.202402, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.00623634 0.945343 0.64861 0.840873 0.59169 0.832122 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.531736 0.83858 0.480173 0.250009 0.551008 0.898236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225651 episodes
GETTING ACTION FROM:
action 3, numVisits=225579, meanQ=4.962205, numObservations: 4
action 0, numVisits=64, meanQ=4.070815, numObservations: 1
action 2, numVisits=5, meanQ=1.794000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.531736 0.83858 0.480173 0.250009 0.551008 0.898236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.680615 0.856217 0.504024 0.896174 0.471672 0.982833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227364 episodes
GETTING ACTION FROM:
action 1, numVisits=208841, meanQ=4.999697, numObservations: 4
action 3, numVisits=18515, meanQ=4.944777, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.680615 0.856217 0.504024 0.896174 0.471672 0.982833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 241
Initial state: 0 0.528394 0.868558 0.917912 0.707258 0.603961 0.859124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214423 episodes
GETTING ACTION FROM:
action 3, numVisits=206557, meanQ=5.150359, numObservations: 5
action -1, numVisits=7848, meanQ=2.912519, numObservations: 1
action 2, numVisits=11, meanQ=1.008182, numObservations: 3
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.528394 0.868558 0.917912 0.707258 0.603961 0.859124 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.628724 0.843839 0.593665 0.869084 0.65214 0.695985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214415 episodes
GETTING ACTION FROM:
action 3, numVisits=198021, meanQ=4.931000, numObservations: 5
action 0, numVisits=16374, meanQ=3.171463, numObservations: 1
action 1, numVisits=17, meanQ=1.572365, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.628724 0.843839 0.593665 0.869084 0.65214 0.695985 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 243
Initial state: 0 0.338929 0.413567 0.530144 0.804417 0.696513 0.860409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224032 episodes
GETTING ACTION FROM:
action 1, numVisits=223948, meanQ=5.002498, numObservations: 4
action 0, numVisits=37, meanQ=3.766755, numObservations: 1
action 3, numVisits=44, meanQ=3.452057, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.338929 0.413567 0.530144 0.804417 0.696513 0.860409 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31255, meanQ=8.386934, numObservations: 5
action 2, numVisits=50, meanQ=7.475600, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285572 episodes
GETTING ACTION FROM:
action 2, numVisits=135429, meanQ=6.199690, numObservations: 4
action 3, numVisits=181448, meanQ=6.194604, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.338929 0.413567 0.530144 0.804417 0.696513 0.860409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 244
Initial state: 0 0.666273 0.827239 0.515455 0.805378 0.878397 0.418131 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222858 episodes
GETTING ACTION FROM:
action 3, numVisits=222852, meanQ=4.914239, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.666273 0.827239 0.515455 0.805378 0.878397 0.418131 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 245
Initial state: 0 0.214878 0.615329 0.5013 0.888669 0.510958 0.896683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217087 episodes
GETTING ACTION FROM:
action 2, numVisits=217026, meanQ=4.847885, numObservations: 5
action 0, numVisits=31, meanQ=3.552626, numObservations: 1
action 1, numVisits=27, meanQ=3.433707, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.214878 0.615329 0.5013 0.888669 0.510958 0.896683 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 246
Initial state: 0 0.555111 0.855354 0.652399 0.8866 0.323403 0.0125623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225446 episodes
GETTING ACTION FROM:
action 2, numVisits=225440, meanQ=5.020245, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.555111 0.855354 0.652399 0.8866 0.323403 0.0125623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.542643 0.802896 0.931526 0.721675 0.624096 0.841213 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223071 episodes
GETTING ACTION FROM:
action 3, numVisits=223021, meanQ=5.024046, numObservations: 5
action 1, numVisits=44, meanQ=3.204093, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.542643 0.802896 0.931526 0.721675 0.624096 0.841213 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.594182 0.890415 0.594042 0.829041 0.3247 0.630409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225255 episodes
GETTING ACTION FROM:
action 2, numVisits=225207, meanQ=4.997078, numObservations: 4
action 0, numVisits=36, meanQ=3.800446, numObservations: 1
action 1, numVisits=9, meanQ=1.886667, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.594182 0.890415 0.594042 0.829041 0.3247 0.630409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 249
Initial state: 0 0.692172 0.82871 0.629226 0.893004 0.552724 0.149127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225658 episodes
GETTING ACTION FROM:
action 3, numVisits=225133, meanQ=4.939402, numObservations: 4
action 2, numVisits=508, meanQ=4.478134, numObservations: 4
action -1, numVisits=14, meanQ=3.032924, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.692172 0.82871 0.629226 0.893004 0.552724 0.149127 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 250
Initial state: 0 0.63994 0.836388 0.620455 0.866509 0.606384 0.420245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224493 episodes
GETTING ACTION FROM:
action 1, numVisits=224487, meanQ=5.140022, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.63994 0.836388 0.620455 0.866509 0.606384 0.420245 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.875464 0.544893 0.634296 0.804045 0.55812 0.856074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221037 episodes
GETTING ACTION FROM:
action 3, numVisits=214387, meanQ=4.989963, numObservations: 5
action -1, numVisits=6641, meanQ=2.850846, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-3.033333, numObservations: 2
action: 3
Next state: 1 0.875464 0.544893 0.634296 0.804045 0.55812 0.856074 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 252
Initial state: 0 0.734324 0.845217 0.639526 0.882483 0.629407 0.833877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157330 episodes
GETTING ACTION FROM:
action -1, numVisits=157288, meanQ=2.988616, numObservations: 1
action 2, numVisits=16, meanQ=1.124388, numObservations: 3
action 1, numVisits=18, meanQ=0.771667, numObservations: 3
action 3, numVisits=6, meanQ=-0.338333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: -1
Next state: 0 0.734324 0.845217 0.639526 0.882483 0.629407 0.833877 w: 1
Observation: 0 0.66375 0 0.723457 0 0.553574 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=157281, meanQ=5.020989, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 250369 episodes
GETTING ACTION FROM:
action 2, numVisits=407650, meanQ=5.219535, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.734324 0.845217 0.639526 0.882483 0.629407 0.833877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 253
Initial state: 0 0.509519 0.876017 0.126211 0.222409 0.510091 0.824349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225631 episodes
GETTING ACTION FROM:
action 1, numVisits=225622, meanQ=4.914593, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.509519 0.876017 0.126211 0.222409 0.510091 0.824349 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.583742 0.871982 0.0805521 0.627676 0.537387 0.878724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223183 episodes
GETTING ACTION FROM:
action 3, numVisits=223167, meanQ=4.971296, numObservations: 4
action 2, numVisits=11, meanQ=2.453636, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.583742 0.871982 0.0805521 0.627676 0.537387 0.878724 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 255
Initial state: 0 0.642084 0.864621 0.984916 0.216941 0.5521 0.894002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226073 episodes
GETTING ACTION FROM:
action 2, numVisits=226064, meanQ=4.942843, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.642084 0.864621 0.984916 0.216941 0.5521 0.894002 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 256
Initial state: 0 0.688439 0.875537 0.320801 0.0944454 0.609926 0.803648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225149 episodes
GETTING ACTION FROM:
action 3, numVisits=225130, meanQ=4.947926, numObservations: 4
action 1, numVisits=11, meanQ=2.081818, numObservations: 2
action 2, numVisits=4, meanQ=-0.504975, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.688439 0.875537 0.320801 0.0944454 0.609926 0.803648 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.572609 0.337953 0.624167 0.812329 0.59995 0.817822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227223 episodes
GETTING ACTION FROM:
action 2, numVisits=227216, meanQ=5.028289, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.572609 0.337953 0.624167 0.812329 0.59995 0.817822 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.566683 0.864084 0.688035 0.806952 0.482832 0.440896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224448 episodes
GETTING ACTION FROM:
action 3, numVisits=224442, meanQ=5.006126, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.566683 0.864084 0.688035 0.806952 0.482832 0.440896 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=34734, meanQ=8.340936, numObservations: 5
action 1, numVisits=1939, meanQ=8.199360, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283666 episodes
GETTING ACTION FROM:
action 2, numVisits=312962, meanQ=6.410154, numObservations: 5
action 1, numVisits=7377, meanQ=6.338143, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.566683 0.864084 0.688035 0.806952 0.482832 0.440896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 259
Initial state: 0 0.659986 0.861724 0.529411 0.82925 0.825636 0.180941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223255 episodes
GETTING ACTION FROM:
action 1, numVisits=223241, meanQ=4.941858, numObservations: 5
action 3, numVisits=8, meanQ=1.987500, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.659986 0.861724 0.529411 0.82925 0.825636 0.180941 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.124146 0.437187 0.622156 0.896816 0.67004 0.887401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218437 episodes
GETTING ACTION FROM:
action 1, numVisits=218366, meanQ=4.780330, numObservations: 4
action 0, numVisits=66, meanQ=1.407479, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.124146 0.437187 0.622156 0.896816 0.67004 0.887401 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=35580, meanQ=8.352627, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292726 episodes
GETTING ACTION FROM:
action 2, numVisits=328305, meanQ=6.227330, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.124146 0.437187 0.622156 0.896816 0.67004 0.887401 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 261
Initial state: 0 0.622761 0.892317 0.620128 0.890553 0.248204 0.10355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223616 episodes
GETTING ACTION FROM:
action 1, numVisits=222030, meanQ=5.009600, numObservations: 5
action -1, numVisits=1581, meanQ=2.887746, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.622761 0.892317 0.620128 0.890553 0.248204 0.10355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.441403 0.871532 0.593349 0.878767 0.562698 0.82573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226568 episodes
GETTING ACTION FROM:
action 3, numVisits=226544, meanQ=5.053500, numObservations: 4
action 2, numVisits=12, meanQ=1.832508, numObservations: 3
action 1, numVisits=8, meanQ=1.500013, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.441403 0.871532 0.593349 0.878767 0.562698 0.82573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.666828 0.845738 0.669596 0.862651 0.263039 0.404114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228107 episodes
GETTING ACTION FROM:
action 2, numVisits=228101, meanQ=5.035178, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.666828 0.845738 0.669596 0.862651 0.263039 0.404114 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.603719 0.867831 0.274756 0.606107 0.585358 0.829302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224889 episodes
GETTING ACTION FROM:
action 1, numVisits=224073, meanQ=4.953839, numObservations: 4
action 2, numVisits=684, meanQ=4.677354, numObservations: 4
action 0, numVisits=129, meanQ=4.339920, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.603719 0.867831 0.274756 0.606107 0.585358 0.829302 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.21862 0.898995 0.696986 0.804208 0.664582 0.853198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215370 episodes
GETTING ACTION FROM:
action 2, numVisits=215356, meanQ=4.903047, numObservations: 5
action 3, numVisits=5, meanQ=1.780000, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.21862 0.898995 0.696986 0.804208 0.664582 0.853198 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.664294 0.867037 0.671697 0.840382 0.613874 0.579919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222864 episodes
GETTING ACTION FROM:
action 1, numVisits=222359, meanQ=4.929422, numObservations: 5
action -1, numVisits=499, meanQ=1.757046, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.664294 0.867037 0.671697 0.840382 0.613874 0.579919 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.684482 0.726932 0.689622 0.899249 0.589863 0.899587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223392 episodes
GETTING ACTION FROM:
action 3, numVisits=223379, meanQ=4.938725, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.684482 0.726932 0.689622 0.899249 0.589863 0.899587 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.579329 0.833049 0.572697 0.145271 0.588262 0.844894 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225705 episodes
GETTING ACTION FROM:
action 1, numVisits=225697, meanQ=5.176348, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.579329 0.833049 0.572697 0.145271 0.588262 0.844894 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.113698 0.0715832 0.565927 0.889249 0.570408 0.83271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154670 episodes
GETTING ACTION FROM:
action 0, numVisits=154651, meanQ=3.142266, numObservations: 1
action 1, numVisits=13, meanQ=0.383846, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 0
Next state: 0 0.113698 0.0715832 0.565927 0.889249 0.570408 0.83271 w: 1
Observation: 0 0 0.145095 0 0.838885 0 0.767994 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=154631, meanQ=5.188386, numObservations: 5
action 3, numVisits=13, meanQ=2.846162, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 247774 episodes
GETTING ACTION FROM:
action 1, numVisits=402405, meanQ=5.237776, numObservations: 5
action 3, numVisits=13, meanQ=2.846162, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.113698 0.0715832 0.565927 0.889249 0.570408 0.83271 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=44420, meanQ=8.529616, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289142 episodes
GETTING ACTION FROM:
action 2, numVisits=333562, meanQ=6.380820, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.113698 0.0715832 0.565927 0.889249 0.570408 0.83271 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 270
Initial state: 0 0.178852 0.245079 0.63387 0.878516 0.509776 0.881061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225797 episodes
GETTING ACTION FROM:
action 2, numVisits=225670, meanQ=4.989541, numObservations: 4
action -1, numVisits=104, meanQ=4.282673, numObservations: 1
action 0, numVisits=21, meanQ=3.465138, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.178852 0.245079 0.63387 0.878516 0.509776 0.881061 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13776, meanQ=5.487732, numObservations: 3
action 3, numVisits=3076, meanQ=4.360373, numObservations: 5
action -1, numVisits=79, meanQ=3.814749, numObservations: 1
action 0, numVisits=60, meanQ=3.722835, numObservations: 1
action 1, numVisits=23, meanQ=2.912191, numObservations: 3
Sampled 266427 episodes
GETTING ACTION FROM:
action 2, numVisits=280203, meanQ=4.812732, numObservations: 3
action 3, numVisits=3076, meanQ=4.360373, numObservations: 5
action -1, numVisits=79, meanQ=3.814749, numObservations: 1
action 0, numVisits=60, meanQ=3.722835, numObservations: 1
action 1, numVisits=23, meanQ=2.912191, numObservations: 3
action: 2
Next state: 1 0.178852 0.245079 0.63387 0.878516 0.509776 0.881061 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 271
Initial state: 0 0.515881 0.899854 0.444271 0.250204 0.564889 0.851209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219086 episodes
GETTING ACTION FROM:
action 1, numVisits=211130, meanQ=4.962905, numObservations: 5
action -1, numVisits=7952, meanQ=2.916711, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.515881 0.899854 0.444271 0.250204 0.564889 0.851209 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.589488 0.810339 0.653497 0.845894 0.00227963 0.500798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224940 episodes
GETTING ACTION FROM:
action 3, numVisits=224934, meanQ=5.166192, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.589488 0.810339 0.653497 0.845894 0.00227963 0.500798 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 273
Initial state: 0 0.60988 0.849755 0.6227 0.82716 0.883032 0.120917 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219409 episodes
GETTING ACTION FROM:
action 1, numVisits=219197, meanQ=4.880366, numObservations: 4
action 0, numVisits=203, meanQ=2.327480, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.60988 0.849755 0.6227 0.82716 0.883032 0.120917 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.110118 0.0509005 0.507781 0.838132 0.58072 0.89358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228248 episodes
GETTING ACTION FROM:
action 3, numVisits=199109, meanQ=5.066750, numObservations: 4
action 2, numVisits=29095, meanQ=5.001320, numObservations: 3
action -1, numVisits=41, meanQ=3.968542, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.110118 0.0509005 0.507781 0.838132 0.58072 0.89358 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.641268 0.846864 0.629614 0.873511 0.90514 0.713749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224415 episodes
GETTING ACTION FROM:
action 2, numVisits=224409, meanQ=4.970506, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.641268 0.846864 0.629614 0.873511 0.90514 0.713749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 276
Initial state: 0 0.307811 0.152906 0.592381 0.841245 0.641925 0.843211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223731 episodes
GETTING ACTION FROM:
action 3, numVisits=223695, meanQ=5.031086, numObservations: 5
action 0, numVisits=31, meanQ=3.705634, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.307811 0.152906 0.592381 0.841245 0.641925 0.843211 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.561769 0.854936 0.565533 0.862898 0.0277025 0.442884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219292 episodes
GETTING ACTION FROM:
action 3, numVisits=219286, meanQ=4.981275, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.561769 0.854936 0.565533 0.862898 0.0277025 0.442884 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 278
Initial state: 0 0.639534 0.828992 0.867148 0.494573 0.616867 0.852719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222762 episodes
GETTING ACTION FROM:
action 1, numVisits=222693, meanQ=4.934417, numObservations: 5
action -1, numVisits=33, meanQ=3.721254, numObservations: 1
action 0, numVisits=34, meanQ=3.719289, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.639534 0.828992 0.867148 0.494573 0.616867 0.852719 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.638436 0.825876 0.264466 0.929372 0.674896 0.848422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221938 episodes
GETTING ACTION FROM:
action 1, numVisits=215818, meanQ=4.946649, numObservations: 4
action -1, numVisits=6116, meanQ=2.820188, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.638436 0.825876 0.264466 0.929372 0.674896 0.848422 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 280
Initial state: 0 0.191655 0.59443 0.613427 0.85922 0.529522 0.873421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226333 episodes
GETTING ACTION FROM:
action 3, numVisits=226227, meanQ=4.941408, numObservations: 4
action 0, numVisits=101, meanQ=4.244594, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.191655 0.59443 0.613427 0.85922 0.529522 0.873421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.406076 0.717492 0.609147 0.891949 0.550119 0.880395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227358 episodes
GETTING ACTION FROM:
action 1, numVisits=227255, meanQ=4.954708, numObservations: 3
action 0, numVisits=59, meanQ=4.044184, numObservations: 1
action -1, numVisits=41, meanQ=3.792024, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.406076 0.717492 0.609147 0.891949 0.550119 0.880395 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=37600, meanQ=8.304957, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285153 episodes
GETTING ACTION FROM:
action 2, numVisits=322753, meanQ=6.648839, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.406076 0.717492 0.609147 0.891949 0.550119 0.880395 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 282
Initial state: 0 0.499225 0.800316 0.572777 0.886285 0.563858 0.845798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226154 episodes
GETTING ACTION FROM:
action 1, numVisits=225948, meanQ=5.015660, numObservations: 5
action -1, numVisits=172, meanQ=4.490112, numObservations: 1
action 0, numVisits=25, meanQ=3.605164, numObservations: 2
action 2, numVisits=8, meanQ=1.245012, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.499225 0.800316 0.572777 0.886285 0.563858 0.845798 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5592, meanQ=7.839205, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 278942 episodes
GETTING ACTION FROM:
action 3, numVisits=284468, meanQ=5.926969, numObservations: 5
action 2, numVisits=57, meanQ=4.824212, numObservations: 5
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.499225 0.800316 0.572777 0.886285 0.563858 0.845798 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 283
Initial state: 0 0.0410628 0.903264 0.646416 0.82162 0.521276 0.879584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223247 episodes
GETTING ACTION FROM:
action 3, numVisits=223220, meanQ=4.993695, numObservations: 5
action 0, numVisits=23, meanQ=3.528464, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0410628 0.903264 0.646416 0.82162 0.521276 0.879584 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.601908 0.256709 0.584913 0.801602 0.579697 0.827393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215986 episodes
GETTING ACTION FROM:
action 3, numVisits=215980, meanQ=4.809249, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.601908 0.256709 0.584913 0.801602 0.579697 0.827393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.571855 0.896353 0.60568 0.810183 0.734347 0.626833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 210418 episodes
GETTING ACTION FROM:
action 3, numVisits=210407, meanQ=4.827769, numObservations: 4
action 2, numVisits=6, meanQ=1.015000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.571855 0.896353 0.60568 0.810183 0.734347 0.626833 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 286
Initial state: 0 0.562532 0.855793 0.26571 0.612268 0.638619 0.882306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217260 episodes
GETTING ACTION FROM:
action 2, numVisits=217055, meanQ=4.833084, numObservations: 4
action -1, numVisits=198, meanQ=4.348251, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.562532 0.855793 0.26571 0.612268 0.638619 0.882306 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=30192, meanQ=8.388232, numObservations: 5
action 1, numVisits=68, meanQ=7.557359, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281628 episodes
GETTING ACTION FROM:
action 3, numVisits=311450, meanQ=6.256397, numObservations: 5
action 1, numVisits=438, meanQ=5.928608, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.562532 0.855793 0.26571 0.612268 0.638619 0.882306 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 287
Initial state: 0 0.638635 0.849917 0.566386 0.850113 0.432734 0.220293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222171 episodes
GETTING ACTION FROM:
action 2, numVisits=222165, meanQ=4.934966, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.638635 0.849917 0.566386 0.850113 0.432734 0.220293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16417, meanQ=4.746395, numObservations: 3
action -1, numVisits=75, meanQ=4.067508, numObservations: 1
action 0, numVisits=43, meanQ=3.794100, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 288140 episodes
GETTING ACTION FROM:
action 3, numVisits=304557, meanQ=5.962130, numObservations: 3
action -1, numVisits=75, meanQ=4.067508, numObservations: 1
action 0, numVisits=43, meanQ=3.794100, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.638635 0.849917 0.566386 0.850113 0.432734 0.220293 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=4050, meanQ=8.258404, numObservations: 4
action 2, numVisits=4156, meanQ=8.239707, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 293805 episodes
GETTING ACTION FROM:
action 2, numVisits=259927, meanQ=6.395373, numObservations: 4
action 1, numVisits=42084, meanQ=6.373293, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.638635 0.849917 0.566386 0.850113 0.432734 0.220293 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=2232, meanQ=8.474947, numObservations: 3
action 2, numVisits=12, meanQ=5.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 298791 episodes
GETTING ACTION FROM:
action 1, numVisits=300982, meanQ=6.117998, numObservations: 3
action 2, numVisits=53, meanQ=5.113021, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.638635 0.849917 0.566386 0.850113 0.432734 0.220293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 288
Initial state: 0 0.578851 0.849214 0.660036 0.855283 0.72445 0.706199 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226513 episodes
GETTING ACTION FROM:
action 2, numVisits=226492, meanQ=4.986856, numObservations: 3
action 3, numVisits=16, meanQ=2.374381, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.578851 0.849214 0.660036 0.855283 0.72445 0.706199 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.514646 0.872152 0.483077 0.0537112 0.557714 0.889146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152126 episodes
GETTING ACTION FROM:
action 0, numVisits=152107, meanQ=2.968083, numObservations: 1
action 2, numVisits=13, meanQ=0.993085, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.514646 0.872152 0.483077 0.0537112 0.557714 0.889146 w: 1
Observation: 0 0 0.810752 0 0.136704 0 0.814681 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=152097, meanQ=5.007087, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 239101 episodes
GETTING ACTION FROM:
action 1, numVisits=391198, meanQ=5.149465, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.514646 0.872152 0.483077 0.0537112 0.557714 0.889146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action -1, numVisits=25850, meanQ=5.340949, numObservations: 1
action 3, numVisits=11, meanQ=0.635455, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284002 episodes
GETTING ACTION FROM:
action 3, numVisits=258288, meanQ=6.067636, numObservations: 3
action -1, numVisits=51569, meanQ=2.592825, numObservations: 1
action 0, numVisits=6, meanQ=-0.350000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.514646 0.872152 0.483077 0.0537112 0.557714 0.889146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 290
Initial state: 0 0.632602 0.842444 0.380022 0.917613 0.514822 0.867943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220444 episodes
GETTING ACTION FROM:
action 2, numVisits=220295, meanQ=4.934071, numObservations: 4
action -1, numVisits=135, meanQ=4.328008, numObservations: 1
action 3, numVisits=11, meanQ=2.453636, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.632602 0.842444 0.380022 0.917613 0.514822 0.867943 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.699197 0.884153 0.927674 0.614969 0.653218 0.827904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223979 episodes
GETTING ACTION FROM:
action 1, numVisits=223973, meanQ=4.970887, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.699197 0.884153 0.927674 0.614969 0.653218 0.827904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 292
Initial state: 0 0.214256 0.155719 0.571602 0.801665 0.505278 0.803303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216058 episodes
GETTING ACTION FROM:
action 3, numVisits=213336, meanQ=4.870441, numObservations: 5
action 2, numVisits=2667, meanQ=4.697959, numObservations: 5
action 0, numVisits=52, meanQ=3.867758, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.214256 0.155719 0.571602 0.801665 0.505278 0.803303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 293
Initial state: 0 0.710837 0.93194 0.697356 0.868357 0.548828 0.82582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225877 episodes
GETTING ACTION FROM:
action 3, numVisits=225855, meanQ=4.962758, numObservations: 4
action -1, numVisits=18, meanQ=3.266516, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.710837 0.93194 0.697356 0.868357 0.548828 0.82582 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.570884 0.945994 0.58176 0.808463 0.600024 0.835543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226350 episodes
GETTING ACTION FROM:
action 2, numVisits=226341, meanQ=5.023645, numObservations: 4
action 3, numVisits=4, meanQ=-0.007500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.570884 0.945994 0.58176 0.808463 0.600024 0.835543 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.545692 0.825412 0.684313 0.845622 0.340377 0.566855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223616 episodes
GETTING ACTION FROM:
action 2, numVisits=223525, meanQ=4.958871, numObservations: 5
action 3, numVisits=86, meanQ=4.171050, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.545692 0.825412 0.684313 0.845622 0.340377 0.566855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.679106 0.857305 0.69154 0.888911 0.402764 0.531556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226082 episodes
GETTING ACTION FROM:
action 1, numVisits=226076, meanQ=4.948445, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.679106 0.857305 0.69154 0.888911 0.402764 0.531556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16948, meanQ=4.867921, numObservations: 4
action -1, numVisits=227, meanQ=1.935871, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 1, numVisits=5, meanQ=-1.019980, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 289893 episodes
GETTING ACTION FROM:
action 2, numVisits=306841, meanQ=5.984034, numObservations: 4
action -1, numVisits=227, meanQ=1.935871, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 1, numVisits=5, meanQ=-1.019980, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.679106 0.857305 0.69154 0.888911 0.402764 0.531556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 297
Initial state: 0 0.546809 0.853638 0.476364 0.520406 0.647316 0.891008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226101 episodes
GETTING ACTION FROM:
action 3, numVisits=226060, meanQ=5.026608, numObservations: 4
action 0, numVisits=24, meanQ=3.600820, numObservations: 1
action 1, numVisits=12, meanQ=2.498342, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.546809 0.853638 0.476364 0.520406 0.647316 0.891008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 298
Initial state: 0 0.627991 0.833105 0.608125 0.865811 0.770103 0.245058 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226346 episodes
GETTING ACTION FROM:
action 3, numVisits=204767, meanQ=5.020148, numObservations: 4
action 2, numVisits=21526, meanQ=4.954641, numObservations: 5
action 0, numVisits=37, meanQ=3.879045, numObservations: 1
action 1, numVisits=14, meanQ=2.998571, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.627991 0.833105 0.608125 0.865811 0.770103 0.245058 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 299
Initial state: 0 0.253794 0.186488 0.635785 0.881256 0.605943 0.875211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229405 episodes
GETTING ACTION FROM:
action 1, numVisits=229380, meanQ=5.025443, numObservations: 3
action 3, numVisits=19, meanQ=2.152121, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.253794 0.186488 0.635785 0.881256 0.605943 0.875211 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37433, meanQ=8.334155, numObservations: 4
action 2, numVisits=50, meanQ=7.439406, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285864 episodes
GETTING ACTION FROM:
action 3, numVisits=323081, meanQ=5.952668, numObservations: 4
action 2, numVisits=264, meanQ=5.514093, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.253794 0.186488 0.635785 0.881256 0.605943 0.875211 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 300
Initial state: 0 0.564245 0.882035 0.679674 0.858936 0.180969 0.0993142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 144585 episodes
GETTING ACTION FROM:
action 0, numVisits=144548, meanQ=5.205328, numObservations: 3
action 2, numVisits=16, meanQ=1.623756, numObservations: 4
action 3, numVisits=16, meanQ=1.498775, numObservations: 4
action 1, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.564245 0.882035 0.679674 0.858936 0.180969 0.0993142 w: 1
Observation: 0 0 0.951887 0 0.927519 0 0.0564193 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48259, meanQ=8.015431, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 245639 episodes
GETTING ACTION FROM:
action 2, numVisits=293793, meanQ=5.433338, numObservations: 4
action -1, numVisits=57, meanQ=4.505927, numObservations: 1
action 0, numVisits=33, meanQ=4.124082, numObservations: 1
action 1, numVisits=19, meanQ=3.625795, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.564245 0.882035 0.679674 0.858936 0.180969 0.0993142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 301
Initial state: 0 0.531361 0.829735 0.273872 0.949539 0.592457 0.860884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224101 episodes
GETTING ACTION FROM:
action 3, numVisits=223580, meanQ=5.046974, numObservations: 5
action 0, numVisits=514, meanQ=1.770406, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 1 0.531361 0.829735 0.273872 0.949539 0.592457 0.860884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.60668 0.831054 0.608129 0.441374 0.639767 0.817591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217294 episodes
GETTING ACTION FROM:
action 1, numVisits=217245, meanQ=4.843474, numObservations: 4
action -1, numVisits=44, meanQ=3.789757, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.60668 0.831054 0.608129 0.441374 0.639767 0.817591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.0467822 0.357347 0.671665 0.898575 0.523094 0.892828 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219560 episodes
GETTING ACTION FROM:
action 3, numVisits=219526, meanQ=4.852774, numObservations: 4
action 0, numVisits=22, meanQ=3.261315, numObservations: 1
action 1, numVisits=9, meanQ=0.331122, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0467822 0.357347 0.671665 0.898575 0.523094 0.892828 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.667695 0.806188 0.129056 0.0427793 0.543673 0.829297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224598 episodes
GETTING ACTION FROM:
action 3, numVisits=224414, meanQ=4.908167, numObservations: 4
action -1, numVisits=94, meanQ=4.191332, numObservations: 1
action 0, numVisits=84, meanQ=4.137764, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.667695 0.806188 0.129056 0.0427793 0.543673 0.829297 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.616672 0.814687 0.591631 0.882819 0.808005 0.795613 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224758 episodes
GETTING ACTION FROM:
action 3, numVisits=224750, meanQ=4.985669, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.616672 0.814687 0.591631 0.882819 0.808005 0.795613 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 306
Initial state: 0 0.669583 0.835162 0.245985 0.941849 0.618052 0.894024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226380 episodes
GETTING ACTION FROM:
action 1, numVisits=226320, meanQ=5.011219, numObservations: 4
action 0, numVisits=51, meanQ=4.026781, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.669583 0.835162 0.245985 0.941849 0.618052 0.894024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.67721 0.87738 0.561321 0.858944 0.125968 0.642876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225914 episodes
GETTING ACTION FROM:
action 1, numVisits=225904, meanQ=5.044936, numObservations: 4
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.67721 0.87738 0.561321 0.858944 0.125968 0.642876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.939247 0.0901611 0.519043 0.805405 0.669525 0.872734 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218460 episodes
GETTING ACTION FROM:
action 3, numVisits=210509, meanQ=4.948831, numObservations: 4
action 0, numVisits=7943, meanQ=3.170889, numObservations: 2
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.939247 0.0901611 0.519043 0.805405 0.669525 0.872734 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.58914 0.801235 0.946924 0.377429 0.555719 0.828803 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225421 episodes
GETTING ACTION FROM:
action 2, numVisits=225249, meanQ=4.997270, numObservations: 4
action 0, numVisits=91, meanQ=4.270204, numObservations: 1
action 3, numVisits=52, meanQ=4.022892, numObservations: 4
action -1, numVisits=24, meanQ=3.546828, numObservations: 1
action 1, numVisits=5, meanQ=1.794000, numObservations: 3
action: 2
Next state: 2 0.58914 0.801235 0.946924 0.377429 0.555719 0.828803 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 310
Initial state: 0 0.691044 0.854206 0.562641 0.820759 0.45946 0.967242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227782 episodes
GETTING ACTION FROM:
action 2, numVisits=227729, meanQ=5.011254, numObservations: 4
action -1, numVisits=49, meanQ=4.005493, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.691044 0.854206 0.562641 0.820759 0.45946 0.967242 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 311
Initial state: 0 0.509814 0.850829 0.440794 0.479763 0.698341 0.824896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222412 episodes
GETTING ACTION FROM:
action 1, numVisits=221620, meanQ=4.962824, numObservations: 5
action -1, numVisits=788, meanQ=1.973367, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.509814 0.850829 0.440794 0.479763 0.698341 0.824896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 312
Initial state: 0 0.67402 0.827586 0.962136 0.670993 0.641977 0.849184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154197 episodes
GETTING ACTION FROM:
action 0, numVisits=154191, meanQ=2.983686, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.67402 0.827586 0.962136 0.670993 0.641977 0.849184 w: 1
Observation: 0 0 0.920901 0 0.642054 0 0.854429 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=154140, meanQ=5.060512, numObservations: 5
action 0, numVisits=28, meanQ=3.740563, numObservations: 1
action -1, numVisits=15, meanQ=3.097436, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 246137 episodes
GETTING ACTION FROM:
action 1, numVisits=400275, meanQ=5.048728, numObservations: 5
action 0, numVisits=30, meanQ=3.732296, numObservations: 1
action -1, numVisits=15, meanQ=3.097436, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.67402 0.827586 0.962136 0.670993 0.641977 0.849184 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 313
Initial state: 0 0.657906 0.83877 0.792574 0.782321 0.518748 0.866126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221863 episodes
GETTING ACTION FROM:
action 3, numVisits=213848, meanQ=4.944542, numObservations: 4
action -1, numVisits=8008, meanQ=2.919240, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.657906 0.83877 0.792574 0.782321 0.518748 0.866126 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.575249 0.870947 0.598031 0.876299 0.0266077 0.75236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216438 episodes
GETTING ACTION FROM:
action 2, numVisits=216428, meanQ=4.856505, numObservations: 4
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.575249 0.870947 0.598031 0.876299 0.0266077 0.75236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.665865 0.801417 0.513212 0.817473 0.38023 0.66143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221800 episodes
GETTING ACTION FROM:
action 3, numVisits=221748, meanQ=4.925721, numObservations: 5
action 0, numVisits=40, meanQ=3.728651, numObservations: 1
action 1, numVisits=8, meanQ=0.501263, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.665865 0.801417 0.513212 0.817473 0.38023 0.66143 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30926, meanQ=8.414756, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 292038 episodes
GETTING ACTION FROM:
action 2, numVisits=322963, meanQ=6.234599, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.665865 0.801417 0.513212 0.817473 0.38023 0.66143 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 316
Initial state: 0 0.565502 0.819508 0.743259 0.299217 0.545399 0.847288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224905 episodes
GETTING ACTION FROM:
action 3, numVisits=224888, meanQ=4.996332, numObservations: 4
action 1, numVisits=12, meanQ=2.509183, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.565502 0.819508 0.743259 0.299217 0.545399 0.847288 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.530275 0.810933 0.0664486 0.0236179 0.693489 0.826967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223203 episodes
GETTING ACTION FROM:
action 2, numVisits=218129, meanQ=4.956924, numObservations: 5
action 1, numVisits=5069, meanQ=4.852543, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.530275 0.810933 0.0664486 0.0236179 0.693489 0.826967 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30411, meanQ=8.406108, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287450 episodes
GETTING ACTION FROM:
action 1, numVisits=317858, meanQ=5.893154, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.530275 0.810933 0.0664486 0.0236179 0.693489 0.826967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7628, meanQ=7.238173, numObservations: 3
action 1, numVisits=431, meanQ=7.013813, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 297791 episodes
GETTING ACTION FROM:
action 3, numVisits=304761, meanQ=6.203440, numObservations: 3
action 1, numVisits=1089, meanQ=5.991526, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.530275 0.810933 0.0664486 0.0236179 0.693489 0.826967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 318
Initial state: 0 0.685951 0.80037 0.50009 0.845815 0.700554 0.359079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 163090 episodes
GETTING ACTION FROM:
action 0, numVisits=163083, meanQ=5.735755, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.685951 0.80037 0.50009 0.845815 0.700554 0.359079 w: 1
Observation: 0 0 0.813674 0 0.849427 0 0.379632 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=44723, meanQ=8.354198, numObservations: 3
action 2, numVisits=105, meanQ=7.738290, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 249329 episodes
GETTING ACTION FROM:
action 1, numVisits=292525, meanQ=5.524821, numObservations: 3
action 2, numVisits=1630, meanQ=5.358196, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.685951 0.80037 0.50009 0.845815 0.700554 0.359079 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 319
Initial state: 0 0.660267 0.821425 0.168152 0.643863 0.654847 0.897106 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222916 episodes
GETTING ACTION FROM:
action 3, numVisits=222848, meanQ=4.910371, numObservations: 4
action 0, numVisits=48, meanQ=3.877206, numObservations: 1
action -1, numVisits=18, meanQ=3.219927, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.660267 0.821425 0.168152 0.643863 0.654847 0.897106 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 320
Initial state: 0 0.583848 0.879086 0.789538 0.450753 0.583081 0.833542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154962 episodes
GETTING ACTION FROM:
action 0, numVisits=154952, meanQ=3.113536, numObservations: 1
action 3, numVisits=5, meanQ=-0.622000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.583848 0.879086 0.789538 0.450753 0.583081 0.833542 w: 1
Observation: 0 0 0.891424 0 0.397391 0 0.886995 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=154729, meanQ=5.193059, numObservations: 5
action 2, numVisits=183, meanQ=4.579565, numObservations: 4
action -1, numVisits=36, meanQ=4.023266, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 244847 episodes
GETTING ACTION FROM:
action 1, numVisits=399576, meanQ=5.317947, numObservations: 5
action 2, numVisits=183, meanQ=4.579565, numObservations: 4
action -1, numVisits=36, meanQ=4.023266, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.583848 0.879086 0.789538 0.450753 0.583081 0.833542 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 321
Initial state: 0 0.544885 0.819023 0.5432 0.803572 0.619344 0.545165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225909 episodes
GETTING ACTION FROM:
action 2, numVisits=225838, meanQ=4.967913, numObservations: 4
action 0, numVisits=63, meanQ=4.094598, numObservations: 1
action 1, numVisits=5, meanQ=1.780000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.544885 0.819023 0.5432 0.803572 0.619344 0.545165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.52882 0.812596 0.656579 0.288423 0.592812 0.888853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223611 episodes
GETTING ACTION FROM:
action 3, numVisits=223224, meanQ=5.067915, numObservations: 5
action 2, numVisits=328, meanQ=4.443316, numObservations: 4
action -1, numVisits=55, meanQ=4.112755, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.52882 0.812596 0.656579 0.288423 0.592812 0.888853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.0134814 0.61414 0.510239 0.810473 0.508791 0.862367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220007 episodes
GETTING ACTION FROM:
action 2, numVisits=220001, meanQ=4.985083, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0134814 0.61414 0.510239 0.810473 0.508791 0.862367 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.294912 0.0695603 0.626259 0.838522 0.696075 0.802485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225408 episodes
GETTING ACTION FROM:
action 1, numVisits=225362, meanQ=5.025474, numObservations: 4
action -1, numVisits=34, meanQ=3.804772, numObservations: 1
action 2, numVisits=9, meanQ=2.333333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.294912 0.0695603 0.626259 0.838522 0.696075 0.802485 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31759, meanQ=8.401519, numObservations: 5
action 3, numVisits=5, meanQ=0.602040, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284271 episodes
GETTING ACTION FROM:
action 2, numVisits=316030, meanQ=6.158637, numObservations: 5
action 3, numVisits=5, meanQ=0.602040, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.294912 0.0695603 0.626259 0.838522 0.696075 0.802485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 325
Initial state: 0 0.608456 0.808055 0.100603 0.420657 0.575324 0.895018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217698 episodes
GETTING ACTION FROM:
action 3, numVisits=209755, meanQ=4.949963, numObservations: 4
action 0, numVisits=7937, meanQ=3.063075, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.608456 0.808055 0.100603 0.420657 0.575324 0.895018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 326
Initial state: 0 0.603435 0.832246 0.565588 0.869168 0.177336 0.694822 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225109 episodes
GETTING ACTION FROM:
action 1, numVisits=225103, meanQ=4.972798, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.603435 0.832246 0.565588 0.869168 0.177336 0.694822 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.561945 0.803774 0.133779 0.734321 0.598096 0.80062 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228504 episodes
GETTING ACTION FROM:
action 1, numVisits=228496, meanQ=5.006015, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.561945 0.803774 0.133779 0.734321 0.598096 0.80062 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.629264 0.842997 0.688282 0.873963 0.79016 0.766121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221231 episodes
GETTING ACTION FROM:
action 2, numVisits=220913, meanQ=4.952384, numObservations: 5
action 3, numVisits=284, meanQ=4.429843, numObservations: 4
action 0, numVisits=28, meanQ=3.533873, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.629264 0.842997 0.688282 0.873963 0.79016 0.766121 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.502321 0.874481 0.404398 0.0804858 0.5361 0.892157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223451 episodes
GETTING ACTION FROM:
action 3, numVisits=223445, meanQ=4.971329, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.502321 0.874481 0.404398 0.0804858 0.5361 0.892157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 330
Initial state: 0 0.791214 0.158215 0.619342 0.885076 0.630605 0.892242 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 160315 episodes
GETTING ACTION FROM:
action 0, numVisits=160234, meanQ=5.919837, numObservations: 3
action -1, numVisits=78, meanQ=2.704910, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.791214 0.158215 0.619342 0.885076 0.630605 0.892242 w: 1
Observation: 0 0 0.210391 0 0.886791 0 0.978739 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=52278, meanQ=8.076021, numObservations: 5
action 2, numVisits=7, meanQ=5.568571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 245143 episodes
GETTING ACTION FROM:
action 3, numVisits=297133, meanQ=5.557543, numObservations: 5
action 2, numVisits=265, meanQ=5.125320, numObservations: 4
action -1, numVisits=30, meanQ=4.247864, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.791214 0.158215 0.619342 0.885076 0.630605 0.892242 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=20822, meanQ=7.606648, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 260681 episodes
GETTING ACTION FROM:
action 3, numVisits=281501, meanQ=5.041985, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.791214 0.158215 0.619342 0.885076 0.630605 0.892242 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 331
Initial state: 0 0.65801 0.882266 0.0735073 0.0207277 0.530928 0.864642 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155684 episodes
GETTING ACTION FROM:
action -1, numVisits=153645, meanQ=2.909177, numObservations: 1
action 0, numVisits=2036, meanQ=1.776781, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.65801 0.882266 0.0735073 0.0207277 0.530928 0.864642 w: 1
Observation: 0 0.558276 0 0.00646821 0 0.53341 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153593, meanQ=4.952188, numObservations: 4
action -1, numVisits=46, meanQ=3.918172, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 246833 episodes
GETTING ACTION FROM:
action 3, numVisits=400426, meanQ=5.099629, numObservations: 4
action -1, numVisits=46, meanQ=3.918172, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.65801 0.882266 0.0735073 0.0207277 0.530928 0.864642 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 332
Initial state: 0 0.47122 0.415054 0.500587 0.840727 0.525927 0.861582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221480 episodes
GETTING ACTION FROM:
action 2, numVisits=221451, meanQ=4.911711, numObservations: 5
action 0, numVisits=23, meanQ=3.393127, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.47122 0.415054 0.500587 0.840727 0.525927 0.861582 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16407, meanQ=4.608974, numObservations: 5
action -1, numVisits=386, meanQ=2.666513, numObservations: 1
action 2, numVisits=22, meanQ=1.445459, numObservations: 3
action 1, numVisits=7, meanQ=0.985714, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 277776 episodes
GETTING ACTION FROM:
action 3, numVisits=294183, meanQ=5.753226, numObservations: 5
action -1, numVisits=386, meanQ=2.666513, numObservations: 1
action 2, numVisits=22, meanQ=1.445459, numObservations: 3
action 1, numVisits=7, meanQ=0.985714, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.47122 0.415054 0.500587 0.840727 0.525927 0.861582 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 333
Initial state: 0 0.197985 0.820877 0.546365 0.880036 0.530283 0.833008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224273 episodes
GETTING ACTION FROM:
action 3, numVisits=224241, meanQ=4.999687, numObservations: 5
action 0, numVisits=19, meanQ=3.402426, numObservations: 1
action 1, numVisits=10, meanQ=1.997010, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.197985 0.820877 0.546365 0.880036 0.530283 0.833008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.649853 0.886207 0.600525 0.842888 0.127348 0.10499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226242 episodes
GETTING ACTION FROM:
action 1, numVisits=226164, meanQ=4.943671, numObservations: 4
action -1, numVisits=36, meanQ=3.749402, numObservations: 1
action 2, numVisits=29, meanQ=3.268972, numObservations: 4
action 3, numVisits=11, meanQ=2.452745, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.649853 0.886207 0.600525 0.842888 0.127348 0.10499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.607957 0.838611 0.976563 0.663828 0.564239 0.859829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224008 episodes
GETTING ACTION FROM:
action 2, numVisits=223992, meanQ=4.979930, numObservations: 5
action 3, numVisits=8, meanQ=2.250025, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.607957 0.838611 0.976563 0.663828 0.564239 0.859829 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 336
Initial state: 0 0.526548 0.844377 0.649557 0.850115 0.986645 0.599941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229141 episodes
GETTING ACTION FROM:
action 3, numVisits=229028, meanQ=5.035624, numObservations: 3
action 0, numVisits=53, meanQ=4.045992, numObservations: 1
action -1, numVisits=42, meanQ=3.954763, numObservations: 1
action 1, numVisits=17, meanQ=3.110588, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.526548 0.844377 0.649557 0.850115 0.986645 0.599941 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 337
Initial state: 0 0.672746 0.816468 0.288098 0.439625 0.595255 0.846333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223043 episodes
GETTING ACTION FROM:
action 3, numVisits=223037, meanQ=4.999461, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.672746 0.816468 0.288098 0.439625 0.595255 0.846333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.627996 0.842738 0.510384 0.873226 0.132059 0.947678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223680 episodes
GETTING ACTION FROM:
action 1, numVisits=223643, meanQ=5.001754, numObservations: 5
action 0, numVisits=29, meanQ=3.688485, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.627996 0.842738 0.510384 0.873226 0.132059 0.947678 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.659342 0.813317 0.646336 0.826623 0.763163 0.928408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227384 episodes
GETTING ACTION FROM:
action 1, numVisits=227378, meanQ=5.014143, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.659342 0.813317 0.646336 0.826623 0.763163 0.928408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 340
Initial state: 0 0.518316 0.825111 0.646955 0.89875 0.914066 0.86866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217266 episodes
GETTING ACTION FROM:
action 1, numVisits=217246, meanQ=5.045311, numObservations: 5
action 2, numVisits=15, meanQ=3.126000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.518316 0.825111 0.646955 0.89875 0.914066 0.86866 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.00158232 0.070516 0.673639 0.812291 0.514456 0.896348 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225954 episodes
GETTING ACTION FROM:
action 3, numVisits=225882, meanQ=5.035725, numObservations: 4
action 0, numVisits=65, meanQ=4.178554, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.00158232 0.070516 0.673639 0.812291 0.514456 0.896348 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 342
Initial state: 0 0.211026 0.91393 0.597298 0.840681 0.564877 0.873255 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214874 episodes
GETTING ACTION FROM:
action 3, numVisits=214836, meanQ=4.819531, numObservations: 5
action 2, numVisits=27, meanQ=2.484822, numObservations: 4
action 1, numVisits=7, meanQ=0.711443, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.211026 0.91393 0.597298 0.840681 0.564877 0.873255 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.0746353 0.335142 0.519633 0.863923 0.531788 0.87503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222933 episodes
GETTING ACTION FROM:
action 3, numVisits=222657, meanQ=4.957673, numObservations: 5
action 2, numVisits=271, meanQ=4.525759, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0746353 0.335142 0.519633 0.863923 0.531788 0.87503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.897528 0.0812747 0.663562 0.820809 0.692265 0.871104 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225547 episodes
GETTING ACTION FROM:
action 2, numVisits=225541, meanQ=5.013165, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.897528 0.0812747 0.663562 0.820809 0.692265 0.871104 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.528086 0.86647 0.644211 0.882788 0.490807 0.628016 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 153517 episodes
GETTING ACTION FROM:
action 0, numVisits=153509, meanQ=2.945041, numObservations: 1
action 1, numVisits=4, meanQ=-0.999975, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.528086 0.86647 0.644211 0.882788 0.490807 0.628016 w: 1
Observation: 0 0 0.784858 0 0.882125 0 0.650168 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153389, meanQ=4.964536, numObservations: 5
action 0, numVisits=84, meanQ=4.207220, numObservations: 1
action -1, numVisits=33, meanQ=3.693568, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 244516 episodes
GETTING ACTION FROM:
action 1, numVisits=397900, meanQ=4.904447, numObservations: 5
action 0, numVisits=88, meanQ=4.147812, numObservations: 1
action -1, numVisits=34, meanQ=3.625596, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.528086 0.86647 0.644211 0.882788 0.490807 0.628016 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 346
Initial state: 0 0.682661 0.807088 0.881896 0.481317 0.690896 0.891399 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227072 episodes
GETTING ACTION FROM:
action 3, numVisits=226554, meanQ=4.986714, numObservations: 4
action 1, numVisits=512, meanQ=4.666244, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.682661 0.807088 0.881896 0.481317 0.690896 0.891399 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.539685 0.886658 0.100308 0.207049 0.586305 0.889749 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223136 episodes
GETTING ACTION FROM:
action 1, numVisits=223083, meanQ=5.000449, numObservations: 5
action 0, numVisits=46, meanQ=3.935563, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.539685 0.886658 0.100308 0.207049 0.586305 0.889749 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 348
Initial state: 0 0.626673 0.888649 0.546479 0.830329 0.35503 0.162853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224030 episodes
GETTING ACTION FROM:
action 3, numVisits=223751, meanQ=5.016979, numObservations: 5
action 1, numVisits=274, meanQ=4.605533, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.626673 0.888649 0.546479 0.830329 0.35503 0.162853 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25667, meanQ=8.533227, numObservations: 3
action 2, numVisits=44, meanQ=7.544777, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285713 episodes
GETTING ACTION FROM:
action 1, numVisits=310032, meanQ=6.472632, numObservations: 5
action 2, numVisits=1392, meanQ=6.285013, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.626673 0.888649 0.546479 0.830329 0.35503 0.162853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 349
Initial state: 0 0.526221 0.869518 0.968347 0.0888354 0.693855 0.800902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229930 episodes
GETTING ACTION FROM:
action 2, numVisits=229794, meanQ=5.027756, numObservations: 3
action -1, numVisits=59, meanQ=4.104035, numObservations: 1
action 0, numVisits=53, meanQ=4.068917, numObservations: 1
action 1, numVisits=12, meanQ=2.833350, numObservations: 3
action 3, numVisits=12, meanQ=2.323333, numObservations: 3
action: 2
Next state: 2 0.526221 0.869518 0.968347 0.0888354 0.693855 0.800902 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 350
Initial state: 0 0.624026 0.837113 0.821219 0.755603 0.581459 0.865183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221800 episodes
GETTING ACTION FROM:
action 3, numVisits=220231, meanQ=5.039573, numObservations: 5
action 0, numVisits=1472, meanQ=2.774776, numObservations: 1
action -1, numVisits=92, meanQ=2.350170, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 1 0.624026 0.837113 0.821219 0.755603 0.581459 0.865183 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 351
Initial state: 0 0.479318 0.0415539 0.641098 0.805571 0.563095 0.801882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228301 episodes
GETTING ACTION FROM:
action 1, numVisits=228105, meanQ=4.950297, numObservations: 3
action -1, numVisits=191, meanQ=4.411632, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.479318 0.0415539 0.641098 0.805571 0.563095 0.801882 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37582, meanQ=8.314044, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 292727 episodes
GETTING ACTION FROM:
action 3, numVisits=330306, meanQ=6.177391, numObservations: 3
action 2, numVisits=5, meanQ=2.598000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.479318 0.0415539 0.641098 0.805571 0.563095 0.801882 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 352
Initial state: 0 0.600438 0.878447 0.233682 0.647465 0.541813 0.82579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223687 episodes
GETTING ACTION FROM:
action 3, numVisits=223613, meanQ=5.030501, numObservations: 3
action -1, numVisits=48, meanQ=3.983630, numObservations: 1
action 1, numVisits=12, meanQ=2.664167, numObservations: 3
action 2, numVisits=12, meanQ=2.323333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.600438 0.878447 0.233682 0.647465 0.541813 0.82579 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.882541 0.222627 0.691796 0.861328 0.607838 0.863293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223676 episodes
GETTING ACTION FROM:
action 1, numVisits=223653, meanQ=4.938317, numObservations: 5
action 0, numVisits=18, meanQ=3.128359, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.882541 0.222627 0.691796 0.861328 0.607838 0.863293 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 354
Initial state: 0 0.594594 0.810129 0.699983 0.82006 0.232798 0.666556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226137 episodes
GETTING ACTION FROM:
action 3, numVisits=226087, meanQ=5.000162, numObservations: 3
action 0, numVisits=46, meanQ=3.969811, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.594594 0.810129 0.699983 0.82006 0.232798 0.666556 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=37471, meanQ=8.324326, numObservations: 4
action 2, numVisits=14, meanQ=6.426429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 285958 episodes
GETTING ACTION FROM:
action 1, numVisits=323302, meanQ=6.285974, numObservations: 4
action 2, numVisits=141, meanQ=5.607945, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.594594 0.810129 0.699983 0.82006 0.232798 0.666556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 355
Initial state: 0 0.469136 0.743379 0.685637 0.864098 0.531644 0.810029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223663 episodes
GETTING ACTION FROM:
action 1, numVisits=223548, meanQ=4.962580, numObservations: 5
action -1, numVisits=104, meanQ=4.277536, numObservations: 1
action 3, numVisits=8, meanQ=1.747513, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.469136 0.743379 0.685637 0.864098 0.531644 0.810029 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=25663, meanQ=8.547040, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 290468 episodes
GETTING ACTION FROM:
action 3, numVisits=316117, meanQ=6.395364, numObservations: 3
action 2, numVisits=16, meanQ=4.499375, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.469136 0.743379 0.685637 0.864098 0.531644 0.810029 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 356
Initial state: 0 0.642922 0.833744 0.518422 0.861547 0.349905 0.785411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226944 episodes
GETTING ACTION FROM:
action 3, numVisits=226866, meanQ=5.029697, numObservations: 4
action 0, numVisits=74, meanQ=4.217921, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.642922 0.833744 0.518422 0.861547 0.349905 0.785411 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31846, meanQ=8.403578, numObservations: 3
action 2, numVisits=21, meanQ=6.903810, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290998 episodes
GETTING ACTION FROM:
action 1, numVisits=322827, meanQ=6.180204, numObservations: 3
action 2, numVisits=38, meanQ=4.733950, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.642922 0.833744 0.518422 0.861547 0.349905 0.785411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=8192, meanQ=7.596336, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291782 episodes
GETTING ACTION FROM:
action 1, numVisits=299967, meanQ=5.801205, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.642922 0.833744 0.518422 0.861547 0.349905 0.785411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 357
Initial state: 0 0.320464 0.0163275 0.663096 0.837373 0.529954 0.898886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224016 episodes
GETTING ACTION FROM:
action 3, numVisits=223902, meanQ=4.992167, numObservations: 5
action -1, numVisits=66, meanQ=4.116895, numObservations: 1
action 0, numVisits=46, meanQ=3.924029, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.320464 0.0163275 0.663096 0.837373 0.529954 0.898886 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.569031 0.884321 0.076463 0.72375 0.693286 0.83989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 159597 episodes
GETTING ACTION FROM:
action 0, numVisits=159592, meanQ=5.960678, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.569031 0.884321 0.076463 0.72375 0.693286 0.83989 w: 1
Observation: 0 0 0.795066 0 0.641334 0 0.937488 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=47242, meanQ=8.261005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 247881 episodes
GETTING ACTION FROM:
action 3, numVisits=295121, meanQ=5.542455, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.569031 0.884321 0.076463 0.72375 0.693286 0.83989 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 359
Initial state: 0 0.563838 0.885368 0.281512 0.193132 0.621332 0.811739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223648 episodes
GETTING ACTION FROM:
action 2, numVisits=223595, meanQ=4.997220, numObservations: 5
action 0, numVisits=38, meanQ=3.848305, numObservations: 1
action -1, numVisits=13, meanQ=2.941109, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.563838 0.885368 0.281512 0.193132 0.621332 0.811739 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=25714, meanQ=8.530984, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 287747 episodes
GETTING ACTION FROM:
action 3, numVisits=183780, meanQ=6.231537, numObservations: 4
action 1, numVisits=129683, meanQ=6.204455, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.563838 0.885368 0.281512 0.193132 0.621332 0.811739 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 360
Initial state: 0 0.548584 0.833182 0.513891 0.805216 0.235025 0.24435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216888 episodes
GETTING ACTION FROM:
action 2, numVisits=216853, meanQ=4.888779, numObservations: 5
action 0, numVisits=18, meanQ=3.232474, numObservations: 1
action 3, numVisits=11, meanQ=1.907282, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.548584 0.833182 0.513891 0.805216 0.235025 0.24435 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.550239 0.804118 0.53222 0.894467 0.753574 0.652744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224049 episodes
GETTING ACTION FROM:
action 1, numVisits=224034, meanQ=4.958889, numObservations: 5
action 3, numVisits=10, meanQ=2.598000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.550239 0.804118 0.53222 0.894467 0.753574 0.652744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.54322 0.865932 0.64329 0.895212 0.176754 0.191439 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225636 episodes
GETTING ACTION FROM:
action 3, numVisits=225630, meanQ=4.967800, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.54322 0.865932 0.64329 0.895212 0.176754 0.191439 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31308, meanQ=8.419738, numObservations: 4
action 1, numVisits=53, meanQ=7.560381, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 279744 episodes
GETTING ACTION FROM:
action 2, numVisits=309529, meanQ=6.245441, numObservations: 4
action 1, numVisits=1576, meanQ=6.078825, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.54322 0.865932 0.64329 0.895212 0.176754 0.191439 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 363
Initial state: 0 0.500628 0.894559 0.944649 0.474606 0.588066 0.82499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224421 episodes
GETTING ACTION FROM:
action 2, numVisits=224402, meanQ=4.972092, numObservations: 4
action 3, numVisits=13, meanQ=0.383092, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.500628 0.894559 0.944649 0.474606 0.588066 0.82499 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 364
Initial state: 0 0.4844 0.335754 0.583133 0.8286 0.606284 0.876583 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 154157 episodes
GETTING ACTION FROM:
action 0, numVisits=154131, meanQ=3.172212, numObservations: 1
action 3, numVisits=17, meanQ=-0.888824, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action: 0
Next state: 0 0.4844 0.335754 0.583133 0.8286 0.606284 0.876583 w: 1
Observation: 0 0 0.275944 0 0.861894 0 0.961416 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=154087, meanQ=5.194992, numObservations: 5
action -1, numVisits=38, meanQ=4.054440, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 246025 episodes
GETTING ACTION FROM:
action 3, numVisits=400103, meanQ=4.968469, numObservations: 5
action -1, numVisits=47, meanQ=3.925503, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.4844 0.335754 0.583133 0.8286 0.606284 0.876583 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 365
Initial state: 0 0.622748 0.875552 0.51187 0.899525 0.690987 0.297497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225694 episodes
GETTING ACTION FROM:
action 3, numVisits=225660, meanQ=4.942063, numObservations: 4
action -1, numVisits=23, meanQ=3.426103, numObservations: 1
action 1, numVisits=6, meanQ=1.001683, numObservations: 3
action 2, numVisits=3, meanQ=-2.966667, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.622748 0.875552 0.51187 0.899525 0.690987 0.297497 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=36557, meanQ=8.371916, numObservations: 5
action 2, numVisits=275, meanQ=8.008910, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 284170 episodes
GETTING ACTION FROM:
action 1, numVisits=285248, meanQ=5.931949, numObservations: 5
action 2, numVisits=35751, meanQ=5.907492, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.622748 0.875552 0.51187 0.899525 0.690987 0.297497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 366
Initial state: 0 0.657639 0.844256 0.644652 0.843473 0.321257 0.264425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225334 episodes
GETTING ACTION FROM:
action 3, numVisits=225328, meanQ=5.008174, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.657639 0.844256 0.644652 0.843473 0.321257 0.264425 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31513, meanQ=8.411403, numObservations: 4
action 1, numVisits=7, meanQ=5.568571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289382 episodes
GETTING ACTION FROM:
action 2, numVisits=320891, meanQ=6.137061, numObservations: 4
action 1, numVisits=11, meanQ=3.545464, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.657639 0.844256 0.644652 0.843473 0.321257 0.264425 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 367
Initial state: 0 0.579228 0.896414 0.638154 0.991534 0.678917 0.895678 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223758 episodes
GETTING ACTION FROM:
action 3, numVisits=223637, meanQ=5.029670, numObservations: 5
action -1, numVisits=97, meanQ=4.269976, numObservations: 1
action 1, numVisits=21, meanQ=3.376676, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.579228 0.896414 0.638154 0.991534 0.678917 0.895678 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.662502 0.818427 0.331287 0.569932 0.697802 0.828897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226389 episodes
GETTING ACTION FROM:
action 1, numVisits=226381, meanQ=5.020720, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.662502 0.818427 0.331287 0.569932 0.697802 0.828897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.665937 0.863807 0.551414 0.897709 0.0166234 0.0579314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222516 episodes
GETTING ACTION FROM:
action 2, numVisits=222504, meanQ=4.984526, numObservations: 5
action 3, numVisits=7, meanQ=1.568600, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.665937 0.863807 0.551414 0.897709 0.0166234 0.0579314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.870195 0.640052 0.676504 0.890005 0.560965 0.868965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225783 episodes
GETTING ACTION FROM:
action 1, numVisits=225777, meanQ=5.000577, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.870195 0.640052 0.676504 0.890005 0.560965 0.868965 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 371
Initial state: 0 0.231826 0.987827 0.676466 0.873881 0.525417 0.837395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224037 episodes
GETTING ACTION FROM:
action 1, numVisits=223961, meanQ=5.021923, numObservations: 5
action -1, numVisits=42, meanQ=3.926582, numObservations: 1
action 0, numVisits=32, meanQ=3.780195, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.231826 0.987827 0.676466 0.873881 0.525417 0.837395 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16728, meanQ=5.251167, numObservations: 4
action 2, numVisits=7, meanQ=2.711429, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 277433 episodes
GETTING ACTION FROM:
action 2, numVisits=214123, meanQ=5.883933, numObservations: 5
action 1, numVisits=80041, meanQ=4.770721, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=4, meanQ=0.475000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.231826 0.987827 0.676466 0.873881 0.525417 0.837395 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 372
Initial state: 0 0.562317 0.849564 0.665786 0.842719 0.947466 0.401023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224061 episodes
GETTING ACTION FROM:
action 3, numVisits=224018, meanQ=4.935069, numObservations: 5
action 0, numVisits=39, meanQ=3.799560, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.562317 0.849564 0.665786 0.842719 0.947466 0.401023 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 373
Initial state: 0 0.539997 0.886155 0.774655 0.594522 0.693575 0.892737 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227469 episodes
GETTING ACTION FROM:
action 2, numVisits=227253, meanQ=5.144977, numObservations: 4
action 1, numVisits=114, meanQ=4.497941, numObservations: 4
action -1, numVisits=99, meanQ=4.439813, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.539997 0.886155 0.774655 0.594522 0.693575 0.892737 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 374
Initial state: 0 0.311896 0.718564 0.550827 0.812551 0.501676 0.820134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228083 episodes
GETTING ACTION FROM:
action 2, numVisits=228063, meanQ=5.016175, numObservations: 3
action 1, numVisits=15, meanQ=0.994687, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.311896 0.718564 0.550827 0.812551 0.501676 0.820134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.43479 0.996637 0.556183 0.884467 0.55116 0.841369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220267 episodes
GETTING ACTION FROM:
action 1, numVisits=220257, meanQ=4.991948, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.43479 0.996637 0.556183 0.884467 0.55116 0.841369 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=5375, meanQ=7.826058, numObservations: 3
action 3, numVisits=54, meanQ=6.924265, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 290268 episodes
GETTING ACTION FROM:
action 3, numVisits=241388, meanQ=6.098953, numObservations: 3
action 2, numVisits=54309, meanQ=5.977976, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.43479 0.996637 0.556183 0.884467 0.55116 0.841369 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 376
Initial state: 0 0.0325989 0.067009 0.530867 0.845271 0.572518 0.858108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226425 episodes
GETTING ACTION FROM:
action 1, numVisits=226416, meanQ=5.017903, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0325989 0.067009 0.530867 0.845271 0.572518 0.858108 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=31383, meanQ=8.410361, numObservations: 5
action 3, numVisits=232, meanQ=7.988795, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283848 episodes
GETTING ACTION FROM:
action 2, numVisits=311640, meanQ=5.981427, numObservations: 5
action 3, numVisits=3821, meanQ=5.876806, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0325989 0.067009 0.530867 0.845271 0.572518 0.858108 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 377
Initial state: 0 0.402598 0.389944 0.650295 0.845776 0.657249 0.869685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222938 episodes
GETTING ACTION FROM:
action 3, numVisits=222865, meanQ=4.953291, numObservations: 5
action 0, numVisits=48, meanQ=3.940236, numObservations: 1
action 1, numVisits=21, meanQ=3.379538, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.402598 0.389944 0.650295 0.845776 0.657249 0.869685 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.387695 0.985275 0.616872 0.863816 0.638043 0.8055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218747 episodes
GETTING ACTION FROM:
action 3, numVisits=218676, meanQ=4.853974, numObservations: 4
action 0, numVisits=50, meanQ=3.845433, numObservations: 1
action 1, numVisits=16, meanQ=2.742500, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.387695 0.985275 0.616872 0.863816 0.638043 0.8055 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 379
Initial state: 0 0.400011 0.311739 0.604227 0.811002 0.682608 0.85292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227455 episodes
GETTING ACTION FROM:
action 1, numVisits=227438, meanQ=4.946826, numObservations: 3
action 3, numVisits=12, meanQ=2.675000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.400011 0.311739 0.604227 0.811002 0.682608 0.85292 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=37448, meanQ=8.338886, numObservations: 4
action 3, numVisits=87, meanQ=7.595522, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289770 episodes
GETTING ACTION FROM:
action 2, numVisits=326765, meanQ=6.523020, numObservations: 4
action 3, numVisits=540, meanQ=6.214556, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.400011 0.311739 0.604227 0.811002 0.682608 0.85292 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 380
Initial state: 0 0.674993 0.881183 0.645611 0.619302 0.641167 0.812801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227203 episodes
GETTING ACTION FROM:
action 2, numVisits=227142, meanQ=5.052345, numObservations: 4
action 0, numVisits=31, meanQ=3.801486, numObservations: 1
action 3, numVisits=16, meanQ=3.113131, numObservations: 3
action 1, numVisits=12, meanQ=2.498342, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.674993 0.881183 0.645611 0.619302 0.641167 0.812801 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=33398, meanQ=8.324461, numObservations: 4
action 3, numVisits=3844, meanQ=8.254458, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286013 episodes
GETTING ACTION FROM:
action 1, numVisits=278464, meanQ=6.059430, numObservations: 4
action 3, numVisits=44788, meanQ=6.038926, numObservations: 5
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.674993 0.881183 0.645611 0.619302 0.641167 0.812801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=7293, meanQ=7.283662, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289664 episodes
GETTING ACTION FROM:
action 3, numVisits=296954, meanQ=5.920679, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.674993 0.881183 0.645611 0.619302 0.641167 0.812801 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 381
Initial state: 0 0.504486 0.836816 0.717407 0.0678802 0.660892 0.825958 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217627 episodes
GETTING ACTION FROM:
action 3, numVisits=207452, meanQ=4.971344, numObservations: 5
action 0, numVisits=10170, meanQ=3.005176, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.504486 0.836816 0.717407 0.0678802 0.660892 0.825958 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.440378 0.398705 0.608887 0.8767 0.546025 0.842813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225746 episodes
GETTING ACTION FROM:
action 1, numVisits=225615, meanQ=5.021506, numObservations: 4
action 0, numVisits=102, meanQ=4.313395, numObservations: 1
action 2, numVisits=21, meanQ=3.462381, numObservations: 3
action 3, numVisits=6, meanQ=-0.316667, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.440378 0.398705 0.608887 0.8767 0.546025 0.842813 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31614, meanQ=8.416237, numObservations: 4
action 2, numVisits=27, meanQ=7.073341, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 285495 episodes
GETTING ACTION FROM:
action 3, numVisits=317078, meanQ=6.188897, numObservations: 4
action 2, numVisits=48, meanQ=5.124590, numObservations: 4
action 1, numVisits=12, meanQ=3.499175, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 3
Next state: 1 0.440378 0.398705 0.608887 0.8767 0.546025 0.842813 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 383
Initial state: 0 0.677291 0.825644 0.523344 0.810422 0.171396 0.241677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225860 episodes
GETTING ACTION FROM:
action 1, numVisits=225846, meanQ=5.010443, numObservations: 4
action 3, numVisits=9, meanQ=2.553344, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.677291 0.825644 0.523344 0.810422 0.171396 0.241677 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 384
Initial state: 0 0.682318 0.808944 0.741113 0.273928 0.555217 0.856718 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226101 episodes
GETTING ACTION FROM:
action 1, numVisits=225952, meanQ=5.011099, numObservations: 4
action 0, numVisits=144, meanQ=4.435795, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.682318 0.808944 0.741113 0.273928 0.555217 0.856718 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.204051 0.452604 0.645065 0.865111 0.522643 0.826117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222431 episodes
GETTING ACTION FROM:
action 3, numVisits=215966, meanQ=5.001708, numObservations: 4
action 0, numVisits=6461, meanQ=3.115417, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.204051 0.452604 0.645065 0.865111 0.522643 0.826117 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.506477 0.837979 0.582512 0.864428 0.755225 0.171837 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223389 episodes
GETTING ACTION FROM:
action 2, numVisits=139972, meanQ=5.007500, numObservations: 5
action 1, numVisits=83368, meanQ=4.981538, numObservations: 5
action -1, numVisits=46, meanQ=3.936661, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.506477 0.837979 0.582512 0.864428 0.755225 0.171837 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.736026 0.463363 0.635213 0.883111 0.548481 0.82184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225603 episodes
GETTING ACTION FROM:
action 1, numVisits=225460, meanQ=4.930577, numObservations: 4
action -1, numVisits=112, meanQ=4.231369, numObservations: 1
action 0, numVisits=29, meanQ=3.559559, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.736026 0.463363 0.635213 0.883111 0.548481 0.82184 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 388
Initial state: 0 0.0704738 0.0332265 0.606037 0.854733 0.69203 0.864845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215209 episodes
GETTING ACTION FROM:
action 1, numVisits=215181, meanQ=4.854849, numObservations: 5
action 2, numVisits=22, meanQ=2.354550, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0704738 0.0332265 0.606037 0.854733 0.69203 0.864845 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=14057, meanQ=8.541006, numObservations: 3
action 3, numVisits=10420, meanQ=8.532025, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284532 episodes
GETTING ACTION FROM:
action 2, numVisits=187125, meanQ=6.187755, numObservations: 5
action 3, numVisits=121884, meanQ=6.185961, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0704738 0.0332265 0.606037 0.854733 0.69203 0.864845 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=1280, meanQ=8.066711, numObservations: 4
action 2, numVisits=25, meanQ=6.515604, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 291918 episodes
GETTING ACTION FROM:
action 3, numVisits=291827, meanQ=5.767893, numObservations: 4
action 2, numVisits=1394, meanQ=5.581456, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0704738 0.0332265 0.606037 0.854733 0.69203 0.864845 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 389
Initial state: 0 0.485837 0.572391 0.562019 0.877738 0.516947 0.87826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228078 episodes
GETTING ACTION FROM:
action 1, numVisits=228072, meanQ=5.019911, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.485837 0.572391 0.562019 0.877738 0.516947 0.87826 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37690, meanQ=8.306153, numObservations: 4
action 2, numVisits=15, meanQ=6.065333, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 286617 episodes
GETTING ACTION FROM:
action 3, numVisits=324297, meanQ=6.259823, numObservations: 4
action 2, numVisits=25, meanQ=4.839200, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.485837 0.572391 0.562019 0.877738 0.516947 0.87826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 390
Initial state: 0 0.150579 0.145777 0.650797 0.881941 0.695585 0.898784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228057 episodes
GETTING ACTION FROM:
action 3, numVisits=227990, meanQ=4.952075, numObservations: 3
action -1, numVisits=63, meanQ=4.057310, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.150579 0.145777 0.650797 0.881941 0.695585 0.898784 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.620667 0.850656 0.340833 0.855673 0.682315 0.877577 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224407 episodes
GETTING ACTION FROM:
action 3, numVisits=224400, meanQ=4.999042, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.620667 0.850656 0.340833 0.855673 0.682315 0.877577 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 392
Initial state: 0 0.670717 0.811615 0.977001 0.0775711 0.507714 0.851771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229048 episodes
GETTING ACTION FROM:
action 1, numVisits=228971, meanQ=4.985107, numObservations: 3
action -1, numVisits=72, meanQ=4.166675, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.670717 0.811615 0.977001 0.0775711 0.507714 0.851771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.0525857 0.937458 0.660929 0.811959 0.65138 0.869451 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226249 episodes
GETTING ACTION FROM:
action 2, numVisits=226153, meanQ=5.151418, numObservations: 4
action 0, numVisits=66, meanQ=4.277719, numObservations: 1
action 1, numVisits=27, meanQ=2.930004, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.0525857 0.937458 0.660929 0.811959 0.65138 0.869451 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=16114, meanQ=7.291213, numObservations: 4
action 1, numVisits=5, meanQ=2.598000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 265420 episodes
GETTING ACTION FROM:
action 1, numVisits=41012, meanQ=5.567747, numObservations: 5
action 2, numVisits=240525, meanQ=5.529765, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.0525857 0.937458 0.660929 0.811959 0.65138 0.869451 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=61, meanQ=7.880328, numObservations: 3
action 3, numVisits=28, meanQ=6.421429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 290534 episodes
GETTING ACTION FROM:
action 3, numVisits=290483, meanQ=6.577362, numObservations: 5
action 1, numVisits=140, meanQ=5.940714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0525857 0.937458 0.660929 0.811959 0.65138 0.869451 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 394
Initial state: 0 0.917992 0.479544 0.69441 0.866357 0.619001 0.850358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 229338 episodes
GETTING ACTION FROM:
action 3, numVisits=229218, meanQ=5.001000, numObservations: 3
action -1, numVisits=88, meanQ=4.257001, numObservations: 1
action 0, numVisits=28, meanQ=3.683759, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.917992 0.479544 0.69441 0.866357 0.619001 0.850358 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.746866 0.859246 0.505775 0.816859 0.596347 0.87687 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226026 episodes
GETTING ACTION FROM:
action 1, numVisits=221908, meanQ=5.029648, numObservations: 4
action 3, numVisits=4113, meanQ=4.902137, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.746866 0.859246 0.505775 0.816859 0.596347 0.87687 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 396
Initial state: 0 0.540783 0.89516 0.555551 0.85363 0.855257 0.745685 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 228807 episodes
GETTING ACTION FROM:
action 1, numVisits=228793, meanQ=4.999891, numObservations: 3
action 2, numVisits=8, meanQ=0.997500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.540783 0.89516 0.555551 0.85363 0.855257 0.745685 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.393276 0.408641 0.595332 0.893647 0.674167 0.87316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224295 episodes
GETTING ACTION FROM:
action 3, numVisits=224277, meanQ=5.165823, numObservations: 4
action 2, numVisits=13, meanQ=2.536923, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.393276 0.408641 0.595332 0.893647 0.674167 0.87316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.847116 0.665216 0.581472 0.812898 0.683274 0.802843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223281 episodes
GETTING ACTION FROM:
action 1, numVisits=212103, meanQ=4.939492, numObservations: 3
action 0, numVisits=11174, meanQ=3.038525, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.847116 0.665216 0.581472 0.812898 0.683274 0.802843 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 399
Initial state: 0 0.554553 0.836867 0.327669 0.0595182 0.545505 0.884556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223400 episodes
GETTING ACTION FROM:
action 3, numVisits=223323, meanQ=4.952746, numObservations: 5
action 0, numVisits=47, meanQ=3.927398, numObservations: 1
action 2, numVisits=27, meanQ=3.218156, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.554553 0.836867 0.327669 0.0595182 0.545505 0.884556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.613691 0.850743 0.176144 0.955729 0.688375 0.833214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219935 episodes
GETTING ACTION FROM:
action 1, numVisits=219887, meanQ=4.928786, numObservations: 4
action 3, numVisits=43, meanQ=3.778142, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.613691 0.850743 0.176144 0.955729 0.688375 0.833214 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 401
Initial state: 0 0.533076 0.821493 0.15045 0.598153 0.545843 0.876768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 152903 episodes
GETTING ACTION FROM:
action 0, numVisits=152867, meanQ=3.087675, numObservations: 1
action 2, numVisits=16, meanQ=1.251888, numObservations: 3
action 3, numVisits=15, meanQ=0.987340, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.533076 0.821493 0.15045 0.598153 0.545843 0.876768 w: 1
Observation: 0 0 0.820885 0 0.638302 0 0.797151 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=152814, meanQ=5.134556, numObservations: 5
action -1, numVisits=43, meanQ=4.091261, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 242629 episodes
GETTING ACTION FROM:
action 3, numVisits=395438, meanQ=5.024429, numObservations: 5
action -1, numVisits=48, meanQ=3.998766, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.533076 0.821493 0.15045 0.598153 0.545843 0.876768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 402
Initial state: 0 0.510478 0.818672 0.213502 0.642987 0.517299 0.831163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219875 episodes
GETTING ACTION FROM:
action 3, numVisits=219479, meanQ=4.939588, numObservations: 5
action 0, numVisits=131, meanQ=4.336213, numObservations: 1
action 2, numVisits=144, meanQ=4.332332, numObservations: 3
action -1, numVisits=120, meanQ=4.307158, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.510478 0.818672 0.213502 0.642987 0.517299 0.831163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.500829 0.845521 0.599988 0.807192 0.36777 0.507277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225488 episodes
GETTING ACTION FROM:
action 1, numVisits=225419, meanQ=4.947901, numObservations: 4
action 0, numVisits=62, meanQ=4.051085, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.500829 0.845521 0.599988 0.807192 0.36777 0.507277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16946, meanQ=5.495954, numObservations: 4
action 3, numVisits=29, meanQ=3.467245, numObservations: 3
action 2, numVisits=5, meanQ=0.998040, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 262609 episodes
GETTING ACTION FROM:
action 1, numVisits=279553, meanQ=5.062640, numObservations: 4
action 3, numVisits=29, meanQ=3.467245, numObservations: 3
action 2, numVisits=5, meanQ=0.998040, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.500829 0.845521 0.599988 0.807192 0.36777 0.507277 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 404
Initial state: 0 0.508092 0.899803 0.564621 0.872531 0.386829 0.80602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224594 episodes
GETTING ACTION FROM:
action 3, numVisits=217626, meanQ=4.980007, numObservations: 4
action 1, numVisits=6963, meanQ=4.877580, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.508092 0.899803 0.564621 0.872531 0.386829 0.80602 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 405
Initial state: 0 0.574186 0.899051 0.681521 0.888494 0.732805 0.0984284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227479 episodes
GETTING ACTION FROM:
action 1, numVisits=227423, meanQ=5.016464, numObservations: 4
action 3, numVisits=50, meanQ=3.836801, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.574186 0.899051 0.681521 0.888494 0.732805 0.0984284 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.157593 0.51402 0.563303 0.871015 0.525115 0.838797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 167876 episodes
GETTING ACTION FROM:
action 1, numVisits=41360, meanQ=4.929288, numObservations: 4
action -1, numVisits=126511, meanQ=2.915137, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.157593 0.51402 0.563303 0.871015 0.525115 0.838797 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5724, meanQ=8.351480, numObservations: 4
action 2, numVisits=5, meanQ=3.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284046 episodes
GETTING ACTION FROM:
action 3, numVisits=289761, meanQ=6.079399, numObservations: 5
action 2, numVisits=14, meanQ=4.143579, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.157593 0.51402 0.563303 0.871015 0.525115 0.838797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 407
Initial state: 0 0.503745 0.870833 0.620152 0.836142 0.0603115 0.55669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226771 episodes
GETTING ACTION FROM:
action 1, numVisits=226733, meanQ=5.017717, numObservations: 4
action -1, numVisits=21, meanQ=3.479200, numObservations: 1
action 0, numVisits=14, meanQ=2.962084, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.503745 0.870833 0.620152 0.836142 0.0603115 0.55669 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.689145 0.811392 0.674545 0.879439 0.376652 0.946712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221022 episodes
GETTING ACTION FROM:
action 3, numVisits=217936, meanQ=4.962838, numObservations: 5
action 2, numVisits=2986, meanQ=4.842908, numObservations: 4
action -1, numVisits=96, meanQ=4.256090, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.689145 0.811392 0.674545 0.879439 0.376652 0.946712 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=16575, meanQ=5.526926, numObservations: 3
action 2, numVisits=39, meanQ=3.848469, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 266451 episodes
GETTING ACTION FROM:
action 3, numVisits=283024, meanQ=5.155673, numObservations: 3
action 2, numVisits=39, meanQ=3.848469, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.689145 0.811392 0.674545 0.879439 0.376652 0.946712 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=6761, meanQ=5.466962, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 264118 episodes
GETTING ACTION FROM:
action 3, numVisits=270877, meanQ=5.054570, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 0 0.689145 0.811392 0.674545 0.879439 0.376652 0.946712 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=5440, meanQ=8.490260, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 293703 episodes
GETTING ACTION FROM:
action 2, numVisits=299141, meanQ=5.799071, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.689145 0.811392 0.674545 0.879439 0.376652 0.946712 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 409
Initial state: 0 0.530136 0.81327 0.50991 0.852859 0.15816 0.585688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 216911 episodes
GETTING ACTION FROM:
action 3, numVisits=216848, meanQ=4.836641, numObservations: 4
action 0, numVisits=55, meanQ=3.885159, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.530136 0.81327 0.50991 0.852859 0.15816 0.585688 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=5554, meanQ=7.673216, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 283576 episodes
GETTING ACTION FROM:
action 1, numVisits=289128, meanQ=6.029577, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.530136 0.81327 0.50991 0.852859 0.15816 0.585688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 410
Initial state: 0 0.0610481 0.71347 0.635439 0.853971 0.519209 0.864656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223889 episodes
GETTING ACTION FROM:
action 2, numVisits=223883, meanQ=5.001618, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0610481 0.71347 0.635439 0.853971 0.519209 0.864656 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.599815 0.846515 0.640987 0.803414 0.742586 0.0988438 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 155516 episodes
GETTING ACTION FROM:
action 0, numVisits=155501, meanQ=3.122573, numObservations: 1
action 2, numVisits=6, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 0
Next state: 0 0.599815 0.846515 0.640987 0.803414 0.742586 0.0988438 w: 1
Observation: 0 0 0.827957 0 0.730927 0 0.0853441 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=155477, meanQ=5.172809, numObservations: 4
action 3, numVisits=18, meanQ=1.548894, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 247987 episodes
GETTING ACTION FROM:
action 1, numVisits=403464, meanQ=4.938667, numObservations: 4
action 3, numVisits=18, meanQ=1.548894, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.599815 0.846515 0.640987 0.803414 0.742586 0.0988438 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 412
Initial state: 0 0.776882 0.620206 0.520839 0.817155 0.624989 0.847966 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225167 episodes
GETTING ACTION FROM:
action 2, numVisits=225158, meanQ=4.994515, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.776882 0.620206 0.520839 0.817155 0.624989 0.847966 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.872322 0.917787 0.681429 0.893255 0.656909 0.856145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225830 episodes
GETTING ACTION FROM:
action 3, numVisits=225796, meanQ=5.189702, numObservations: 4
action -1, numVisits=16, meanQ=3.409528, numObservations: 1
action 2, numVisits=15, meanQ=1.400680, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.872322 0.917787 0.681429 0.893255 0.656909 0.856145 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 414
Initial state: 0 0.66385 0.821669 0.547508 0.850048 0.912842 0.202109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227825 episodes
GETTING ACTION FROM:
action 2, numVisits=227795, meanQ=4.984495, numObservations: 3
action 0, numVisits=22, meanQ=3.387610, numObservations: 1
action 1, numVisits=5, meanQ=1.396020, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.66385 0.821669 0.547508 0.850048 0.912842 0.202109 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.622539 0.807029 0.867839 0.396826 0.572197 0.889661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222927 episodes
GETTING ACTION FROM:
action 3, numVisits=222921, meanQ=5.223823, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.622539 0.807029 0.867839 0.396826 0.572197 0.889661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.670654 0.8215 0.696186 0.89771 0.141588 0.632227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226238 episodes
GETTING ACTION FROM:
action 1, numVisits=226044, meanQ=5.001767, numObservations: 4
action -1, numVisits=111, meanQ=4.348795, numObservations: 1
action 0, numVisits=74, meanQ=4.196806, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.670654 0.8215 0.696186 0.89771 0.141588 0.632227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.215673 0.219407 0.638479 0.817178 0.64221 0.840667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225326 episodes
GETTING ACTION FROM:
action 1, numVisits=225301, meanQ=4.942918, numObservations: 4
action 3, numVisits=20, meanQ=2.999020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.215673 0.219407 0.638479 0.817178 0.64221 0.840667 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=37139, meanQ=8.323232, numObservations: 4
action 3, numVisits=17, meanQ=6.647065, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289167 episodes
GETTING ACTION FROM:
action 2, numVisits=326253, meanQ=6.427172, numObservations: 4
action 3, numVisits=70, meanQ=5.571430, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.215673 0.219407 0.638479 0.817178 0.64221 0.840667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 418
Initial state: 0 0.690321 0.871804 0.616708 0.80796 0.00497555 0.034495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226542 episodes
GETTING ACTION FROM:
action 1, numVisits=226524, meanQ=4.938192, numObservations: 3
action 0, numVisits=14, meanQ=2.819872, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.690321 0.871804 0.616708 0.80796 0.00497555 0.034495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.0460296 0.900017 0.584731 0.847178 0.613764 0.897308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225089 episodes
GETTING ACTION FROM:
action 1, numVisits=224932, meanQ=4.941413, numObservations: 4
action -1, numVisits=144, meanQ=4.366534, numObservations: 1
action 2, numVisits=9, meanQ=0.552222, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.0460296 0.900017 0.584731 0.847178 0.613764 0.897308 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=17022, meanQ=4.741247, numObservations: 4
action -1, numVisits=113, meanQ=4.131170, numObservations: 1
action 0, numVisits=23, meanQ=3.233643, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 1, numVisits=7, meanQ=0.428571, numObservations: 3
Sampled 285439 episodes
GETTING ACTION FROM:
action 2, numVisits=302461, meanQ=5.647961, numObservations: 4
action -1, numVisits=113, meanQ=4.131170, numObservations: 1
action 0, numVisits=23, meanQ=3.233643, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 1, numVisits=7, meanQ=0.428571, numObservations: 3
action: 2
Next state: 1 0.0460296 0.900017 0.584731 0.847178 0.613764 0.897308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 420
Initial state: 0 0.594367 0.876528 0.504866 0.89667 0.219323 0.0733486 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218647 episodes
GETTING ACTION FROM:
action 3, numVisits=218571, meanQ=4.874156, numObservations: 5
action 0, numVisits=63, meanQ=3.972358, numObservations: 1
action 2, numVisits=10, meanQ=2.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.594367 0.876528 0.504866 0.89667 0.219323 0.0733486 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30481, meanQ=8.423308, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 288966 episodes
GETTING ACTION FROM:
action 2, numVisits=319447, meanQ=6.279338, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.594367 0.876528 0.504866 0.89667 0.219323 0.0733486 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 421
Initial state: 0 0.354803 0.552401 0.541911 0.877695 0.518664 0.810566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225290 episodes
GETTING ACTION FROM:
action 2, numVisits=225250, meanQ=4.954242, numObservations: 4
action -1, numVisits=35, meanQ=3.769951, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.354803 0.552401 0.541911 0.877695 0.518664 0.810566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.558271 0.854033 0.550336 0.860602 0.363924 0.962738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 199256 episodes
GETTING ACTION FROM:
action 3, numVisits=180244, meanQ=4.562985, numObservations: 4
action 0, numVisits=19000, meanQ=3.085902, numObservations: 1
action 1, numVisits=9, meanQ=0.331133, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.558271 0.854033 0.550336 0.860602 0.363924 0.962738 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=4455, meanQ=7.805452, numObservations: 5
action 1, numVisits=46, meanQ=6.820224, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284414 episodes
GETTING ACTION FROM:
action 2, numVisits=288459, meanQ=5.980212, numObservations: 5
action 1, numVisits=454, meanQ=5.659223, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.558271 0.854033 0.550336 0.860602 0.363924 0.962738 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 423
Initial state: 0 0.34663 0.169854 0.556991 0.86169 0.522745 0.863665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224522 episodes
GETTING ACTION FROM:
action 3, numVisits=224504, meanQ=4.998719, numObservations: 4
action 1, numVisits=13, meanQ=1.307700, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.34663 0.169854 0.556991 0.86169 0.522745 0.863665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.612185 0.855496 0.75035 0.572122 0.585125 0.803591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222120 episodes
GETTING ACTION FROM:
action 2, numVisits=221953, meanQ=4.952270, numObservations: 5
action -1, numVisits=93, meanQ=4.215425, numObservations: 1
action 0, numVisits=64, meanQ=4.067296, numObservations: 1
action 1, numVisits=9, meanQ=1.218900, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.612185 0.855496 0.75035 0.572122 0.585125 0.803591 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 425
Initial state: 0 0.12118 0.82725 0.601283 0.88949 0.662774 0.83993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218640 episodes
GETTING ACTION FROM:
action 2, numVisits=203702, meanQ=4.992895, numObservations: 5
action 0, numVisits=14909, meanQ=3.139212, numObservations: 1
action 1, numVisits=26, meanQ=1.692712, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.12118 0.82725 0.601283 0.88949 0.662774 0.83993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 426
Initial state: 0 0.616801 0.233878 0.567445 0.814953 0.622489 0.8069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221898 episodes
GETTING ACTION FROM:
action 3, numVisits=214752, meanQ=4.929822, numObservations: 4
action -1, numVisits=7136, meanQ=2.877159, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.616801 0.233878 0.567445 0.814953 0.622489 0.8069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 427
Initial state: 0 0.559416 0.824362 0.299929 0.263348 0.571064 0.810522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 198880 episodes
GETTING ACTION FROM:
action 1, numVisits=141918, meanQ=4.956774, numObservations: 4
action 0, numVisits=56944, meanQ=3.128024, numObservations: 1
action 3, numVisits=13, meanQ=0.998462, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.559416 0.824362 0.299929 0.263348 0.571064 0.810522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.516865 0.830456 0.743438 0.0465718 0.590124 0.859049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222587 episodes
GETTING ACTION FROM:
action 3, numVisits=222567, meanQ=4.919257, numObservations: 5
action 1, numVisits=13, meanQ=2.846154, numObservations: 3
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.516865 0.830456 0.743438 0.0465718 0.590124 0.859049 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.591289 0.874743 0.0982962 0.0371603 0.610624 0.880695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219714 episodes
GETTING ACTION FROM:
action 2, numVisits=219603, meanQ=5.025355, numObservations: 4
action -1, numVisits=65, meanQ=4.159447, numObservations: 1
action 0, numVisits=44, meanQ=3.937441, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.591289 0.874743 0.0982962 0.0371603 0.610624 0.880695 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=19887, meanQ=8.532054, numObservations: 3
action 3, numVisits=5223, meanQ=8.487833, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 287189 episodes
GETTING ACTION FROM:
action 1, numVisits=205850, meanQ=6.282571, numObservations: 3
action 3, numVisits=106449, meanQ=6.278091, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.591289 0.874743 0.0982962 0.0371603 0.610624 0.880695 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 430
Initial state: 0 0.645204 0.823172 0.196563 0.905951 0.695442 0.816955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221201 episodes
GETTING ACTION FROM:
action 3, numVisits=221177, meanQ=4.971597, numObservations: 5
action 2, numVisits=19, meanQ=3.205274, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.645204 0.823172 0.196563 0.905951 0.695442 0.816955 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.52748 0.836327 0.977665 0.195973 0.64677 0.877774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226136 episodes
GETTING ACTION FROM:
action 2, numVisits=217777, meanQ=5.010732, numObservations: 4
action 1, numVisits=8353, meanQ=4.824896, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.52748 0.836327 0.977665 0.195973 0.64677 0.877774 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 432
Initial state: 0 0.558984 0.882361 0.152221 0.392648 0.563999 0.813232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224082 episodes
GETTING ACTION FROM:
action 2, numVisits=224076, meanQ=5.021551, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.558984 0.882361 0.152221 0.392648 0.563999 0.813232 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=31316, meanQ=8.424538, numObservations: 5
action 3, numVisits=207, meanQ=7.941116, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284207 episodes
GETTING ACTION FROM:
action 1, numVisits=314937, meanQ=6.262065, numObservations: 5
action 3, numVisits=793, meanQ=6.019088, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.558984 0.882361 0.152221 0.392648 0.563999 0.813232 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 433
Initial state: 0 0.627104 0.868956 0.551804 0.840535 0.989433 0.061741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 227991 episodes
GETTING ACTION FROM:
action 2, numVisits=227850, meanQ=5.010332, numObservations: 3
action 3, numVisits=135, meanQ=4.399264, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.627104 0.868956 0.551804 0.840535 0.989433 0.061741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 434
Initial state: 0 0.841247 0.716924 0.608132 0.827773 0.646756 0.823395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215404 episodes
GETTING ACTION FROM:
action 3, numVisits=215341, meanQ=4.933159, numObservations: 4
action 0, numVisits=59, meanQ=4.020457, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.841247 0.716924 0.608132 0.827773 0.646756 0.823395 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.392856 0.202482 0.526517 0.852176 0.581702 0.813102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219178 episodes
GETTING ACTION FROM:
action 3, numVisits=219161, meanQ=4.808054, numObservations: 3
action 1, numVisits=10, meanQ=2.598000, numObservations: 3
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.392856 0.202482 0.526517 0.852176 0.581702 0.813102 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.671767 0.839358 0.653946 0.860229 0.841789 0.86731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224061 episodes
GETTING ACTION FROM:
action 1, numVisits=223966, meanQ=4.949564, numObservations: 5
action -1, numVisits=87, meanQ=4.200866, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.671767 0.839358 0.653946 0.860229 0.841789 0.86731 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.90152 0.520839 0.520742 0.867065 0.637808 0.889144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 156595 episodes
GETTING ACTION FROM:
action -1, numVisits=156429, meanQ=3.126492, numObservations: 1
action 0, numVisits=119, meanQ=2.240708, numObservations: 1
action 1, numVisits=21, meanQ=1.474776, numObservations: 4
action 3, numVisits=18, meanQ=0.888339, numObservations: 3
action 2, numVisits=8, meanQ=-0.512500, numObservations: 4
action: -1
Next state: 0 0.90152 0.520839 0.520742 0.867065 0.637808 0.889144 w: 1
Observation: 0 0.846268 0 0.475751 0 0.634031 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=156411, meanQ=5.158580, numObservations: 4
action 2, numVisits=12, meanQ=1.166683, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 249022 episodes
GETTING ACTION FROM:
action 1, numVisits=405433, meanQ=5.126275, numObservations: 4
action 2, numVisits=12, meanQ=1.166683, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.90152 0.520839 0.520742 0.867065 0.637808 0.889144 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 438
Initial state: 0 0.698035 0.824325 0.387544 0.35891 0.55886 0.809341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223543 episodes
GETTING ACTION FROM:
action 2, numVisits=223528, meanQ=5.041005, numObservations: 5
action 3, numVisits=10, meanQ=2.209000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.698035 0.824325 0.387544 0.35891 0.55886 0.809341 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=31309, meanQ=8.411632, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282955 episodes
GETTING ACTION FROM:
action 3, numVisits=314258, meanQ=5.978821, numObservations: 3
action 1, numVisits=6, meanQ=2.663350, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.698035 0.824325 0.387544 0.35891 0.55886 0.809341 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 439
Initial state: 0 0.66355 0.889322 0.685166 0.842447 0.773409 0.42517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 161182 episodes
GETTING ACTION FROM:
action 0, numVisits=159104, meanQ=5.889396, numObservations: 3
action 1, numVisits=2051, meanQ=4.321808, numObservations: 3
action -1, numVisits=23, meanQ=3.266943, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.66355 0.889322 0.685166 0.842447 0.773409 0.42517 w: 1
Observation: 0 0 0.946459 0 0.836299 0 0.364194 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=47607, meanQ=8.205111, numObservations: 4
action 2, numVisits=8, meanQ=5.501263, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 248789 episodes
GETTING ACTION FROM:
action 1, numVisits=296379, meanQ=5.709572, numObservations: 4
action 2, numVisits=23, meanQ=4.126535, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.66355 0.889322 0.685166 0.842447 0.773409 0.42517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 440
Initial state: 0 0.932943 0.249239 0.655493 0.882982 0.666024 0.88594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 226222 episodes
GETTING ACTION FROM:
action 3, numVisits=225727, meanQ=4.964059, numObservations: 3
action 2, numVisits=487, meanQ=4.619812, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.932943 0.249239 0.655493 0.882982 0.666024 0.88594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 441
Initial state: 0 0.973792 0.661654 0.579915 0.891884 0.586586 0.872942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225883 episodes
GETTING ACTION FROM:
action 3, numVisits=225801, meanQ=5.006670, numObservations: 4
action 1, numVisits=45, meanQ=3.878224, numObservations: 4
action -1, numVisits=34, meanQ=3.795673, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.973792 0.661654 0.579915 0.891884 0.586586 0.872942 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.507308 0.884239 0.361337 0.408637 0.615501 0.823716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225000 episodes
GETTING ACTION FROM:
action 3, numVisits=224875, meanQ=4.959693, numObservations: 4
action -1, numVisits=113, meanQ=4.311275, numObservations: 1
action 2, numVisits=9, meanQ=0.998889, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.507308 0.884239 0.361337 0.408637 0.615501 0.823716 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.50189 0.807256 0.135586 0.346342 0.599232 0.879341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223406 episodes
GETTING ACTION FROM:
action 2, numVisits=214234, meanQ=5.216034, numObservations: 5
action -1, numVisits=9162, meanQ=2.968055, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.50189 0.807256 0.135586 0.346342 0.599232 0.879341 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=24431, meanQ=8.523985, numObservations: 3
action 3, numVisits=11, meanQ=6.635464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289137 episodes
GETTING ACTION FROM:
action 1, numVisits=313425, meanQ=6.155261, numObservations: 4
action 3, numVisits=154, meanQ=5.517016, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.50189 0.807256 0.135586 0.346342 0.599232 0.879341 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 444
Initial state: 0 0.543237 0.898699 0.522268 0.840357 0.927629 0.223015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217529 episodes
GETTING ACTION FROM:
action 1, numVisits=217419, meanQ=4.981263, numObservations: 5
action 0, numVisits=105, meanQ=4.240648, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.543237 0.898699 0.522268 0.840357 0.927629 0.223015 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.292231 0.226537 0.640951 0.868872 0.562361 0.86729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225440 episodes
GETTING ACTION FROM:
action 2, numVisits=220843, meanQ=4.955387, numObservations: 4
action -1, numVisits=4589, meanQ=2.712270, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.292231 0.226537 0.640951 0.868872 0.562361 0.86729 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 446
Initial state: 0 0.5331 0.89104 0.644551 0.880653 0.294178 0.933256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 225006 episodes
GETTING ACTION FROM:
action 1, numVisits=224997, meanQ=4.947437, numObservations: 5
action 3, numVisits=4, meanQ=-0.007500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.5331 0.89104 0.644551 0.880653 0.294178 0.933256 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 447
Initial state: 0 0.619453 0.807531 0.221303 0.595155 0.51117 0.831981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222780 episodes
GETTING ACTION FROM:
action 3, numVisits=222260, meanQ=4.962417, numObservations: 5
action 0, numVisits=511, meanQ=2.315761, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.619453 0.807531 0.221303 0.595155 0.51117 0.831981 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.571924 0.831931 0.667456 0.844035 0.856549 0.586971 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221888 episodes
GETTING ACTION FROM:
action 3, numVisits=221882, meanQ=4.947602, numObservations: 5
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.571924 0.831931 0.667456 0.844035 0.856549 0.586971 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 449
Initial state: 0 0.516029 0.888502 0.648428 0.843412 0.707629 0.611835 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 186569 episodes
GETTING ACTION FROM:
action 1, numVisits=186563, meanQ=4.941881, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.516029 0.888502 0.648428 0.843412 0.707629 0.611835 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.590844 0.833886 0.533598 0.683718 0.669755 0.803659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157145 episodes
GETTING ACTION FROM:
action 0, numVisits=157049, meanQ=5.639725, numObservations: 2
action -1, numVisits=75, meanQ=2.504849, numObservations: 1
action 3, numVisits=12, meanQ=0.666675, numObservations: 3
action 2, numVisits=8, meanQ=-0.001250, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.590844 0.833886 0.533598 0.683718 0.669755 0.803659 w: 1
Observation: 0 0 0.908439 0 0.657891 0 0.847865 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=38798, meanQ=8.365375, numObservations: 5
action 1, numVisits=1849, meanQ=8.205302, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 240037 episodes
GETTING ACTION FROM:
action 3, numVisits=269611, meanQ=5.430628, numObservations: 5
action 1, numVisits=10969, meanQ=5.376038, numObservations: 5
action -1, numVisits=72, meanQ=4.606610, numObservations: 1
action 0, numVisits=31, meanQ=4.164523, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action: 3
Next state: 1 0.590844 0.833886 0.533598 0.683718 0.669755 0.803659 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 451
Initial state: 0 0.697274 0.851913 0.112851 0.104237 0.553136 0.819056 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219123 episodes
GETTING ACTION FROM:
action 2, numVisits=219060, meanQ=5.003579, numObservations: 5
action 0, numVisits=20, meanQ=3.398486, numObservations: 1
action 1, numVisits=36, meanQ=3.386114, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.697274 0.851913 0.112851 0.104237 0.553136 0.819056 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=24026, meanQ=8.532564, numObservations: 3
action 3, numVisits=1022, meanQ=8.373098, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 282370 episodes
GETTING ACTION FROM:
action 1, numVisits=300972, meanQ=6.300785, numObservations: 3
action 3, numVisits=6446, meanQ=6.224075, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.697274 0.851913 0.112851 0.104237 0.553136 0.819056 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 452
Initial state: 0 0.444783 0.350778 0.66448 0.81017 0.674 0.887817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 215793 episodes
GETTING ACTION FROM:
action 1, numVisits=203399, meanQ=5.173702, numObservations: 5
action -1, numVisits=12388, meanQ=3.074874, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.444783 0.350778 0.66448 0.81017 0.674 0.887817 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=28218, meanQ=8.400990, numObservations: 3
action 2, numVisits=7, meanQ=3.871429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284719 episodes
GETTING ACTION FROM:
action 3, numVisits=312928, meanQ=6.214209, numObservations: 3
action 2, numVisits=16, meanQ=4.256250, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.444783 0.350778 0.66448 0.81017 0.674 0.887817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 453
Initial state: 0 0.0310294 0.649848 0.501539 0.870548 0.548892 0.88085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221019 episodes
GETTING ACTION FROM:
action 3, numVisits=220989, meanQ=5.021093, numObservations: 4
action 0, numVisits=20, meanQ=3.332799, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0310294 0.649848 0.501539 0.870548 0.548892 0.88085 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 454
Initial state: 0 0.659086 0.820724 0.690672 0.853557 0.541912 0.552198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218510 episodes
GETTING ACTION FROM:
action 3, numVisits=218497, meanQ=4.973418, numObservations: 4
action 2, numVisits=8, meanQ=1.498775, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.659086 0.820724 0.690672 0.853557 0.541912 0.552198 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 455
Initial state: 0 0.635541 0.832736 0.375637 0.536428 0.552725 0.870488 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218510 episodes
GETTING ACTION FROM:
action 3, numVisits=218230, meanQ=5.017050, numObservations: 5
action -1, numVisits=267, meanQ=1.447216, numObservations: 1
action 1, numVisits=7, meanQ=-0.172857, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.635541 0.832736 0.375637 0.536428 0.552725 0.870488 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.672377 0.848869 0.557453 0.889059 0.0800952 0.392724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219010 episodes
GETTING ACTION FROM:
action 3, numVisits=218999, meanQ=4.999739, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.672377 0.848869 0.557453 0.889059 0.0800952 0.392724 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=30262, meanQ=8.367525, numObservations: 5
action 1, numVisits=6, meanQ=4.996667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 277487 episodes
GETTING ACTION FROM:
action 2, numVisits=307687, meanQ=6.139170, numObservations: 5
action 1, numVisits=68, meanQ=5.116181, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.672377 0.848869 0.557453 0.889059 0.0800952 0.392724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 457
Initial state: 0 0.557419 0.85062 0.596038 0.884948 0.136121 0.408727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221197 episodes
GETTING ACTION FROM:
action 2, numVisits=221116, meanQ=5.027809, numObservations: 4
action 0, numVisits=61, meanQ=4.131853, numObservations: 1
action 1, numVisits=17, meanQ=2.764129, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.557419 0.85062 0.596038 0.884948 0.136121 0.408727 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.721886 0.732125 0.607726 0.830437 0.527723 0.847772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218132 episodes
GETTING ACTION FROM:
action 2, numVisits=218095, meanQ=4.932581, numObservations: 5
action -1, numVisits=29, meanQ=3.573992, numObservations: 1
action 3, numVisits=5, meanQ=1.780000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.721886 0.732125 0.607726 0.830437 0.527723 0.847772 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1646, meanQ=4.124570, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 281610 episodes
GETTING ACTION FROM:
action 1, numVisits=283256, meanQ=5.982697, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.721886 0.732125 0.607726 0.830437 0.527723 0.847772 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 459
Initial state: 0 0.575686 0.836204 0.992722 0.122186 0.502048 0.897953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219174 episodes
GETTING ACTION FROM:
action 2, numVisits=212773, meanQ=5.036864, numObservations: 4
action -1, numVisits=6384, meanQ=2.836821, numObservations: 1
action 3, numVisits=14, meanQ=0.993593, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.575686 0.836204 0.992722 0.122186 0.502048 0.897953 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 460
Initial state: 0 0.805849 0.45108 0.676492 0.864512 0.586485 0.873113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220998 episodes
GETTING ACTION FROM:
action 2, numVisits=220923, meanQ=4.980921, numObservations: 4
action 0, numVisits=43, meanQ=3.908977, numObservations: 1
action 3, numVisits=15, meanQ=2.998007, numObservations: 4
action 1, numVisits=15, meanQ=2.598000, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.805849 0.45108 0.676492 0.864512 0.586485 0.873113 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.605423 0.841833 0.452916 0.661544 0.681156 0.891739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219561 episodes
GETTING ACTION FROM:
action 1, numVisits=219537, meanQ=4.964259, numObservations: 5
action -1, numVisits=16, meanQ=3.077709, numObservations: 1
action 2, numVisits=5, meanQ=1.794000, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.605423 0.841833 0.452916 0.661544 0.681156 0.891739 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 462
Initial state: 0 0.301228 0.0774314 0.601101 0.88729 0.565372 0.893179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 125851 episodes
GETTING ACTION FROM:
action 0, numVisits=125840, meanQ=4.293297, numObservations: 2
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.301228 0.0774314 0.601101 0.88729 0.565372 0.893179 w: 1
Observation: 0 0 0.0577291 0 0.900616 0 0.931443 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=95410, meanQ=5.791790, numObservations: 2
action 1, numVisits=2813, meanQ=4.519194, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 166626 episodes
GETTING ACTION FROM:
action 0, numVisits=262036, meanQ=5.877789, numObservations: 3
action 1, numVisits=2813, meanQ=4.519194, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.301228 0.0774314 0.601101 0.88729 0.565372 0.893179 w: 1
Observation: 0 0 0 0 0.831444 0 0.865496 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=101526, meanQ=7.914477, numObservations: 5
action 2, numVisits=14, meanQ=5.572150, numObservations: 2
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 231132 episodes
GETTING ACTION FROM:
action 3, numVisits=332650, meanQ=5.555373, numObservations: 5
action 2, numVisits=20, meanQ=3.795505, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.301228 0.0774314 0.601101 0.88729 0.565372 0.893179 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 463
Initial state: 0 0.538182 0.828008 0.551446 0.841356 0.96148 0.264993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222324 episodes
GETTING ACTION FROM:
action 2, numVisits=222254, meanQ=4.949454, numObservations: 4
action -1, numVisits=65, meanQ=4.054412, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.538182 0.828008 0.551446 0.841356 0.96148 0.264993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=16850, meanQ=4.632828, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 284280 episodes
GETTING ACTION FROM:
action 1, numVisits=301130, meanQ=5.836174, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.538182 0.828008 0.551446 0.841356 0.96148 0.264993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 464
Initial state: 0 0.567794 0.800681 0.575421 0.891711 0.08227 0.970119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221360 episodes
GETTING ACTION FROM:
action 1, numVisits=221217, meanQ=5.029375, numObservations: 4
action -1, numVisits=122, meanQ=4.403685, numObservations: 1
action 0, numVisits=10, meanQ=2.485195, numObservations: 1
action 2, numVisits=10, meanQ=1.800000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.567794 0.800681 0.575421 0.891711 0.08227 0.970119 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 465
Initial state: 0 0.551773 0.0489184 0.695226 0.807885 0.615157 0.811034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218464 episodes
GETTING ACTION FROM:
action 3, numVisits=218289, meanQ=4.987271, numObservations: 5
action -1, numVisits=161, meanQ=4.394371, numObservations: 1
action 2, numVisits=11, meanQ=2.453636, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.551773 0.0489184 0.695226 0.807885 0.615157 0.811034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.667713 0.866005 0.0376086 0.721095 0.519408 0.855176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214002 episodes
GETTING ACTION FROM:
action 1, numVisits=213929, meanQ=4.868799, numObservations: 4
action 0, numVisits=68, meanQ=4.020412, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.667713 0.866005 0.0376086 0.721095 0.519408 0.855176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.668354 0.870272 0.927128 0.582103 0.606346 0.814992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220893 episodes
GETTING ACTION FROM:
action 1, numVisits=220887, meanQ=4.988496, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.668354 0.870272 0.927128 0.582103 0.606346 0.814992 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.675337 0.856996 0.0363096 0.212845 0.510932 0.872724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 223131 episodes
GETTING ACTION FROM:
action 1, numVisits=223125, meanQ=5.059520, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.675337 0.856996 0.0363096 0.212845 0.510932 0.872724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.523222 0.863375 0.690432 0.864148 0.319436 0.642692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217407 episodes
GETTING ACTION FROM:
action 1, numVisits=217331, meanQ=4.953157, numObservations: 5
action 0, numVisits=30, meanQ=3.678109, numObservations: 1
action -1, numVisits=27, meanQ=3.610014, numObservations: 1
action 2, numVisits=18, meanQ=2.776678, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.523222 0.863375 0.690432 0.864148 0.319436 0.642692 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 470
Initial state: 0 0.634437 0.824526 0.670438 0.882385 0.29417 0.977855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221584 episodes
GETTING ACTION FROM:
action 1, numVisits=190511, meanQ=5.007682, numObservations: 4
action 3, numVisits=30959, meanQ=4.879341, numObservations: 4
action -1, numVisits=83, meanQ=4.204891, numObservations: 1
action 0, numVisits=27, meanQ=3.644169, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.634437 0.824526 0.670438 0.882385 0.29417 0.977855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.474684 0.470692 0.59363 0.800305 0.589612 0.899028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222431 episodes
GETTING ACTION FROM:
action 1, numVisits=222425, meanQ=5.007467, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.474684 0.470692 0.59363 0.800305 0.589612 0.899028 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5487, meanQ=7.706524, numObservations: 4
action 2, numVisits=5, meanQ=5.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281319 episodes
GETTING ACTION FROM:
action 3, numVisits=286805, meanQ=6.123475, numObservations: 4
action 2, numVisits=6, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.474684 0.470692 0.59363 0.800305 0.589612 0.899028 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 472
Initial state: 0 0.827491 0.579928 0.660361 0.874589 0.647388 0.890947 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219772 episodes
GETTING ACTION FROM:
action 1, numVisits=219659, meanQ=4.988351, numObservations: 4
action 0, numVisits=57, meanQ=4.056532, numObservations: 1
action 2, numVisits=48, meanQ=3.872929, numObservations: 4
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.827491 0.579928 0.660361 0.874589 0.647388 0.890947 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 473
Initial state: 0 0.527797 0.866497 0.178107 0.840515 0.682894 0.87842 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220517 episodes
GETTING ACTION FROM:
action 2, numVisits=220502, meanQ=4.952110, numObservations: 4
action 3, numVisits=10, meanQ=2.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.527797 0.866497 0.178107 0.840515 0.682894 0.87842 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36143, meanQ=8.324320, numObservations: 5
action 1, numVisits=18, meanQ=6.777783, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 277526 episodes
GETTING ACTION FROM:
action 3, numVisits=313635, meanQ=6.308774, numObservations: 5
action 1, numVisits=52, meanQ=5.307502, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.527797 0.866497 0.178107 0.840515 0.682894 0.87842 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 474
Initial state: 0 0.577636 0.814832 0.730747 0.688088 0.621844 0.809363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222312 episodes
GETTING ACTION FROM:
action 2, numVisits=222306, meanQ=4.966526, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.577636 0.814832 0.730747 0.688088 0.621844 0.809363 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 475
Initial state: 0 0.57185 0.899442 0.524984 0.817516 0.2703 0.626037 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220957 episodes
GETTING ACTION FROM:
action 3, numVisits=220951, meanQ=4.935605, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.57185 0.899442 0.524984 0.817516 0.2703 0.626037 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=36695, meanQ=8.315178, numObservations: 4
action 1, numVisits=4, meanQ=4.975000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 281528 episodes
GETTING ACTION FROM:
action 2, numVisits=318114, meanQ=6.327404, numObservations: 4
action 1, numVisits=113, meanQ=5.582302, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.57185 0.899442 0.524984 0.817516 0.2703 0.626037 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 476
Initial state: 0 0.908023 0.18643 0.532347 0.827292 0.634295 0.858996 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 157947 episodes
GETTING ACTION FROM:
action 0, numVisits=153744, meanQ=5.890854, numObservations: 3
action 2, numVisits=4175, meanQ=4.677269, numObservations: 3
action 3, numVisits=25, meanQ=3.144404, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.908023 0.18643 0.532347 0.827292 0.634295 0.858996 w: 1
Observation: 0 0 0.284622 0 0.801157 0 0.769959 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=50446, meanQ=8.066996, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 234418 episodes
GETTING ACTION FROM:
action 3, numVisits=284855, meanQ=5.598875, numObservations: 5
action -1, numVisits=9, meanQ=3.164500, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.908023 0.18643 0.532347 0.827292 0.634295 0.858996 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=12613, meanQ=5.735790, numObservations: 1
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 271323 episodes
GETTING ACTION FROM:
action 1, numVisits=262339, meanQ=6.006044, numObservations: 4
action 0, numVisits=21597, meanQ=3.265381, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-2.997475, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.908023 0.18643 0.532347 0.827292 0.634295 0.858996 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 477
Initial state: 0 0.467163 0.951942 0.640626 0.826077 0.685245 0.869851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 218904 episodes
GETTING ACTION FROM:
action 3, numVisits=218898, meanQ=4.947382, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.467163 0.951942 0.640626 0.826077 0.685245 0.869851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.299435 0.789465 0.522972 0.886581 0.62848 0.827101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 214219 episodes
GETTING ACTION FROM:
action 3, numVisits=214210, meanQ=4.843430, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.299435 0.789465 0.522972 0.886581 0.62848 0.827101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 479
Initial state: 0 0.6147 0.847963 0.587972 0.908819 0.573016 0.811902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221490 episodes
GETTING ACTION FROM:
action 2, numVisits=220895, meanQ=4.990101, numObservations: 3
action -1, numVisits=508, meanQ=3.025245, numObservations: 1
action 0, numVisits=73, meanQ=2.642690, numObservations: 1
action 1, numVisits=13, meanQ=0.997708, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.6147 0.847963 0.587972 0.908819 0.573016 0.811902 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 480
Initial state: 0 0.546028 0.879113 0.705123 0.0656707 0.541736 0.880838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220816 episodes
GETTING ACTION FROM:
action 2, numVisits=220743, meanQ=4.955983, numObservations: 4
action 0, numVisits=68, meanQ=4.097459, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.546028 0.879113 0.705123 0.0656707 0.541736 0.880838 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 481
Initial state: 0 0.273276 0.717435 0.559564 0.823107 0.620329 0.829005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220088 episodes
GETTING ACTION FROM:
action 2, numVisits=220026, meanQ=4.957810, numObservations: 4
action 1, numVisits=33, meanQ=3.520303, numObservations: 4
action 0, numVisits=16, meanQ=3.085197, numObservations: 1
action 3, numVisits=11, meanQ=2.081818, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.273276 0.717435 0.559564 0.823107 0.620329 0.829005 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.501262 0.881926 0.671186 0.861499 0.440617 0.295474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 219513 episodes
GETTING ACTION FROM:
action 1, numVisits=219507, meanQ=4.927106, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.501262 0.881926 0.671186 0.861499 0.440617 0.295474 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 483
Initial state: 0 0.575909 0.813425 0.092481 0.541152 0.56944 0.838149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220246 episodes
GETTING ACTION FROM:
action 2, numVisits=220157, meanQ=4.967075, numObservations: 4
action 0, numVisits=71, meanQ=4.141009, numObservations: 1
action 1, numVisits=15, meanQ=2.853333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.575909 0.813425 0.092481 0.541152 0.56944 0.838149 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=36237, meanQ=8.326444, numObservations: 4
action 1, numVisits=7, meanQ=5.001443, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 280701 episodes
GETTING ACTION FROM:
action 3, numVisits=316858, meanQ=6.291966, numObservations: 4
action 1, numVisits=87, meanQ=5.412762, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.575909 0.813425 0.092481 0.541152 0.56944 0.838149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 484
Initial state: 0 0.546674 0.83321 0.658666 0.812121 0.902998 0.310461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 209718 episodes
GETTING ACTION FROM:
action 2, numVisits=182696, meanQ=4.953433, numObservations: 4
action -1, numVisits=27016, meanQ=2.962344, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.546674 0.83321 0.658666 0.812121 0.902998 0.310461 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 485
Initial state: 0 0.602834 0.805462 0.141526 0.882195 0.587881 0.878063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217615 episodes
GETTING ACTION FROM:
action 2, numVisits=206668, meanQ=4.947463, numObservations: 4
action -1, numVisits=10939, meanQ=3.031034, numObservations: 1
action 1, numVisits=5, meanQ=-0.201980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.602834 0.805462 0.141526 0.882195 0.587881 0.878063 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=18256, meanQ=5.073577, numObservations: 4
action 2, numVisits=8, meanQ=1.996250, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 282028 episodes
GETTING ACTION FROM:
action 1, numVisits=300284, meanQ=5.913188, numObservations: 4
action 2, numVisits=8, meanQ=1.996250, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.602834 0.805462 0.141526 0.882195 0.587881 0.878063 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 486
Initial state: 0 0.524941 0.894831 0.316352 0.510671 0.528621 0.850742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220757 episodes
GETTING ACTION FROM:
action 3, numVisits=220695, meanQ=4.949114, numObservations: 3
action 0, numVisits=58, meanQ=4.034310, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.524941 0.894831 0.316352 0.510671 0.528621 0.850742 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.669514 0.855084 0.150997 0.618607 0.535316 0.844338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221390 episodes
GETTING ACTION FROM:
action 3, numVisits=221376, meanQ=4.973382, numObservations: 4
action 1, numVisits=9, meanQ=-0.335556, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.669514 0.855084 0.150997 0.618607 0.535316 0.844338 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 488
Initial state: 0 0.527007 0.853968 0.690574 0.837635 0.498029 0.321973 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220232 episodes
GETTING ACTION FROM:
action 2, numVisits=220226, meanQ=4.932581, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.527007 0.853968 0.690574 0.837635 0.498029 0.321973 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.640806 0.856739 0.509543 0.848417 0.122474 0.950169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 158388 episodes
GETTING ACTION FROM:
action 0, numVisits=158351, meanQ=5.948249, numObservations: 3
action 1, numVisits=22, meanQ=1.640459, numObservations: 4
action -1, numVisits=12, meanQ=1.462112, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.640806 0.856739 0.509543 0.848417 0.122474 0.950169 w: 1
Observation: 0 0 0.811087 0 0.928608 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=63129, meanQ=7.710966, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
Sampled 243318 episodes
GETTING ACTION FROM:
action 3, numVisits=306345, meanQ=5.368104, numObservations: 3
action -1, numVisits=70, meanQ=4.523051, numObservations: 1
action 0, numVisits=34, meanQ=4.135336, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 0 0.640806 0.856739 0.509543 0.848417 0.122474 0.950169 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=23899, meanQ=5.538581, numObservations: 4
action 3, numVisits=190, meanQ=5.107132, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 280091 episodes
GETTING ACTION FROM:
action 2, numVisits=303987, meanQ=5.560835, numObservations: 4
action 3, numVisits=191, meanQ=5.022801, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.640806 0.856739 0.509543 0.848417 0.122474 0.950169 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 490
Initial state: 0 0.589404 0.824143 0.623826 0.83007 0.857934 0.234469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 151953 episodes
GETTING ACTION FROM:
action 0, numVisits=151937, meanQ=3.062604, numObservations: 1
action 2, numVisits=11, meanQ=0.263645, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.589404 0.824143 0.623826 0.83007 0.857934 0.234469 w: 1
Observation: 0 0 0.729345 0 0.802697 0 0.252977 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=151917, meanQ=5.137053, numObservations: 4
action 2, numVisits=14, meanQ=2.569293, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 241953 episodes
GETTING ACTION FROM:
action 3, numVisits=393870, meanQ=5.176695, numObservations: 4
action 2, numVisits=14, meanQ=2.569293, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.589404 0.824143 0.623826 0.83007 0.857934 0.234469 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 491
Initial state: 0 0.598604 0.824 0.666482 0.814231 0.212833 0.108044 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221808 episodes
GETTING ACTION FROM:
action 1, numVisits=221795, meanQ=5.162773, numObservations: 4
action 2, numVisits=5, meanQ=0.998040, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.598604 0.824 0.666482 0.814231 0.212833 0.108044 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.181238 0.22705 0.654443 0.860804 0.613015 0.87429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 217858 episodes
GETTING ACTION FROM:
action 3, numVisits=217852, meanQ=4.953970, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.181238 0.22705 0.654443 0.860804 0.613015 0.87429 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.687662 0.835814 0.649104 0.813018 0.80292 0.197351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 220978 episodes
GETTING ACTION FROM:
action 2, numVisits=220942, meanQ=4.960850, numObservations: 4
action 1, numVisits=31, meanQ=3.052913, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.687662 0.835814 0.649104 0.813018 0.80292 0.197351 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 494
Initial state: 0 0.624738 0.8713 0.597614 0.819896 0.745879 0.0645413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222671 episodes
GETTING ACTION FROM:
action 3, numVisits=222556, meanQ=5.042430, numObservations: 4
action 0, numVisits=44, meanQ=3.832544, numObservations: 1
action 2, numVisits=68, meanQ=3.760588, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.624738 0.8713 0.597614 0.819896 0.745879 0.0645413 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4285, meanQ=6.953682, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 276388 episodes
GETTING ACTION FROM:
action 1, numVisits=280671, meanQ=5.942570, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.624738 0.8713 0.597614 0.819896 0.745879 0.0645413 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 495
Initial state: 0 0.616286 0.877612 0.619683 0.897258 0.945772 0.436288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221226 episodes
GETTING ACTION FROM:
action 1, numVisits=221213, meanQ=4.948848, numObservations: 4
action 2, numVisits=7, meanQ=-0.429986, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.616286 0.877612 0.619683 0.897258 0.945772 0.436288 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.55717 0.807736 0.581806 0.862701 0.289867 0.310777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221064 episodes
GETTING ACTION FROM:
action 1, numVisits=221006, meanQ=5.018279, numObservations: 4
action 0, numVisits=32, meanQ=3.784186, numObservations: 1
action 2, numVisits=13, meanQ=2.845400, numObservations: 2
action 3, numVisits=11, meanQ=2.808182, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.55717 0.807736 0.581806 0.862701 0.289867 0.310777 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.695737 0.845492 0.745166 0.0186597 0.593828 0.869409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 224403 episodes
GETTING ACTION FROM:
action 3, numVisits=224355, meanQ=4.947773, numObservations: 3
action -1, numVisits=41, meanQ=3.858125, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.695737 0.845492 0.745166 0.0186597 0.593828 0.869409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.432181 0.449947 0.689299 0.879622 0.535238 0.89001 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221906 episodes
GETTING ACTION FROM:
action 2, numVisits=221855, meanQ=4.979983, numObservations: 4
action -1, numVisits=23, meanQ=3.484769, numObservations: 1
action 3, numVisits=22, meanQ=2.903641, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.432181 0.449947 0.689299 0.879622 0.535238 0.89001 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.691426 0.25976 0.546852 0.841674 0.582039 0.875314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 222185 episodes
GETTING ACTION FROM:
action 2, numVisits=222024, meanQ=4.962007, numObservations: 4
action -1, numVisits=129, meanQ=4.354163, numObservations: 1
action 3, numVisits=29, meanQ=2.513448, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.691426 0.25976 0.546852 0.841674 0.582039 0.875314 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.589211 0.788146 0.633394 0.878663 0.554914 0.834343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 221396 episodes
GETTING ACTION FROM:
action 2, numVisits=221360, meanQ=4.958623, numObservations: 4
action 0, numVisits=17, meanQ=3.151975, numObservations: 1
action 1, numVisits=16, meanQ=2.242513, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.589211 0.788146 0.633394 0.878663 0.554914 0.834343 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=10876, meanQ=7.806220, numObservations: 4
action 3, numVisits=17, meanQ=5.822959, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 282418 episodes
GETTING ACTION FROM:
action 1, numVisits=293199, meanQ=5.829585, numObservations: 4
action 3, numVisits=100, meanQ=5.056103, numObservations: 4
action 2, numVisits=12, meanQ=3.665000, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.589211 0.788146 0.633394 0.878663 0.554914 0.834343 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=1678, meanQ=5.643459, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 285679 episodes
GETTING ACTION FROM:
action 1, numVisits=284334, meanQ=5.535008, numObservations: 4
action 0, numVisits=3024, meanQ=2.399363, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.589211 0.788146 0.633394 0.878663 0.554914 0.834343 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=4487, meanQ=8.466855, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 289414 episodes
GETTING ACTION FROM:
action 3, numVisits=293901, meanQ=6.411181, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.589211 0.788146 0.633394 0.878663 0.554914 0.834343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
