Run # 1
Initial state: 0 0.648869 0.821305 0.00236788 0.988214 0.681161 0.843318 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2064838 episodes
GETTING ACTION FROM:
action 3, numVisits=2064728, meanQ=5.002573, numObservations: 5
action -1, numVisits=106, meanQ=4.265017, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.648869 0.821305 0.00236788 0.988214 0.681161 0.843318 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.224752 0.715805 0.513464 0.836757 0.617102 0.859121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2167959 episodes
GETTING ACTION FROM:
action 3, numVisits=2167952, meanQ=4.952351, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.224752 0.715805 0.513464 0.836757 0.617102 0.859121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.600307 0.85431 0.0404272 0.251639 0.681432 0.865175 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2198187 episodes
GETTING ACTION FROM:
action 2, numVisits=2198180, meanQ=4.946684, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.600307 0.85431 0.0404272 0.251639 0.681432 0.865175 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=251724, meanQ=8.539895, numObservations: 3
action 3, numVisits=9, meanQ=6.110011, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2826499 episodes
GETTING ACTION FROM:
action 3, numVisits=1238630, meanQ=6.226299, numObservations: 4
action 1, numVisits=1839600, meanQ=6.202403, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.600307 0.85431 0.0404272 0.251639 0.681432 0.865175 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3123, meanQ=7.852044, numObservations: 3
action 1, numVisits=131, meanQ=7.161762, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2914228 episodes
GETTING ACTION FROM:
action 1, numVisits=2894763, meanQ=6.264833, numObservations: 4
action 3, numVisits=22717, meanQ=6.217376, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600307 0.85431 0.0404272 0.251639 0.681432 0.865175 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 4
Initial state: 0 0.0481526 0.204688 0.527139 0.80206 0.578992 0.893462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2207974 episodes
GETTING ACTION FROM:
action 3, numVisits=2207965, meanQ=4.951026, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0481526 0.204688 0.527139 0.80206 0.578992 0.893462 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 5
Initial state: 0 0.338661 0.238204 0.616875 0.860013 0.62728 0.836271 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1517682 episodes
GETTING ACTION FROM:
action 0, numVisits=1318775, meanQ=2.975220, numObservations: 1
action -1, numVisits=198903, meanQ=2.919143, numObservations: 1
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.338661 0.238204 0.616875 0.860013 0.62728 0.836271 w: 1
Observation: 0 0 0.21767 0 0.949137 0 0.913163 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1318733, meanQ=5.027129, numObservations: 4
action 0, numVisits=26, meanQ=3.358935, numObservations: 2
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2415744 episodes
GETTING ACTION FROM:
action 3, numVisits=3734474, meanQ=4.813767, numObservations: 4
action 0, numVisits=29, meanQ=3.326143, numObservations: 2
action 1, numVisits=11, meanQ=2.453636, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.338661 0.238204 0.616875 0.860013 0.62728 0.836271 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 6
Initial state: 0 0.56511 0.890383 0.684774 0.820307 0.717323 0.0118998 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2184560 episodes
GETTING ACTION FROM:
action 2, numVisits=2184525, meanQ=4.952056, numObservations: 5
action 0, numVisits=31, meanQ=3.488706, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.56511 0.890383 0.684774 0.820307 0.717323 0.0118998 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.629083 0.822592 0.586423 0.858475 0.00292723 0.056346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2075483 episodes
GETTING ACTION FROM:
action 3, numVisits=2075452, meanQ=4.729800, numObservations: 5
action -1, numVisits=20, meanQ=2.939884, numObservations: 1
action 2, numVisits=8, meanQ=1.747512, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.629083 0.822592 0.586423 0.858475 0.00292723 0.056346 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=289985, meanQ=6.330207, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2827009 episodes
GETTING ACTION FROM:
action 1, numVisits=2678640, meanQ=5.965031, numObservations: 4
action -1, numVisits=438355, meanQ=4.187661, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.629083 0.822592 0.586423 0.858475 0.00292723 0.056346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 8
Initial state: 0 0.686558 0.886321 0.911647 0.948559 0.687817 0.846684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2200839 episodes
GETTING ACTION FROM:
action 1, numVisits=2188216, meanQ=5.028579, numObservations: 5
action -1, numVisits=12563, meanQ=3.081145, numObservations: 1
action 0, numVisits=58, meanQ=2.323030, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.686558 0.886321 0.911647 0.948559 0.687817 0.846684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.502927 0.810861 0.222567 0.766969 0.516227 0.812717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2283685 episodes
GETTING ACTION FROM:
action 2, numVisits=2276393, meanQ=5.025580, numObservations: 4
action 0, numVisits=7284, meanQ=2.884797, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.502927 0.810861 0.222567 0.766969 0.516227 0.812717 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 10
Initial state: 0 0.136563 0.647292 0.666595 0.838686 0.591656 0.861294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245782 episodes
GETTING ACTION FROM:
action 2, numVisits=2239864, meanQ=5.008125, numObservations: 4
action -1, numVisits=5914, meanQ=3.004953, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.136563 0.647292 0.666595 0.838686 0.591656 0.861294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.655457 0.886985 0.698539 0.836014 0.912797 0.283656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2233333 episodes
GETTING ACTION FROM:
action 3, numVisits=2233300, meanQ=4.957912, numObservations: 5
action 1, numVisits=25, meanQ=3.389212, numObservations: 3
action 2, numVisits=4, meanQ=-0.007500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.655457 0.886985 0.698539 0.836014 0.912797 0.283656 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.617993 0.850073 0.121545 0.644509 0.565226 0.889441 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2283856 episodes
GETTING ACTION FROM:
action 3, numVisits=2283586, meanQ=4.963367, numObservations: 3
action 1, numVisits=211, meanQ=3.902892, numObservations: 5
action -1, numVisits=43, meanQ=3.772279, numObservations: 1
action 2, numVisits=14, meanQ=2.427857, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.617993 0.850073 0.121545 0.644509 0.565226 0.889441 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.333931 0.239381 0.518584 0.807698 0.632176 0.886435 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251578 episodes
GETTING ACTION FROM:
action 3, numVisits=2251571, meanQ=4.940411, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.333931 0.239381 0.518584 0.807698 0.632176 0.886435 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 14
Initial state: 0 0.763685 0.461158 0.544179 0.802056 0.682552 0.85578 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263058 episodes
GETTING ACTION FROM:
action 1, numVisits=2261975, meanQ=4.962422, numObservations: 4
action 2, numVisits=1078, meanQ=4.731484, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.763685 0.461158 0.544179 0.802056 0.682552 0.85578 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.669655 0.853983 0.541287 0.847439 0.80108 0.567026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268971 episodes
GETTING ACTION FROM:
action 2, numVisits=2268937, meanQ=5.022208, numObservations: 4
action 1, numVisits=29, meanQ=3.331034, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.669655 0.853983 0.541287 0.847439 0.80108 0.567026 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.472416 0.744711 0.590395 0.81726 0.536 0.802692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1567514 episodes
GETTING ACTION FROM:
action 0, numVisits=1567503, meanQ=2.947183, numObservations: 1
action 1, numVisits=5, meanQ=-0.597980, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.472416 0.744711 0.590395 0.81726 0.536 0.802692 w: 1
Observation: 0 0 0.686061 0 0.838971 0 0.737087 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1567443, meanQ=4.996356, numObservations: 4
action 0, numVisits=32, meanQ=3.615986, numObservations: 1
action -1, numVisits=22, meanQ=3.372571, numObservations: 1
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
Sampled 2523519 episodes
GETTING ACTION FROM:
action 1, numVisits=4090952, meanQ=4.872753, numObservations: 4
action 0, numVisits=33, meanQ=3.509105, numObservations: 1
action -1, numVisits=31, meanQ=3.460234, numObservations: 1
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 0 0.472416 0.744711 0.590395 0.81726 0.536 0.802692 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=578725, meanQ=8.405559, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2889201 episodes
GETTING ACTION FROM:
action 2, numVisits=3467917, meanQ=6.475023, numObservations: 4
action 0, numVisits=6, meanQ=2.620000, numObservations: 1
action 3, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.472416 0.744711 0.590395 0.81726 0.536 0.802692 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 17
Initial state: 0 0.203852 0.190121 0.609005 0.819635 0.680164 0.825107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260733 episodes
GETTING ACTION FROM:
action 3, numVisits=2260637, meanQ=5.000278, numObservations: 4
action 1, numVisits=61, meanQ=3.717057, numObservations: 5
action -1, numVisits=32, meanQ=3.588201, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.203852 0.190121 0.609005 0.819635 0.680164 0.825107 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.185926 0.60701 0.682309 0.845708 0.663116 0.868424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2124481 episodes
GETTING ACTION FROM:
action 2, numVisits=2124453, meanQ=4.874778, numObservations: 5
action 0, numVisits=13, meanQ=2.493077, numObservations: 1
action 3, numVisits=8, meanQ=1.498775, numObservations: 2
action 1, numVisits=5, meanQ=0.998040, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.185926 0.60701 0.682309 0.845708 0.663116 0.868424 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 19
Initial state: 0 0.59703 0.85347 0.510198 0.803816 0.756355 0.901519 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261767 episodes
GETTING ACTION FROM:
action 2, numVisits=2261761, meanQ=5.011753, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.59703 0.85347 0.510198 0.803816 0.756355 0.901519 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 20
Initial state: 0 0.593655 0.825158 0.664087 0.898552 0.235592 0.200289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243781 episodes
GETTING ACTION FROM:
action 2, numVisits=2243667, meanQ=5.142400, numObservations: 5
action -1, numVisits=58, meanQ=4.142586, numObservations: 1
action 0, numVisits=44, meanQ=3.973101, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action: 2
Next state: 1 0.593655 0.825158 0.664087 0.898552 0.235592 0.200289 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.55543 0.808539 0.659204 0.860168 0.478668 0.0938615 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237218 episodes
GETTING ACTION FROM:
action 2, numVisits=2235831, meanQ=5.020641, numObservations: 5
action 0, numVisits=1382, meanQ=2.659441, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.55543 0.808539 0.659204 0.860168 0.478668 0.0938615 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 22
Initial state: 0 0.857458 0.379098 0.504891 0.875769 0.569452 0.861365 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2145558 episodes
GETTING ACTION FROM:
action 1, numVisits=2145499, meanQ=4.898017, numObservations: 4
action 0, numVisits=37, meanQ=3.599885, numObservations: 1
action 3, numVisits=19, meanQ=2.788426, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.857458 0.379098 0.504891 0.875769 0.569452 0.861365 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 23
Initial state: 0 0.76542 0.178247 0.617884 0.884932 0.523466 0.811979 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2278148 episodes
GETTING ACTION FROM:
action 2, numVisits=2278087, meanQ=5.015924, numObservations: 4
action -1, numVisits=40, meanQ=3.773956, numObservations: 1
action 0, numVisits=10, meanQ=2.485195, numObservations: 1
action 1, numVisits=9, meanQ=2.333344, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.76542 0.178247 0.617884 0.884932 0.523466 0.811979 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.696906 0.873938 0.24622 0.666198 0.511591 0.892952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247864 episodes
GETTING ACTION FROM:
action 1, numVisits=2247795, meanQ=4.947703, numObservations: 5
action 2, numVisits=48, meanQ=3.838009, numObservations: 5
action 3, numVisits=17, meanQ=3.000600, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.696906 0.873938 0.24622 0.666198 0.511591 0.892952 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 25
Initial state: 0 0.743783 0.83422 0.674822 0.822203 0.663105 0.837567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259917 episodes
GETTING ACTION FROM:
action 2, numVisits=2259865, meanQ=5.016773, numObservations: 5
action -1, numVisits=30, meanQ=3.559403, numObservations: 1
action 0, numVisits=16, meanQ=2.999546, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.743783 0.83422 0.674822 0.822203 0.663105 0.837567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.274805 0.932105 0.598732 0.875675 0.639338 0.838473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250003 episodes
GETTING ACTION FROM:
action 1, numVisits=2249993, meanQ=4.963021, numObservations: 4
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.274805 0.932105 0.598732 0.875675 0.639338 0.838473 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.586677 0.801309 0.910617 0.848447 0.634264 0.888148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1543298 episodes
GETTING ACTION FROM:
action -1, numVisits=1542690, meanQ=2.911701, numObservations: 1
action 0, numVisits=599, meanQ=2.609276, numObservations: 1
action 1, numVisits=4, meanQ=-2.005000, numObservations: 3
action 3, numVisits=3, meanQ=-2.966667, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: -1
Next state: 0 0.586677 0.801309 0.910617 0.848447 0.634264 0.888148 w: 1
Observation: 0 0.488771 0 1 0 0.714828 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1542594, meanQ=4.963849, numObservations: 5
action -1, numVisits=87, meanQ=4.140551, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2452977 episodes
GETTING ACTION FROM:
action 3, numVisits=3995571, meanQ=5.160472, numObservations: 5
action -1, numVisits=87, meanQ=4.140551, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.586677 0.801309 0.910617 0.848447 0.634264 0.888148 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 28
Initial state: 0 0.564577 0.8074 0.323689 0.393824 0.692538 0.805082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1595681 episodes
GETTING ACTION FROM:
action 0, numVisits=1595664, meanQ=5.899127, numObservations: 3
action 1, numVisits=13, meanQ=1.307700, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.564577 0.8074 0.323689 0.393824 0.692538 0.805082 w: 1
Observation: 0 0 0.862267 0 0.333473 0 0.799237 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=538022, meanQ=7.847912, numObservations: 5
action 3, numVisits=17, meanQ=5.700000, numObservations: 3
action 2, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2387486 episodes
GETTING ACTION FROM:
action 1, numVisits=2925216, meanQ=5.503633, numObservations: 5
action 3, numVisits=303, meanQ=5.048257, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.564577 0.8074 0.323689 0.393824 0.692538 0.805082 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 29
Initial state: 0 0.665769 0.811137 0.853963 0.543525 0.501231 0.876327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2231945 episodes
GETTING ACTION FROM:
action 1, numVisits=2231846, meanQ=4.963423, numObservations: 5
action -1, numVisits=95, meanQ=4.180222, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.665769 0.811137 0.853963 0.543525 0.501231 0.876327 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 30
Initial state: 0 0.600299 0.864139 0.0334182 0.546019 0.64377 0.867429 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271621 episodes
GETTING ACTION FROM:
action 2, numVisits=2271603, meanQ=5.014492, numObservations: 3
action 3, numVisits=13, meanQ=-0.231523, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.600299 0.864139 0.0334182 0.546019 0.64377 0.867429 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=371362, meanQ=8.354994, numObservations: 4
action 3, numVisits=156, meanQ=7.759888, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2885638 episodes
GETTING ACTION FROM:
action 1, numVisits=3255258, meanQ=6.122997, numObservations: 4
action 3, numVisits=1892, meanQ=5.943127, numObservations: 4
action 0, numVisits=6, meanQ=2.620000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600299 0.864139 0.0334182 0.546019 0.64377 0.867429 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 31
Initial state: 0 0.648871 0.884801 0.833513 0.981066 0.508401 0.823836 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1460240 episodes
GETTING ACTION FROM:
action 0, numVisits=1459467, meanQ=5.318547, numObservations: 3
action -1, numVisits=768, meanQ=3.845054, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.648871 0.884801 0.833513 0.981066 0.508401 0.823836 w: 1
Observation: 0 0 0.797544 0 0.906695 0 0.845209 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=469895, meanQ=6.033764, numObservations: 1
action 1, numVisits=24, meanQ=1.976667, numObservations: 3
action 3, numVisits=5, meanQ=-0.597980, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 1683475 episodes
GETTING ACTION FROM:
action 0, numVisits=2153370, meanQ=4.790160, numObservations: 1
action 1, numVisits=24, meanQ=1.976667, numObservations: 3
action 3, numVisits=5, meanQ=-0.597980, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 0
Next state: 0 0.648871 0.884801 0.833513 0.981066 0.508401 0.823836 w: 1
Observation: 0 0 0.805148 0 1 0 0.815067 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2060849, meanQ=5.913985, numObservations: 3
action 3, numVisits=92515, meanQ=5.894149, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2527603 episodes
GETTING ACTION FROM:
action 2, numVisits=4530617, meanQ=5.564831, numObservations: 3
action 3, numVisits=150350, meanQ=5.548225, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.648871 0.884801 0.833513 0.981066 0.508401 0.823836 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 32
Initial state: 0 0.14146 0.263638 0.62764 0.879277 0.56464 0.83055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1557235 episodes
GETTING ACTION FROM:
action -1, numVisits=1557072, meanQ=2.905106, numObservations: 1
action 0, numVisits=110, meanQ=2.182604, numObservations: 1
action 3, numVisits=26, meanQ=1.383473, numObservations: 4
action 2, numVisits=23, meanQ=0.912191, numObservations: 4
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action: -1
Next state: 0 0.14146 0.263638 0.62764 0.879277 0.56464 0.83055 w: 1
Observation: 0 0.150871 0 0.592339 0 0.60701 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1556893, meanQ=4.952572, numObservations: 4
action 3, numVisits=164, meanQ=4.364327, numObservations: 5
action 1, numVisits=10, meanQ=1.799010, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2479844 episodes
GETTING ACTION FROM:
action 2, numVisits=4036648, meanQ=4.941883, numObservations: 4
action 3, numVisits=253, meanQ=4.438816, numObservations: 5
action 1, numVisits=10, meanQ=1.799010, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.14146 0.263638 0.62764 0.879277 0.56464 0.83055 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=306773, meanQ=4.823104, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2903186 episodes
GETTING ACTION FROM:
action 1, numVisits=3209959, meanQ=5.794926, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.14146 0.263638 0.62764 0.879277 0.56464 0.83055 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=100699, meanQ=7.935201, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2946596 episodes
GETTING ACTION FROM:
action 2, numVisits=3047293, meanQ=5.953663, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.14146 0.263638 0.62764 0.879277 0.56464 0.83055 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 33
Initial state: 0 0.699832 0.85374 0.578021 0.827848 0.0605676 0.605327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261147 episodes
GETTING ACTION FROM:
action 1, numVisits=2261049, meanQ=4.956488, numObservations: 4
action 0, numVisits=79, meanQ=4.090379, numObservations: 1
action 2, numVisits=14, meanQ=2.564293, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.699832 0.85374 0.578021 0.827848 0.0605676 0.605327 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 34
Initial state: 0 0.538083 0.83875 0.735672 0.253941 0.594086 0.837591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2272670 episodes
GETTING ACTION FROM:
action 1, numVisits=2253608, meanQ=4.959124, numObservations: 3
action 3, numVisits=19031, meanQ=4.895186, numObservations: 4
action 0, numVisits=27, meanQ=3.434684, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.538083 0.83875 0.735672 0.253941 0.594086 0.837591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.856635 0.468092 0.689669 0.88678 0.555472 0.878475 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261725 episodes
GETTING ACTION FROM:
action 2, numVisits=2261718, meanQ=5.045722, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.856635 0.468092 0.689669 0.88678 0.555472 0.878475 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 36
Initial state: 0 0.388917 0.413523 0.508539 0.812311 0.625929 0.847355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241687 episodes
GETTING ACTION FROM:
action 1, numVisits=2241495, meanQ=5.015189, numObservations: 5
action 0, numVisits=188, meanQ=4.461433, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.388917 0.413523 0.508539 0.812311 0.625929 0.847355 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=53957, meanQ=7.988026, numObservations: 4
action 3, numVisits=5, meanQ=4.196000, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2906313 episodes
GETTING ACTION FROM:
action 2, numVisits=2960256, meanQ=5.905727, numObservations: 4
action 3, numVisits=12, meanQ=3.665000, numObservations: 4
action 1, numVisits=7, meanQ=2.711429, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.388917 0.413523 0.508539 0.812311 0.625929 0.847355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 37
Initial state: 0 0.295972 0.686906 0.695298 0.839948 0.511099 0.846393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242925 episodes
GETTING ACTION FROM:
action 3, numVisits=2242915, meanQ=5.025943, numObservations: 5
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.295972 0.686906 0.695298 0.839948 0.511099 0.846393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 38
Initial state: 0 0.00925704 0.724623 0.668682 0.883048 0.676834 0.876652 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268758 episodes
GETTING ACTION FROM:
action 3, numVisits=2268690, meanQ=5.025654, numObservations: 4
action -1, numVisits=35, meanQ=3.706755, numObservations: 1
action 2, numVisits=30, meanQ=3.257673, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.00925704 0.724623 0.668682 0.883048 0.676834 0.876652 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.697026 0.894486 0.59756 0.840975 0.849241 0.720809 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249919 episodes
GETTING ACTION FROM:
action 1, numVisits=2249911, meanQ=4.963191, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.697026 0.894486 0.59756 0.840975 0.849241 0.720809 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=21745, meanQ=5.455961, numObservations: 3
action 2, numVisits=15, meanQ=3.134007, numObservations: 4
action 3, numVisits=9, meanQ=2.553344, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2656491 episodes
GETTING ACTION FROM:
action 1, numVisits=2678232, meanQ=5.217488, numObservations: 4
action 2, numVisits=15, meanQ=3.134007, numObservations: 4
action 3, numVisits=9, meanQ=2.553344, numObservations: 3
action -1, numVisits=4, meanQ=0.475000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.697026 0.894486 0.59756 0.840975 0.849241 0.720809 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 40
Initial state: 0 0.527794 0.880554 0.569055 0.826156 0.934525 0.49336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242718 episodes
GETTING ACTION FROM:
action 1, numVisits=2242673, meanQ=4.951332, numObservations: 5
action 0, numVisits=29, meanQ=3.499920, numObservations: 1
action 2, numVisits=13, meanQ=2.536169, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.527794 0.880554 0.569055 0.826156 0.934525 0.49336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.232234 0.101172 0.545964 0.854195 0.638851 0.883354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264016 episodes
GETTING ACTION FROM:
action 3, numVisits=2263988, meanQ=5.019225, numObservations: 4
action -1, numVisits=24, meanQ=3.414816, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.232234 0.101172 0.545964 0.854195 0.638851 0.883354 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 42
Initial state: 0 0.331207 0.16095 0.501577 0.827228 0.605611 0.882911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2290788 episodes
GETTING ACTION FROM:
action 3, numVisits=2290654, meanQ=5.035559, numObservations: 3
action 0, numVisits=126, meanQ=4.353219, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.331207 0.16095 0.501577 0.827228 0.605611 0.882911 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.640957 0.879022 0.873199 0.0518349 0.588138 0.846717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245101 episodes
GETTING ACTION FROM:
action 1, numVisits=2238214, meanQ=5.007678, numObservations: 5
action 0, numVisits=6867, meanQ=2.863822, numObservations: 1
action 2, numVisits=8, meanQ=0.748763, numObservations: 2
action 3, numVisits=10, meanQ=0.598000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.640957 0.879022 0.873199 0.0518349 0.588138 0.846717 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 44
Initial state: 0 0.682643 0.805502 0.529258 0.827305 0.313072 0.493854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240180 episodes
GETTING ACTION FROM:
action 1, numVisits=2229532, meanQ=4.947394, numObservations: 5
action -1, numVisits=10635, meanQ=3.021332, numObservations: 1
action 2, numVisits=10, meanQ=0.590020, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.682643 0.805502 0.529258 0.827305 0.313072 0.493854 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 45
Initial state: 0 0.654885 0.861989 0.685427 0.880776 0.390923 0.369829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2235315 episodes
GETTING ACTION FROM:
action 3, numVisits=2235221, meanQ=4.956113, numObservations: 5
action 0, numVisits=58, meanQ=3.944166, numObservations: 1
action 1, numVisits=24, meanQ=2.999167, numObservations: 4
action -1, numVisits=11, meanQ=2.590000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.654885 0.861989 0.685427 0.880776 0.390923 0.369829 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=256017, meanQ=8.545616, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2944015 episodes
GETTING ACTION FROM:
action 1, numVisits=3200030, meanQ=6.321824, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.654885 0.861989 0.685427 0.880776 0.390923 0.369829 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 46
Initial state: 0 0.336172 0.694515 0.557678 0.829726 0.683363 0.829484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256750 episodes
GETTING ACTION FROM:
action 2, numVisits=2256593, meanQ=5.007966, numObservations: 4
action 0, numVisits=126, meanQ=4.326124, numObservations: 1
action -1, numVisits=28, meanQ=3.547529, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.336172 0.694515 0.557678 0.829726 0.683363 0.829484 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.131162 0.559589 0.694637 0.894222 0.543433 0.883659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257843 episodes
GETTING ACTION FROM:
action 1, numVisits=2257829, meanQ=4.934841, numObservations: 4
action 2, numVisits=7, meanQ=0.144314, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.131162 0.559589 0.694637 0.894222 0.543433 0.883659 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=313796, meanQ=8.413468, numObservations: 5
action 3, numVisits=3357, meanQ=8.301419, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2899759 episodes
GETTING ACTION FROM:
action 3, numVisits=1819343, meanQ=6.411236, numObservations: 3
action 2, numVisits=1397567, meanQ=6.410237, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.131162 0.559589 0.694637 0.894222 0.543433 0.883659 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 48
Initial state: 0 0.728633 0.121255 0.506843 0.841525 0.646964 0.869245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2221038 episodes
GETTING ACTION FROM:
action 3, numVisits=2221026, meanQ=4.966303, numObservations: 5
action 2, numVisits=7, meanQ=1.014286, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.728633 0.121255 0.506843 0.841525 0.646964 0.869245 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=165252, meanQ=4.930103, numObservations: 5
action 2, numVisits=206, meanQ=4.143663, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2863352 episodes
GETTING ACTION FROM:
action 1, numVisits=3028604, meanQ=6.087303, numObservations: 5
action 2, numVisits=206, meanQ=4.143663, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.728633 0.121255 0.506843 0.841525 0.646964 0.869245 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 49
Initial state: 0 0.689494 0.898578 0.621509 0.00813093 0.654261 0.896532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228811 episodes
GETTING ACTION FROM:
action 2, numVisits=2225566, meanQ=4.980425, numObservations: 5
action -1, numVisits=3241, meanQ=2.576919, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.689494 0.898578 0.621509 0.00813093 0.654261 0.896532 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 50
Initial state: 0 0.853508 0.726619 0.678715 0.89678 0.530051 0.897312 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271704 episodes
GETTING ACTION FROM:
action 1, numVisits=2271697, meanQ=5.021780, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.853508 0.726619 0.678715 0.89678 0.530051 0.897312 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 51
Initial state: 0 0.568844 0.847097 0.508073 0.51207 0.551178 0.858424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242420 episodes
GETTING ACTION FROM:
action 2, numVisits=2242410, meanQ=5.019042, numObservations: 5
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.568844 0.847097 0.508073 0.51207 0.551178 0.858424 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 52
Initial state: 0 0.551308 0.857817 0.779135 0.135618 0.682331 0.859524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267846 episodes
GETTING ACTION FROM:
action 1, numVisits=2267837, meanQ=5.034715, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.551308 0.857817 0.779135 0.135618 0.682331 0.859524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 53
Initial state: 0 0.545442 0.817374 0.535785 0.894292 0.427488 0.278294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246491 episodes
GETTING ACTION FROM:
action 2, numVisits=2246480, meanQ=4.964779, numObservations: 4
action 3, numVisits=6, meanQ=-0.669983, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.545442 0.817374 0.535785 0.894292 0.427488 0.278294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.996475 0.307667 0.684357 0.849305 0.502521 0.850956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2227850 episodes
GETTING ACTION FROM:
action 1, numVisits=2227843, meanQ=4.947846, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.996475 0.307667 0.684357 0.849305 0.502521 0.850956 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 55
Initial state: 0 0.200302 0.826121 0.66739 0.824985 0.617892 0.820386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248214 episodes
GETTING ACTION FROM:
action 2, numVisits=2248208, meanQ=5.010142, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.200302 0.826121 0.66739 0.824985 0.617892 0.820386 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 56
Initial state: 0 0.620894 0.882277 0.569414 0.833913 0.0645432 0.0714672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229586 episodes
GETTING ACTION FROM:
action 2, numVisits=2229580, meanQ=4.957166, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.620894 0.882277 0.569414 0.833913 0.0645432 0.0714672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=166109, meanQ=4.900309, numObservations: 4
action 0, numVisits=45, meanQ=3.859202, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2889271 episodes
GETTING ACTION FROM:
action 3, numVisits=3055380, meanQ=5.760568, numObservations: 4
action 0, numVisits=45, meanQ=3.859202, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.620894 0.882277 0.569414 0.833913 0.0645432 0.0714672 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=26854, meanQ=7.907149, numObservations: 5
action 2, numVisits=764, meanQ=7.710193, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2952442 episodes
GETTING ACTION FROM:
action 1, numVisits=2976456, meanQ=6.166956, numObservations: 5
action 2, numVisits=3602, meanQ=6.041980, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.620894 0.882277 0.569414 0.833913 0.0645432 0.0714672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 57
Initial state: 0 0.6414 0.8667 0.654047 0.852225 0.850129 0.741069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268143 episodes
GETTING ACTION FROM:
action 1, numVisits=2268137, meanQ=4.959675, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.6414 0.8667 0.654047 0.852225 0.850129 0.741069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=166731, meanQ=4.719469, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2849912 episodes
GETTING ACTION FROM:
action 3, numVisits=3016643, meanQ=5.855931, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.6414 0.8667 0.654047 0.852225 0.850129 0.741069 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 58
Initial state: 0 0.511431 0.867951 0.696627 0.836191 0.34759 0.67607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2231224 episodes
GETTING ACTION FROM:
action 1, numVisits=2185658, meanQ=4.960272, numObservations: 4
action -1, numVisits=45557, meanQ=2.975179, numObservations: 1
action 2, numVisits=6, meanQ=-1.670000, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.511431 0.867951 0.696627 0.836191 0.34759 0.67607 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.98652 0.388167 0.592764 0.819506 0.609822 0.845832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1550585 episodes
GETTING ACTION FROM:
action -1, numVisits=1550577, meanQ=3.096245, numObservations: 1
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.98652 0.388167 0.592764 0.819506 0.609822 0.845832 w: 1
Observation: 0 1 0 0.545124 0 0.515835 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1550482, meanQ=5.152698, numObservations: 5
action -1, numVisits=25, meanQ=3.638233, numObservations: 1
action 3, numVisits=66, meanQ=3.440612, numObservations: 5
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2484321 episodes
GETTING ACTION FROM:
action 2, numVisits=4034803, meanQ=5.320531, numObservations: 5
action -1, numVisits=25, meanQ=3.638233, numObservations: 1
action 3, numVisits=66, meanQ=3.440612, numObservations: 5
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.98652 0.388167 0.592764 0.819506 0.609822 0.845832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 60
Initial state: 0 0.58281 0.85495 0.65344 0.845544 0.310886 0.214366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238736 episodes
GETTING ACTION FROM:
action 1, numVisits=2226317, meanQ=5.027530, numObservations: 5
action 0, numVisits=12414, meanQ=3.075554, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.58281 0.85495 0.65344 0.845544 0.310886 0.214366 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.633943 0.805865 0.236804 0.785611 0.526528 0.894116 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255857 episodes
GETTING ACTION FROM:
action 2, numVisits=2251334, meanQ=5.021606, numObservations: 4
action 0, numVisits=4519, meanQ=3.016647, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.633943 0.805865 0.236804 0.785611 0.526528 0.894116 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=194298, meanQ=8.542271, numObservations: 3
action 3, numVisits=63992, meanQ=8.522571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2920488 episodes
GETTING ACTION FROM:
action 1, numVisits=2636828, meanQ=6.290984, numObservations: 3
action 3, numVisits=541948, meanQ=6.285072, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.633943 0.805865 0.236804 0.785611 0.526528 0.894116 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 62
Initial state: 0 0.117611 0.874177 0.649373 0.831254 0.554123 0.837057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258871 episodes
GETTING ACTION FROM:
action 2, numVisits=2258659, meanQ=4.957175, numObservations: 4
action -1, numVisits=169, meanQ=4.261428, numObservations: 1
action 0, numVisits=38, meanQ=3.675918, numObservations: 1
action 3, numVisits=4, meanQ=-0.007500, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.117611 0.874177 0.649373 0.831254 0.554123 0.837057 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=167947, meanQ=4.705951, numObservations: 5
action -1, numVisits=2517, meanQ=2.846394, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2844198 episodes
GETTING ACTION FROM:
action 3, numVisits=3012145, meanQ=5.740129, numObservations: 5
action -1, numVisits=2517, meanQ=2.846394, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.117611 0.874177 0.649373 0.831254 0.554123 0.837057 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 63
Initial state: 0 0.0999026 0.612101 0.528546 0.828097 0.501754 0.861224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2273128 episodes
GETTING ACTION FROM:
action 2, numVisits=2273090, meanQ=5.014955, numObservations: 4
action -1, numVisits=34, meanQ=3.701927, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0999026 0.612101 0.528546 0.828097 0.501754 0.861224 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.908893 0.0351155 0.587546 0.800286 0.664579 0.841101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234481 episodes
GETTING ACTION FROM:
action 3, numVisits=2234475, meanQ=5.034903, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.908893 0.0351155 0.587546 0.800286 0.664579 0.841101 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.534318 0.845087 0.260902 0.568786 0.550293 0.870183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2205447 episodes
GETTING ACTION FROM:
action 1, numVisits=2205413, meanQ=5.066184, numObservations: 4
action 0, numVisits=21, meanQ=3.398454, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.534318 0.845087 0.260902 0.568786 0.550293 0.870183 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.682656 0.853824 0.593543 0.892248 0.221255 0.455629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242717 episodes
GETTING ACTION FROM:
action 3, numVisits=2242250, meanQ=5.217824, numObservations: 5
action 2, numVisits=428, meanQ=4.429377, numObservations: 4
action 0, numVisits=33, meanQ=3.869798, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.682656 0.853824 0.593543 0.892248 0.221255 0.455629 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=129425, meanQ=8.006499, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2901461 episodes
GETTING ACTION FROM:
action 2, numVisits=3030881, meanQ=5.894851, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 2
Next state: 1 0.682656 0.853824 0.593543 0.892248 0.221255 0.455629 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 67
Initial state: 0 0.582142 0.844779 0.528475 0.318444 0.52112 0.804362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1605195 episodes
GETTING ACTION FROM:
action 0, numVisits=1605180, meanQ=5.078133, numObservations: 2
action 3, numVisits=8, meanQ=-0.002475, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 0
Next state: 0 0.582142 0.844779 0.528475 0.318444 0.52112 0.804362 w: 1
Observation: 0 0 0.888893 0 0.235083 0 0.806444 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1257719, meanQ=7.182623, numObservations: 5
action -1, numVisits=34, meanQ=3.872420, numObservations: 1
action 3, numVisits=10, meanQ=2.598000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2506881 episodes
GETTING ACTION FROM:
action 1, numVisits=3764600, meanQ=5.712387, numObservations: 5
action -1, numVisits=34, meanQ=3.872420, numObservations: 1
action 3, numVisits=10, meanQ=2.598000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.582142 0.844779 0.528475 0.318444 0.52112 0.804362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=251427, meanQ=6.317970, numObservations: 3
action 2, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2733048 episodes
GETTING ACTION FROM:
action 1, numVisits=2984471, meanQ=5.095424, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.582142 0.844779 0.528475 0.318444 0.52112 0.804362 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 68
Initial state: 0 0.413263 0.221641 0.627987 0.885065 0.634598 0.898608 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253028 episodes
GETTING ACTION FROM:
action 2, numVisits=2253020, meanQ=5.036343, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.413263 0.221641 0.627987 0.885065 0.634598 0.898608 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.510275 0.836481 0.839414 0.496581 0.692007 0.868797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242464 episodes
GETTING ACTION FROM:
action 3, numVisits=2242421, meanQ=4.944667, numObservations: 5
action -1, numVisits=38, meanQ=3.703164, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.510275 0.836481 0.839414 0.496581 0.692007 0.868797 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.144898 0.0901249 0.650421 0.807486 0.527227 0.848528 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2222749 episodes
GETTING ACTION FROM:
action 3, numVisits=2222622, meanQ=4.939757, numObservations: 5
action -1, numVisits=84, meanQ=4.090182, numObservations: 1
action 0, numVisits=41, meanQ=3.741416, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.144898 0.0901249 0.650421 0.807486 0.527227 0.848528 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 71
Initial state: 0 0.213101 0.464716 0.524072 0.823878 0.593072 0.877425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248344 episodes
GETTING ACTION FROM:
action 2, numVisits=2248313, meanQ=4.951010, numObservations: 4
action 0, numVisits=23, meanQ=3.114304, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.213101 0.464716 0.524072 0.823878 0.593072 0.877425 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=167619, meanQ=4.640922, numObservations: 4
action -1, numVisits=232, meanQ=4.186394, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2917808 episodes
GETTING ACTION FROM:
action 1, numVisits=3085427, meanQ=5.824349, numObservations: 4
action -1, numVisits=232, meanQ=4.186394, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.213101 0.464716 0.524072 0.823878 0.593072 0.877425 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=43618, meanQ=8.274542, numObservations: 3
action 2, numVisits=28574, meanQ=8.260080, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2994275 episodes
GETTING ACTION FROM:
action 2, numVisits=2844088, meanQ=6.329874, numObservations: 3
action 3, numVisits=222377, meanQ=6.317475, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.213101 0.464716 0.524072 0.823878 0.593072 0.877425 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 72
Initial state: 0 0.988989 0.722009 0.563523 0.821246 0.663894 0.888034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249131 episodes
GETTING ACTION FROM:
action 2, numVisits=2249043, meanQ=4.942664, numObservations: 5
action -1, numVisits=69, meanQ=4.018187, numObservations: 1
action 3, numVisits=8, meanQ=1.500012, numObservations: 3
action 1, numVisits=9, meanQ=0.998889, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.988989 0.722009 0.563523 0.821246 0.663894 0.888034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.586874 0.855888 0.809283 0.326228 0.531801 0.800035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2232462 episodes
GETTING ACTION FROM:
action 1, numVisits=2232455, meanQ=4.950568, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.586874 0.855888 0.809283 0.326228 0.531801 0.800035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.375319 0.330319 0.603205 0.831051 0.534087 0.851733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2212125 episodes
GETTING ACTION FROM:
action 2, numVisits=2212009, meanQ=4.976371, numObservations: 5
action 0, numVisits=58, meanQ=3.954775, numObservations: 1
action 3, numVisits=38, meanQ=3.617113, numObservations: 4
action 1, numVisits=18, meanQ=3.110017, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.375319 0.330319 0.603205 0.831051 0.534087 0.851733 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.505526 0.851314 0.257243 0.828765 0.638483 0.876948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2287407 episodes
GETTING ACTION FROM:
action 1, numVisits=2287379, meanQ=5.030123, numObservations: 3
action 0, numVisits=24, meanQ=3.452748, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.505526 0.851314 0.257243 0.828765 0.638483 0.876948 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.668165 0.899035 0.237089 0.677719 0.587561 0.896907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255018 episodes
GETTING ACTION FROM:
action 2, numVisits=2254793, meanQ=5.045094, numObservations: 5
action 1, numVisits=128, meanQ=4.315699, numObservations: 4
action 0, numVisits=68, meanQ=4.105336, numObservations: 1
action -1, numVisits=28, meanQ=3.547685, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.668165 0.899035 0.237089 0.677719 0.587561 0.896907 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=258451, meanQ=8.544141, numObservations: 3
action 1, numVisits=35, meanQ=7.113723, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2932903 episodes
GETTING ACTION FROM:
action 3, numVisits=3189933, meanQ=6.019984, numObservations: 3
action 1, numVisits=1454, meanQ=5.817054, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.668165 0.899035 0.237089 0.677719 0.587561 0.896907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 77
Initial state: 0 0.301077 0.139769 0.545498 0.810292 0.637707 0.829993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2227447 episodes
GETTING ACTION FROM:
action 3, numVisits=2227435, meanQ=5.029248, numObservations: 5
action 2, numVisits=7, meanQ=1.570000, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.301077 0.139769 0.545498 0.810292 0.637707 0.829993 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.67409 0.86644 0.556596 0.800703 0.902212 0.450384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2301725 episodes
GETTING ACTION FROM:
action 1, numVisits=2296779, meanQ=5.016771, numObservations: 3
action 0, numVisits=4942, meanQ=2.740179, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.67409 0.86644 0.556596 0.800703 0.902212 0.450384 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.646181 0.830909 0.656027 0.820939 0.779883 0.79962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239725 episodes
GETTING ACTION FROM:
action 2, numVisits=2236097, meanQ=5.031974, numObservations: 5
action -1, numVisits=3604, meanQ=2.953512, numObservations: 1
action 3, numVisits=21, meanQ=1.760495, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.646181 0.830909 0.656027 0.820939 0.779883 0.79962 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.561001 0.833146 0.626202 0.812487 0.996499 0.374069 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255783 episodes
GETTING ACTION FROM:
action 1, numVisits=2255604, meanQ=4.944393, numObservations: 4
action 0, numVisits=175, meanQ=4.346440, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.561001 0.833146 0.626202 0.812487 0.996499 0.374069 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.545923 0.818084 0.0447924 0.594907 0.5699 0.839877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1567877 episodes
GETTING ACTION FROM:
action -1, numVisits=1567865, meanQ=2.934114, numObservations: 1
action 3, numVisits=6, meanQ=-2.318333, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.545923 0.818084 0.0447924 0.594907 0.5699 0.839877 w: 1
Observation: 0 0.568401 0 0.0418859 0 0.510228 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1567858, meanQ=4.988143, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2500586 episodes
GETTING ACTION FROM:
action 2, numVisits=4068444, meanQ=4.949252, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.545923 0.818084 0.0447924 0.594907 0.5699 0.839877 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=199868, meanQ=7.826319, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2868358 episodes
GETTING ACTION FROM:
action 1, numVisits=3068224, meanQ=6.317611, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.545923 0.818084 0.0447924 0.594907 0.5699 0.839877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 82
Initial state: 0 0.536427 0.832909 0.430928 0.390955 0.57281 0.841938 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260507 episodes
GETTING ACTION FROM:
action 3, numVisits=2260422, meanQ=5.016639, numObservations: 4
action 0, numVisits=55, meanQ=3.980711, numObservations: 1
action 2, numVisits=19, meanQ=3.104737, numObservations: 4
action 1, numVisits=9, meanQ=0.998900, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.536427 0.832909 0.430928 0.390955 0.57281 0.841938 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.626883 0.829645 0.692794 0.864762 0.968612 0.925726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2274373 episodes
GETTING ACTION FROM:
action 1, numVisits=2274364, meanQ=4.949228, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.626883 0.829645 0.692794 0.864762 0.968612 0.925726 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.603092 0.867845 0.210822 0.633486 0.58015 0.866889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2147955 episodes
GETTING ACTION FROM:
action 3, numVisits=1927870, meanQ=4.947165, numObservations: 5
action 0, numVisits=219277, meanQ=2.920145, numObservations: 1
action -1, numVisits=805, meanQ=2.687461, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.603092 0.867845 0.210822 0.633486 0.58015 0.866889 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.561372 0.877554 0.537449 0.850479 0.0778368 0.358882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246733 episodes
GETTING ACTION FROM:
action 1, numVisits=2246723, meanQ=5.018274, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.561372 0.877554 0.537449 0.850479 0.0778368 0.358882 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 86
Initial state: 0 0.784361 0.236812 0.577799 0.87639 0.647795 0.858874 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243375 episodes
GETTING ACTION FROM:
action 2, numVisits=2243209, meanQ=4.951771, numObservations: 5
action -1, numVisits=63, meanQ=3.986529, numObservations: 1
action 0, numVisits=62, meanQ=3.980448, numObservations: 1
action 1, numVisits=39, meanQ=2.741033, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.784361 0.236812 0.577799 0.87639 0.647795 0.858874 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 87
Initial state: 0 0.582465 0.862392 0.533406 0.821778 0.127142 0.346295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247405 episodes
GETTING ACTION FROM:
action 3, numVisits=2247344, meanQ=4.973390, numObservations: 3
action -1, numVisits=57, meanQ=3.910362, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.582465 0.862392 0.533406 0.821778 0.127142 0.346295 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=318785, meanQ=8.348415, numObservations: 4
action 2, numVisits=50401, meanQ=8.328502, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2891652 episodes
GETTING ACTION FROM:
action 1, numVisits=2973639, meanQ=6.176603, numObservations: 4
action 2, numVisits=287197, meanQ=6.166561, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.582465 0.862392 0.533406 0.821778 0.127142 0.346295 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 88
Initial state: 0 0.686432 0.813976 0.685812 0.82318 0.147892 0.424669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2270931 episodes
GETTING ACTION FROM:
action 2, numVisits=2270899, meanQ=4.946847, numObservations: 4
action -1, numVisits=28, meanQ=3.464409, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.686432 0.813976 0.685812 0.82318 0.147892 0.424669 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 89
Initial state: 0 0.539461 0.877664 0.515407 0.834223 0.00776477 0.996459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250485 episodes
GETTING ACTION FROM:
action 3, numVisits=2105008, meanQ=5.008851, numObservations: 4
action 1, numVisits=145472, meanQ=4.810246, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.539461 0.877664 0.515407 0.834223 0.00776477 0.996459 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 90
Initial state: 0 0.534178 0.959444 0.681363 0.897765 0.609784 0.814852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1613904 episodes
GETTING ACTION FROM:
action 0, numVisits=1613896, meanQ=5.689630, numObservations: 2
action 2, numVisits=4, meanQ=-0.999975, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.534178 0.959444 0.681363 0.897765 0.609784 0.814852 w: 1
Observation: 0 0 1 0 0.990384 0 0.892896 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1209339, meanQ=7.535808, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2458151 episodes
GETTING ACTION FROM:
action 3, numVisits=3667464, meanQ=5.858317, numObservations: 5
action -1, numVisits=26, meanQ=4.261637, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.534178 0.959444 0.681363 0.897765 0.609784 0.814852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 91
Initial state: 0 0.505524 0.815099 0.788184 0.741915 0.561904 0.864278 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2213772 episodes
GETTING ACTION FROM:
action 2, numVisits=2213761, meanQ=4.949014, numObservations: 5
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.505524 0.815099 0.788184 0.741915 0.561904 0.864278 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 92
Initial state: 0 0.698749 0.87487 0.712602 0.324426 0.684928 0.841136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2220322 episodes
GETTING ACTION FROM:
action 3, numVisits=2220315, meanQ=4.948604, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.698749 0.87487 0.712602 0.324426 0.684928 0.841136 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.686713 0.828792 0.574379 0.833587 0.062003 0.376716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2292125 episodes
GETTING ACTION FROM:
action 2, numVisits=2292042, meanQ=5.024224, numObservations: 3
action 0, numVisits=69, meanQ=4.104082, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.686713 0.828792 0.574379 0.833587 0.062003 0.376716 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 94
Initial state: 0 0.673747 0.87818 0.189803 0.0579102 0.52164 0.831343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2274367 episodes
GETTING ACTION FROM:
action 1, numVisits=2274357, meanQ=5.012517, numObservations: 4
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.673747 0.87818 0.189803 0.0579102 0.52164 0.831343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.65019 0.811508 0.737446 0.607784 0.536096 0.86465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242063 episodes
GETTING ACTION FROM:
action 1, numVisits=2242036, meanQ=5.016774, numObservations: 5
action 3, numVisits=21, meanQ=2.890476, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.65019 0.811508 0.737446 0.607784 0.536096 0.86465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 96
Initial state: 0 0.520695 0.879071 0.529992 0.875618 0.150954 0.297653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239910 episodes
GETTING ACTION FROM:
action 2, numVisits=2239902, meanQ=4.958552, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.520695 0.879071 0.529992 0.875618 0.150954 0.297653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.606644 0.877887 0.668083 0.813005 0.279707 0.694977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241198 episodes
GETTING ACTION FROM:
action 1, numVisits=2241065, meanQ=5.014024, numObservations: 5
action 0, numVisits=101, meanQ=4.254616, numObservations: 1
action 2, numVisits=20, meanQ=2.904505, numObservations: 3
action -1, numVisits=11, meanQ=2.590000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.606644 0.877887 0.668083 0.813005 0.279707 0.694977 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.64064 0.832482 0.699779 0.811718 0.486002 0.992281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263336 episodes
GETTING ACTION FROM:
action 2, numVisits=2263114, meanQ=5.161804, numObservations: 4
action 3, numVisits=217, meanQ=4.617734, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.64064 0.832482 0.699779 0.811718 0.486002 0.992281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.694079 0.82992 0.661889 0.864477 0.471253 0.421216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1617521 episodes
GETTING ACTION FROM:
action 0, numVisits=1605837, meanQ=5.952555, numObservations: 3
action 1, numVisits=11620, meanQ=5.052070, numObservations: 4
action -1, numVisits=55, meanQ=4.278869, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 0
Next state: 0 0.694079 0.82992 0.661889 0.864477 0.471253 0.421216 w: 1
Observation: 0 0 0.884733 0 0.866992 0 0.416701 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=515175, meanQ=8.141694, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2456290 episodes
GETTING ACTION FROM:
action 1, numVisits=2971463, meanQ=5.607308, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.694079 0.82992 0.661889 0.864477 0.471253 0.421216 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 100
Initial state: 0 0.413644 0.373301 0.592586 0.837103 0.539364 0.891728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253830 episodes
GETTING ACTION FROM:
action 2, numVisits=2253745, meanQ=4.951482, numObservations: 4
action 0, numVisits=50, meanQ=3.873196, numObservations: 1
action -1, numVisits=33, meanQ=3.558839, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.413644 0.373301 0.592586 0.837103 0.539364 0.891728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.632198 0.846244 0.627527 0.81075 0.384595 0.396039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2202789 episodes
GETTING ACTION FROM:
action 3, numVisits=2202698, meanQ=4.937133, numObservations: 4
action 0, numVisits=82, meanQ=4.093370, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.632198 0.846244 0.627527 0.81075 0.384595 0.396039 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=361035, meanQ=8.355653, numObservations: 5
action 1, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2866170 episodes
GETTING ACTION FROM:
action 2, numVisits=3227201, meanQ=6.097683, numObservations: 5
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.632198 0.846244 0.627527 0.81075 0.384595 0.396039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 102
Initial state: 0 0.695098 0.800864 0.647308 0.841461 0.860393 0.689205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255853 episodes
GETTING ACTION FROM:
action 2, numVisits=2255796, meanQ=5.027491, numObservations: 5
action 3, numVisits=52, meanQ=3.868463, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.695098 0.800864 0.647308 0.841461 0.860393 0.689205 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.352403 0.984264 0.619499 0.819079 0.687713 0.821616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2252144 episodes
GETTING ACTION FROM:
action 1, numVisits=2240099, meanQ=4.937921, numObservations: 4
action -1, numVisits=12041, meanQ=3.064849, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.352403 0.984264 0.619499 0.819079 0.687713 0.821616 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=167637, meanQ=4.602130, numObservations: 5
action 0, numVisits=69, meanQ=3.774296, numObservations: 1
action -1, numVisits=22, meanQ=3.097414, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2825502 episodes
GETTING ACTION FROM:
action 3, numVisits=2993139, meanQ=5.737448, numObservations: 5
action 0, numVisits=69, meanQ=3.774296, numObservations: 1
action -1, numVisits=22, meanQ=3.097414, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.352403 0.984264 0.619499 0.819079 0.687713 0.821616 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 104
Initial state: 0 0.586155 0.879585 0.525599 0.887368 0.0343781 0.984506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2273177 episodes
GETTING ACTION FROM:
action 2, numVisits=2273121, meanQ=4.925821, numObservations: 3
action -1, numVisits=48, meanQ=3.807350, numObservations: 1
action 1, numVisits=5, meanQ=1.000020, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.586155 0.879585 0.525599 0.887368 0.0343781 0.984506 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.571397 0.897258 0.562246 0.584293 0.565351 0.880211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2277313 episodes
GETTING ACTION FROM:
action 1, numVisits=2277250, meanQ=4.991165, numObservations: 4
action -1, numVisits=22, meanQ=3.316680, numObservations: 1
action 3, numVisits=31, meanQ=3.236777, numObservations: 5
action 2, numVisits=8, meanQ=1.236263, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.571397 0.897258 0.562246 0.584293 0.565351 0.880211 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.807664 0.159933 0.546674 0.824711 0.619361 0.823565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2269648 episodes
GETTING ACTION FROM:
action 3, numVisits=2269594, meanQ=4.959184, numObservations: 3
action 2, numVisits=34, meanQ=3.231488, numObservations: 4
action -1, numVisits=17, meanQ=3.054862, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.807664 0.159933 0.546674 0.824711 0.619361 0.823565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.586249 0.860899 0.501786 0.84522 0.215233 0.405624 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262994 episodes
GETTING ACTION FROM:
action 1, numVisits=2262952, meanQ=4.970107, numObservations: 4
action 0, numVisits=26, meanQ=3.419743, numObservations: 1
action 3, numVisits=10, meanQ=1.600020, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.586249 0.860899 0.501786 0.84522 0.215233 0.405624 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.967696 0.0566774 0.514846 0.874205 0.607845 0.811907 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2270949 episodes
GETTING ACTION FROM:
action 2, numVisits=2270807, meanQ=4.962856, numObservations: 4
action 0, numVisits=79, meanQ=4.104764, numObservations: 1
action -1, numVisits=61, meanQ=3.965767, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.967696 0.0566774 0.514846 0.874205 0.607845 0.811907 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.67756 0.865477 0.931667 0.617683 0.628862 0.887135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275534 episodes
GETTING ACTION FROM:
action 2, numVisits=2275503, meanQ=5.050236, numObservations: 4
action -1, numVisits=18, meanQ=3.231706, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-2.005000, numObservations: 3
action: 2
Next state: 2 0.67756 0.865477 0.931667 0.617683 0.628862 0.887135 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 110
Initial state: 0 0.876107 0.728957 0.623389 0.805592 0.569896 0.855607 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254491 episodes
GETTING ACTION FROM:
action 3, numVisits=2254339, meanQ=4.947548, numObservations: 4
action -1, numVisits=148, meanQ=4.321915, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.876107 0.728957 0.623389 0.805592 0.569896 0.855607 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.572912 0.866696 0.397814 0.921041 0.503654 0.898472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239388 episodes
GETTING ACTION FROM:
action 3, numVisits=2229591, meanQ=4.933934, numObservations: 4
action 0, numVisits=9765, meanQ=2.991623, numObservations: 1
action 1, numVisits=24, meanQ=1.412088, numObservations: 3
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.572912 0.866696 0.397814 0.921041 0.503654 0.898472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.0760161 0.527065 0.584715 0.826814 0.604548 0.86668 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2143081 episodes
GETTING ACTION FROM:
action 2, numVisits=2143036, meanQ=4.670957, numObservations: 4
action -1, numVisits=41, meanQ=3.473906, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0760161 0.527065 0.584715 0.826814 0.604548 0.86668 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.507732 0.821822 0.0963388 0.415696 0.530465 0.892015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295232 episodes
GETTING ACTION FROM:
action 3, numVisits=2295142, meanQ=5.034808, numObservations: 3
action -1, numVisits=82, meanQ=4.180377, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.507732 0.821822 0.0963388 0.415696 0.530465 0.892015 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.657933 0.815214 0.383951 0.296636 0.601937 0.835635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257557 episodes
GETTING ACTION FROM:
action 2, numVisits=2257517, meanQ=5.006040, numObservations: 5
action -1, numVisits=22, meanQ=3.277884, numObservations: 1
action 1, numVisits=15, meanQ=2.047347, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.657933 0.815214 0.383951 0.296636 0.601937 0.835635 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=111507, meanQ=7.915272, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2848720 episodes
GETTING ACTION FROM:
action 1, numVisits=2960225, meanQ=6.104536, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.657933 0.815214 0.383951 0.296636 0.601937 0.835635 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 115
Initial state: 0 0.555867 0.865809 0.603782 0.880292 0.426185 0.0491755 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265255 episodes
GETTING ACTION FROM:
action 3, numVisits=2265219, meanQ=5.026482, numObservations: 4
action 2, numVisits=19, meanQ=2.996332, numObservations: 3
action 1, numVisits=13, meanQ=2.846162, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.555867 0.865809 0.603782 0.880292 0.426185 0.0491755 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=289387, meanQ=8.353015, numObservations: 4
action 1, numVisits=80559, meanQ=8.338659, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2883681 episodes
GETTING ACTION FROM:
action 2, numVisits=2716242, meanQ=6.361554, numObservations: 4
action 1, numVisits=537382, meanQ=6.355655, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.555867 0.865809 0.603782 0.880292 0.426185 0.0491755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=69368, meanQ=7.723803, numObservations: 5
action 2, numVisits=62, meanQ=6.870173, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2938391 episodes
GETTING ACTION FROM:
action 1, numVisits=3006399, meanQ=6.252608, numObservations: 5
action 2, numVisits=1420, meanQ=6.051127, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.555867 0.865809 0.603782 0.880292 0.426185 0.0491755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=6704, meanQ=8.210703, numObservations: 3
action 2, numVisits=6511, meanQ=7.446409, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2956122 episodes
GETTING ACTION FROM:
action 2, numVisits=2927357, meanQ=6.330125, numObservations: 5
action 1, numVisits=41978, meanQ=6.292212, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.555867 0.865809 0.603782 0.880292 0.426185 0.0491755 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 116
Initial state: 0 0.659056 0.576908 0.68174 0.863637 0.503339 0.814782 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2181995 episodes
GETTING ACTION FROM:
action 2, numVisits=2181887, meanQ=5.033003, numObservations: 5
action 0, numVisits=57, meanQ=4.001336, numObservations: 1
action -1, numVisits=33, meanQ=3.658811, numObservations: 1
action 1, numVisits=17, meanQ=1.941182, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.659056 0.576908 0.68174 0.863637 0.503339 0.814782 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.570909 0.841394 0.435732 0.278503 0.558499 0.849781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2230630 episodes
GETTING ACTION FROM:
action 1, numVisits=2230612, meanQ=4.952354, numObservations: 5
action 3, numVisits=12, meanQ=1.998333, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.570909 0.841394 0.435732 0.278503 0.558499 0.849781 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 118
Initial state: 0 0.814098 0.064892 0.699981 0.872806 0.534801 0.833074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1555321 episodes
GETTING ACTION FROM:
action -1, numVisits=1555304, meanQ=2.943239, numObservations: 1
action 2, numVisits=9, meanQ=0.331122, numObservations: 4
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.814098 0.064892 0.699981 0.872806 0.534801 0.833074 w: 1
Observation: 0 0.831814 0 0.778207 0 0.597556 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1555177, meanQ=5.002196, numObservations: 5
action -1, numVisits=81, meanQ=4.157805, numObservations: 1
action 0, numVisits=34, meanQ=3.706189, numObservations: 1
action 3, numVisits=10, meanQ=2.201010, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2477833 episodes
GETTING ACTION FROM:
action 1, numVisits=4033007, meanQ=4.997713, numObservations: 5
action -1, numVisits=83, meanQ=4.137988, numObservations: 1
action 0, numVisits=35, meanQ=3.627824, numObservations: 1
action 3, numVisits=10, meanQ=2.201010, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.814098 0.064892 0.699981 0.872806 0.534801 0.833074 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=300871, meanQ=5.544991, numObservations: 3
action 0, numVisits=12, meanQ=1.296436, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2677172 episodes
GETTING ACTION FROM:
action 1, numVisits=2978043, meanQ=4.990382, numObservations: 3
action 0, numVisits=12, meanQ=1.296436, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.814098 0.064892 0.699981 0.872806 0.534801 0.833074 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 119
Initial state: 0 0.679466 0.824503 0.0851417 0.884463 0.670518 0.871918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2217928 episodes
GETTING ACTION FROM:
action 2, numVisits=2212117, meanQ=4.983870, numObservations: 5
action -1, numVisits=5807, meanQ=3.086300, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.679466 0.824503 0.0851417 0.884463 0.670518 0.871918 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=109069, meanQ=7.902921, numObservations: 4
action 1, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2894504 episodes
GETTING ACTION FROM:
action 3, numVisits=3003481, meanQ=6.010814, numObservations: 4
action 1, numVisits=93, meanQ=5.170969, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.679466 0.824503 0.0851417 0.884463 0.670518 0.871918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 120
Initial state: 0 0.618981 0.80604 0.0587898 0.127948 0.545659 0.80227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245937 episodes
GETTING ACTION FROM:
action 1, numVisits=2245819, meanQ=4.948646, numObservations: 5
action 0, numVisits=55, meanQ=3.917792, numObservations: 1
action -1, numVisits=52, meanQ=3.872020, numObservations: 1
action 2, numVisits=9, meanQ=0.998889, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.618981 0.80604 0.0587898 0.127948 0.545659 0.80227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 121
Initial state: 0 0.689416 0.86147 0.59469 0.844519 0.84434 0.786129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264554 episodes
GETTING ACTION FROM:
action 1, numVisits=2264185, meanQ=5.016811, numObservations: 4
action 2, numVisits=343, meanQ=4.590544, numObservations: 3
action 0, numVisits=23, meanQ=3.425039, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.689416 0.86147 0.59469 0.844519 0.84434 0.786129 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 122
Initial state: 0 0.354736 0.226637 0.507619 0.888014 0.581798 0.849522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259561 episodes
GETTING ACTION FROM:
action 1, numVisits=2259555, meanQ=4.995679, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.354736 0.226637 0.507619 0.888014 0.581798 0.849522 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=166825, meanQ=8.410163, numObservations: 3
action 2, numVisits=149980, meanQ=8.404900, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2866231 episodes
GETTING ACTION FROM:
action 2, numVisits=2433365, meanQ=6.324683, numObservations: 5
action 3, numVisits=749669, meanQ=6.320696, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.354736 0.226637 0.507619 0.888014 0.581798 0.849522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 123
Initial state: 0 0.64874 0.854499 0.848615 0.127067 0.666822 0.801692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229003 episodes
GETTING ACTION FROM:
action 1, numVisits=2228980, meanQ=4.933279, numObservations: 5
action 3, numVisits=18, meanQ=2.110556, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.64874 0.854499 0.848615 0.127067 0.666822 0.801692 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 124
Initial state: 0 0.61516 0.813901 0.29168 0.160727 0.660556 0.896754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256328 episodes
GETTING ACTION FROM:
action 3, numVisits=2256267, meanQ=4.955326, numObservations: 4
action -1, numVisits=27, meanQ=3.483534, numObservations: 1
action 0, numVisits=31, meanQ=3.443459, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.61516 0.813901 0.29168 0.160727 0.660556 0.896754 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.71484 0.782335 0.643861 0.821968 0.503508 0.866269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2189232 episodes
GETTING ACTION FROM:
action 1, numVisits=2189219, meanQ=5.023619, numObservations: 5
action 3, numVisits=7, meanQ=1.568600, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.71484 0.782335 0.643861 0.821968 0.503508 0.866269 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 126
Initial state: 0 0.587019 0.40626 0.507213 0.886233 0.676214 0.823228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258962 episodes
GETTING ACTION FROM:
action 1, numVisits=2258956, meanQ=4.938514, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.587019 0.40626 0.507213 0.886233 0.676214 0.823228 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 127
Initial state: 0 0.945096 0.835418 0.57836 0.879291 0.600609 0.852023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2291343 episodes
GETTING ACTION FROM:
action 2, numVisits=2291331, meanQ=4.957777, numObservations: 3
action 1, numVisits=7, meanQ=1.285743, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.945096 0.835418 0.57836 0.879291 0.600609 0.852023 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.556857 0.874849 0.630736 0.800822 0.409721 0.181165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2222147 episodes
GETTING ACTION FROM:
action 3, numVisits=2222140, meanQ=4.965845, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.556857 0.874849 0.630736 0.800822 0.409721 0.181165 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=54095, meanQ=7.909333, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2888977 episodes
GETTING ACTION FROM:
action 2, numVisits=2943015, meanQ=5.822181, numObservations: 4
action 1, numVisits=57, meanQ=4.787368, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.556857 0.874849 0.630736 0.800822 0.409721 0.181165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 129
Initial state: 0 0.445393 0.749181 0.54379 0.825863 0.643869 0.864911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248407 episodes
GETTING ACTION FROM:
action 2, numVisits=2248180, meanQ=4.964745, numObservations: 4
action 1, numVisits=168, meanQ=4.348680, numObservations: 4
action 0, numVisits=49, meanQ=3.865546, numObservations: 1
action 3, numVisits=8, meanQ=1.500000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.445393 0.749181 0.54379 0.825863 0.643869 0.864911 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=168572, meanQ=4.713803, numObservations: 5
action -1, numVisits=27, meanQ=3.372500, numObservations: 1
action 2, numVisits=9, meanQ=1.432222, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2866346 episodes
GETTING ACTION FROM:
action 3, numVisits=3034918, meanQ=5.918674, numObservations: 5
action -1, numVisits=27, meanQ=3.372500, numObservations: 1
action 2, numVisits=9, meanQ=1.432222, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.445393 0.749181 0.54379 0.825863 0.643869 0.864911 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 130
Initial state: 0 0.591093 0.831782 0.633801 0.897691 0.849658 0.940539 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1548599 episodes
GETTING ACTION FROM:
action -1, numVisits=1548591, meanQ=3.005634, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.591093 0.831782 0.633801 0.897691 0.849658 0.940539 w: 1
Observation: 0 0.577867 0 0.601389 0 0.910805 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1082711, meanQ=5.046089, numObservations: 5
action 1, numVisits=465874, meanQ=5.042841, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2405788 episodes
GETTING ACTION FROM:
action 1, numVisits=2563623, meanQ=5.010209, numObservations: 4
action 3, numVisits=1390750, meanQ=5.008140, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.591093 0.831782 0.633801 0.897691 0.849658 0.940539 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 131
Initial state: 0 0.588442 0.834393 0.660384 0.884017 0.474885 0.0811503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247399 episodes
GETTING ACTION FROM:
action 1, numVisits=2247279, meanQ=5.001879, numObservations: 4
action 0, numVisits=116, meanQ=4.292192, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.588442 0.834393 0.660384 0.884017 0.474885 0.0811503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.519661 0.829105 0.694518 0.242231 0.579595 0.872102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2222666 episodes
GETTING ACTION FROM:
action 2, numVisits=2222657, meanQ=4.886864, numObservations: 3
action 1, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.519661 0.829105 0.694518 0.242231 0.579595 0.872102 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=364169, meanQ=8.347565, numObservations: 5
action 1, numVisits=5, meanQ=3.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2850182 episodes
GETTING ACTION FROM:
action 3, numVisits=3214333, meanQ=6.301247, numObservations: 5
action 1, numVisits=21, meanQ=3.857624, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.519661 0.829105 0.694518 0.242231 0.579595 0.872102 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 133
Initial state: 0 0.628083 0.897777 0.643268 0.870291 0.0341022 0.790384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2095821 episodes
GETTING ACTION FROM:
action 1, numVisits=2095815, meanQ=4.802191, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.628083 0.897777 0.643268 0.870291 0.0341022 0.790384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 134
Initial state: 0 0.917527 0.48714 0.584705 0.855192 0.56954 0.840293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2173204 episodes
GETTING ACTION FROM:
action 1, numVisits=2173198, meanQ=4.869340, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.917527 0.48714 0.584705 0.855192 0.56954 0.840293 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=163052, meanQ=3.564677, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2824258 episodes
GETTING ACTION FROM:
action 3, numVisits=2593832, meanQ=6.015626, numObservations: 5
action 0, numVisits=393477, meanQ=1.075343, numObservations: 1
action -1, numVisits=6, meanQ=-2.168300, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.917527 0.48714 0.584705 0.855192 0.56954 0.840293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 135
Initial state: 0 0.475786 0.0191659 0.50855 0.868237 0.664616 0.849677 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1553635 episodes
GETTING ACTION FROM:
action 0, numVisits=1296593, meanQ=2.957751, numObservations: 1
action -1, numVisits=257032, meanQ=2.899147, numObservations: 1
action 2, numVisits=6, meanQ=-0.669983, numObservations: 2
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 0
Next state: 0 0.475786 0.0191659 0.50855 0.868237 0.664616 0.849677 w: 1
Observation: 0 0 0.0303084 0 0.9264 0 0.866534 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1296503, meanQ=5.016076, numObservations: 5
action -1, numVisits=57, meanQ=4.003191, numObservations: 1
action 0, numVisits=20, meanQ=3.263316, numObservations: 1
action 2, numVisits=11, meanQ=2.638209, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2491753 episodes
GETTING ACTION FROM:
action 3, numVisits=3788247, meanQ=4.963890, numObservations: 5
action -1, numVisits=60, meanQ=3.932009, numObservations: 1
action 0, numVisits=21, meanQ=3.164258, numObservations: 1
action 2, numVisits=16, meanQ=2.501275, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.475786 0.0191659 0.50855 0.868237 0.664616 0.849677 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 136
Initial state: 0 0.551812 0.883929 0.396058 0.152099 0.550227 0.877668 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249095 episodes
GETTING ACTION FROM:
action 3, numVisits=2249022, meanQ=4.950215, numObservations: 4
action 1, numVisits=51, meanQ=3.784124, numObservations: 3
action 2, numVisits=18, meanQ=2.776678, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.551812 0.883929 0.396058 0.152099 0.550227 0.877668 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.521436 0.87261 0.574566 0.863879 0.0672759 0.322187 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2193236 episodes
GETTING ACTION FROM:
action 2, numVisits=2193100, meanQ=4.859619, numObservations: 4
action -1, numVisits=80, meanQ=4.008990, numObservations: 1
action 0, numVisits=54, meanQ=3.810226, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.521436 0.87261 0.574566 0.863879 0.0672759 0.322187 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.517092 0.896706 0.618335 0.821359 0.949858 0.712307 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297850 episodes
GETTING ACTION FROM:
action 2, numVisits=2297662, meanQ=4.953522, numObservations: 3
action -1, numVisits=142, meanQ=4.309690, numObservations: 1
action 0, numVisits=22, meanQ=3.317635, numObservations: 1
action 3, numVisits=22, meanQ=2.816818, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.517092 0.896706 0.618335 0.821359 0.949858 0.712307 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.539049 0.834311 0.372143 0.0813613 0.534983 0.862974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2210431 episodes
GETTING ACTION FROM:
action 3, numVisits=2210424, meanQ=4.956612, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.539049 0.834311 0.372143 0.0813613 0.534983 0.862974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.515274 0.80148 0.195509 0.150034 0.618876 0.893353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2227187 episodes
GETTING ACTION FROM:
action 3, numVisits=2227173, meanQ=5.177841, numObservations: 5
action 1, numVisits=8, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.515274 0.80148 0.195509 0.150034 0.618876 0.893353 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.666974 0.879696 0.637879 0.8779 0.555688 0.704788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256268 episodes
GETTING ACTION FROM:
action 1, numVisits=2256089, meanQ=5.016994, numObservations: 5
action -1, numVisits=107, meanQ=4.269878, numObservations: 1
action 0, numVisits=62, meanQ=4.016359, numObservations: 1
action 2, numVisits=9, meanQ=1.886667, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.666974 0.879696 0.637879 0.8779 0.555688 0.704788 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.29642 0.979746 0.582008 0.87498 0.660389 0.882273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259735 episodes
GETTING ACTION FROM:
action 1, numVisits=2253735, meanQ=4.940558, numObservations: 4
action 0, numVisits=5993, meanQ=2.812828, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=4, meanQ=-2.502475, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.29642 0.979746 0.582008 0.87498 0.660389 0.882273 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=168179, meanQ=4.710440, numObservations: 4
action 1, numVisits=10, meanQ=2.399010, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2868220 episodes
GETTING ACTION FROM:
action 3, numVisits=3036399, meanQ=5.917842, numObservations: 4
action 1, numVisits=10, meanQ=2.399010, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.29642 0.979746 0.582008 0.87498 0.660389 0.882273 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 143
Initial state: 0 0.648106 0.895179 0.610409 0.898305 0.668741 0.900077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236219 episodes
GETTING ACTION FROM:
action 2, numVisits=2236211, meanQ=4.944894, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.648106 0.895179 0.610409 0.898305 0.668741 0.900077 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 144
Initial state: 0 0.596322 0.862115 0.681424 0.879051 0.0929715 0.11722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2113322 episodes
GETTING ACTION FROM:
action 3, numVisits=2113303, meanQ=4.781065, numObservations: 5
action 2, numVisits=14, meanQ=2.427157, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.596322 0.862115 0.681424 0.879051 0.0929715 0.11722 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=294858, meanQ=6.326920, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2899560 episodes
GETTING ACTION FROM:
action 2, numVisits=2744238, meanQ=6.255034, numObservations: 4
action -1, numVisits=450170, meanQ=4.195161, numObservations: 1
action 1, numVisits=12, meanQ=1.832508, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.596322 0.862115 0.681424 0.879051 0.0929715 0.11722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 145
Initial state: 0 0.212299 0.0399251 0.679995 0.884727 0.64512 0.837777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237523 episodes
GETTING ACTION FROM:
action 3, numVisits=2237368, meanQ=4.948782, numObservations: 4
action -1, numVisits=96, meanQ=4.115740, numObservations: 1
action 0, numVisits=29, meanQ=3.472873, numObservations: 1
action 2, numVisits=29, meanQ=3.066555, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.212299 0.0399251 0.679995 0.884727 0.64512 0.837777 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.677176 0.839895 0.624658 0.893404 0.368788 0.942282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263899 episodes
GETTING ACTION FROM:
action 1, numVisits=2263892, meanQ=4.942940, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.677176 0.839895 0.624658 0.893404 0.368788 0.942282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.855834 0.328437 0.671619 0.816147 0.638852 0.850103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2160228 episodes
GETTING ACTION FROM:
action 1, numVisits=2160222, meanQ=4.958393, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.855834 0.328437 0.671619 0.816147 0.638852 0.850103 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=19547, meanQ=4.580937, numObservations: 4
action 0, numVisits=68, meanQ=3.842700, numObservations: 1
action -1, numVisits=32, meanQ=3.486225, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2887324 episodes
GETTING ACTION FROM:
action 3, numVisits=2906871, meanQ=6.022615, numObservations: 4
action 0, numVisits=68, meanQ=3.842700, numObservations: 1
action -1, numVisits=32, meanQ=3.486225, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.855834 0.328437 0.671619 0.816147 0.638852 0.850103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 148
Initial state: 0 0.0714734 0.618932 0.594632 0.801741 0.624023 0.827224 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1554800 episodes
GETTING ACTION FROM:
action 0, numVisits=1554782, meanQ=2.953728, numObservations: 1
action 1, numVisits=12, meanQ=0.673333, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0714734 0.618932 0.594632 0.801741 0.624023 0.827224 w: 1
Observation: 0 0 0.601946 0 0.794049 0 0.745493 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1554741, meanQ=5.005888, numObservations: 4
action 2, numVisits=35, meanQ=3.503143, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2486761 episodes
GETTING ACTION FROM:
action 3, numVisits=4041502, meanQ=4.926777, numObservations: 4
action 2, numVisits=35, meanQ=3.503143, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0714734 0.618932 0.594632 0.801741 0.624023 0.827224 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 149
Initial state: 0 0.614908 0.814496 0.26607 0.637998 0.529045 0.857605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2235246 episodes
GETTING ACTION FROM:
action 3, numVisits=2235225, meanQ=5.016460, numObservations: 5
action 2, numVisits=9, meanQ=1.886667, numObservations: 3
action 1, numVisits=8, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.614908 0.814496 0.26607 0.637998 0.529045 0.857605 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 150
Initial state: 0 0.683373 0.880755 0.342913 0.999861 0.509712 0.884815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2220853 episodes
GETTING ACTION FROM:
action 3, numVisits=2204891, meanQ=5.002722, numObservations: 5
action -1, numVisits=15957, meanQ=3.036722, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.683373 0.880755 0.342913 0.999861 0.509712 0.884815 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.483128 0.0137508 0.658938 0.892339 0.647198 0.812281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2252215 episodes
GETTING ACTION FROM:
action 1, numVisits=2252207, meanQ=5.004536, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.483128 0.0137508 0.658938 0.892339 0.647198 0.812281 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=315806, meanQ=8.356489, numObservations: 3
action 3, numVisits=8, meanQ=4.998750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2933263 episodes
GETTING ACTION FROM:
action 2, numVisits=3249049, meanQ=6.115079, numObservations: 3
action 3, numVisits=26, meanQ=4.537308, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.483128 0.0137508 0.658938 0.892339 0.647198 0.812281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 152
Initial state: 0 0.64209 0.889057 0.4245 0.894915 0.54446 0.85785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2168790 episodes
GETTING ACTION FROM:
action 1, numVisits=1956577, meanQ=5.016997, numObservations: 5
action 0, numVisits=210795, meanQ=2.981963, numObservations: 1
action -1, numVisits=1385, meanQ=2.808994, numObservations: 1
action 2, numVisits=32, meanQ=1.687200, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.64209 0.889057 0.4245 0.894915 0.54446 0.85785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.640003 0.806539 0.777652 0.787983 0.53214 0.830351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2272110 episodes
GETTING ACTION FROM:
action 1, numVisits=2272035, meanQ=5.016443, numObservations: 4
action 0, numVisits=48, meanQ=3.900085, numObservations: 1
action -1, numVisits=25, meanQ=3.356638, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.640003 0.806539 0.777652 0.787983 0.53214 0.830351 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.93133 0.085705 0.684193 0.886016 0.55614 0.844057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238597 episodes
GETTING ACTION FROM:
action 3, numVisits=2238525, meanQ=5.007016, numObservations: 5
action -1, numVisits=37, meanQ=3.728967, numObservations: 1
action 2, numVisits=32, meanQ=3.545003, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.93133 0.085705 0.684193 0.886016 0.55614 0.844057 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.82316 0.374876 0.560479 0.89733 0.575104 0.801672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243249 episodes
GETTING ACTION FROM:
action 3, numVisits=2243180, meanQ=5.013448, numObservations: 5
action -1, numVisits=42, meanQ=3.769990, numObservations: 1
action 0, numVisits=21, meanQ=3.262397, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.82316 0.374876 0.560479 0.89733 0.575104 0.801672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.554827 0.872592 0.661383 0.806442 0.410682 0.593164 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236522 episodes
GETTING ACTION FROM:
action 2, numVisits=2236495, meanQ=4.944503, numObservations: 4
action 1, numVisits=22, meanQ=2.999100, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.554827 0.872592 0.661383 0.806442 0.410682 0.593164 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 157
Initial state: 0 0.329117 0.711797 0.616463 0.801319 0.68317 0.873733 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251710 episodes
GETTING ACTION FROM:
action 3, numVisits=2251648, meanQ=4.948447, numObservations: 4
action 2, numVisits=35, meanQ=3.391714, numObservations: 3
action 1, numVisits=23, meanQ=3.090878, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.329117 0.711797 0.616463 0.801319 0.68317 0.873733 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.0508914 0.717576 0.61711 0.801663 0.645254 0.847522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257992 episodes
GETTING ACTION FROM:
action 3, numVisits=2257933, meanQ=4.933109, numObservations: 4
action 0, numVisits=55, meanQ=3.885739, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0508914 0.717576 0.61711 0.801663 0.645254 0.847522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=169756, meanQ=4.577641, numObservations: 5
action 0, numVisits=192, meanQ=4.072540, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2805613 episodes
GETTING ACTION FROM:
action 2, numVisits=2975369, meanQ=5.920531, numObservations: 5
action 0, numVisits=192, meanQ=4.072540, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0508914 0.717576 0.61711 0.801663 0.645254 0.847522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 159
Initial state: 0 0.489445 0.480519 0.683828 0.860308 0.693747 0.838107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2226233 episodes
GETTING ACTION FROM:
action 3, numVisits=2208699, meanQ=4.995873, numObservations: 5
action 0, numVisits=17512, meanQ=3.194761, numObservations: 1
action 2, numVisits=12, meanQ=1.166683, numObservations: 3
action 1, numVisits=8, meanQ=0.486250, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.489445 0.480519 0.683828 0.860308 0.693747 0.838107 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.620811 0.822867 0.11207 0.3911 0.600475 0.894596 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249397 episodes
GETTING ACTION FROM:
action 2, numVisits=2249388, meanQ=5.009206, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.620811 0.822867 0.11207 0.3911 0.600475 0.894596 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=369389, meanQ=8.331415, numObservations: 4
action 3, numVisits=267, meanQ=7.886376, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2878268 episodes
GETTING ACTION FROM:
action 1, numVisits=3222237, meanQ=6.297881, numObservations: 4
action 3, numVisits=25684, meanQ=6.253645, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.620811 0.822867 0.11207 0.3911 0.600475 0.894596 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 161
Initial state: 0 0.624444 0.802216 0.247383 0.302936 0.673759 0.873358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241463 episodes
GETTING ACTION FROM:
action 3, numVisits=2241457, meanQ=5.005326, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.624444 0.802216 0.247383 0.302936 0.673759 0.873358 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 162
Initial state: 0 0.694805 0.814456 0.706415 0.453446 0.522521 0.820593 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2222678 episodes
GETTING ACTION FROM:
action 3, numVisits=2222656, meanQ=4.997621, numObservations: 5
action 1, numVisits=17, meanQ=2.523535, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.694805 0.814456 0.706415 0.453446 0.522521 0.820593 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.633233 0.831858 0.0841735 0.599048 0.540017 0.802832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2188384 episodes
GETTING ACTION FROM:
action 3, numVisits=2188353, meanQ=4.855091, numObservations: 4
action -1, numVisits=26, meanQ=3.309314, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.633233 0.831858 0.0841735 0.599048 0.540017 0.802832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 164
Initial state: 0 0.55023 0.853114 0.827939 0.86539 0.554394 0.881751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254982 episodes
GETTING ACTION FROM:
action 3, numVisits=2251347, meanQ=5.004911, numObservations: 4
action -1, numVisits=3397, meanQ=2.924134, numObservations: 1
action 0, numVisits=233, meanQ=2.646624, numObservations: 1
action 2, numVisits=4, meanQ=-2.502475, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.55023 0.853114 0.827939 0.86539 0.554394 0.881751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.548028 0.833986 0.312966 0.983743 0.50722 0.843361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247146 episodes
GETTING ACTION FROM:
action 2, numVisits=2246964, meanQ=5.024535, numObservations: 4
action 1, numVisits=141, meanQ=4.359984, numObservations: 5
action 0, numVisits=38, meanQ=3.778197, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.548028 0.833986 0.312966 0.983743 0.50722 0.843361 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=161747, meanQ=5.636900, numObservations: 4
action 1, numVisits=3584, meanQ=4.858214, numObservations: 5
action 0, numVisits=21, meanQ=4.129706, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2490024 episodes
GETTING ACTION FROM:
action 2, numVisits=2651768, meanQ=5.077422, numObservations: 5
action 1, numVisits=3584, meanQ=4.858214, numObservations: 5
action 0, numVisits=24, meanQ=3.363493, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.548028 0.833986 0.312966 0.983743 0.50722 0.843361 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=54097, meanQ=6.518448, numObservations: 4
action 3, numVisits=23, meanQ=4.971739, numObservations: 3
action 1, numVisits=3, meanQ=2.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2972716 episodes
GETTING ACTION FROM:
action 3, numVisits=2952167, meanQ=6.253767, numObservations: 3
action 2, numVisits=69132, meanQ=6.211789, numObservations: 4
action 1, numVisits=5538, meanQ=6.140564, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.548028 0.833986 0.312966 0.983743 0.50722 0.843361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 166
Initial state: 0 0.588651 0.807918 0.596067 0.853425 0.0452615 0.973045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271073 episodes
GETTING ACTION FROM:
action 3, numVisits=2271030, meanQ=4.945808, numObservations: 3
action 0, numVisits=38, meanQ=3.642285, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.588651 0.807918 0.596067 0.853425 0.0452615 0.973045 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=372297, meanQ=8.352860, numObservations: 5
action 1, numVisits=50, meanQ=7.275806, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2863008 episodes
GETTING ACTION FROM:
action 1, numVisits=755673, meanQ=6.003079, numObservations: 5
action 2, numVisits=2479680, meanQ=6.001651, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.588651 0.807918 0.596067 0.853425 0.0452615 0.973045 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 167
Initial state: 0 0.592165 0.855564 0.654331 0.858862 0.122626 0.856877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248846 episodes
GETTING ACTION FROM:
action 2, numVisits=2248770, meanQ=4.938860, numObservations: 5
action -1, numVisits=72, meanQ=4.036814, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.592165 0.855564 0.654331 0.858862 0.122626 0.856877 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.302738 0.751544 0.587092 0.856663 0.66916 0.811124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263294 episodes
GETTING ACTION FROM:
action 1, numVisits=2263279, meanQ=4.999711, numObservations: 4
action 2, numVisits=10, meanQ=2.189000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.302738 0.751544 0.587092 0.856663 0.66916 0.811124 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=316655, meanQ=8.415372, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2900235 episodes
GETTING ACTION FROM:
action 2, numVisits=3216888, meanQ=6.300145, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.302738 0.751544 0.587092 0.856663 0.66916 0.811124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 169
Initial state: 0 0.665999 0.809689 0.541378 0.861607 0.0120269 0.192029 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256670 episodes
GETTING ACTION FROM:
action 2, numVisits=2256659, meanQ=5.008703, numObservations: 4
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.665999 0.809689 0.541378 0.861607 0.0120269 0.192029 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.0804744 0.0273451 0.531081 0.876493 0.511693 0.879118 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268883 episodes
GETTING ACTION FROM:
action 3, numVisits=2268877, meanQ=4.942968, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.0804744 0.0273451 0.531081 0.876493 0.511693 0.879118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=169142, meanQ=4.753197, numObservations: 5
action -1, numVisits=81, meanQ=3.981256, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2887252 episodes
GETTING ACTION FROM:
action 2, numVisits=3056394, meanQ=5.988143, numObservations: 5
action -1, numVisits=81, meanQ=3.981256, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0804744 0.0273451 0.531081 0.876493 0.511693 0.879118 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 171
Initial state: 0 0.547672 0.878883 0.686625 0.86766 0.581012 0.713034 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253527 episodes
GETTING ACTION FROM:
action 2, numVisits=2253476, meanQ=5.016254, numObservations: 4
action 3, numVisits=39, meanQ=3.763846, numObservations: 3
action 1, numVisits=8, meanQ=1.996250, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.547672 0.878883 0.686625 0.86766 0.581012 0.713034 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.579393 0.858783 0.841132 0.469504 0.527841 0.837485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1547160 episodes
GETTING ACTION FROM:
action -1, numVisits=1177568, meanQ=2.981460, numObservations: 1
action 0, numVisits=369589, meanQ=2.975998, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.579393 0.858783 0.841132 0.469504 0.527841 0.837485 w: 1
Observation: 0 0.564704 0 0.767512 0 0.450902 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1177379, meanQ=5.023634, numObservations: 5
action 2, numVisits=176, meanQ=4.147616, numObservations: 4
action 1, numVisits=8, meanQ=1.236263, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2473843 episodes
GETTING ACTION FROM:
action 3, numVisits=3651222, meanQ=4.874873, numObservations: 5
action 2, numVisits=176, meanQ=4.147616, numObservations: 4
action 1, numVisits=8, meanQ=1.236263, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.579393 0.858783 0.841132 0.469504 0.527841 0.837485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 173
Initial state: 0 0.725305 0.77216 0.500188 0.819494 0.567824 0.894571 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237855 episodes
GETTING ACTION FROM:
action 1, numVisits=2231168, meanQ=5.164424, numObservations: 5
action -1, numVisits=6678, meanQ=2.853005, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.725305 0.77216 0.500188 0.819494 0.567824 0.894571 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 174
Initial state: 0 0.651732 0.846174 0.657321 0.876713 0.386579 0.481363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261904 episodes
GETTING ACTION FROM:
action 2, numVisits=2261876, meanQ=4.954062, numObservations: 5
action -1, numVisits=24, meanQ=3.354408, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.651732 0.846174 0.657321 0.876713 0.386579 0.481363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.533081 0.849473 0.467633 0.0188614 0.661498 0.875527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260859 episodes
GETTING ACTION FROM:
action 3, numVisits=2250300, meanQ=4.944816, numObservations: 4
action -1, numVisits=10551, meanQ=3.018319, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.533081 0.849473 0.467633 0.0188614 0.661498 0.875527 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.645936 0.842496 0.555967 0.856976 0.464686 0.582181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228005 episodes
GETTING ACTION FROM:
action 2, numVisits=2227854, meanQ=4.928886, numObservations: 5
action 0, numVisits=71, meanQ=4.019215, numObservations: 1
action 1, numVisits=33, meanQ=3.423339, numObservations: 4
action -1, numVisits=25, meanQ=3.382953, numObservations: 1
action 3, numVisits=22, meanQ=2.909100, numObservations: 4
action: 2
Next state: 1 0.645936 0.842496 0.555967 0.856976 0.464686 0.582181 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.666937 0.860022 0.833053 0.211297 0.591883 0.863114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246828 episodes
GETTING ACTION FROM:
action 1, numVisits=2241683, meanQ=5.195514, numObservations: 5
action 0, numVisits=5139, meanQ=1.042727, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.666937 0.860022 0.833053 0.211297 0.591883 0.863114 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 178
Initial state: 0 0.574582 0.844072 0.61795 0.833572 0.392335 0.877244 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264488 episodes
GETTING ACTION FROM:
action 2, numVisits=2264482, meanQ=4.953292, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.574582 0.844072 0.61795 0.833572 0.392335 0.877244 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.361592 0.0877012 0.530268 0.82501 0.697765 0.857024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264225 episodes
GETTING ACTION FROM:
action 3, numVisits=2264217, meanQ=5.019654, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.361592 0.0877012 0.530268 0.82501 0.697765 0.857024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.647124 0.893844 0.409973 0.075367 0.633941 0.819068 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228611 episodes
GETTING ACTION FROM:
action 3, numVisits=2228553, meanQ=5.003296, numObservations: 5
action 0, numVisits=53, meanQ=3.952278, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.647124 0.893844 0.409973 0.075367 0.633941 0.819068 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 181
Initial state: 0 0.611433 0.82521 0.588029 0.895656 0.226483 0.127388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2166240 episodes
GETTING ACTION FROM:
action 3, numVisits=2166206, meanQ=4.867886, numObservations: 5
action 0, numVisits=22, meanQ=3.164061, numObservations: 1
action 2, numVisits=9, meanQ=1.445567, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.611433 0.82521 0.588029 0.895656 0.226483 0.127388 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=51178, meanQ=5.882809, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2609845 episodes
GETTING ACTION FROM:
action 3, numVisits=2497750, meanQ=5.018329, numObservations: 5
action 0, numVisits=163270, meanQ=1.888979, numObservations: 1
action 2, numVisits=8, meanQ=-0.752487, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 3
Next state: 0 0.611433 0.82521 0.588029 0.895656 0.226483 0.127388 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=342989, meanQ=8.523431, numObservations: 4
action 1, numVisits=153, meanQ=7.929023, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2944971 episodes
GETTING ACTION FROM:
action 2, numVisits=3287688, meanQ=6.874277, numObservations: 4
action 1, numVisits=425, meanQ=6.484333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.611433 0.82521 0.588029 0.895656 0.226483 0.127388 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 182
Initial state: 0 0.515591 0.849571 0.672654 0.842891 0.116493 0.598575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2233139 episodes
GETTING ACTION FROM:
action 1, numVisits=2224968, meanQ=4.947238, numObservations: 5
action 0, numVisits=8060, meanQ=3.045714, numObservations: 1
action -1, numVisits=92, meanQ=2.450162, numObservations: 1
action 2, numVisits=14, meanQ=1.428579, numObservations: 3
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action: 1
Next state: 1 0.515591 0.849571 0.672654 0.842891 0.116493 0.598575 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.554358 0.856662 0.606817 0.867646 0.240465 0.506983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276405 episodes
GETTING ACTION FROM:
action 2, numVisits=2276396, meanQ=5.022324, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.554358 0.856662 0.606817 0.867646 0.240465 0.506983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.628012 0.895819 0.844779 0.599603 0.563315 0.895522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2225326 episodes
GETTING ACTION FROM:
action 2, numVisits=2225185, meanQ=4.936401, numObservations: 5
action 3, numVisits=136, meanQ=4.208868, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.628012 0.895819 0.844779 0.599603 0.563315 0.895522 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 185
Initial state: 0 0.109441 0.129174 0.656035 0.85436 0.590802 0.875073 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2244521 episodes
GETTING ACTION FROM:
action 2, numVisits=2244479, meanQ=5.015798, numObservations: 5
action 0, numVisits=38, meanQ=3.767891, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.109441 0.129174 0.656035 0.85436 0.590802 0.875073 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=314626, meanQ=8.405127, numObservations: 5
action 1, numVisits=14, meanQ=6.426429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2858385 episodes
GETTING ACTION FROM:
action 3, numVisits=3172989, meanQ=6.171254, numObservations: 5
action 1, numVisits=32, meanQ=4.499069, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.109441 0.129174 0.656035 0.85436 0.590802 0.875073 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 186
Initial state: 0 0.69171 0.835782 0.516985 0.879461 0.394316 0.0286896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254720 episodes
GETTING ACTION FROM:
action 3, numVisits=2254042, meanQ=4.946587, numObservations: 4
action 1, numVisits=669, meanQ=4.653822, numObservations: 5
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.69171 0.835782 0.516985 0.879461 0.394316 0.0286896 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=315006, meanQ=8.411476, numObservations: 3
action 1, numVisits=6, meanQ=4.335017, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2944493 episodes
GETTING ACTION FROM:
action 2, numVisits=3259481, meanQ=6.274147, numObservations: 3
action 1, numVisits=22, meanQ=4.454550, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.69171 0.835782 0.516985 0.879461 0.394316 0.0286896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 187
Initial state: 0 0.560331 0.86933 0.548988 0.867501 0.302137 0.738191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1313721 episodes
GETTING ACTION FROM:
action 0, numVisits=1313711, meanQ=4.130150, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.560331 0.86933 0.548988 0.867501 0.302137 0.738191 w: 1
Observation: 0 0 0.801945 0 0.881331 0 0.834735 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=966724, meanQ=5.458231, numObservations: 1
action 0, numVisits=44, meanQ=4.282540, numObservations: 1
action 3, numVisits=532, meanQ=3.997268, numObservations: 4
action 1, numVisits=423, meanQ=3.943046, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 4
Sampled 1681433 episodes
GETTING ACTION FROM:
action -1, numVisits=2648140, meanQ=4.866327, numObservations: 1
action 3, numVisits=532, meanQ=3.997268, numObservations: 4
action 1, numVisits=423, meanQ=3.943046, numObservations: 4
action 0, numVisits=61, meanQ=3.873709, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 4
action: -1
Next state: 0 0.560331 0.86933 0.548988 0.867501 0.302137 0.738191 w: 1
Observation: 0 0.624849 0 0.459497 0 0.401824 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=2648129, meanQ=6.081384, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2494830 episodes
GETTING ACTION FROM:
action 2, numVisits=5142959, meanQ=5.583444, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.560331 0.86933 0.548988 0.867501 0.302137 0.738191 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 188
Initial state: 0 0.527686 0.831411 0.655419 0.881056 0.796 0.0470713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246414 episodes
GETTING ACTION FROM:
action 2, numVisits=2246267, meanQ=5.005038, numObservations: 5
action 0, numVisits=82, meanQ=4.163533, numObservations: 1
action -1, numVisits=53, meanQ=3.936350, numObservations: 1
action 1, numVisits=11, meanQ=2.453636, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.527686 0.831411 0.655419 0.881056 0.796 0.0470713 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.649193 0.851302 0.682327 0.813968 0.429758 0.0955017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1625058 episodes
GETTING ACTION FROM:
action 0, numVisits=1625027, meanQ=5.471159, numObservations: 2
action 1, numVisits=19, meanQ=1.210026, numObservations: 3
action 2, numVisits=9, meanQ=0.331122, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.649193 0.851302 0.682327 0.813968 0.429758 0.0955017 w: 1
Observation: 0 0 0.882782 0 0.912125 0 0.0774603 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1181230, meanQ=7.371506, numObservations: 4
action 2, numVisits=49701, meanQ=4.256732, numObservations: 3
action -1, numVisits=119, meanQ=3.678484, numObservations: 1
action 3, numVisits=9, meanQ=1.886667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2475132 episodes
GETTING ACTION FROM:
action 1, numVisits=3656362, meanQ=5.798451, numObservations: 4
action 2, numVisits=49701, meanQ=4.256732, numObservations: 3
action -1, numVisits=119, meanQ=3.678484, numObservations: 1
action 3, numVisits=9, meanQ=1.886667, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.649193 0.851302 0.682327 0.813968 0.429758 0.0955017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=294191, meanQ=6.086345, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2684661 episodes
GETTING ACTION FROM:
action 1, numVisits=2978848, meanQ=5.165713, numObservations: 4
action -1, numVisits=4, meanQ=0.475000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.649193 0.851302 0.682327 0.813968 0.429758 0.0955017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 190
Initial state: 0 0.857903 0.489789 0.609882 0.871987 0.650249 0.887713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2269532 episodes
GETTING ACTION FROM:
action 3, numVisits=2269482, meanQ=4.993043, numObservations: 4
action 0, numVisits=46, meanQ=3.855046, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.857903 0.489789 0.609882 0.871987 0.650249 0.887713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.265901 0.302364 0.532905 0.883759 0.531936 0.862793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2168558 episodes
GETTING ACTION FROM:
action 1, numVisits=2168550, meanQ=4.865071, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=2, meanQ=-8.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.265901 0.302364 0.532905 0.883759 0.531936 0.862793 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 192
Initial state: 0 0.644791 0.878267 0.608532 0.863105 0.837597 0.750886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2219018 episodes
GETTING ACTION FROM:
action 3, numVisits=2218999, meanQ=4.984181, numObservations: 3
action -1, numVisits=15, meanQ=2.999068, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.644791 0.878267 0.608532 0.863105 0.837597 0.750886 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 193
Initial state: 0 0.881012 0.204902 0.530897 0.899806 0.62618 0.811703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238444 episodes
GETTING ACTION FROM:
action 1, numVisits=2238375, meanQ=5.013200, numObservations: 5
action 0, numVisits=54, meanQ=3.951024, numObservations: 1
action 2, numVisits=12, meanQ=2.009175, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.881012 0.204902 0.530897 0.899806 0.62618 0.811703 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=166142, meanQ=5.549333, numObservations: 4
action 3, numVisits=17, meanQ=3.817059, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2682104 episodes
GETTING ACTION FROM:
action 1, numVisits=2848237, meanQ=5.269061, numObservations: 4
action 3, numVisits=26, meanQ=3.534235, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.881012 0.204902 0.530897 0.899806 0.62618 0.811703 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 194
Initial state: 0 0.675296 0.821545 0.580664 0.817392 0.806509 0.190332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234439 episodes
GETTING ACTION FROM:
action 1, numVisits=2234423, meanQ=5.007621, numObservations: 5
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 2, numVisits=7, meanQ=-0.145714, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.675296 0.821545 0.580664 0.817392 0.806509 0.190332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.625168 0.817522 0.774676 0.207794 0.672886 0.869934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237817 episodes
GETTING ACTION FROM:
action 2, numVisits=2237809, meanQ=4.986769, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.625168 0.817522 0.774676 0.207794 0.672886 0.869934 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 196
Initial state: 0 0.505214 0.826749 0.656393 0.81863 0.708816 0.523397 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261627 episodes
GETTING ACTION FROM:
action 1, numVisits=2261599, meanQ=5.015520, numObservations: 4
action 0, numVisits=24, meanQ=3.455563, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.505214 0.826749 0.656393 0.81863 0.708816 0.523397 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 197
Initial state: 0 0.668006 0.819833 0.552537 0.863869 0.895662 0.0334786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2278370 episodes
GETTING ACTION FROM:
action 1, numVisits=2274119, meanQ=4.935076, numObservations: 3
action -1, numVisits=4235, meanQ=2.998988, numObservations: 1
action 2, numVisits=13, meanQ=1.002323, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.668006 0.819833 0.552537 0.863869 0.895662 0.0334786 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.696808 0.886032 0.540111 0.8566 0.142125 0.775847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2226133 episodes
GETTING ACTION FROM:
action 1, numVisits=2226106, meanQ=4.943782, numObservations: 5
action 0, numVisits=21, meanQ=3.194621, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.696808 0.886032 0.540111 0.8566 0.142125 0.775847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 199
Initial state: 0 0.693374 0.943587 0.571618 0.819524 0.674267 0.821324 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2233257 episodes
GETTING ACTION FROM:
action 3, numVisits=2233177, meanQ=5.013895, numObservations: 5
action -1, numVisits=74, meanQ=4.126524, numObservations: 1
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.693374 0.943587 0.571618 0.819524 0.674267 0.821324 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.977046 0.0103369 0.541251 0.802756 0.502392 0.86228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246311 episodes
GETTING ACTION FROM:
action 1, numVisits=2246253, meanQ=5.012479, numObservations: 5
action 0, numVisits=44, meanQ=3.842529, numObservations: 1
action 3, numVisits=10, meanQ=1.997010, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.977046 0.0103369 0.541251 0.802756 0.502392 0.86228 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 201
Initial state: 0 0.587394 0.818374 0.641833 0.878674 0.333114 0.0592449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260478 episodes
GETTING ACTION FROM:
action 2, numVisits=2260438, meanQ=5.024436, numObservations: 5
action -1, numVisits=19, meanQ=3.219846, numObservations: 1
action 0, numVisits=18, meanQ=3.160475, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.587394 0.818374 0.641833 0.878674 0.333114 0.0592449 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.638783 0.845475 0.573362 0.823061 0.064412 0.252294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264114 episodes
GETTING ACTION FROM:
action 3, numVisits=2264068, meanQ=5.014752, numObservations: 4
action 1, numVisits=41, meanQ=3.682685, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.638783 0.845475 0.573362 0.823061 0.064412 0.252294 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=355719, meanQ=8.343059, numObservations: 5
action 2, numVisits=15333, meanQ=8.296196, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2859637 episodes
GETTING ACTION FROM:
action 1, numVisits=3149460, meanQ=6.243039, numObservations: 5
action 2, numVisits=81227, meanQ=6.220068, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.638783 0.845475 0.573362 0.823061 0.064412 0.252294 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 203
Initial state: 0 0.320955 0.619537 0.624952 0.827141 0.672025 0.86521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251563 episodes
GETTING ACTION FROM:
action 3, numVisits=2025955, meanQ=5.232931, numObservations: 5
action 1, numVisits=225573, meanQ=4.966564, numObservations: 5
action 0, numVisits=30, meanQ=3.641187, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.320955 0.619537 0.624952 0.827141 0.672025 0.86521 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.693552 0.880404 0.18356 0.762853 0.590434 0.843023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1571877 episodes
GETTING ACTION FROM:
action -1, numVisits=1571870, meanQ=2.893056, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.693552 0.880404 0.18356 0.762853 0.590434 0.843023 w: 1
Observation: 0 0.754032 0 0.0844621 0 0.616473 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1571823, meanQ=4.944884, numObservations: 4
action 3, numVisits=27, meanQ=3.437793, numObservations: 4
action 2, numVisits=15, meanQ=2.998007, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2510294 episodes
GETTING ACTION FROM:
action 1, numVisits=4082117, meanQ=5.014047, numObservations: 4
action 3, numVisits=27, meanQ=3.437793, numObservations: 4
action 2, numVisits=15, meanQ=2.998007, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.693552 0.880404 0.18356 0.762853 0.590434 0.843023 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 205
Initial state: 0 0.527145 0.829274 0.577002 0.838326 0.71272 0.639047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257043 episodes
GETTING ACTION FROM:
action 2, numVisits=2256952, meanQ=4.971972, numObservations: 4
action -1, numVisits=60, meanQ=3.922883, numObservations: 1
action 0, numVisits=24, meanQ=3.358959, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action: 2
Next state: 1 0.527145 0.829274 0.577002 0.838326 0.71272 0.639047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.211895 0.692693 0.63028 0.893616 0.61922 0.862319 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2281632 episodes
GETTING ACTION FROM:
action 1, numVisits=2281598, meanQ=5.025787, numObservations: 4
action 2, numVisits=29, meanQ=2.645521, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.211895 0.692693 0.63028 0.893616 0.61922 0.862319 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=261035, meanQ=8.546482, numObservations: 3
action 3, numVisits=13, meanQ=6.532315, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2869906 episodes
GETTING ACTION FROM:
action 2, numVisits=3130932, meanQ=6.233836, numObservations: 5
action 3, numVisits=20, meanQ=4.396005, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.211895 0.692693 0.63028 0.893616 0.61922 0.862319 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 207
Initial state: 0 0.520966 0.841033 0.57034 0.866164 0.401041 0.580146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2202091 episodes
GETTING ACTION FROM:
action 1, numVisits=2202080, meanQ=4.864650, numObservations: 3
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.520966 0.841033 0.57034 0.866164 0.401041 0.580146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=165883, meanQ=3.601955, numObservations: 1
action -1, numVisits=35, meanQ=2.299309, numObservations: 1
action 3, numVisits=16, meanQ=1.108137, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
Sampled 2908889 episodes
GETTING ACTION FROM:
action 3, numVisits=2872875, meanQ=6.050160, numObservations: 4
action 0, numVisits=201907, meanQ=2.840126, numObservations: 1
action -1, numVisits=41, meanQ=1.670142, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 0 0.520966 0.841033 0.57034 0.866164 0.401041 0.580146 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=30096, meanQ=8.342806, numObservations: 3
action 1, numVisits=7, meanQ=5.568571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 3020134 episodes
GETTING ACTION FROM:
action 2, numVisits=3049953, meanQ=6.532559, numObservations: 3
action 1, numVisits=282, meanQ=6.069539, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.520966 0.841033 0.57034 0.866164 0.401041 0.580146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 208
Initial state: 0 0.697666 0.873359 0.631245 0.813526 0.450993 0.724492 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255752 episodes
GETTING ACTION FROM:
action 2, numVisits=2249037, meanQ=5.015091, numObservations: 5
action 0, numVisits=6709, meanQ=2.854578, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.697666 0.873359 0.631245 0.813526 0.450993 0.724492 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.660903 0.833577 0.577995 0.880728 0.482098 0.2978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246369 episodes
GETTING ACTION FROM:
action 3, numVisits=2246273, meanQ=4.955886, numObservations: 5
action -1, numVisits=43, meanQ=3.782426, numObservations: 1
action 1, numVisits=43, meanQ=3.027449, numObservations: 4
action 2, numVisits=8, meanQ=1.987500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.660903 0.833577 0.577995 0.880728 0.482098 0.2978 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=53716, meanQ=7.970287, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2931197 episodes
GETTING ACTION FROM:
action 2, numVisits=2984911, meanQ=5.674552, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.660903 0.833577 0.577995 0.880728 0.482098 0.2978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 210
Initial state: 0 0.598077 0.826317 0.558321 0.325973 0.531863 0.82317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262845 episodes
GETTING ACTION FROM:
action 1, numVisits=2262788, meanQ=5.164172, numObservations: 4
action 0, numVisits=29, meanQ=3.706423, numObservations: 1
action -1, numVisits=22, meanQ=3.501388, numObservations: 1
action 3, numVisits=4, meanQ=-0.999975, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.598077 0.826317 0.558321 0.325973 0.531863 0.82317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.633892 0.826667 0.517467 0.833708 0.81835 0.159954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246077 episodes
GETTING ACTION FROM:
action 3, numVisits=2246030, meanQ=4.948120, numObservations: 5
action 0, numVisits=43, meanQ=3.756386, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.633892 0.826667 0.517467 0.833708 0.81835 0.159954 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 212
Initial state: 0 0.620868 0.893588 0.839615 0.199198 0.648909 0.873823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1553675 episodes
GETTING ACTION FROM:
action 0, numVisits=1548669, meanQ=2.941498, numObservations: 1
action -1, numVisits=4984, meanQ=2.833009, numObservations: 1
action 2, numVisits=15, meanQ=0.731347, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 0
Next state: 0 0.620868 0.893588 0.839615 0.199198 0.648909 0.873823 w: 1
Observation: 0 0 0.808235 0 0.15258 0 0.777163 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1548546, meanQ=4.997388, numObservations: 5
action -1, numVisits=118, meanQ=4.298448, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2475006 episodes
GETTING ACTION FROM:
action 2, numVisits=4023526, meanQ=4.808230, numObservations: 5
action -1, numVisits=144, meanQ=4.158744, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.620868 0.893588 0.839615 0.199198 0.648909 0.873823 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 213
Initial state: 0 0.43596 0.9541 0.519908 0.895872 0.525907 0.857815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240264 episodes
GETTING ACTION FROM:
action 1, numVisits=2240253, meanQ=5.028867, numObservations: 5
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.43596 0.9541 0.519908 0.895872 0.525907 0.857815 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.654185 0.879796 0.866853 0.866445 0.549106 0.884735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2167234 episodes
GETTING ACTION FROM:
action 1, numVisits=2167200, meanQ=4.866191, numObservations: 4
action 0, numVisits=20, meanQ=3.015919, numObservations: 1
action 3, numVisits=11, meanQ=2.452745, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.654185 0.879796 0.866853 0.866445 0.549106 0.884735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=162001, meanQ=3.540422, numObservations: 1
action 3, numVisits=24, meanQ=1.995417, numObservations: 3
action 1, numVisits=4, meanQ=0.025000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
Sampled 2886096 episodes
GETTING ACTION FROM:
action 3, numVisits=2880428, meanQ=5.995254, numObservations: 4
action -1, numVisits=167692, meanQ=3.394446, numObservations: 1
action 1, numVisits=5, meanQ=-0.582000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 1 0.654185 0.879796 0.866853 0.866445 0.549106 0.884735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 215
Initial state: 0 0.557599 0.802531 0.096544 0.16633 0.526005 0.841905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262817 episodes
GETTING ACTION FROM:
action 3, numVisits=2262794, meanQ=4.955096, numObservations: 4
action -1, numVisits=16, meanQ=2.974755, numObservations: 1
action 2, numVisits=4, meanQ=-0.504975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.557599 0.802531 0.096544 0.16633 0.526005 0.841905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 216
Initial state: 0 0.750036 0.129452 0.503146 0.855768 0.56625 0.813165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2231241 episodes
GETTING ACTION FROM:
action 2, numVisits=2228878, meanQ=4.975243, numObservations: 4
action -1, numVisits=2359, meanQ=2.826863, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.750036 0.129452 0.503146 0.855768 0.56625 0.813165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 217
Initial state: 0 0.40665 0.24832 0.527345 0.871502 0.689935 0.891286 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2142279 episodes
GETTING ACTION FROM:
action 3, numVisits=1898479, meanQ=4.944986, numObservations: 4
action 0, numVisits=243685, meanQ=2.806452, numObservations: 1
action -1, numVisits=113, meanQ=2.156913, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.40665 0.24832 0.527345 0.871502 0.689935 0.891286 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.549635 0.890227 0.520998 0.879881 0.346247 0.383205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260864 episodes
GETTING ACTION FROM:
action 2, numVisits=2260729, meanQ=4.956797, numObservations: 4
action 0, numVisits=63, meanQ=3.986627, numObservations: 1
action -1, numVisits=39, meanQ=3.696387, numObservations: 1
action 3, numVisits=23, meanQ=2.821309, numObservations: 4
action 1, numVisits=10, meanQ=2.399010, numObservations: 3
action: 2
Next state: 1 0.549635 0.890227 0.520998 0.879881 0.346247 0.383205 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.682911 0.843188 0.690501 0.847958 0.831192 0.676458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271261 episodes
GETTING ACTION FROM:
action 2, numVisits=2271217, meanQ=5.032549, numObservations: 4
action 0, numVisits=34, meanQ=3.703050, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.682911 0.843188 0.690501 0.847958 0.831192 0.676458 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.675928 0.898622 0.593307 0.849421 0.294287 0.299632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249193 episodes
GETTING ACTION FROM:
action 2, numVisits=2249065, meanQ=5.039173, numObservations: 5
action 0, numVisits=104, meanQ=4.282243, numObservations: 1
action 1, numVisits=18, meanQ=2.662794, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.675928 0.898622 0.593307 0.849421 0.294287 0.299632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 221
Initial state: 0 0.872489 0.904448 0.539582 0.882005 0.536485 0.813997 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254852 episodes
GETTING ACTION FROM:
action 1, numVisits=2234111, meanQ=5.016289, numObservations: 4
action -1, numVisits=20727, meanQ=2.925211, numObservations: 1
action 3, numVisits=7, meanQ=0.411429, numObservations: 3
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.872489 0.904448 0.539582 0.882005 0.536485 0.813997 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.620428 0.805913 0.685005 0.206591 0.510021 0.8771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229325 episodes
GETTING ACTION FROM:
action 2, numVisits=2226789, meanQ=4.946810, numObservations: 5
action 3, numVisits=2504, meanQ=4.797907, numObservations: 5
action 0, numVisits=29, meanQ=3.406928, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.620428 0.805913 0.685005 0.206591 0.510021 0.8771 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 223
Initial state: 0 0.668392 0.804437 0.423798 0.252509 0.624521 0.867876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2225974 episodes
GETTING ACTION FROM:
action 1, numVisits=2225963, meanQ=4.923216, numObservations: 5
action 2, numVisits=6, meanQ=-0.316667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.668392 0.804437 0.423798 0.252509 0.624521 0.867876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 224
Initial state: 0 0.66528 0.810638 0.826257 0.778857 0.630708 0.821272 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2305542 episodes
GETTING ACTION FROM:
action 2, numVisits=2304770, meanQ=5.025307, numObservations: 3
action 3, numVisits=629, meanQ=4.721818, numObservations: 5
action 1, numVisits=103, meanQ=4.220583, numObservations: 4
action -1, numVisits=38, meanQ=3.724109, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.66528 0.810638 0.826257 0.778857 0.630708 0.821272 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=314013, meanQ=8.355976, numObservations: 3
action 1, numVisits=63180, meanQ=8.335553, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2925282 episodes
GETTING ACTION FROM:
action 3, numVisits=2776828, meanQ=6.202672, numObservations: 3
action 1, numVisits=525645, meanQ=6.196698, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.66528 0.810638 0.826257 0.778857 0.630708 0.821272 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 225
Initial state: 0 0.519318 0.800605 0.850471 0.111476 0.530678 0.806717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2226679 episodes
GETTING ACTION FROM:
action 1, numVisits=2221165, meanQ=4.957753, numObservations: 5
action 0, numVisits=5492, meanQ=2.781103, numObservations: 1
action 2, numVisits=17, meanQ=0.764135, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.519318 0.800605 0.850471 0.111476 0.530678 0.806717 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 226
Initial state: 0 0.313155 0.179431 0.599888 0.823442 0.611287 0.852769 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1626371 episodes
GETTING ACTION FROM:
action 0, numVisits=1626197, meanQ=5.784580, numObservations: 2
action -1, numVisits=170, meanQ=2.418898, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.313155 0.179431 0.599888 0.823442 0.611287 0.852769 w: 1
Observation: 0 0 0.249818 0 0.818629 0 0.912869 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=475215, meanQ=8.287504, numObservations: 4
action 3, numVisits=371, meanQ=7.913440, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2490468 episodes
GETTING ACTION FROM:
action 2, numVisits=2963964, meanQ=5.662988, numObservations: 4
action 3, numVisits=2088, meanQ=5.492021, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.313155 0.179431 0.599888 0.823442 0.611287 0.852769 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 227
Initial state: 0 0.636471 0.851763 0.582586 0.865607 0.921079 0.65059 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2166400 episodes
GETTING ACTION FROM:
action 3, numVisits=2166350, meanQ=4.845973, numObservations: 5
action -1, numVisits=45, meanQ=3.671893, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.636471 0.851763 0.582586 0.865607 0.921079 0.65059 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 228
Initial state: 0 0.677287 0.847924 0.796983 0.781915 0.569719 0.888788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1559767 episodes
GETTING ACTION FROM:
action 0, numVisits=1556139, meanQ=2.967675, numObservations: 1
action -1, numVisits=3621, meanQ=2.846194, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 0
Next state: 0 0.677287 0.847924 0.796983 0.781915 0.569719 0.888788 w: 1
Observation: 0 0 0.762145 0 0.76138 0 0.815343 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1555739, meanQ=5.025914, numObservations: 5
action -1, numVisits=385, meanQ=4.642363, numObservations: 1
action 2, numVisits=11, meanQ=2.452745, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2516063 episodes
GETTING ACTION FROM:
action 1, numVisits=4071802, meanQ=5.196827, numObservations: 5
action -1, numVisits=385, meanQ=4.642363, numObservations: 1
action 2, numVisits=11, meanQ=2.452745, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.677287 0.847924 0.796983 0.781915 0.569719 0.888788 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 229
Initial state: 0 0.111636 0.527516 0.683206 0.822762 0.670641 0.823866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2244125 episodes
GETTING ACTION FROM:
action 1, numVisits=2244023, meanQ=5.008534, numObservations: 5
action 0, numVisits=98, meanQ=4.228333, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.111636 0.527516 0.683206 0.822762 0.670641 0.823866 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=313405, meanQ=8.420515, numObservations: 3
action 3, numVisits=21, meanQ=6.522867, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2944198 episodes
GETTING ACTION FROM:
action 2, numVisits=3256905, meanQ=6.452444, numObservations: 3
action 3, numVisits=717, meanQ=6.159498, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.111636 0.527516 0.683206 0.822762 0.670641 0.823866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 230
Initial state: 0 0.673472 0.896503 0.965734 0.228885 0.604215 0.805817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234926 episodes
GETTING ACTION FROM:
action 3, numVisits=2234716, meanQ=5.019172, numObservations: 5
action -1, numVisits=144, meanQ=4.386805, numObservations: 1
action 1, numVisits=48, meanQ=3.777710, numObservations: 5
action 0, numVisits=15, meanQ=3.012442, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 1 0.673472 0.896503 0.965734 0.228885 0.604215 0.805817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.558304 0.897849 0.59347 0.245393 0.518306 0.87698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2222074 episodes
GETTING ACTION FROM:
action 2, numVisits=2222024, meanQ=4.954699, numObservations: 5
action 0, numVisits=23, meanQ=3.239212, numObservations: 1
action 1, numVisits=23, meanQ=3.170883, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.558304 0.897849 0.59347 0.245393 0.518306 0.87698 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=269613, meanQ=8.406737, numObservations: 5
action 1, numVisits=41897, meanQ=8.385331, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2853897 episodes
GETTING ACTION FROM:
action 3, numVisits=2631687, meanQ=6.160581, numObservations: 5
action 1, numVisits=533717, meanQ=6.154736, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.558304 0.897849 0.59347 0.245393 0.518306 0.87698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 232
Initial state: 0 0.501133 0.834307 0.395611 0.484004 0.683992 0.838386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236035 episodes
GETTING ACTION FROM:
action 1, numVisits=2236018, meanQ=4.994732, numObservations: 5
action 3, numVisits=12, meanQ=2.333342, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.501133 0.834307 0.395611 0.484004 0.683992 0.838386 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 233
Initial state: 0 0.611929 0.831684 0.0562786 0.589098 0.682894 0.860865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256101 episodes
GETTING ACTION FROM:
action 1, numVisits=2247661, meanQ=5.018413, numObservations: 5
action 0, numVisits=8436, meanQ=2.938110, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.611929 0.831684 0.0562786 0.589098 0.682894 0.860865 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 234
Initial state: 0 0.547808 0.845943 0.4299 0.173841 0.574629 0.894953 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248609 episodes
GETTING ACTION FROM:
action 2, numVisits=2248467, meanQ=5.014427, numObservations: 5
action 1, numVisits=137, meanQ=4.175207, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.547808 0.845943 0.4299 0.173841 0.574629 0.894953 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=315963, meanQ=8.402725, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2925197 episodes
GETTING ACTION FROM:
action 1, numVisits=3241158, meanQ=6.401225, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.547808 0.845943 0.4299 0.173841 0.574629 0.894953 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 235
Initial state: 0 0.279923 0.572994 0.574356 0.839118 0.551506 0.801066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267875 episodes
GETTING ACTION FROM:
action 3, numVisits=2267826, meanQ=4.957884, numObservations: 3
action 0, numVisits=41, meanQ=3.667916, numObservations: 1
action 1, numVisits=5, meanQ=1.000020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.279923 0.572994 0.574356 0.839118 0.551506 0.801066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.628456 0.800209 0.581755 0.846975 0.410173 0.868047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2292512 episodes
GETTING ACTION FROM:
action 1, numVisits=2292400, meanQ=4.949177, numObservations: 3
action -1, numVisits=53, meanQ=3.896352, numObservations: 1
action 0, numVisits=40, meanQ=3.714832, numObservations: 1
action 2, numVisits=15, meanQ=2.865347, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action: 1
Next state: 1 0.628456 0.800209 0.581755 0.846975 0.410173 0.868047 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.0762366 0.461644 0.541041 0.811613 0.673146 0.817133 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239406 episodes
GETTING ACTION FROM:
action 3, numVisits=2239343, meanQ=4.922277, numObservations: 4
action 0, numVisits=47, meanQ=3.802081, numObservations: 1
action 1, numVisits=13, meanQ=2.237692, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0762366 0.461644 0.541041 0.811613 0.673146 0.817133 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.630199 0.875636 0.138639 0.683339 0.60334 0.807617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265763 episodes
GETTING ACTION FROM:
action 3, numVisits=2265694, meanQ=5.016982, numObservations: 4
action 0, numVisits=27, meanQ=3.520412, numObservations: 1
action 2, numVisits=31, meanQ=3.319358, numObservations: 5
action 1, numVisits=9, meanQ=2.112244, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.630199 0.875636 0.138639 0.683339 0.60334 0.807617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 239
Initial state: 0 0.539497 0.878766 0.633408 0.179497 0.537396 0.894103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256631 episodes
GETTING ACTION FROM:
action 3, numVisits=2256582, meanQ=5.145670, numObservations: 4
action -1, numVisits=42, meanQ=3.944666, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.539497 0.878766 0.633408 0.179497 0.537396 0.894103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.935755 0.997315 0.557578 0.810656 0.628778 0.896875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2219019 episodes
GETTING ACTION FROM:
action 3, numVisits=2218994, meanQ=4.940484, numObservations: 5
action 0, numVisits=20, meanQ=3.188588, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.935755 0.997315 0.557578 0.810656 0.628778 0.896875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=165201, meanQ=4.581885, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2840044 episodes
GETTING ACTION FROM:
action 2, numVisits=3005245, meanQ=5.941149, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.935755 0.997315 0.557578 0.810656 0.628778 0.896875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 241
Initial state: 0 0.584931 0.879558 0.960667 0.790243 0.634094 0.827595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248543 episodes
GETTING ACTION FROM:
action 2, numVisits=2248535, meanQ=5.013036, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.584931 0.879558 0.960667 0.790243 0.634094 0.827595 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 242
Initial state: 0 0.653523 0.859808 0.371952 0.720975 0.693915 0.863216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1566648 episodes
GETTING ACTION FROM:
action -1, numVisits=1566641, meanQ=2.899836, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-8.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.653523 0.859808 0.371952 0.720975 0.693915 0.863216 w: 1
Observation: 0 0.663772 0 0.297063 0 0.733625 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1566619, meanQ=4.946492, numObservations: 4
action 3, numVisits=15, meanQ=2.206007, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2486893 episodes
GETTING ACTION FROM:
action 1, numVisits=4053512, meanQ=5.012650, numObservations: 4
action 3, numVisits=15, meanQ=2.206007, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.653523 0.859808 0.371952 0.720975 0.693915 0.863216 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 243
Initial state: 0 0.137554 0.768426 0.650706 0.847897 0.514461 0.806694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263815 episodes
GETTING ACTION FROM:
action 2, numVisits=2263787, meanQ=4.959917, numObservations: 4
action 3, numVisits=23, meanQ=3.260435, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.137554 0.768426 0.650706 0.847897 0.514461 0.806694 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.576556 0.803208 0.746715 0.634614 0.698214 0.855231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2220494 episodes
GETTING ACTION FROM:
action 2, numVisits=2220445, meanQ=4.943613, numObservations: 5
action 0, numVisits=19, meanQ=3.120813, numObservations: 1
action 3, numVisits=26, meanQ=2.226169, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.576556 0.803208 0.746715 0.634614 0.698214 0.855231 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 245
Initial state: 0 0.117706 0.582351 0.500662 0.804294 0.5334 0.861253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255630 episodes
GETTING ACTION FROM:
action 1, numVisits=2255620, meanQ=5.016357, numObservations: 5
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.117706 0.582351 0.500662 0.804294 0.5334 0.861253 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=111173, meanQ=7.954671, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2864446 episodes
GETTING ACTION FROM:
action 3, numVisits=2975617, meanQ=5.974878, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.117706 0.582351 0.500662 0.804294 0.5334 0.861253 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 246
Initial state: 0 0.676571 0.831116 0.411774 0.987317 0.514885 0.89856 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248465 episodes
GETTING ACTION FROM:
action 3, numVisits=2248458, meanQ=4.956148, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.676571 0.831116 0.411774 0.987317 0.514885 0.89856 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.676172 0.884 0.881732 0.362589 0.527875 0.839606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251425 episodes
GETTING ACTION FROM:
action 2, numVisits=2251373, meanQ=4.962571, numObservations: 5
action -1, numVisits=43, meanQ=3.773792, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.676172 0.884 0.881732 0.362589 0.527875 0.839606 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 248
Initial state: 0 0.579191 0.847129 0.514868 0.839767 0.968525 0.452331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247886 episodes
GETTING ACTION FROM:
action 3, numVisits=2247866, meanQ=5.016226, numObservations: 4
action 1, numVisits=12, meanQ=2.498342, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.579191 0.847129 0.514868 0.839767 0.968525 0.452331 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 249
Initial state: 0 0.699625 0.875861 0.637345 0.896553 0.464575 0.683735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2278763 episodes
GETTING ACTION FROM:
action 1, numVisits=2278685, meanQ=4.969579, numObservations: 3
action 0, numVisits=71, meanQ=4.047755, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.699625 0.875861 0.637345 0.896553 0.464575 0.683735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=171110, meanQ=4.727137, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2845833 episodes
GETTING ACTION FROM:
action 2, numVisits=3016943, meanQ=5.782460, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.699625 0.875861 0.637345 0.896553 0.464575 0.683735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 250
Initial state: 0 0.863737 0.257335 0.599682 0.81025 0.568029 0.857315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2270294 episodes
GETTING ACTION FROM:
action 2, numVisits=2270152, meanQ=4.947853, numObservations: 4
action 0, numVisits=71, meanQ=4.041828, numObservations: 1
action -1, numVisits=65, meanQ=3.965075, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.863737 0.257335 0.599682 0.81025 0.568029 0.857315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.501878 0.888351 0.647028 0.862501 0.201341 0.607186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260050 episodes
GETTING ACTION FROM:
action 1, numVisits=2259941, meanQ=5.024313, numObservations: 4
action 0, numVisits=72, meanQ=4.122598, numObservations: 1
action -1, numVisits=25, meanQ=3.482100, numObservations: 1
action 2, numVisits=11, meanQ=2.453636, numObservations: 4
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.501878 0.888351 0.647028 0.862501 0.201341 0.607186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 252
Initial state: 0 0.141577 0.941272 0.619814 0.854666 0.531824 0.875548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2233295 episodes
GETTING ACTION FROM:
action 3, numVisits=2233283, meanQ=5.210318, numObservations: 5
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.141577 0.941272 0.619814 0.854666 0.531824 0.875548 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 253
Initial state: 0 0.506702 0.888152 0.657479 0.838611 0.716777 0.609675 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259694 episodes
GETTING ACTION FROM:
action 1, numVisits=2259595, meanQ=5.013592, numObservations: 4
action -1, numVisits=48, meanQ=3.887596, numObservations: 1
action 0, numVisits=23, meanQ=3.413044, numObservations: 1
action 3, numVisits=22, meanQ=3.091386, numObservations: 5
action 2, numVisits=6, meanQ=1.331683, numObservations: 2
action: 1
Next state: 1 0.506702 0.888152 0.657479 0.838611 0.716777 0.609675 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.503984 0.862803 0.20627 0.770813 0.633003 0.8924 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264000 episodes
GETTING ACTION FROM:
action 2, numVisits=2263929, meanQ=4.963985, numObservations: 4
action 0, numVisits=67, meanQ=4.023594, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.503984 0.862803 0.20627 0.770813 0.633003 0.8924 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=369118, meanQ=8.363208, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2891567 episodes
GETTING ACTION FROM:
action 3, numVisits=3260682, meanQ=6.054768, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.503984 0.862803 0.20627 0.770813 0.633003 0.8924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=81617, meanQ=7.589444, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2952282 episodes
GETTING ACTION FROM:
action 3, numVisits=3033897, meanQ=5.662413, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.503984 0.862803 0.20627 0.770813 0.633003 0.8924 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 255
Initial state: 0 0.0605846 0.664598 0.562287 0.828444 0.573383 0.85949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268742 episodes
GETTING ACTION FROM:
action 1, numVisits=2268548, meanQ=4.998180, numObservations: 4
action -1, numVisits=187, meanQ=4.443521, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0605846 0.664598 0.562287 0.828444 0.573383 0.85949 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=371101, meanQ=8.340048, numObservations: 4
action 2, numVisits=18, meanQ=6.220561, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2883183 episodes
GETTING ACTION FROM:
action 3, numVisits=3254233, meanQ=6.043613, numObservations: 4
action 2, numVisits=66, meanQ=5.087729, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0605846 0.664598 0.562287 0.828444 0.573383 0.85949 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 256
Initial state: 0 0.53042 0.882219 0.174328 0.173047 0.527309 0.850602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254474 episodes
GETTING ACTION FROM:
action 1, numVisits=2254418, meanQ=5.161756, numObservations: 5
action -1, numVisits=52, meanQ=4.074466, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.53042 0.882219 0.174328 0.173047 0.527309 0.850602 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.692482 0.817167 0.411122 0.943549 0.630483 0.810126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271555 episodes
GETTING ACTION FROM:
action 2, numVisits=2271549, meanQ=4.933682, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.692482 0.817167 0.411122 0.943549 0.630483 0.810126 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=170274, meanQ=4.718112, numObservations: 4
action -1, numVisits=167, meanQ=4.174089, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2889236 episodes
GETTING ACTION FROM:
action 1, numVisits=3059510, meanQ=5.718791, numObservations: 4
action -1, numVisits=167, meanQ=4.174089, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.692482 0.817167 0.411122 0.943549 0.630483 0.810126 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 258
Initial state: 0 0.0391582 0.23108 0.691231 0.804165 0.535121 0.813999 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1716700 episodes
GETTING ACTION FROM:
action 1, numVisits=577327, meanQ=4.899265, numObservations: 4
action 0, numVisits=1139363, meanQ=2.724986, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0391582 0.23108 0.691231 0.804165 0.535121 0.813999 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80746, meanQ=8.417968, numObservations: 3
action 2, numVisits=4, meanQ=2.995000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2928032 episodes
GETTING ACTION FROM:
action 3, numVisits=3008774, meanQ=6.227469, numObservations: 3
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0391582 0.23108 0.691231 0.804165 0.535121 0.813999 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 259
Initial state: 0 0.566657 0.867283 0.507433 0.804841 0.253121 0.326466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237732 episodes
GETTING ACTION FROM:
action 3, numVisits=2234521, meanQ=4.935926, numObservations: 5
action 1, numVisits=3106, meanQ=4.755303, numObservations: 4
action -1, numVisits=101, meanQ=4.174848, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.566657 0.867283 0.507433 0.804841 0.253121 0.326466 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=158993, meanQ=8.402781, numObservations: 5
action 2, numVisits=153242, meanQ=8.400929, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2853093 episodes
GETTING ACTION FROM:
action 1, numVisits=2600888, meanQ=6.484670, numObservations: 5
action 2, numVisits=564437, meanQ=6.478975, numObservations: 5
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.566657 0.867283 0.507433 0.804841 0.253121 0.326466 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=60242, meanQ=7.535050, numObservations: 5
action 1, numVisits=6, meanQ=4.335017, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2916400 episodes
GETTING ACTION FROM:
action 2, numVisits=2976634, meanQ=5.879435, numObservations: 5
action 1, numVisits=12, meanQ=3.334175, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.566657 0.867283 0.507433 0.804841 0.253121 0.326466 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 260
Initial state: 0 0.626873 0.857969 0.853947 0.822289 0.522902 0.823885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251772 episodes
GETTING ACTION FROM:
action 2, numVisits=2251754, meanQ=5.009468, numObservations: 4
action 0, numVisits=11, meanQ=2.136705, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.626873 0.857969 0.853947 0.822289 0.522902 0.823885 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 261
Initial state: 0 0.571963 0.292924 0.545273 0.886047 0.631174 0.873449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262613 episodes
GETTING ACTION FROM:
action 3, numVisits=2262470, meanQ=4.960747, numObservations: 4
action 0, numVisits=110, meanQ=4.221823, numObservations: 1
action -1, numVisits=28, meanQ=3.481240, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.571963 0.292924 0.545273 0.886047 0.631174 0.873449 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=21102, meanQ=5.772802, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2624734 episodes
GETTING ACTION FROM:
action 3, numVisits=2645834, meanQ=4.926017, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.571963 0.292924 0.545273 0.886047 0.631174 0.873449 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 262
Initial state: 0 0.9686 0.554349 0.672679 0.832089 0.611419 0.852933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2290191 episodes
GETTING ACTION FROM:
action 2, numVisits=2290182, meanQ=5.014463, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.9686 0.554349 0.672679 0.832089 0.611419 0.852933 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.626245 0.876908 0.536313 0.845222 0.362916 0.233206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2277114 episodes
GETTING ACTION FROM:
action 2, numVisits=2276943, meanQ=5.018834, numObservations: 4
action 0, numVisits=126, meanQ=4.339882, numObservations: 1
action 3, numVisits=42, meanQ=3.562386, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.626245 0.876908 0.536313 0.845222 0.362916 0.233206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.88744 0.583969 0.529814 0.872385 0.559013 0.86889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268842 episodes
GETTING ACTION FROM:
action 2, numVisits=2268285, meanQ=5.026594, numObservations: 4
action 3, numVisits=543, meanQ=4.699901, numObservations: 5
action 1, numVisits=10, meanQ=2.598000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.88744 0.583969 0.529814 0.872385 0.559013 0.86889 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.571423 0.801456 0.676704 0.811593 0.39571 0.822531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2244795 episodes
GETTING ACTION FROM:
action 3, numVisits=2244391, meanQ=5.007628, numObservations: 5
action -1, numVisits=148, meanQ=4.381013, numObservations: 1
action 2, numVisits=253, meanQ=4.205794, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.571423 0.801456 0.676704 0.811593 0.39571 0.822531 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=78513, meanQ=7.929337, numObservations: 4
action 2, numVisits=31436, meanQ=7.916495, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2897770 episodes
GETTING ACTION FROM:
action 1, numVisits=2905895, meanQ=6.635125, numObservations: 4
action 2, numVisits=101822, meanQ=6.615224, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.571423 0.801456 0.676704 0.811593 0.39571 0.822531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 266
Initial state: 0 0.684824 0.858627 0.0894291 0.520289 0.604111 0.80508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2224436 episodes
GETTING ACTION FROM:
action 3, numVisits=2224409, meanQ=4.937642, numObservations: 4
action -1, numVisits=19, meanQ=3.159557, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.684824 0.858627 0.0894291 0.520289 0.604111 0.80508 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.560733 0.854853 0.382208 0.0311537 0.509638 0.883848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251738 episodes
GETTING ACTION FROM:
action 2, numVisits=2249797, meanQ=4.950937, numObservations: 4
action 1, numVisits=1889, meanQ=4.776005, numObservations: 4
action 3, numVisits=20, meanQ=3.099005, numObservations: 4
action -1, numVisits=17, meanQ=3.089123, numObservations: 1
action 0, numVisits=15, meanQ=2.745103, numObservations: 1
action: 2
Next state: 0 0.560733 0.854853 0.382208 0.0311537 0.509638 0.883848 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=366960, meanQ=8.367633, numObservations: 4
action 1, numVisits=14, meanQ=6.000729, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2886318 episodes
GETTING ACTION FROM:
action 3, numVisits=3252945, meanQ=6.209638, numObservations: 4
action 1, numVisits=345, meanQ=5.773943, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.560733 0.854853 0.382208 0.0311537 0.509638 0.883848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 268
Initial state: 0 0.521554 0.847504 0.59331 0.851212 0.529434 0.337946 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2286736 episodes
GETTING ACTION FROM:
action 2, numVisits=2286679, meanQ=5.026123, numObservations: 3
action 0, numVisits=53, meanQ=3.963538, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.521554 0.847504 0.59331 0.851212 0.529434 0.337946 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.57685 0.810428 0.531609 0.832638 0.804133 0.375963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237190 episodes
GETTING ACTION FROM:
action 2, numVisits=2237184, meanQ=5.003063, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.57685 0.810428 0.531609 0.832638 0.804133 0.375963 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 270
Initial state: 0 0.396982 0.272568 0.57469 0.870934 0.649817 0.807412 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267764 episodes
GETTING ACTION FROM:
action 3, numVisits=2267719, meanQ=4.967835, numObservations: 3
action 0, numVisits=41, meanQ=3.760217, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.396982 0.272568 0.57469 0.870934 0.649817 0.807412 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.507529 0.807812 0.0165587 0.496512 0.534378 0.841115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1561945 episodes
GETTING ACTION FROM:
action 0, numVisits=1561932, meanQ=2.917925, numObservations: 1
action 2, numVisits=4, meanQ=-2.502475, numObservations: 3
action 1, numVisits=5, meanQ=-2.603980, numObservations: 3
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.507529 0.807812 0.0165587 0.496512 0.534378 0.841115 w: 1
Observation: 0 0 0.83747 0 0.52961 0 0.775348 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1561925, meanQ=4.962808, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2477079 episodes
GETTING ACTION FROM:
action 2, numVisits=4039004, meanQ=5.006359, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.507529 0.807812 0.0165587 0.496512 0.534378 0.841115 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=696395, meanQ=8.335918, numObservations: 4
action 3, numVisits=9, meanQ=5.890011, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2913328 episodes
GETTING ACTION FROM:
action 1, numVisits=3609702, meanQ=6.368568, numObservations: 4
action 3, numVisits=28, meanQ=4.568218, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.507529 0.807812 0.0165587 0.496512 0.534378 0.841115 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 272
Initial state: 0 0.670263 0.888515 0.833114 0.979894 0.639973 0.824789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268894 episodes
GETTING ACTION FROM:
action 1, numVisits=2133228, meanQ=4.951771, numObservations: 4
action 3, numVisits=135646, meanQ=4.895357, numObservations: 4
action 2, numVisits=16, meanQ=2.250019, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.670263 0.888515 0.833114 0.979894 0.639973 0.824789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.515653 0.811334 0.699714 0.894852 0.286304 0.230206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2221131 episodes
GETTING ACTION FROM:
action 2, numVisits=2215772, meanQ=4.931053, numObservations: 4
action -1, numVisits=5343, meanQ=2.770406, numObservations: 1
action 1, numVisits=13, meanQ=1.160777, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.515653 0.811334 0.699714 0.894852 0.286304 0.230206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=110777, meanQ=4.730867, numObservations: 4
action 0, numVisits=56603, meanQ=3.650635, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2893029 episodes
GETTING ACTION FROM:
action 1, numVisits=3003806, meanQ=5.743492, numObservations: 4
action 0, numVisits=56603, meanQ=3.650635, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.515653 0.811334 0.699714 0.894852 0.286304 0.230206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=64792, meanQ=7.387671, numObservations: 4
action 3, numVisits=5, meanQ=2.598000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2938846 episodes
GETTING ACTION FROM:
action 1, numVisits=3003633, meanQ=5.607569, numObservations: 5
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.515653 0.811334 0.699714 0.894852 0.286304 0.230206 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 274
Initial state: 0 0.500634 0.857865 0.647977 0.829451 0.0785224 0.384362 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237768 episodes
GETTING ACTION FROM:
action 2, numVisits=2237697, meanQ=5.015889, numObservations: 5
action 1, numVisits=52, meanQ=3.913850, numObservations: 4
action 3, numVisits=15, meanQ=2.333340, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.500634 0.857865 0.647977 0.829451 0.0785224 0.384362 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 275
Initial state: 0 0.0860344 0.936928 0.630265 0.828189 0.536906 0.810176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228724 episodes
GETTING ACTION FROM:
action 1, numVisits=2228711, meanQ=4.914312, numObservations: 4
action 2, numVisits=6, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.0860344 0.936928 0.630265 0.828189 0.536906 0.810176 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=167133, meanQ=5.653888, numObservations: 3
action 0, numVisits=23, meanQ=4.186214, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2687306 episodes
GETTING ACTION FROM:
action 1, numVisits=2854437, meanQ=5.232164, numObservations: 4
action 0, numVisits=25, meanQ=3.691317, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0860344 0.936928 0.630265 0.828189 0.536906 0.810176 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=56524, meanQ=6.081393, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2939646 episodes
GETTING ACTION FROM:
action 2, numVisits=2996168, meanQ=5.812913, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0860344 0.936928 0.630265 0.828189 0.536906 0.810176 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 276
Initial state: 0 0.699291 0.888787 0.904086 0.649399 0.624202 0.864129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240535 episodes
GETTING ACTION FROM:
action 3, numVisits=2240520, meanQ=5.009271, numObservations: 5
action -1, numVisits=11, meanQ=2.590000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.699291 0.888787 0.904086 0.649399 0.624202 0.864129 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.68572 0.888651 0.51416 0.774599 0.502197 0.887006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2199017 episodes
GETTING ACTION FROM:
action 1, numVisits=2199002, meanQ=4.817835, numObservations: 4
action 3, numVisits=10, meanQ=1.600020, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.68572 0.888651 0.51416 0.774599 0.502197 0.887006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.635186 0.854913 0.256734 0.466593 0.694709 0.803042 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1564815 episodes
GETTING ACTION FROM:
action -1, numVisits=1564619, meanQ=2.897774, numObservations: 1
action 0, numVisits=188, meanQ=2.337588, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.635186 0.854913 0.256734 0.466593 0.694709 0.803042 w: 1
Observation: 0 0.729757 0 0.192299 0 0.742665 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1564605, meanQ=4.949283, numObservations: 4
action 2, numVisits=8, meanQ=1.510000, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2496292 episodes
GETTING ACTION FROM:
action 3, numVisits=4060897, meanQ=4.702343, numObservations: 4
action 2, numVisits=8, meanQ=1.510000, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.635186 0.854913 0.256734 0.466593 0.694709 0.803042 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=315269, meanQ=4.887313, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2842303 episodes
GETTING ACTION FROM:
action 2, numVisits=3157572, meanQ=5.691542, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.635186 0.854913 0.256734 0.466593 0.694709 0.803042 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 279
Initial state: 0 0.582024 0.891797 0.355126 0.101602 0.625249 0.864829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256123 episodes
GETTING ACTION FROM:
action 3, numVisits=2256116, meanQ=5.004132, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.582024 0.891797 0.355126 0.101602 0.625249 0.864829 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 280
Initial state: 0 0.612555 0.802443 0.603041 0.807321 0.93641 0.561866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2273956 episodes
GETTING ACTION FROM:
action 1, numVisits=2273856, meanQ=5.019156, numObservations: 4
action 0, numVisits=57, meanQ=4.000819, numObservations: 1
action -1, numVisits=41, meanQ=3.803643, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.612555 0.802443 0.603041 0.807321 0.93641 0.561866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.611741 0.88362 0.574993 0.849493 0.0538758 0.795452 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2233764 episodes
GETTING ACTION FROM:
action 3, numVisits=2233758, meanQ=4.941519, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.611741 0.88362 0.574993 0.849493 0.0538758 0.795452 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=255507, meanQ=8.541416, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2888028 episodes
GETTING ACTION FROM:
action 1, numVisits=3143533, meanQ=6.092290, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.611741 0.88362 0.574993 0.849493 0.0538758 0.795452 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 282
Initial state: 0 0.676945 0.888972 0.771516 0.865056 0.687372 0.833573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260210 episodes
GETTING ACTION FROM:
action 1, numVisits=2254424, meanQ=4.948621, numObservations: 4
action -1, numVisits=5782, meanQ=3.085140, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.676945 0.888972 0.771516 0.865056 0.687372 0.833573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.69369 0.890979 0.576733 0.878905 0.420872 0.206635 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2210253 episodes
GETTING ACTION FROM:
action 3, numVisits=1089265, meanQ=5.013763, numObservations: 4
action 2, numVisits=1120945, meanQ=4.969978, numObservations: 4
action 0, numVisits=29, meanQ=3.529539, numObservations: 1
action 1, numVisits=12, meanQ=2.498342, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.69369 0.890979 0.576733 0.878905 0.420872 0.206635 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=177052, meanQ=8.358121, numObservations: 3
action 2, numVisits=31, meanQ=7.064200, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2932745 episodes
GETTING ACTION FROM:
action 1, numVisits=3108989, meanQ=6.169862, numObservations: 3
action 2, numVisits=837, meanQ=5.893908, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.69369 0.890979 0.576733 0.878905 0.420872 0.206635 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 284
Initial state: 0 0.501535 0.892687 0.666647 0.896961 0.777696 0.58357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254498 episodes
GETTING ACTION FROM:
action 3, numVisits=2254308, meanQ=5.000395, numObservations: 4
action -1, numVisits=87, meanQ=4.174963, numObservations: 1
action 0, numVisits=56, meanQ=3.958311, numObservations: 1
action 2, numVisits=36, meanQ=3.664175, numObservations: 3
action 1, numVisits=11, meanQ=2.452745, numObservations: 3
action: 3
Next state: 2 0.501535 0.892687 0.666647 0.896961 0.777696 0.58357 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 285
Initial state: 0 0.681298 0.858902 0.537295 0.820006 0.188282 0.563092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261477 episodes
GETTING ACTION FROM:
action 1, numVisits=2261470, meanQ=4.982916, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.681298 0.858902 0.537295 0.820006 0.188282 0.563092 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.523672 0.870666 0.643659 0.857211 0.352459 0.91625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2226623 episodes
GETTING ACTION FROM:
action 3, numVisits=2226614, meanQ=4.945311, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.523672 0.870666 0.643659 0.857211 0.352459 0.91625 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=45677, meanQ=6.794548, numObservations: 4
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2898329 episodes
GETTING ACTION FROM:
action 1, numVisits=2944004, meanQ=6.113448, numObservations: 4
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.523672 0.870666 0.643659 0.857211 0.352459 0.91625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 287
Initial state: 0 0.329917 0.118876 0.564671 0.858098 0.527648 0.897112 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275747 episodes
GETTING ACTION FROM:
action 2, numVisits=2275718, meanQ=4.938114, numObservations: 3
action 0, numVisits=18, meanQ=3.080649, numObservations: 1
action 3, numVisits=8, meanQ=1.747513, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.329917 0.118876 0.564671 0.858098 0.527648 0.897112 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.559884 0.840609 0.634941 0.836254 0.0252528 0.316101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2240971 episodes
GETTING ACTION FROM:
action 1, numVisits=2240954, meanQ=4.944562, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.559884 0.840609 0.634941 0.836254 0.0252528 0.316101 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.671857 0.819785 0.395329 0.585362 0.572923 0.846623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264730 episodes
GETTING ACTION FROM:
action 1, numVisits=2264723, meanQ=5.015160, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.671857 0.819785 0.395329 0.585362 0.572923 0.846623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 290
Initial state: 0 0.53469 0.847249 0.684537 0.873191 0.265483 0.909448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2286131 episodes
GETTING ACTION FROM:
action 1, numVisits=2286077, meanQ=4.981701, numObservations: 3
action -1, numVisits=50, meanQ=3.903309, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.53469 0.847249 0.684537 0.873191 0.265483 0.909448 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.605539 0.818369 0.364718 0.605372 0.664872 0.855799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2252201 episodes
GETTING ACTION FROM:
action 2, numVisits=2252195, meanQ=4.947832, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.605539 0.818369 0.364718 0.605372 0.664872 0.855799 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=278508, meanQ=8.412458, numObservations: 5
action 3, numVisits=37017, meanQ=8.366151, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2870285 episodes
GETTING ACTION FROM:
action 1, numVisits=2905618, meanQ=6.181084, numObservations: 5
action 3, numVisits=280190, meanQ=6.170922, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.605539 0.818369 0.364718 0.605372 0.664872 0.855799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 292
Initial state: 0 0.0427851 0.00177634 0.697087 0.825831 0.698761 0.867714 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268332 episodes
GETTING ACTION FROM:
action 3, numVisits=2268310, meanQ=5.017919, numObservations: 4
action 0, numVisits=15, meanQ=2.895672, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0427851 0.00177634 0.697087 0.825831 0.698761 0.867714 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 293
Initial state: 0 0.603984 0.833197 0.508535 0.863749 0.418011 0.0758077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2266293 episodes
GETTING ACTION FROM:
action 2, numVisits=2266268, meanQ=4.931445, numObservations: 4
action -1, numVisits=21, meanQ=3.189771, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.603984 0.833197 0.508535 0.863749 0.418011 0.0758077 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.674351 0.885849 0.610884 0.84838 0.85431 0.755819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282516 episodes
GETTING ACTION FROM:
action 1, numVisits=2282501, meanQ=4.941631, numObservations: 3
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.674351 0.885849 0.610884 0.84838 0.85431 0.755819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.685756 0.833075 0.586036 0.873026 0.424614 0.67008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2273135 episodes
GETTING ACTION FROM:
action 2, numVisits=2273103, meanQ=4.942652, numObservations: 4
action 3, numVisits=27, meanQ=2.997426, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.685756 0.833075 0.586036 0.873026 0.424614 0.67008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.651548 0.831715 0.693645 0.878331 0.371743 0.578728 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228871 episodes
GETTING ACTION FROM:
action 2, numVisits=2228843, meanQ=4.946359, numObservations: 4
action 0, numVisits=21, meanQ=3.145415, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.651548 0.831715 0.693645 0.878331 0.371743 0.578728 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 297
Initial state: 0 0.507561 0.849757 0.530081 0.822743 0.110322 0.160351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261246 episodes
GETTING ACTION FROM:
action 2, numVisits=2261216, meanQ=4.949228, numObservations: 4
action 0, numVisits=25, meanQ=3.376963, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.507561 0.849757 0.530081 0.822743 0.110322 0.160351 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 298
Initial state: 0 0.59568 0.863981 0.587284 0.801371 0.786136 0.474379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2207637 episodes
GETTING ACTION FROM:
action 3, numVisits=2207631, meanQ=4.969869, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.59568 0.863981 0.587284 0.801371 0.786136 0.474379 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 299
Initial state: 0 0.0625952 0.134757 0.507989 0.806483 0.666794 0.882346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2236655 episodes
GETTING ACTION FROM:
action 1, numVisits=2236648, meanQ=5.000308, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0625952 0.134757 0.507989 0.806483 0.666794 0.882346 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=312230, meanQ=8.414572, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2933213 episodes
GETTING ACTION FROM:
action 2, numVisits=3245441, meanQ=6.238373, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0625952 0.134757 0.507989 0.806483 0.666794 0.882346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 300
Initial state: 0 0.277948 0.342948 0.618261 0.838651 0.628005 0.872246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258714 episodes
GETTING ACTION FROM:
action 1, numVisits=2258608, meanQ=4.935958, numObservations: 3
action 0, numVisits=87, meanQ=1.577082, numObservations: 1
action 3, numVisits=16, meanQ=0.373144, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.277948 0.342948 0.618261 0.838651 0.628005 0.872246 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=362098, meanQ=8.352134, numObservations: 5
action 2, numVisits=7627, meanQ=8.266302, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2853123 episodes
GETTING ACTION FROM:
action 3, numVisits=1807015, meanQ=6.336826, numObservations: 5
action 2, numVisits=1415831, meanQ=6.336181, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.277948 0.342948 0.618261 0.838651 0.628005 0.872246 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 301
Initial state: 0 0.595164 0.808776 0.509303 0.888281 0.214247 0.452566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2278900 episodes
GETTING ACTION FROM:
action 1, numVisits=2278857, meanQ=4.951656, numObservations: 3
action 0, numVisits=34, meanQ=3.621094, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.595164 0.808776 0.509303 0.888281 0.214247 0.452566 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.533026 0.859261 0.624132 0.825761 0.0572297 0.142598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2273013 episodes
GETTING ACTION FROM:
action 1, numVisits=2272777, meanQ=5.022675, numObservations: 4
action -1, numVisits=155, meanQ=4.411075, numObservations: 1
action 0, numVisits=76, meanQ=4.132822, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.533026 0.859261 0.624132 0.825761 0.0572297 0.142598 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.205534 0.455091 0.611374 0.831287 0.533927 0.81146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2232119 episodes
GETTING ACTION FROM:
action 3, numVisits=2232043, meanQ=4.960175, numObservations: 5
action -1, numVisits=42, meanQ=3.764424, numObservations: 1
action 2, numVisits=31, meanQ=2.741945, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.205534 0.455091 0.611374 0.831287 0.533927 0.81146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.59717 0.841311 0.211846 0.721686 0.595443 0.808801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228410 episodes
GETTING ACTION FROM:
action 3, numVisits=2228393, meanQ=5.021894, numObservations: 5
action 1, numVisits=10, meanQ=1.997010, numObservations: 4
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.59717 0.841311 0.211846 0.721686 0.595443 0.808801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.632743 0.855867 0.0687698 0.347167 0.593134 0.836339 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2251914 episodes
GETTING ACTION FROM:
action 1, numVisits=2251617, meanQ=4.966042, numObservations: 4
action 2, numVisits=262, meanQ=4.446565, numObservations: 4
action -1, numVisits=24, meanQ=3.299537, numObservations: 1
action 3, numVisits=9, meanQ=1.886667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.632743 0.855867 0.0687698 0.347167 0.593134 0.836339 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 306
Initial state: 0 0.525211 0.815933 0.000264283 0.91126 0.683601 0.841024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2276556 episodes
GETTING ACTION FROM:
action 1, numVisits=2276548, meanQ=5.010100, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.525211 0.815933 0.000264283 0.91126 0.683601 0.841024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.670746 0.856617 0.562112 0.891187 0.271881 0.645848 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1558719 episodes
GETTING ACTION FROM:
action 0, numVisits=1558470, meanQ=2.946180, numObservations: 1
action -1, numVisits=244, meanQ=2.468068, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.670746 0.856617 0.562112 0.891187 0.271881 0.645848 w: 1
Observation: 0 0 0.843498 0 0.853306 0 0.63678 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1558447, meanQ=4.999060, numObservations: 4
action 1, numVisits=14, meanQ=2.706429, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2495880 episodes
GETTING ACTION FROM:
action 2, numVisits=4054304, meanQ=4.806097, numObservations: 4
action 3, numVisits=27, meanQ=3.140374, numObservations: 5
action 1, numVisits=14, meanQ=2.706429, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.670746 0.856617 0.562112 0.891187 0.271881 0.645848 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 308
Initial state: 0 0.617912 0.813121 0.338301 0.146331 0.525438 0.838013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264604 episodes
GETTING ACTION FROM:
action 1, numVisits=2264562, meanQ=4.960992, numObservations: 4
action -1, numVisits=25, meanQ=3.410016, numObservations: 1
action 0, numVisits=15, meanQ=2.741058, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.617912 0.813121 0.338301 0.146331 0.525438 0.838013 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.066735 0.138425 0.57111 0.863443 0.562038 0.898125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2168517 episodes
GETTING ACTION FROM:
action 2, numVisits=1884457, meanQ=4.866061, numObservations: 5
action 1, numVisits=284039, meanQ=4.847516, numObservations: 4
action 3, numVisits=17, meanQ=2.854706, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.066735 0.138425 0.57111 0.863443 0.562038 0.898125 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.587433 0.887818 0.503101 0.804199 0.793346 0.235136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2274634 episodes
GETTING ACTION FROM:
action 2, numVisits=2274559, meanQ=5.022514, numObservations: 3
action -1, numVisits=47, meanQ=3.740527, numObservations: 1
action 0, numVisits=25, meanQ=3.372937, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.587433 0.887818 0.503101 0.804199 0.793346 0.235136 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 311
Initial state: 0 0.516984 0.803691 0.334149 0.6251 0.631632 0.833937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229822 episodes
GETTING ACTION FROM:
action 1, numVisits=2229804, meanQ=5.005346, numObservations: 4
action 2, numVisits=13, meanQ=2.231546, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.516984 0.803691 0.334149 0.6251 0.631632 0.833937 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 312
Initial state: 0 0.264206 0.123039 0.580926 0.813722 0.679516 0.830553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257942 episodes
GETTING ACTION FROM:
action 2, numVisits=2257909, meanQ=5.023922, numObservations: 3
action 3, numVisits=28, meanQ=3.207864, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.264206 0.123039 0.580926 0.813722 0.679516 0.830553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 313
Initial state: 0 0.574343 0.88525 0.756433 0.641207 0.577747 0.832385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2202588 episodes
GETTING ACTION FROM:
action 3, numVisits=2202555, meanQ=5.023234, numObservations: 5
action -1, numVisits=26, meanQ=3.474753, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.574343 0.88525 0.756433 0.641207 0.577747 0.832385 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.0616415 0.848719 0.505429 0.81836 0.655982 0.867385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2157481 episodes
GETTING ACTION FROM:
action 2, numVisits=2149974, meanQ=5.027730, numObservations: 5
action 0, numVisits=7503, meanQ=2.895541, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0616415 0.848719 0.505429 0.81836 0.655982 0.867385 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 315
Initial state: 0 0.678054 0.810967 0.56017 0.821812 0.135251 0.939961 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2184208 episodes
GETTING ACTION FROM:
action 1, numVisits=2184202, meanQ=4.987317, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678054 0.810967 0.56017 0.821812 0.135251 0.939961 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.849462 0.155035 0.538869 0.891559 0.53761 0.834381 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2174309 episodes
GETTING ACTION FROM:
action 3, numVisits=2174303, meanQ=4.956037, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.849462 0.155035 0.538869 0.891559 0.53761 0.834381 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 317
Initial state: 0 0.637822 0.875445 0.0163335 0.406629 0.581271 0.824612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1517635 episodes
GETTING ACTION FROM:
action -1, numVisits=1517588, meanQ=2.916752, numObservations: 1
action 0, numVisits=43, meanQ=1.759489, numObservations: 1
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.637822 0.875445 0.0163335 0.406629 0.581271 0.824612 w: 1
Observation: 0 0.713894 0 0.0131058 0 0.648925 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1517548, meanQ=4.969776, numObservations: 4
action 0, numVisits=29, meanQ=3.564916, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2407072 episodes
GETTING ACTION FROM:
action 2, numVisits=3924620, meanQ=5.046782, numObservations: 4
action 0, numVisits=29, meanQ=3.564916, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.637822 0.875445 0.0163335 0.406629 0.581271 0.824612 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=570226, meanQ=8.398845, numObservations: 4
action 3, numVisits=6, meanQ=4.665017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2824493 episodes
GETTING ACTION FROM:
action 1, numVisits=3394575, meanQ=6.551867, numObservations: 4
action 3, numVisits=148, meanQ=5.861623, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.637822 0.875445 0.0163335 0.406629 0.581271 0.824612 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 318
Initial state: 0 0.533041 0.885643 0.687059 0.887673 0.239508 0.581589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2186865 episodes
GETTING ACTION FROM:
action 3, numVisits=2186855, meanQ=5.014381, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=3, meanQ=-4.333333, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.533041 0.885643 0.687059 0.887673 0.239508 0.581589 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=305085, meanQ=8.412658, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2805423 episodes
GETTING ACTION FROM:
action 2, numVisits=3110506, meanQ=6.249893, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.533041 0.885643 0.687059 0.887673 0.239508 0.581589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 319
Initial state: 0 0.629668 0.802823 0.650281 0.869035 0.406247 0.524384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2201058 episodes
GETTING ACTION FROM:
action 3, numVisits=2200938, meanQ=4.986633, numObservations: 4
action -1, numVisits=71, meanQ=4.065788, numObservations: 1
action 0, numVisits=31, meanQ=3.548058, numObservations: 1
action 1, numVisits=17, meanQ=3.122353, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.629668 0.802823 0.650281 0.869035 0.406247 0.524384 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=308705, meanQ=8.421245, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2801329 episodes
GETTING ACTION FROM:
action 2, numVisits=3110026, meanQ=6.312355, numObservations: 5
action 1, numVisits=8, meanQ=2.498750, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.629668 0.802823 0.650281 0.869035 0.406247 0.524384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 320
Initial state: 0 0.557597 0.857223 0.532205 0.894218 0.59264 0.0349535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239246 episodes
GETTING ACTION FROM:
action 2, numVisits=2239190, meanQ=5.027694, numObservations: 4
action -1, numVisits=50, meanQ=3.935097, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.557597 0.857223 0.532205 0.894218 0.59264 0.0349535 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.631777 0.877768 0.570521 0.896076 0.978679 0.193968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2227642 episodes
GETTING ACTION FROM:
action 1, numVisits=2227162, meanQ=5.008021, numObservations: 4
action 3, numVisits=435, meanQ=4.635607, numObservations: 5
action -1, numVisits=42, meanQ=3.812364, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.631777 0.877768 0.570521 0.896076 0.978679 0.193968 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.0145189 0.172612 0.549652 0.846834 0.516265 0.875851 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2204999 episodes
GETTING ACTION FROM:
action 2, numVisits=2204978, meanQ=5.008943, numObservations: 4
action 3, numVisits=11, meanQ=2.452745, numObservations: 3
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.0145189 0.172612 0.549652 0.846834 0.516265 0.875851 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.598975 0.891865 0.618277 0.865328 0.168674 0.508347 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2190485 episodes
GETTING ACTION FROM:
action 1, numVisits=2190444, meanQ=5.150707, numObservations: 5
action 0, numVisits=37, meanQ=3.861912, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.598975 0.891865 0.618277 0.865328 0.168674 0.508347 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.235992 0.501303 0.631051 0.896826 0.666923 0.86703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2225325 episodes
GETTING ACTION FROM:
action 1, numVisits=2225002, meanQ=5.018338, numObservations: 4
action 2, numVisits=312, meanQ=4.589267, numObservations: 5
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.235992 0.501303 0.631051 0.896826 0.666923 0.86703 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=255017, meanQ=8.546343, numObservations: 3
action 2, numVisits=5, meanQ=4.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2812136 episodes
GETTING ACTION FROM:
action 3, numVisits=3067149, meanQ=6.439332, numObservations: 4
action 2, numVisits=7, meanQ=2.711429, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.235992 0.501303 0.631051 0.896826 0.666923 0.86703 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 325
Initial state: 0 0.775677 0.91832 0.633295 0.835848 0.570938 0.801077 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229667 episodes
GETTING ACTION FROM:
action 2, numVisits=2229584, meanQ=4.951487, numObservations: 4
action -1, numVisits=73, meanQ=4.047263, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.775677 0.91832 0.633295 0.835848 0.570938 0.801077 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 326
Initial state: 0 0.531078 0.844029 0.574705 0.827953 0.476322 0.18043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2163019 episodes
GETTING ACTION FROM:
action 2, numVisits=2163009, meanQ=4.930141, numObservations: 5
action 1, numVisits=5, meanQ=1.396020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.531078 0.844029 0.574705 0.827953 0.476322 0.18043 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.636205 0.803795 0.233253 0.325336 0.617804 0.881076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1587733 episodes
GETTING ACTION FROM:
action 0, numVisits=1575088, meanQ=5.923798, numObservations: 3
action 3, numVisits=12617, meanQ=5.080829, numObservations: 4
action 2, numVisits=19, meanQ=3.525263, numObservations: 3
action 1, numVisits=7, meanQ=2.155714, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 0
Next state: 0 0.636205 0.803795 0.233253 0.325336 0.617804 0.881076 w: 1
Observation: 0 0 0.798053 0 0.269105 0 0.891412 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=459257, meanQ=8.303178, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2456268 episodes
GETTING ACTION FROM:
action 3, numVisits=2915523, meanQ=5.644517, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.636205 0.803795 0.233253 0.325336 0.617804 0.881076 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 328
Initial state: 0 0.56474 0.827 0.354068 0.989701 0.576227 0.854766 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2215771 episodes
GETTING ACTION FROM:
action 3, numVisits=2215739, meanQ=5.023084, numObservations: 4
action 0, numVisits=22, meanQ=3.298933, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.56474 0.827 0.354068 0.989701 0.576227 0.854766 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.506307 0.872739 0.685923 0.878387 0.74098 0.865142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2214892 episodes
GETTING ACTION FROM:
action 1, numVisits=2214791, meanQ=5.001133, numObservations: 4
action -1, numVisits=58, meanQ=3.997059, numObservations: 1
action 2, numVisits=40, meanQ=3.791000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.506307 0.872739 0.685923 0.878387 0.74098 0.865142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 330
Initial state: 0 0.695837 0.832423 0.354643 0.0372958 0.501142 0.859698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2187268 episodes
GETTING ACTION FROM:
action 3, numVisits=2187214, meanQ=4.969992, numObservations: 5
action 2, numVisits=28, meanQ=3.417864, numObservations: 3
action 0, numVisits=15, meanQ=2.965708, numObservations: 1
action 1, numVisits=9, meanQ=1.454444, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.695837 0.832423 0.354643 0.0372958 0.501142 0.859698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.612181 0.811716 0.508395 0.852002 0.748963 0.293553 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2118109 episodes
GETTING ACTION FROM:
action 1, numVisits=2118059, meanQ=4.873566, numObservations: 5
action 0, numVisits=32, meanQ=3.480187, numObservations: 1
action 3, numVisits=15, meanQ=2.738673, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.612181 0.811716 0.508395 0.852002 0.748963 0.293553 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.237762 0.973313 0.647102 0.849604 0.682725 0.865299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2205488 episodes
GETTING ACTION FROM:
action 3, numVisits=2205470, meanQ=4.990455, numObservations: 4
action 1, numVisits=8, meanQ=1.500000, numObservations: 2
action 2, numVisits=6, meanQ=1.001683, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.237762 0.973313 0.647102 0.849604 0.682725 0.865299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=149229, meanQ=5.583915, numObservations: 3
action 0, numVisits=15933, meanQ=3.162273, numObservations: 1
action 2, numVisits=10, meanQ=0.809010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
Sampled 2645669 episodes
GETTING ACTION FROM:
action 3, numVisits=2794898, meanQ=5.089569, numObservations: 4
action 0, numVisits=15933, meanQ=3.162273, numObservations: 1
action 2, numVisits=10, meanQ=0.809010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 1 0.237762 0.973313 0.647102 0.849604 0.682725 0.865299 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 333
Initial state: 0 0.616423 0.840024 0.481486 0.752206 0.524823 0.800497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254773 episodes
GETTING ACTION FROM:
action 3, numVisits=2254712, meanQ=4.960246, numObservations: 4
action 0, numVisits=49, meanQ=3.869672, numObservations: 2
action -1, numVisits=10, meanQ=2.058510, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.616423 0.840024 0.481486 0.752206 0.524823 0.800497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.63839 0.892541 0.657121 0.868908 0.0431279 0.974513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2272280 episodes
GETTING ACTION FROM:
action 2, numVisits=2272268, meanQ=4.949872, numObservations: 4
action 3, numVisits=7, meanQ=0.985714, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.63839 0.892541 0.657121 0.868908 0.0431279 0.974513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.625504 0.884777 0.520071 0.868557 0.909789 0.19197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1295335 episodes
GETTING ACTION FROM:
action 0, numVisits=1295321, meanQ=4.086920, numObservations: 2
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 0
Next state: 0 0.625504 0.884777 0.520071 0.868557 0.909789 0.19197 w: 1
Observation: 0 0 0.894009 0 0.791703 0 0.247247 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=315730, meanQ=8.491183, numObservations: 3
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2547932 episodes
GETTING ACTION FROM:
action 1, numVisits=2863660, meanQ=5.272710, numObservations: 3
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.625504 0.884777 0.520071 0.868557 0.909789 0.19197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 336
Initial state: 0 0.593384 0.856733 0.873697 0.405431 0.50694 0.842995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303832 episodes
GETTING ACTION FROM:
action 1, numVisits=2303762, meanQ=5.018127, numObservations: 3
action -1, numVisits=62, meanQ=4.042334, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.593384 0.856733 0.873697 0.405431 0.50694 0.842995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.298228 0.996412 0.583123 0.810253 0.645979 0.838752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2146267 episodes
GETTING ACTION FROM:
action 2, numVisits=1941139, meanQ=4.950320, numObservations: 5
action -1, numVisits=205066, meanQ=2.964102, numObservations: 1
action 0, numVisits=60, meanQ=2.073045, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.298228 0.996412 0.583123 0.810253 0.645979 0.838752 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.53256 0.862377 0.575661 0.847987 0.231779 0.11885 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264019 episodes
GETTING ACTION FROM:
action 2, numVisits=2263982, meanQ=5.015705, numObservations: 4
action 1, numVisits=19, meanQ=2.788426, numObservations: 2
action 3, numVisits=14, meanQ=2.427157, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.53256 0.862377 0.575661 0.847987 0.231779 0.11885 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 339
Initial state: 0 0.620905 0.82788 0.577983 0.83007 0.916901 0.0769138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275563 episodes
GETTING ACTION FROM:
action 1, numVisits=2273163, meanQ=5.007768, numObservations: 3
action 3, numVisits=2252, meanQ=4.848030, numObservations: 4
action -1, numVisits=145, meanQ=4.376643, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.620905 0.82788 0.577983 0.83007 0.916901 0.0769138 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=372825, meanQ=8.281204, numObservations: 3
action 2, numVisits=45, meanQ=7.127113, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2903266 episodes
GETTING ACTION FROM:
action 3, numVisits=3275748, meanQ=6.244460, numObservations: 3
action 2, numVisits=386, meanQ=5.825933, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.620905 0.82788 0.577983 0.83007 0.916901 0.0769138 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 340
Initial state: 0 0.643141 0.818003 0.569789 0.845521 0.464308 0.272246 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2178421 episodes
GETTING ACTION FROM:
action 2, numVisits=2178331, meanQ=4.863152, numObservations: 4
action 1, numVisits=52, meanQ=3.688475, numObservations: 4
action 3, numVisits=34, meanQ=3.352359, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.643141 0.818003 0.569789 0.845521 0.464308 0.272246 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.0327725 0.662233 0.597638 0.823484 0.66889 0.881425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275465 episodes
GETTING ACTION FROM:
action 1, numVisits=2275432, meanQ=5.016604, numObservations: 4
action -1, numVisits=29, meanQ=3.563651, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0327725 0.662233 0.597638 0.823484 0.66889 0.881425 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=319819, meanQ=8.388624, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2901040 episodes
GETTING ACTION FROM:
action 3, numVisits=3220857, meanQ=6.327014, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0327725 0.662233 0.597638 0.823484 0.66889 0.881425 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 342
Initial state: 0 0.673897 0.823392 0.416089 0.960585 0.598967 0.851422 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254436 episodes
GETTING ACTION FROM:
action 2, numVisits=2254430, meanQ=5.000013, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.673897 0.823392 0.416089 0.960585 0.598967 0.851422 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 343
Initial state: 0 0.654333 0.832196 0.644125 0.479803 0.622254 0.894038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2211370 episodes
GETTING ACTION FROM:
action 3, numVisits=2186733, meanQ=5.011904, numObservations: 5
action -1, numVisits=24625, meanQ=2.887575, numObservations: 1
action 2, numVisits=6, meanQ=-0.350000, numObservations: 1
action 1, numVisits=4, meanQ=-1.002450, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.654333 0.832196 0.644125 0.479803 0.622254 0.894038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.529417 0.850173 0.544284 0.839189 0.290707 0.150817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2225119 episodes
GETTING ACTION FROM:
action 3, numVisits=2225092, meanQ=4.930412, numObservations: 5
action -1, numVisits=22, meanQ=3.303206, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.529417 0.850173 0.544284 0.839189 0.290707 0.150817 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=311869, meanQ=8.411356, numObservations: 5
action 2, numVisits=8, meanQ=5.501263, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2860926 episodes
GETTING ACTION FROM:
action 1, numVisits=3172745, meanQ=6.003003, numObservations: 5
action 2, numVisits=56, meanQ=4.821432, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.529417 0.850173 0.544284 0.839189 0.290707 0.150817 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 345
Initial state: 0 0.0696839 0.850948 0.536897 0.881884 0.537036 0.898379 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257692 episodes
GETTING ACTION FROM:
action 1, numVisits=2257675, meanQ=5.023887, numObservations: 5
action -1, numVisits=10, meanQ=2.488000, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.0696839 0.850948 0.536897 0.881884 0.537036 0.898379 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110998, meanQ=7.940802, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2881759 episodes
GETTING ACTION FROM:
action 3, numVisits=2992416, meanQ=5.979860, numObservations: 4
action 2, numVisits=341, meanQ=5.537156, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0696839 0.850948 0.536897 0.881884 0.537036 0.898379 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 346
Initial state: 0 0.528038 0.880422 0.526095 0.858006 0.926878 0.254814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2199229 episodes
GETTING ACTION FROM:
action 1, numVisits=2199124, meanQ=4.866623, numObservations: 4
action -1, numVisits=70, meanQ=3.958208, numObservations: 1
action 0, numVisits=28, meanQ=3.412236, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.528038 0.880422 0.526095 0.858006 0.926878 0.254814 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.560291 0.812048 0.660957 0.894965 0.161324 0.174855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2248640 episodes
GETTING ACTION FROM:
action 3, numVisits=2243955, meanQ=4.945810, numObservations: 4
action 0, numVisits=4679, meanQ=2.719536, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.560291 0.812048 0.660957 0.894965 0.161324 0.174855 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=52999, meanQ=7.909546, numObservations: 4
action 1, numVisits=16, meanQ=5.749375, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2897487 episodes
GETTING ACTION FROM:
action 2, numVisits=2950475, meanQ=6.244804, numObservations: 4
action 1, numVisits=25, meanQ=4.519600, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.560291 0.812048 0.660957 0.894965 0.161324 0.174855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 348
Initial state: 0 0.615681 0.891737 0.129324 0.56137 0.554903 0.897079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258305 episodes
GETTING ACTION FROM:
action 2, numVisits=2258204, meanQ=5.032557, numObservations: 5
action -1, numVisits=59, meanQ=4.012377, numObservations: 1
action 0, numVisits=22, meanQ=3.322598, numObservations: 1
action 3, numVisits=19, meanQ=2.677895, numObservations: 5
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.615681 0.891737 0.129324 0.56137 0.554903 0.897079 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=316295, meanQ=8.407837, numObservations: 4
action 3, numVisits=4, meanQ=2.995000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2904641 episodes
GETTING ACTION FROM:
action 1, numVisits=3220728, meanQ=5.970353, numObservations: 4
action 3, numVisits=210, meanQ=5.380620, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.615681 0.891737 0.129324 0.56137 0.554903 0.897079 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 349
Initial state: 0 0.256039 0.45157 0.618428 0.818195 0.564908 0.846499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2190863 episodes
GETTING ACTION FROM:
action 3, numVisits=2190821, meanQ=4.793464, numObservations: 4
action 0, numVisits=19, meanQ=3.028728, numObservations: 1
action 1, numVisits=12, meanQ=2.157508, numObservations: 3
action 2, numVisits=9, meanQ=2.112244, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.256039 0.45157 0.618428 0.818195 0.564908 0.846499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.186446 0.683357 0.579965 0.841171 0.611389 0.847153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1562317 episodes
GETTING ACTION FROM:
action -1, numVisits=1562305, meanQ=2.903920, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: -1
Next state: 0 0.186446 0.683357 0.579965 0.841171 0.611389 0.847153 w: 1
Observation: 0 0.136638 0 0.533717 0 0.592545 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1562296, meanQ=4.961662, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2502095 episodes
GETTING ACTION FROM:
action 2, numVisits=4064391, meanQ=4.788759, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.186446 0.683357 0.579965 0.841171 0.611389 0.847153 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 351
Initial state: 0 0.851542 0.118125 0.54327 0.895963 0.626564 0.808289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246988 episodes
GETTING ACTION FROM:
action 3, numVisits=2246969, meanQ=5.030788, numObservations: 4
action 2, numVisits=13, meanQ=2.222308, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.851542 0.118125 0.54327 0.895963 0.626564 0.808289 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 352
Initial state: 0 0.157639 0.208941 0.581889 0.876465 0.678032 0.857102 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254038 episodes
GETTING ACTION FROM:
action 3, numVisits=2253963, meanQ=5.216296, numObservations: 5
action -1, numVisits=44, meanQ=4.046947, numObservations: 1
action 0, numVisits=23, meanQ=3.559079, numObservations: 1
action 2, numVisits=7, meanQ=2.144300, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.157639 0.208941 0.581889 0.876465 0.678032 0.857102 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.79032 0.575093 0.666468 0.845707 0.62547 0.891355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249817 episodes
GETTING ACTION FROM:
action 1, numVisits=2249811, meanQ=5.006786, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.79032 0.575093 0.666468 0.845707 0.62547 0.891355 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 354
Initial state: 0 0.528286 0.834189 0.747942 0.830493 0.673462 0.841006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2230215 episodes
GETTING ACTION FROM:
action 1, numVisits=2230186, meanQ=4.946847, numObservations: 5
action 3, numVisits=24, meanQ=3.165850, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.528286 0.834189 0.747942 0.830493 0.673462 0.841006 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 355
Initial state: 0 0.537807 0.843015 0.465437 0.432388 0.542282 0.881772 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2232321 episodes
GETTING ACTION FROM:
action 2, numVisits=2232309, meanQ=5.013394, numObservations: 5
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.537807 0.843015 0.465437 0.432388 0.542282 0.881772 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=312300, meanQ=8.386646, numObservations: 4
action 3, numVisits=898, meanQ=8.158144, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2891693 episodes
GETTING ACTION FROM:
action 1, numVisits=3193482, meanQ=6.253825, numObservations: 4
action 3, numVisits=11406, meanQ=6.184875, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.537807 0.843015 0.465437 0.432388 0.542282 0.881772 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 356
Initial state: 0 0.543198 0.852445 0.626068 0.821682 0.987646 0.379418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2266085 episodes
GETTING ACTION FROM:
action 1, numVisits=2265425, meanQ=4.950313, numObservations: 4
action 2, numVisits=655, meanQ=4.651093, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.543198 0.852445 0.626068 0.821682 0.987646 0.379418 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.659836 0.897349 0.608158 0.862627 0.482842 0.0886646 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2293227 episodes
GETTING ACTION FROM:
action 2, numVisits=2293123, meanQ=5.037669, numObservations: 3
action 0, numVisits=90, meanQ=4.233201, numObservations: 1
action -1, numVisits=12, meanQ=2.585116, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.659836 0.897349 0.608158 0.862627 0.482842 0.0886646 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.647584 0.87429 0.68039 0.849017 0.00783321 0.250434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267304 episodes
GETTING ACTION FROM:
action 1, numVisits=2267264, meanQ=5.002149, numObservations: 4
action -1, numVisits=36, meanQ=3.638167, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.647584 0.87429 0.68039 0.849017 0.00783321 0.250434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.207945 0.201108 0.675551 0.839964 0.621915 0.870292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263398 episodes
GETTING ACTION FROM:
action 3, numVisits=2263364, meanQ=4.949068, numObservations: 3
action 0, numVisits=29, meanQ=3.491702, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.207945 0.201108 0.675551 0.839964 0.621915 0.870292 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.585413 0.829943 0.0488145 0.485451 0.533841 0.816432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243955 episodes
GETTING ACTION FROM:
action 3, numVisits=2243889, meanQ=5.027913, numObservations: 5
action 0, numVisits=26, meanQ=3.487130, numObservations: 1
action -1, numVisits=26, meanQ=3.459648, numObservations: 1
action 1, numVisits=13, meanQ=2.683854, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.585413 0.829943 0.0488145 0.485451 0.533841 0.816432 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.572595 0.889954 0.546439 0.805524 0.867557 0.605622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2217632 episodes
GETTING ACTION FROM:
action 2, numVisits=2217623, meanQ=4.907864, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.572595 0.889954 0.546439 0.805524 0.867557 0.605622 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.686558 0.80194 0.571755 0.883571 0.95318 0.249598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245424 episodes
GETTING ACTION FROM:
action 3, numVisits=2245418, meanQ=4.947597, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.686558 0.80194 0.571755 0.883571 0.95318 0.249598 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 363
Initial state: 0 0.593025 0.86583 0.616039 0.886865 0.289058 0.372498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2252638 episodes
GETTING ACTION FROM:
action 2, numVisits=2252584, meanQ=5.123484, numObservations: 4
action 0, numVisits=36, meanQ=3.541527, numObservations: 2
action 3, numVisits=9, meanQ=2.320000, numObservations: 4
action 1, numVisits=7, meanQ=1.568600, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.593025 0.86583 0.616039 0.886865 0.289058 0.372498 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 364
Initial state: 0 0.246922 0.727984 0.693322 0.85215 0.616698 0.870028 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243733 episodes
GETTING ACTION FROM:
action 3, numVisits=2189226, meanQ=5.021284, numObservations: 4
action 1, numVisits=54447, meanQ=4.698694, numObservations: 5
action 2, numVisits=56, meanQ=3.777502, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.246922 0.727984 0.693322 0.85215 0.616698 0.870028 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 365
Initial state: 0 0.538185 0.873411 0.0683072 0.834275 0.500263 0.869076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255502 episodes
GETTING ACTION FROM:
action 1, numVisits=2255483, meanQ=5.014691, numObservations: 5
action 2, numVisits=14, meanQ=2.720714, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.538185 0.873411 0.0683072 0.834275 0.500263 0.869076 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 366
Initial state: 0 0.639616 0.843888 0.66359 0.899079 0.802031 0.987691 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262196 episodes
GETTING ACTION FROM:
action 1, numVisits=2262186, meanQ=4.945744, numObservations: 4
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.639616 0.843888 0.66359 0.899079 0.802031 0.987691 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.595184 0.881457 0.36325 0.0764756 0.583139 0.861598 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2303064 episodes
GETTING ACTION FROM:
action 1, numVisits=2303045, meanQ=5.014535, numObservations: 3
action 2, numVisits=14, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.595184 0.881457 0.36325 0.0764756 0.583139 0.861598 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.615347 0.857087 0.0243234 0.0514506 0.595895 0.837111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2218360 episodes
GETTING ACTION FROM:
action 1, numVisits=2208310, meanQ=4.937125, numObservations: 5
action -1, numVisits=10019, meanQ=3.023774, numObservations: 1
action 3, numVisits=13, meanQ=1.307700, numObservations: 2
action 0, numVisits=13, meanQ=1.043108, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 4
action: 1
Next state: 1 0.615347 0.857087 0.0243234 0.0514506 0.595895 0.837111 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.611183 0.894863 0.146631 0.305546 0.525836 0.863606 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253815 episodes
GETTING ACTION FROM:
action 1, numVisits=2253801, meanQ=5.024042, numObservations: 5
action 3, numVisits=9, meanQ=2.320000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.611183 0.894863 0.146631 0.305546 0.525836 0.863606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=170986, meanQ=5.635534, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2723748 episodes
GETTING ACTION FROM:
action 1, numVisits=2894734, meanQ=4.886816, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.611183 0.894863 0.146631 0.305546 0.525836 0.863606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=68886, meanQ=6.509639, numObservations: 5
action 1, numVisits=1377, meanQ=5.687303, numObservations: 4
action 3, numVisits=12, meanQ=3.665000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2914142 episodes
GETTING ACTION FROM:
action 2, numVisits=2983026, meanQ=6.138455, numObservations: 5
action 1, numVisits=1377, meanQ=5.687303, numObservations: 4
action 3, numVisits=12, meanQ=3.665000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 0 0.611183 0.894863 0.146631 0.305546 0.525836 0.863606 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=5903, meanQ=8.582689, numObservations: 3
action 1, numVisits=2739, meanQ=8.541718, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2935808 episodes
GETTING ACTION FROM:
action 3, numVisits=2933602, meanQ=6.268442, numObservations: 5
action 1, numVisits=10846, meanQ=6.197288, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.611183 0.894863 0.146631 0.305546 0.525836 0.863606 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 370
Initial state: 0 0.672725 0.820229 0.653061 0.809835 0.232461 0.380493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2237973 episodes
GETTING ACTION FROM:
action 2, numVisits=2237944, meanQ=4.965358, numObservations: 5
action 1, numVisits=20, meanQ=3.185500, numObservations: 4
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.672725 0.820229 0.653061 0.809835 0.232461 0.380493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=167731, meanQ=4.725751, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2853851 episodes
GETTING ACTION FROM:
action 1, numVisits=3021582, meanQ=5.744410, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.672725 0.820229 0.653061 0.809835 0.232461 0.380493 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 371
Initial state: 0 0.211518 0.187983 0.512515 0.822037 0.577246 0.838363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2200280 episodes
GETTING ACTION FROM:
action 3, numVisits=2200266, meanQ=4.942998, numObservations: 5
action 2, numVisits=9, meanQ=0.998889, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.211518 0.187983 0.512515 0.822037 0.577246 0.838363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 372
Initial state: 0 0.565084 0.828683 0.0463903 0.818122 0.674623 0.881952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261163 episodes
GETTING ACTION FROM:
action 1, numVisits=2251299, meanQ=5.013286, numObservations: 4
action 0, numVisits=9855, meanQ=2.994126, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.565084 0.828683 0.0463903 0.818122 0.674623 0.881952 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.882997 0.519796 0.591294 0.87371 0.518493 0.83942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239892 episodes
GETTING ACTION FROM:
action 1, numVisits=2000689, meanQ=4.955988, numObservations: 5
action 2, numVisits=239104, meanQ=4.941271, numObservations: 5
action 0, numVisits=96, meanQ=4.169981, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.882997 0.519796 0.591294 0.87371 0.518493 0.83942 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 374
Initial state: 0 0.353969 0.735977 0.544229 0.828786 0.647422 0.862369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297905 episodes
GETTING ACTION FROM:
action 1, numVisits=2297896, meanQ=5.013743, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.353969 0.735977 0.544229 0.828786 0.647422 0.862369 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=376290, meanQ=8.349452, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2912502 episodes
GETTING ACTION FROM:
action 2, numVisits=3288748, meanQ=6.151434, numObservations: 4
action 3, numVisits=43, meanQ=4.628142, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.353969 0.735977 0.544229 0.828786 0.647422 0.862369 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 375
Initial state: 0 0.564127 0.839188 0.622689 0.809147 0.120345 0.432761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260674 episodes
GETTING ACTION FROM:
action 3, numVisits=2260609, meanQ=4.952311, numObservations: 4
action -1, numVisits=36, meanQ=3.641428, numObservations: 1
action 1, numVisits=22, meanQ=2.990909, numObservations: 3
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.564127 0.839188 0.622689 0.809147 0.120345 0.432761 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=369749, meanQ=8.356575, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2854374 episodes
GETTING ACTION FROM:
action 2, numVisits=3224120, meanQ=6.248793, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.564127 0.839188 0.622689 0.809147 0.120345 0.432761 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 376
Initial state: 0 0.698361 0.866614 0.446019 0.632414 0.530576 0.827393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255800 episodes
GETTING ACTION FROM:
action 3, numVisits=2255623, meanQ=5.002409, numObservations: 4
action -1, numVisits=117, meanQ=4.295297, numObservations: 1
action 0, numVisits=40, meanQ=3.790207, numObservations: 1
action 2, numVisits=17, meanQ=2.411176, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action: 3
Next state: 1 0.698361 0.866614 0.446019 0.632414 0.530576 0.827393 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 377
Initial state: 0 0.686185 0.863469 0.606355 0.841406 0.436794 0.687988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263361 episodes
GETTING ACTION FROM:
action 1, numVisits=2263243, meanQ=4.946322, numObservations: 4
action 0, numVisits=43, meanQ=3.732240, numObservations: 1
action 2, numVisits=42, meanQ=3.609764, numObservations: 4
action -1, numVisits=32, meanQ=3.565418, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.686185 0.863469 0.606355 0.841406 0.436794 0.687988 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.510337 0.826358 0.0843488 0.633451 0.613318 0.854045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2231535 episodes
GETTING ACTION FROM:
action 1, numVisits=2231495, meanQ=4.942809, numObservations: 5
action 0, numVisits=36, meanQ=3.610760, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.510337 0.826358 0.0843488 0.633451 0.613318 0.854045 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 379
Initial state: 0 0.522208 0.885601 0.524013 0.806845 0.662859 0.956813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2258462 episodes
GETTING ACTION FROM:
action 1, numVisits=2258439, meanQ=4.975886, numObservations: 4
action 2, numVisits=11, meanQ=2.453645, numObservations: 4
action 3, numVisits=8, meanQ=1.251275, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.522208 0.885601 0.524013 0.806845 0.662859 0.956813 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=167606, meanQ=5.336977, numObservations: 3
action 2, numVisits=1785, meanQ=4.865101, numObservations: 5
action 0, numVisits=26, meanQ=3.930029, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2689144 episodes
GETTING ACTION FROM:
action 2, numVisits=120858, meanQ=5.815554, numObservations: 5
action 1, numVisits=2737674, meanQ=5.018394, numObservations: 3
action 0, numVisits=29, meanQ=3.490340, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.522208 0.885601 0.524013 0.806845 0.662859 0.956813 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 380
Initial state: 0 0.55839 0.824345 0.555046 0.881806 0.252864 0.256146 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259598 episodes
GETTING ACTION FROM:
action 2, numVisits=2259503, meanQ=4.955283, numObservations: 4
action 0, numVisits=62, meanQ=3.981100, numObservations: 1
action 1, numVisits=24, meanQ=3.248763, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.55839 0.824345 0.555046 0.881806 0.252864 0.256146 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.505551 0.897836 0.368237 0.594746 0.643145 0.843908 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2269069 episodes
GETTING ACTION FROM:
action 3, numVisits=2268665, meanQ=5.005260, numObservations: 3
action -1, numVisits=392, meanQ=2.501774, numObservations: 1
action 1, numVisits=9, meanQ=0.111111, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.505551 0.897836 0.368237 0.594746 0.643145 0.843908 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.826884 0.116448 0.655109 0.885251 0.655835 0.872152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2132449 episodes
GETTING ACTION FROM:
action 3, numVisits=2132412, meanQ=4.799447, numObservations: 4
action 1, numVisits=32, meanQ=3.107194, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.826884 0.116448 0.655109 0.885251 0.655835 0.872152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=159434, meanQ=2.672682, numObservations: 1
action 1, numVisits=8, meanQ=-0.001250, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2893735 episodes
GETTING ACTION FROM:
action 2, numVisits=2876591, meanQ=5.899680, numObservations: 4
action 0, numVisits=176576, meanQ=2.327021, numObservations: 1
action 1, numVisits=13, meanQ=0.383846, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.826884 0.116448 0.655109 0.885251 0.655835 0.872152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=53634, meanQ=6.998362, numObservations: 5
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2952089 episodes
GETTING ACTION FROM:
action 1, numVisits=3005721, meanQ=5.904869, numObservations: 5
action 2, numVisits=3, meanQ=0.993333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 2 0.826884 0.116448 0.655109 0.885251 0.655835 0.872152 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 383
Initial state: 0 0.685186 0.861937 0.890061 0.944018 0.609213 0.84005 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2193626 episodes
GETTING ACTION FROM:
action 3, numVisits=2193618, meanQ=4.873480, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.685186 0.861937 0.890061 0.944018 0.609213 0.84005 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 384
Initial state: 0 0.692547 0.883521 0.623415 0.883345 0.128404 0.343105 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254620 episodes
GETTING ACTION FROM:
action 2, numVisits=2254609, meanQ=4.943622, numObservations: 4
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.692547 0.883521 0.623415 0.883345 0.128404 0.343105 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.523398 0.895221 0.55988 0.86338 0.315843 0.784817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2243865 episodes
GETTING ACTION FROM:
action 1, numVisits=2243818, meanQ=5.154611, numObservations: 5
action -1, numVisits=25, meanQ=3.606638, numObservations: 1
action 0, numVisits=18, meanQ=3.352152, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.523398 0.895221 0.55988 0.86338 0.315843 0.784817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.621301 0.892551 0.421169 0.705994 0.60556 0.825569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245695 episodes
GETTING ACTION FROM:
action 3, numVisits=2245572, meanQ=4.995848, numObservations: 4
action 2, numVisits=115, meanQ=4.198525, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.005000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.621301 0.892551 0.421169 0.705994 0.60556 0.825569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=165604, meanQ=5.590640, numObservations: 4
action 1, numVisits=23, meanQ=4.130004, numObservations: 4
action 2, numVisits=12, meanQ=3.334175, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 2872175 episodes
GETTING ACTION FROM:
action 1, numVisits=2772476, meanQ=6.207106, numObservations: 5
action 3, numVisits=265326, meanQ=5.426778, numObservations: 4
action 2, numVisits=12, meanQ=3.334175, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.621301 0.892551 0.421169 0.705994 0.60556 0.825569 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=15289, meanQ=7.881885, numObservations: 5
action 1, numVisits=4, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2915914 episodes
GETTING ACTION FROM:
action 1, numVisits=2689214, meanQ=6.144146, numObservations: 5
action 2, numVisits=241991, meanQ=5.990297, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.621301 0.892551 0.421169 0.705994 0.60556 0.825569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 387
Initial state: 0 0.791975 0.0570267 0.630181 0.880356 0.559856 0.850233 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2235776 episodes
GETTING ACTION FROM:
action 3, numVisits=2235765, meanQ=4.949645, numObservations: 5
action 2, numVisits=6, meanQ=-0.316667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.791975 0.0570267 0.630181 0.880356 0.559856 0.850233 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.560619 0.843451 0.258074 0.665738 0.62224 0.856949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2256973 episodes
GETTING ACTION FROM:
action 1, numVisits=2256905, meanQ=4.945395, numObservations: 4
action 0, numVisits=59, meanQ=3.942610, numObservations: 1
action 2, numVisits=6, meanQ=1.001683, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.560619 0.843451 0.258074 0.665738 0.62224 0.856949 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=169098, meanQ=4.731456, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2865677 episodes
GETTING ACTION FROM:
action 3, numVisits=3034775, meanQ=6.001762, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.560619 0.843451 0.258074 0.665738 0.62224 0.856949 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 389
Initial state: 0 0.637193 0.792975 0.56578 0.820424 0.597897 0.82612 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2275951 episodes
GETTING ACTION FROM:
action 1, numVisits=2275916, meanQ=5.168165, numObservations: 4
action -1, numVisits=31, meanQ=3.776599, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.637193 0.792975 0.56578 0.820424 0.597897 0.82612 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 390
Initial state: 0 0.0110828 0.16407 0.542331 0.832538 0.645766 0.888377 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238157 episodes
GETTING ACTION FROM:
action 2, numVisits=2238050, meanQ=5.012345, numObservations: 5
action 0, numVisits=74, meanQ=4.126640, numObservations: 1
action 3, numVisits=30, meanQ=3.581337, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.0110828 0.16407 0.542331 0.832538 0.645766 0.888377 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.606628 0.867214 0.544971 0.820291 0.509986 0.613117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2223714 episodes
GETTING ACTION FROM:
action 3, numVisits=2223690, meanQ=4.952836, numObservations: 5
action 2, numVisits=19, meanQ=2.788426, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.606628 0.867214 0.544971 0.820291 0.509986 0.613117 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=108935, meanQ=7.955724, numObservations: 4
action 2, numVisits=9, meanQ=5.655567, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2901385 episodes
GETTING ACTION FROM:
action 1, numVisits=3010301, meanQ=6.049802, numObservations: 4
action 2, numVisits=26, meanQ=3.996158, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.606628 0.867214 0.544971 0.820291 0.509986 0.613117 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 392
Initial state: 0 0.64835 0.818038 0.618573 0.822701 0.985621 0.332021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254262 episodes
GETTING ACTION FROM:
action 1, numVisits=2254256, meanQ=4.983448, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.64835 0.818038 0.618573 0.822701 0.985621 0.332021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.661104 0.838251 0.856883 0.424815 0.502681 0.869426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2266164 episodes
GETTING ACTION FROM:
action 1, numVisits=2265449, meanQ=5.031326, numObservations: 4
action -1, numVisits=689, meanQ=2.230700, numObservations: 1
action 2, numVisits=23, meanQ=1.165657, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.661104 0.838251 0.856883 0.424815 0.502681 0.869426 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.732181 0.00858765 0.53159 0.856496 0.635981 0.851535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234903 episodes
GETTING ACTION FROM:
action 3, numVisits=2234889, meanQ=4.996866, numObservations: 5
action 1, numVisits=7, meanQ=1.568600, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.732181 0.00858765 0.53159 0.856496 0.635981 0.851535 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.205358 0.0607368 0.626716 0.895556 0.645539 0.847446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2183408 episodes
GETTING ACTION FROM:
action 2, numVisits=2183402, meanQ=5.011967, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.205358 0.0607368 0.626716 0.895556 0.645539 0.847446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 396
Initial state: 0 0.598956 0.836709 0.293742 0.322872 0.610765 0.842789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267038 episodes
GETTING ACTION FROM:
action 1, numVisits=2267020, meanQ=5.002791, numObservations: 4
action 2, numVisits=13, meanQ=0.997708, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.598956 0.836709 0.293742 0.322872 0.610765 0.842789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.856066 0.950521 0.599303 0.874107 0.526613 0.85942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271728 episodes
GETTING ACTION FROM:
action 2, numVisits=2271685, meanQ=5.019839, numObservations: 4
action 0, numVisits=38, meanQ=3.749303, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.856066 0.950521 0.599303 0.874107 0.526613 0.85942 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.136864 0.593557 0.658668 0.80316 0.551263 0.83436 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2223249 episodes
GETTING ACTION FROM:
action 2, numVisits=2217423, meanQ=4.942073, numObservations: 5
action 3, numVisits=5809, meanQ=4.845679, numObservations: 4
action 1, numVisits=13, meanQ=1.922308, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.136864 0.593557 0.658668 0.80316 0.551263 0.83436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=139162, meanQ=4.001158, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2808155 episodes
GETTING ACTION FROM:
action 1, numVisits=2947317, meanQ=5.508559, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.136864 0.593557 0.658668 0.80316 0.551263 0.83436 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=68787, meanQ=8.206828, numObservations: 3
action 3, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2904547 episodes
GETTING ACTION FROM:
action 2, numVisits=2973327, meanQ=6.582807, numObservations: 4
action 3, numVisits=11, meanQ=3.180000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.136864 0.593557 0.658668 0.80316 0.551263 0.83436 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 399
Initial state: 0 0.461 0.747647 0.674024 0.80265 0.673102 0.824602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1525351 episodes
GETTING ACTION FROM:
action 0, numVisits=1525344, meanQ=2.951126, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.461 0.747647 0.674024 0.80265 0.673102 0.824602 w: 1
Observation: 0 0 0.791521 0 0.755512 0 0.898766 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1525336, meanQ=5.008241, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 2470055 episodes
GETTING ACTION FROM:
action 3, numVisits=3995391, meanQ=5.106546, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.461 0.747647 0.674024 0.80265 0.673102 0.824602 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 400
Initial state: 0 0.629479 0.833898 0.509287 0.820445 0.285697 0.28784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1528252 episodes
GETTING ACTION FROM:
action -1, numVisits=1528040, meanQ=2.948313, numObservations: 1
action 0, numVisits=184, meanQ=2.397582, numObservations: 1
action 2, numVisits=15, meanQ=0.859340, numObservations: 3
action 3, numVisits=11, meanQ=0.635464, numObservations: 3
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: -1
Next state: 0 0.629479 0.833898 0.509287 0.820445 0.285697 0.28784 w: 1
Observation: 0 0.60927 0 0.591014 0 0.234777 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1526221, meanQ=5.002091, numObservations: 5
action 1, numVisits=1774, meanQ=4.822922, numObservations: 5
action -1, numVisits=25, meanQ=3.492717, numObservations: 1
action 3, numVisits=17, meanQ=2.877065, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2454774 episodes
GETTING ACTION FROM:
action 2, numVisits=3980995, meanQ=5.049344, numObservations: 5
action 1, numVisits=1774, meanQ=4.822922, numObservations: 5
action -1, numVisits=25, meanQ=3.492717, numObservations: 1
action 3, numVisits=17, meanQ=2.877065, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.629479 0.833898 0.509287 0.820445 0.285697 0.28784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 401
Initial state: 0 0.584345 0.877158 0.0872213 0.639074 0.696185 0.881192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2209176 episodes
GETTING ACTION FROM:
action 3, numVisits=2209130, meanQ=5.004910, numObservations: 4
action 2, numVisits=41, meanQ=3.724634, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.584345 0.877158 0.0872213 0.639074 0.696185 0.881192 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.502201 0.810412 0.887368 0.972236 0.566978 0.882296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2181412 episodes
GETTING ACTION FROM:
action 3, numVisits=2180281, meanQ=5.016912, numObservations: 5
action 2, numVisits=903, meanQ=4.765341, numObservations: 4
action -1, numVisits=174, meanQ=4.439391, numObservations: 1
action 0, numVisits=33, meanQ=3.632121, numObservations: 1
action 1, numVisits=21, meanQ=2.990481, numObservations: 2
action: 3
Next state: 1 0.502201 0.810412 0.887368 0.972236 0.566978 0.882296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.550328 0.878855 0.687382 0.815308 0.282059 0.901315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2197785 episodes
GETTING ACTION FROM:
action 3, numVisits=2197766, meanQ=4.991016, numObservations: 4
action 2, numVisits=14, meanQ=2.550721, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.550328 0.878855 0.687382 0.815308 0.282059 0.901315 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.676025 0.855938 0.600568 0.89572 0.318268 0.171995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1542955 episodes
GETTING ACTION FROM:
action 0, numVisits=1542943, meanQ=2.960694, numObservations: 1
action 2, numVisits=5, meanQ=-0.582000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.676025 0.855938 0.600568 0.89572 0.318268 0.171995 w: 1
Observation: 0 0 0.880949 0 0.972906 0 0.0821306 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1542888, meanQ=5.006714, numObservations: 4
action -1, numVisits=46, meanQ=3.855641, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2471336 episodes
GETTING ACTION FROM:
action 1, numVisits=870842, meanQ=5.414203, numObservations: 4
action 2, numVisits=3143383, meanQ=4.861059, numObservations: 4
action -1, numVisits=49, meanQ=3.756901, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.676025 0.855938 0.600568 0.89572 0.318268 0.171995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 405
Initial state: 0 0.45527 0.634876 0.696092 0.822011 0.673585 0.817933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2208569 episodes
GETTING ACTION FROM:
action 3, numVisits=2200521, meanQ=4.960617, numObservations: 4
action 1, numVisits=7963, meanQ=4.877150, numObservations: 4
action -1, numVisits=82, meanQ=4.120875, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.45527 0.634876 0.696092 0.822011 0.673585 0.817933 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.198281 0.0666842 0.583354 0.87358 0.668019 0.814411 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2200591 episodes
GETTING ACTION FROM:
action 3, numVisits=2200583, meanQ=4.940461, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.198281 0.0666842 0.583354 0.87358 0.668019 0.814411 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 407
Initial state: 0 0.276923 0.354979 0.567749 0.882071 0.691878 0.852941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2218226 episodes
GETTING ACTION FROM:
action 3, numVisits=2218183, meanQ=5.005724, numObservations: 4
action -1, numVisits=26, meanQ=3.478646, numObservations: 1
action 1, numVisits=14, meanQ=2.400714, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.276923 0.354979 0.567749 0.882071 0.691878 0.852941 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.4339 0.406698 0.527917 0.832934 0.561332 0.878937 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2194557 episodes
GETTING ACTION FROM:
action 3, numVisits=2194493, meanQ=4.956609, numObservations: 5
action -1, numVisits=46, meanQ=3.795462, numObservations: 1
action 1, numVisits=15, meanQ=2.460680, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.4339 0.406698 0.527917 0.832934 0.561332 0.878937 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 409
Initial state: 0 0.00558786 0.975012 0.695946 0.895494 0.638215 0.897889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2213745 episodes
GETTING ACTION FROM:
action 3, numVisits=2205982, meanQ=4.937618, numObservations: 4
action 0, numVisits=7642, meanQ=2.907256, numObservations: 1
action -1, numVisits=111, meanQ=2.332795, numObservations: 1
action 2, numVisits=9, meanQ=0.544444, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.00558786 0.975012 0.695946 0.895494 0.638215 0.897889 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=20598, meanQ=4.670678, numObservations: 4
action 0, numVisits=66, meanQ=3.930666, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2814462 episodes
GETTING ACTION FROM:
action 2, numVisits=2835060, meanQ=6.387633, numObservations: 4
action 0, numVisits=66, meanQ=3.930666, numObservations: 1
action 1, numVisits=3, meanQ=0.993333, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.00558786 0.975012 0.695946 0.895494 0.638215 0.897889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=57247, meanQ=6.636251, numObservations: 4
action 3, numVisits=21, meanQ=3.185243, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2925865 episodes
GETTING ACTION FROM:
action 1, numVisits=2983110, meanQ=5.813992, numObservations: 4
action 3, numVisits=21, meanQ=3.185243, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.00558786 0.975012 0.695946 0.895494 0.638215 0.897889 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=1585, meanQ=7.459939, numObservations: 3
action 3, numVisits=152, meanQ=3.433463, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2880775 episodes
GETTING ACTION FROM:
action 1, numVisits=2882358, meanQ=5.481753, numObservations: 5
action 3, numVisits=152, meanQ=3.433463, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.00558786 0.975012 0.695946 0.895494 0.638215 0.897889 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=42, meanQ=4.347228, numObservations: 4
action 1, numVisits=31, meanQ=3.770648, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2909980 episodes
GETTING ACTION FROM:
action 2, numVisits=2910020, meanQ=6.637738, numObservations: 5
action 1, numVisits=31, meanQ=3.770648, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.00558786 0.975012 0.695946 0.895494 0.638215 0.897889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -7.11623
Run # 410
Initial state: 0 0.542513 0.892258 0.631442 0.88943 0.0885802 0.732619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2136822 episodes
GETTING ACTION FROM:
action 1, numVisits=2136736, meanQ=5.068340, numObservations: 5
action 0, numVisits=60, meanQ=4.013733, numObservations: 1
action 3, numVisits=22, meanQ=2.999100, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.542513 0.892258 0.631442 0.88943 0.0885802 0.732619 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 411
Initial state: 0 0.688842 0.812124 0.612654 0.853131 0.453768 0.286304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1346090 episodes
GETTING ACTION FROM:
action 0, numVisits=1346078, meanQ=4.694788, numObservations: 2
action 1, numVisits=8, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.688842 0.812124 0.612654 0.853131 0.453768 0.286304 w: 1
Observation: 0 0 0.888479 0 0.833196 0 0.310927 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=748373, meanQ=5.676593, numObservations: 1
action 3, numVisits=9708, meanQ=4.988355, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1640426 episodes
GETTING ACTION FROM:
action -1, numVisits=2380065, meanQ=4.916943, numObservations: 1
action 3, numVisits=18442, meanQ=4.864650, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.688842 0.812124 0.612654 0.853131 0.453768 0.286304 w: 1
Observation: 0 0.655306 0 0.641298 0 0.391123 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=2380057, meanQ=6.112076, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2456353 episodes
GETTING ACTION FROM:
action 1, numVisits=4836410, meanQ=5.601003, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.688842 0.812124 0.612654 0.853131 0.453768 0.286304 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 412
Initial state: 0 0.806275 0.855703 0.528294 0.841543 0.534286 0.823509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2222780 episodes
GETTING ACTION FROM:
action 2, numVisits=2222724, meanQ=5.000002, numObservations: 4
action 3, numVisits=33, meanQ=3.553870, numObservations: 4
action -1, numVisits=20, meanQ=3.038279, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.806275 0.855703 0.528294 0.841543 0.534286 0.823509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.119495 0.963687 0.563102 0.892163 0.606643 0.867132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2250736 episodes
GETTING ACTION FROM:
action 1, numVisits=2250672, meanQ=5.015839, numObservations: 3
action -1, numVisits=22, meanQ=3.356017, numObservations: 1
action 3, numVisits=39, meanQ=3.249236, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.119495 0.963687 0.563102 0.892163 0.606643 0.867132 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=168479, meanQ=5.570431, numObservations: 4
action 0, numVisits=23, meanQ=4.035903, numObservations: 1
action 2, numVisits=9, meanQ=3.221111, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2823684 episodes
GETTING ACTION FROM:
action 2, numVisits=2814802, meanQ=5.789617, numObservations: 4
action 1, numVisits=177370, meanQ=5.522264, numObservations: 5
action 0, numVisits=23, meanQ=4.035903, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.119495 0.963687 0.563102 0.892163 0.606643 0.867132 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 414
Initial state: 0 0.632395 0.883659 0.559474 0.818278 0.120084 0.959995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234040 episodes
GETTING ACTION FROM:
action 3, numVisits=2209610, meanQ=5.013675, numObservations: 3
action 2, numVisits=15909, meanQ=4.953127, numObservations: 5
action 1, numVisits=8460, meanQ=4.931624, numObservations: 4
action 0, numVisits=41, meanQ=3.823396, numObservations: 1
action -1, numVisits=20, meanQ=3.220400, numObservations: 1
action: 3
Next state: 0 0.632395 0.883659 0.559474 0.818278 0.120084 0.959995 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=165938, meanQ=5.547375, numObservations: 4
action -1, numVisits=29, meanQ=4.245449, numObservations: 1
action 0, numVisits=20, meanQ=3.986407, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2603250 episodes
GETTING ACTION FROM:
action 3, numVisits=2769183, meanQ=5.365844, numObservations: 4
action -1, numVisits=32, meanQ=3.953080, numObservations: 1
action 0, numVisits=22, meanQ=3.442188, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.632395 0.883659 0.559474 0.818278 0.120084 0.959995 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=62346, meanQ=6.029453, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2876840 episodes
GETTING ACTION FROM:
action 1, numVisits=2939184, meanQ=5.943921, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.632395 0.883659 0.559474 0.818278 0.120084 0.959995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 415
Initial state: 0 0.698122 0.886749 0.683724 0.130822 0.573977 0.842468 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2209030 episodes
GETTING ACTION FROM:
action 1, numVisits=2209022, meanQ=5.011971, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.698122 0.886749 0.683724 0.130822 0.573977 0.842468 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.614441 0.835392 0.663859 0.853614 0.498434 0.990252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2161734 episodes
GETTING ACTION FROM:
action 3, numVisits=2161707, meanQ=4.922561, numObservations: 4
action 0, numVisits=23, meanQ=3.311213, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.614441 0.835392 0.663859 0.853614 0.498434 0.990252 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.456163 0.685619 0.63514 0.840569 0.646244 0.893764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2212504 episodes
GETTING ACTION FROM:
action 2, numVisits=2212423, meanQ=4.959222, numObservations: 5
action -1, numVisits=67, meanQ=4.026159, numObservations: 1
action 3, numVisits=8, meanQ=1.723763, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.456163 0.685619 0.63514 0.840569 0.646244 0.893764 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.658402 0.278769 0.553458 0.803482 0.513483 0.814726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2196093 episodes
GETTING ACTION FROM:
action 3, numVisits=2196045, meanQ=5.046461, numObservations: 5
action 2, numVisits=23, meanQ=3.438696, numObservations: 4
action 0, numVisits=18, meanQ=3.134508, numObservations: 1
action 1, numVisits=5, meanQ=1.396020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.658402 0.278769 0.553458 0.803482 0.513483 0.814726 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 419
Initial state: 0 0.847715 0.111287 0.506253 0.815396 0.593025 0.805013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2183638 episodes
GETTING ACTION FROM:
action 1, numVisits=2183578, meanQ=4.959008, numObservations: 5
action 0, numVisits=45, meanQ=3.823393, numObservations: 1
action 2, numVisits=11, meanQ=1.360927, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.847715 0.111287 0.506253 0.815396 0.593025 0.805013 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 420
Initial state: 0 0.339249 0.76989 0.648129 0.890223 0.627032 0.867858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2220032 episodes
GETTING ACTION FROM:
action 2, numVisits=2219842, meanQ=5.020934, numObservations: 4
action -1, numVisits=184, meanQ=0.309589, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.339249 0.76989 0.648129 0.890223 0.627032 0.867858 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 421
Initial state: 0 0.69208 0.875713 0.43153 0.504005 0.562154 0.822653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2201823 episodes
GETTING ACTION FROM:
action 3, numVisits=2201806, meanQ=5.042829, numObservations: 5
action 2, numVisits=12, meanQ=2.157508, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.69208 0.875713 0.43153 0.504005 0.562154 0.822653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.276771 0.695053 0.578722 0.847325 0.640377 0.839126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2262356 episodes
GETTING ACTION FROM:
action 1, numVisits=2262350, meanQ=4.934872, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.276771 0.695053 0.578722 0.847325 0.640377 0.839126 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=282841, meanQ=8.399457, numObservations: 4
action 2, numVisits=33463, meanQ=8.370032, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2884486 episodes
GETTING ACTION FROM:
action 3, numVisits=2520853, meanQ=6.124506, numObservations: 4
action 2, numVisits=679935, meanQ=6.120773, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.276771 0.695053 0.578722 0.847325 0.640377 0.839126 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 423
Initial state: 0 0.598409 0.816881 0.562347 0.897605 0.661617 0.148171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2252245 episodes
GETTING ACTION FROM:
action 1, numVisits=2252166, meanQ=4.949372, numObservations: 5
action 0, numVisits=43, meanQ=3.769302, numObservations: 1
action -1, numVisits=33, meanQ=3.596282, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.598409 0.816881 0.562347 0.897605 0.661617 0.148171 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=171286, meanQ=4.723265, numObservations: 5
action -1, numVisits=427, meanQ=4.390243, numObservations: 1
action 1, numVisits=11, meanQ=2.627282, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2854352 episodes
GETTING ACTION FROM:
action 3, numVisits=3025638, meanQ=5.850330, numObservations: 5
action -1, numVisits=427, meanQ=4.390243, numObservations: 1
action 1, numVisits=11, meanQ=2.627282, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.598409 0.816881 0.562347 0.897605 0.661617 0.148171 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 424
Initial state: 0 0.983686 0.61291 0.67398 0.890844 0.549248 0.803943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1602420 episodes
GETTING ACTION FROM:
action 0, numVisits=1602415, meanQ=5.878674, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.983686 0.61291 0.67398 0.890844 0.549248 0.803943 w: 1
Observation: 0 0 0.587973 0 0.921372 0 0.836542 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=603739, meanQ=7.588577, numObservations: 5
action 3, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2395245 episodes
GETTING ACTION FROM:
action 2, numVisits=2998982, meanQ=5.325276, numObservations: 5
action 3, numVisits=7, meanQ=0.428571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.983686 0.61291 0.67398 0.890844 0.549248 0.803943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 425
Initial state: 0 0.710679 0.12738 0.573882 0.838765 0.624214 0.893791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2231784 episodes
GETTING ACTION FROM:
action 1, numVisits=2231702, meanQ=5.153206, numObservations: 5
action 0, numVisits=55, meanQ=4.095925, numObservations: 1
action 2, numVisits=22, meanQ=3.354091, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.710679 0.12738 0.573882 0.838765 0.624214 0.893791 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 426
Initial state: 0 0.449209 0.0630562 0.668093 0.856374 0.579345 0.875484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253785 episodes
GETTING ACTION FROM:
action 1, numVisits=2253701, meanQ=4.921512, numObservations: 4
action -1, numVisits=52, meanQ=3.837004, numObservations: 1
action 3, numVisits=26, meanQ=2.988469, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.449209 0.0630562 0.668093 0.856374 0.579345 0.875484 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=317013, meanQ=8.400063, numObservations: 4
action 3, numVisits=19, meanQ=6.262116, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2872416 episodes
GETTING ACTION FROM:
action 2, numVisits=3188959, meanQ=6.339727, numObservations: 4
action 3, numVisits=487, meanQ=5.991315, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.449209 0.0630562 0.668093 0.856374 0.579345 0.875484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 427
Initial state: 0 0.69873 0.801924 0.508342 0.827633 0.00647535 0.915965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2297137 episodes
GETTING ACTION FROM:
action 1, numVisits=2297109, meanQ=5.029458, numObservations: 3
action -1, numVisits=24, meanQ=3.337688, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.69873 0.801924 0.508342 0.827633 0.00647535 0.915965 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.564675 0.81349 0.541114 0.842422 0.477875 0.128366 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2229419 episodes
GETTING ACTION FROM:
action 1, numVisits=2228723, meanQ=5.003491, numObservations: 5
action 3, numVisits=612, meanQ=4.407309, numObservations: 3
action 0, numVisits=81, meanQ=4.157012, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.564675 0.81349 0.541114 0.842422 0.477875 0.128366 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.428798 0.00502784 0.691247 0.887588 0.588245 0.881358 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2220252 episodes
GETTING ACTION FROM:
action 3, numVisits=2220191, meanQ=4.937256, numObservations: 5
action -1, numVisits=44, meanQ=3.788467, numObservations: 1
action 2, numVisits=13, meanQ=2.383854, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.428798 0.00502784 0.691247 0.887588 0.588245 0.881358 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=164859, meanQ=4.711341, numObservations: 5
action 0, numVisits=198, meanQ=4.220934, numObservations: 1
action -1, numVisits=41, meanQ=3.605320, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2876781 episodes
GETTING ACTION FROM:
action 2, numVisits=3041640, meanQ=5.932559, numObservations: 5
action 0, numVisits=198, meanQ=4.220934, numObservations: 1
action -1, numVisits=41, meanQ=3.605320, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.428798 0.00502784 0.691247 0.887588 0.588245 0.881358 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=63729, meanQ=8.347413, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2955652 episodes
GETTING ACTION FROM:
action 3, numVisits=2776794, meanQ=6.359789, numObservations: 4
action 1, numVisits=242587, meanQ=6.345243, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.428798 0.00502784 0.691247 0.887588 0.588245 0.881358 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 430
Initial state: 0 0.696731 0.892186 0.477392 0.684685 0.613975 0.872789 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2267992 episodes
GETTING ACTION FROM:
action 1, numVisits=2267881, meanQ=5.019327, numObservations: 4
action -1, numVisits=88, meanQ=4.198418, numObservations: 1
action 0, numVisits=21, meanQ=3.343204, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.696731 0.892186 0.477392 0.684685 0.613975 0.872789 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.614001 0.863837 0.581679 0.880091 0.316904 0.622478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2234684 episodes
GETTING ACTION FROM:
action 3, numVisits=2234676, meanQ=4.959625, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.614001 0.863837 0.581679 0.880091 0.316904 0.622478 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=255254, meanQ=8.538847, numObservations: 3
action 1, numVisits=36, meanQ=7.111119, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2850083 episodes
GETTING ACTION FROM:
action 2, numVisits=3104442, meanQ=6.250339, numObservations: 5
action 1, numVisits=928, meanQ=5.994422, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.614001 0.863837 0.581679 0.880091 0.316904 0.622478 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=10247, meanQ=7.540934, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2986578 episodes
GETTING ACTION FROM:
action 1, numVisits=2996817, meanQ=6.371166, numObservations: 4
action 2, numVisits=8, meanQ=2.498750, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.614001 0.863837 0.581679 0.880091 0.316904 0.622478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 432
Initial state: 0 0.111144 0.524575 0.610423 0.80879 0.675128 0.895442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2242763 episodes
GETTING ACTION FROM:
action 2, numVisits=2242747, meanQ=4.947621, numObservations: 5
action 1, numVisits=11, meanQ=0.618182, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.111144 0.524575 0.610423 0.80879 0.675128 0.895442 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 433
Initial state: 0 0.508158 0.811224 0.584793 0.853599 0.945691 0.236089 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254290 episodes
GETTING ACTION FROM:
action 3, numVisits=2254265, meanQ=5.009142, numObservations: 4
action 1, numVisits=20, meanQ=2.300010, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.508158 0.811224 0.584793 0.853599 0.945691 0.236089 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 434
Initial state: 0 0.0615892 0.331487 0.546892 0.898971 0.655637 0.857036 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2295101 episodes
GETTING ACTION FROM:
action 1, numVisits=2295095, meanQ=5.016237, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0615892 0.331487 0.546892 0.898971 0.655637 0.857036 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=374276, meanQ=8.370749, numObservations: 4
action 2, numVisits=7, meanQ=5.568571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2883701 episodes
GETTING ACTION FROM:
action 3, numVisits=3257939, meanQ=6.129579, numObservations: 4
action 2, numVisits=43, meanQ=4.813956, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.0615892 0.331487 0.546892 0.898971 0.655637 0.857036 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=87618, meanQ=7.424017, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2918572 episodes
GETTING ACTION FROM:
action 3, numVisits=3006188, meanQ=5.779429, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0615892 0.331487 0.546892 0.898971 0.655637 0.857036 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 435
Initial state: 0 0.631467 0.884863 0.563827 0.877074 0.102835 0.59297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2246466 episodes
GETTING ACTION FROM:
action 3, numVisits=2245695, meanQ=5.012290, numObservations: 5
action 1, numVisits=722, meanQ=4.719479, numObservations: 4
action 0, numVisits=44, meanQ=3.861423, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.631467 0.884863 0.563827 0.877074 0.102835 0.59297 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 436
Initial state: 0 0.588645 0.885537 0.447659 0.851036 0.607722 0.869518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238199 episodes
GETTING ACTION FROM:
action 3, numVisits=2238133, meanQ=4.997663, numObservations: 5
action -1, numVisits=35, meanQ=3.635165, numObservations: 1
action 0, numVisits=29, meanQ=3.540118, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.588645 0.885537 0.447659 0.851036 0.607722 0.869518 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.374477 0.388362 0.522834 0.823928 0.604046 0.809901 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268914 episodes
GETTING ACTION FROM:
action 3, numVisits=2268785, meanQ=5.064596, numObservations: 4
action 0, numVisits=104, meanQ=4.313263, numObservations: 1
action -1, numVisits=21, meanQ=3.393767, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.374477 0.388362 0.522834 0.823928 0.604046 0.809901 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 438
Initial state: 0 0.825678 0.224559 0.627537 0.863227 0.655284 0.885721 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253947 episodes
GETTING ACTION FROM:
action 3, numVisits=2242455, meanQ=5.003627, numObservations: 4
action -1, numVisits=11441, meanQ=3.048175, numObservations: 1
action 0, numVisits=45, meanQ=2.193390, numObservations: 1
action 2, numVisits=4, meanQ=-1.002450, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 1 0.825678 0.224559 0.627537 0.863227 0.655284 0.885721 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 439
Initial state: 0 0.590517 0.875253 0.663072 0.81186 0.0782762 0.319355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241660 episodes
GETTING ACTION FROM:
action 3, numVisits=2241644, meanQ=5.007518, numObservations: 5
action 2, numVisits=11, meanQ=2.081818, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.590517 0.875253 0.663072 0.81186 0.0782762 0.319355 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=312844, meanQ=8.405817, numObservations: 4
action 2, numVisits=28, meanQ=6.857146, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2913945 episodes
GETTING ACTION FROM:
action 1, numVisits=3226733, meanQ=6.402244, numObservations: 4
action 2, numVisits=82, meanQ=5.534637, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.590517 0.875253 0.663072 0.81186 0.0782762 0.319355 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 440
Initial state: 0 0.595623 0.836301 0.68114 0.531939 0.675746 0.873794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2254072 episodes
GETTING ACTION FROM:
action 2, numVisits=2251789, meanQ=5.016623, numObservations: 4
action 0, numVisits=2279, meanQ=2.816420, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.595623 0.836301 0.68114 0.531939 0.675746 0.873794 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=111447, meanQ=7.889972, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2874112 episodes
GETTING ACTION FROM:
action 1, numVisits=2985557, meanQ=5.927285, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.595623 0.836301 0.68114 0.531939 0.675746 0.873794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 441
Initial state: 0 0.0875476 0.719247 0.648193 0.861913 0.506237 0.830618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1606071 episodes
GETTING ACTION FROM:
action 0, numVisits=1606061, meanQ=4.159581, numObservations: 2
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0875476 0.719247 0.648193 0.861913 0.506237 0.830618 w: 1
Observation: 0 0 0.760151 0 0.950559 0 0.861605 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1341823, meanQ=6.587685, numObservations: 4
action 2, numVisits=2467, meanQ=4.999257, numObservations: 4
action -1, numVisits=26, meanQ=3.663091, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2530481 episodes
GETTING ACTION FROM:
action 1, numVisits=3872304, meanQ=5.854675, numObservations: 4
action 2, numVisits=2467, meanQ=4.999257, numObservations: 4
action -1, numVisits=26, meanQ=3.663091, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.0875476 0.719247 0.648193 0.861913 0.506237 0.830618 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 442
Initial state: 0 0.566527 0.806339 0.549345 0.860252 0.620255 0.143254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264982 episodes
GETTING ACTION FROM:
action 1, numVisits=2264975, meanQ=4.960894, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.566527 0.806339 0.549345 0.860252 0.620255 0.143254 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.619945 0.495703 0.601195 0.824288 0.63254 0.875325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2228327 episodes
GETTING ACTION FROM:
action 1, numVisits=2228299, meanQ=4.994469, numObservations: 5
action 2, numVisits=23, meanQ=3.087409, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.619945 0.495703 0.601195 0.824288 0.63254 0.875325 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=242398, meanQ=8.398016, numObservations: 3
action 2, numVisits=69871, meanQ=8.384816, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2915363 episodes
GETTING ACTION FROM:
action 3, numVisits=2700052, meanQ=6.200417, numObservations: 3
action 2, numVisits=527577, meanQ=6.194441, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.619945 0.495703 0.601195 0.824288 0.63254 0.875325 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 444
Initial state: 0 0.610053 0.891019 0.872545 0.692109 0.622671 0.890738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268201 episodes
GETTING ACTION FROM:
action 3, numVisits=2268178, meanQ=5.058532, numObservations: 4
action -1, numVisits=19, meanQ=3.282350, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.610053 0.891019 0.872545 0.692109 0.622671 0.890738 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.650017 0.851686 0.65855 0.830827 0.880933 0.168446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239708 episodes
GETTING ACTION FROM:
action 3, numVisits=2239676, meanQ=5.025362, numObservations: 5
action 0, numVisits=25, meanQ=3.477249, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.650017 0.851686 0.65855 0.830827 0.880933 0.168446 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 446
Initial state: 0 0.656426 0.886144 0.617916 0.853672 0.937732 0.132197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2259618 episodes
GETTING ACTION FROM:
action 1, numVisits=2259609, meanQ=4.949014, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.656426 0.886144 0.617916 0.853672 0.937732 0.132197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 447
Initial state: 0 0.670252 0.824807 0.557289 0.817253 0.247818 0.229427 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2253426 episodes
GETTING ACTION FROM:
action 3, numVisits=2253248, meanQ=4.935837, numObservations: 4
action 0, numVisits=174, meanQ=4.311789, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.670252 0.824807 0.557289 0.817253 0.247818 0.229427 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=370187, meanQ=8.362356, numObservations: 3
action 2, numVisits=20, meanQ=6.699505, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 2958138 episodes
GETTING ACTION FROM:
action 1, numVisits=3325256, meanQ=6.194312, numObservations: 3
action 2, numVisits=3086, meanQ=6.057468, numObservations: 5
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.670252 0.824807 0.557289 0.817253 0.247818 0.229427 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 448
Initial state: 0 0.501448 0.838931 0.555266 0.770176 0.560618 0.815933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241461 episodes
GETTING ACTION FROM:
action 3, numVisits=2241435, meanQ=4.944462, numObservations: 4
action 2, numVisits=21, meanQ=3.096681, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.501448 0.838931 0.555266 0.770176 0.560618 0.815933 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.0936066 0.406799 0.636798 0.860843 0.613685 0.805127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247364 episodes
GETTING ACTION FROM:
action 3, numVisits=2247309, meanQ=5.220760, numObservations: 5
action -1, numVisits=36, meanQ=3.927573, numObservations: 1
action 1, numVisits=13, meanQ=2.831538, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0936066 0.406799 0.636798 0.860843 0.613685 0.805127 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 450
Initial state: 0 0.599175 0.856891 0.959509 0.077638 0.552294 0.839493 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2249417 episodes
GETTING ACTION FROM:
action 2, numVisits=2249408, meanQ=5.136397, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.599175 0.856891 0.959509 0.077638 0.552294 0.839493 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 451
Initial state: 0 0.684545 0.873407 0.562981 0.891904 0.959415 0.437384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1557468 episodes
GETTING ACTION FROM:
action 0, numVisits=1557052, meanQ=2.943971, numObservations: 1
action -1, numVisits=403, meanQ=2.573138, numObservations: 1
action 2, numVisits=11, meanQ=-0.271800, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.684545 0.873407 0.562981 0.891904 0.959415 0.437384 w: 1
Observation: 0 0 0.929856 0 0.824795 0 0.449792 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1556973, meanQ=5.009087, numObservations: 4
action 0, numVisits=74, meanQ=1.813218, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2469356 episodes
GETTING ACTION FROM:
action 2, numVisits=4026329, meanQ=4.815227, numObservations: 4
action 0, numVisits=74, meanQ=1.813218, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.684545 0.873407 0.562981 0.891904 0.959415 0.437384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 452
Initial state: 0 0.725077 0.361456 0.647335 0.871858 0.532472 0.892327 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1561357 episodes
GETTING ACTION FROM:
action 0, numVisits=1561344, meanQ=2.923961, numObservations: 1
action 3, numVisits=8, meanQ=-1.001225, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.725077 0.361456 0.647335 0.871858 0.532472 0.892327 w: 1
Observation: 0 0 0.412323 0 0.97001 0 0.876821 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=1561286, meanQ=4.990484, numObservations: 4
action 0, numVisits=50, meanQ=3.909040, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2486075 episodes
GETTING ACTION FROM:
action 2, numVisits=4047361, meanQ=5.029838, numObservations: 4
action 0, numVisits=50, meanQ=3.909040, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.725077 0.361456 0.647335 0.871858 0.532472 0.892327 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 453
Initial state: 0 0.902767 0.626901 0.651282 0.809741 0.676299 0.81401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264482 episodes
GETTING ACTION FROM:
action 1, numVisits=2264237, meanQ=5.041047, numObservations: 4
action 0, numVisits=198, meanQ=4.501518, numObservations: 1
action -1, numVisits=45, meanQ=3.851819, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.902767 0.626901 0.651282 0.809741 0.676299 0.81401 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 454
Initial state: 0 0.592093 0.639227 0.665722 0.816412 0.517123 0.870767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1559048 episodes
GETTING ACTION FROM:
action 0, numVisits=1559034, meanQ=3.101923, numObservations: 1
action 2, numVisits=8, meanQ=-1.023750, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.592093 0.639227 0.665722 0.816412 0.517123 0.870767 w: 1
Observation: 0 0 0.688594 0 0.729816 0 0.822657 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1558978, meanQ=5.153695, numObservations: 4
action 0, numVisits=48, meanQ=4.035481, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2511879 episodes
GETTING ACTION FROM:
action 3, numVisits=4070856, meanQ=5.124427, numObservations: 4
action 0, numVisits=49, meanQ=4.007019, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.592093 0.639227 0.665722 0.816412 0.517123 0.870767 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 455
Initial state: 0 0.672604 0.855675 0.511313 0.898586 0.960539 0.356853 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2245252 episodes
GETTING ACTION FROM:
action 2, numVisits=2245241, meanQ=4.933936, numObservations: 5
action 1, numVisits=6, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.672604 0.855675 0.511313 0.898586 0.960539 0.356853 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.961208 0.233608 0.520856 0.880534 0.669821 0.866515 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2179585 episodes
GETTING ACTION FROM:
action 2, numVisits=2179557, meanQ=4.897334, numObservations: 5
action 3, numVisits=23, meanQ=3.066087, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.961208 0.233608 0.520856 0.880534 0.669821 0.866515 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 457
Initial state: 0 0.686387 0.89285 0.548615 0.897023 0.87091 0.98418 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239755 episodes
GETTING ACTION FROM:
action 1, numVisits=2239749, meanQ=4.942746, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.686387 0.89285 0.548615 0.897023 0.87091 0.98418 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.31857 0.537387 0.577935 0.82062 0.671739 0.880448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282064 episodes
GETTING ACTION FROM:
action 2, numVisits=2281886, meanQ=5.053886, numObservations: 4
action 3, numVisits=102, meanQ=4.247382, numObservations: 3
action 1, numVisits=34, meanQ=3.630303, numObservations: 3
action -1, numVisits=24, meanQ=3.372710, numObservations: 1
action 0, numVisits=18, meanQ=3.212883, numObservations: 1
action: 2
Next state: 1 0.31857 0.537387 0.577935 0.82062 0.671739 0.880448 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 459
Initial state: 0 0.57761 0.811756 0.692581 0.855049 0.665209 0.346742 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1567134 episodes
GETTING ACTION FROM:
action -1, numVisits=1566204, meanQ=2.962234, numObservations: 1
action 0, numVisits=897, meanQ=2.715797, numObservations: 1
action 3, numVisits=21, meanQ=0.994762, numObservations: 4
action 2, numVisits=9, meanQ=0.111122, numObservations: 3
action 1, numVisits=3, meanQ=-4.333333, numObservations: 1
action: -1
Next state: 0 0.57761 0.811756 0.692581 0.855049 0.665209 0.346742 w: 1
Observation: 0 0.538971 0 0.61815 0 0.597223 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1566147, meanQ=5.011717, numObservations: 5
action -1, numVisits=22, meanQ=3.372977, numObservations: 1
action 3, numVisits=28, meanQ=3.272143, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 2482639 episodes
GETTING ACTION FROM:
action 1, numVisits=4048785, meanQ=4.986449, numObservations: 5
action -1, numVisits=23, meanQ=3.354521, numObservations: 1
action 3, numVisits=28, meanQ=3.272143, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.57761 0.811756 0.692581 0.855049 0.665209 0.346742 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 460
Initial state: 0 0.697729 0.833862 0.634493 0.894144 0.221957 0.79267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2241585 episodes
GETTING ACTION FROM:
action 3, numVisits=2241548, meanQ=4.927215, numObservations: 4
action 2, numVisits=32, meanQ=3.369066, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.697729 0.833862 0.634493 0.894144 0.221957 0.79267 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=313839, meanQ=8.394817, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2895033 episodes
GETTING ACTION FROM:
action 2, numVisits=3208870, meanQ=6.231820, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.697729 0.833862 0.634493 0.894144 0.221957 0.79267 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 461
Initial state: 0 0.432447 0.145364 0.576963 0.852366 0.656542 0.825268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260762 episodes
GETTING ACTION FROM:
action 1, numVisits=2260114, meanQ=5.159229, numObservations: 4
action 2, numVisits=617, meanQ=4.827888, numObservations: 5
action 0, numVisits=27, meanQ=3.660625, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.432447 0.145364 0.576963 0.852366 0.656542 0.825268 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=258761, meanQ=8.537661, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2930292 episodes
GETTING ACTION FROM:
action 2, numVisits=3189048, meanQ=5.950800, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.432447 0.145364 0.576963 0.852366 0.656542 0.825268 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 462
Initial state: 0 0.507398 0.860812 0.569182 0.88013 0.328401 0.133774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2166384 episodes
GETTING ACTION FROM:
action 3, numVisits=2166247, meanQ=4.982914, numObservations: 5
action 0, numVisits=84, meanQ=4.143197, numObservations: 1
action -1, numVisits=46, meanQ=3.838728, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.507398 0.860812 0.569182 0.88013 0.328401 0.133774 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 463
Initial state: 0 0.980788 0.655599 0.591871 0.85122 0.506782 0.891605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2231171 episodes
GETTING ACTION FROM:
action 3, numVisits=2213098, meanQ=4.958655, numObservations: 5
action 0, numVisits=18026, meanQ=2.878884, numObservations: 1
action -1, numVisits=29, meanQ=1.666522, numObservations: 1
action 2, numVisits=16, meanQ=1.243150, numObservations: 2
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action: 3
Next state: 1 0.980788 0.655599 0.591871 0.85122 0.506782 0.891605 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 464
Initial state: 0 0.656347 0.875597 0.699165 0.839743 0.10642 0.644688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2239753 episodes
GETTING ACTION FROM:
action 3, numVisits=2239554, meanQ=5.019033, numObservations: 5
action -1, numVisits=121, meanQ=4.325040, numObservations: 1
action 2, numVisits=41, meanQ=3.509512, numObservations: 3
action 0, numVisits=26, meanQ=3.405742, numObservations: 1
action 1, numVisits=11, meanQ=2.453636, numObservations: 2
action: 3
Next state: 0 0.656347 0.875597 0.699165 0.839743 0.10642 0.644688 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=138096, meanQ=8.544559, numObservations: 3
action 1, numVisits=117708, meanQ=8.542146, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2908992 episodes
GETTING ACTION FROM:
action 2, numVisits=2534576, meanQ=6.259203, numObservations: 3
action 1, numVisits=630218, meanQ=6.254161, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.656347 0.875597 0.699165 0.839743 0.10642 0.644688 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 465
Initial state: 0 0.169747 0.992919 0.507575 0.837585 0.580689 0.832876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2263785 episodes
GETTING ACTION FROM:
action 1, numVisits=2263724, meanQ=4.946473, numObservations: 4
action -1, numVisits=57, meanQ=3.905147, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.169747 0.992919 0.507575 0.837585 0.580689 0.832876 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.920885 0.641619 0.506814 0.880071 0.565478 0.883531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238299 episodes
GETTING ACTION FROM:
action 3, numVisits=2238236, meanQ=4.965981, numObservations: 5
action 0, numVisits=28, meanQ=3.476449, numObservations: 1
action -1, numVisits=26, meanQ=3.416660, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 1 0.920885 0.641619 0.506814 0.880071 0.565478 0.883531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.699403 0.861521 0.547662 0.869554 0.310522 0.29022 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2212217 episodes
GETTING ACTION FROM:
action 2, numVisits=2212158, meanQ=4.874967, numObservations: 3
action 0, numVisits=46, meanQ=3.722259, numObservations: 1
action 1, numVisits=10, meanQ=0.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.699403 0.861521 0.547662 0.869554 0.310522 0.29022 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.643171 0.817166 0.538352 0.520295 0.553656 0.829267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265770 episodes
GETTING ACTION FROM:
action 1, numVisits=2265730, meanQ=4.951797, numObservations: 4
action -1, numVisits=30, meanQ=3.532450, numObservations: 1
action 2, numVisits=7, meanQ=1.285743, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.643171 0.817166 0.538352 0.520295 0.553656 0.829267 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.60139 0.872854 0.377643 0.118609 0.611181 0.83986 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268834 episodes
GETTING ACTION FROM:
action 1, numVisits=2267325, meanQ=4.948141, numObservations: 3
action -1, numVisits=1429, meanQ=2.683135, numObservations: 1
action 0, numVisits=78, meanQ=2.197941, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.60139 0.872854 0.377643 0.118609 0.611181 0.83986 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 470
Initial state: 0 0.506117 0.849237 0.558549 0.817555 0.9898 0.986015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271452 episodes
GETTING ACTION FROM:
action 3, numVisits=2271383, meanQ=5.009396, numObservations: 4
action 0, numVisits=32, meanQ=3.654747, numObservations: 1
action -1, numVisits=28, meanQ=3.534262, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 2 0.506117 0.849237 0.558549 0.817555 0.9898 0.986015 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 471
Initial state: 0 0.777578 0.593063 0.629344 0.855903 0.521194 0.831899 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2238115 episodes
GETTING ACTION FROM:
action 2, numVisits=2238106, meanQ=4.966697, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=3, meanQ=-2.966667, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.777578 0.593063 0.629344 0.855903 0.521194 0.831899 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.604683 0.815565 0.278899 0.800344 0.687409 0.806563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2280306 episodes
GETTING ACTION FROM:
action 2, numVisits=2280300, meanQ=4.974882, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.604683 0.815565 0.278899 0.800344 0.687409 0.806563 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=373852, meanQ=8.341625, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2940008 episodes
GETTING ACTION FROM:
action 1, numVisits=3313834, meanQ=6.352840, numObservations: 3
action 3, numVisits=26, meanQ=4.691923, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.604683 0.815565 0.278899 0.800344 0.687409 0.806563 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 473
Initial state: 0 0.655152 0.830941 0.695412 0.83493 0.173769 0.977518 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1551029 episodes
GETTING ACTION FROM:
action 0, numVisits=1551012, meanQ=3.103875, numObservations: 1
action 3, numVisits=10, meanQ=0.399010, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.655152 0.830941 0.695412 0.83493 0.173769 0.977518 w: 1
Observation: 0 0 0.926468 0 0.818685 0 1 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1550998, meanQ=5.152384, numObservations: 5
action 2, numVisits=8, meanQ=1.500013, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2495774 episodes
GETTING ACTION FROM:
action 1, numVisits=4046772, meanQ=5.193528, numObservations: 5
action 2, numVisits=8, meanQ=1.500013, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.655152 0.830941 0.695412 0.83493 0.173769 0.977518 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 474
Initial state: 0 0.597138 0.843154 0.306506 0.336153 0.604862 0.876622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2268448 episodes
GETTING ACTION FROM:
action 3, numVisits=2268420, meanQ=5.010499, numObservations: 4
action 0, numVisits=21, meanQ=3.330249, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.597138 0.843154 0.306506 0.336153 0.604862 0.876622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 475
Initial state: 0 0.636423 0.803893 0.692692 0.838684 0.995947 0.924781 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2264253 episodes
GETTING ACTION FROM:
action 3, numVisits=2264217, meanQ=5.022876, numObservations: 4
action -1, numVisits=26, meanQ=3.420078, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.636423 0.803893 0.692692 0.838684 0.995947 0.924781 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.620551 0.880688 0.654325 0.823134 0.988043 0.0024629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2284409 episodes
GETTING ACTION FROM:
action 2, numVisits=2284388, meanQ=4.993117, numObservations: 4
action -1, numVisits=14, meanQ=2.929047, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.620551 0.880688 0.654325 0.823134 0.988043 0.0024629 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 477
Initial state: 0 0.22366 0.178065 0.684046 0.879848 0.651073 0.801513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2279259 episodes
GETTING ACTION FROM:
action 3, numVisits=2279140, meanQ=4.956569, numObservations: 3
action 0, numVisits=83, meanQ=4.117158, numObservations: 1
action 2, numVisits=31, meanQ=2.920977, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.22366 0.178065 0.684046 0.879848 0.651073 0.801513 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.568183 0.81378 0.609303 0.807865 0.339302 0.684729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2192682 episodes
GETTING ACTION FROM:
action 3, numVisits=2192643, meanQ=4.934762, numObservations: 5
action -1, numVisits=35, meanQ=3.644193, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.568183 0.81378 0.609303 0.807865 0.339302 0.684729 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=250488, meanQ=8.541922, numObservations: 3
action 1, numVisits=5, meanQ=3.798020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2857634 episodes
GETTING ACTION FROM:
action 2, numVisits=3108060, meanQ=6.155616, numObservations: 5
action 1, numVisits=65, meanQ=5.118772, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.568183 0.81378 0.609303 0.807865 0.339302 0.684729 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 479
Initial state: 0 0.569395 0.819867 0.690192 0.411582 0.507001 0.848101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2211340 episodes
GETTING ACTION FROM:
action 3, numVisits=2201300, meanQ=4.913298, numObservations: 4
action -1, numVisits=10017, meanQ=3.000321, numObservations: 1
action 1, numVisits=19, meanQ=0.989474, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 3
Next state: 1 0.569395 0.819867 0.690192 0.411582 0.507001 0.848101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.132915 0.384835 0.687285 0.890556 0.58359 0.888941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2282199 episodes
GETTING ACTION FROM:
action 1, numVisits=2282111, meanQ=4.955690, numObservations: 3
action 2, numVisits=56, meanQ=3.625453, numObservations: 4
action -1, numVisits=25, meanQ=3.399624, numObservations: 1
action 3, numVisits=5, meanQ=0.196000, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.132915 0.384835 0.687285 0.890556 0.58359 0.888941 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=373692, meanQ=8.334182, numObservations: 5
action 2, numVisits=16, meanQ=6.375637, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2838764 episodes
GETTING ACTION FROM:
action 3, numVisits=3210410, meanQ=6.145840, numObservations: 5
action 2, numVisits=2060, meanQ=5.978630, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.132915 0.384835 0.687285 0.890556 0.58359 0.888941 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 481
Initial state: 0 0.590162 0.815348 0.528305 0.896358 0.497205 0.511648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2260744 episodes
GETTING ACTION FROM:
action 1, numVisits=2252946, meanQ=5.163888, numObservations: 4
action 0, numVisits=7605, meanQ=2.908574, numObservations: 1
action -1, numVisits=191, meanQ=1.855482, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.590162 0.815348 0.528305 0.896358 0.497205 0.511648 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.893356 0.357506 0.57866 0.842171 0.575003 0.821876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1556632 episodes
GETTING ACTION FROM:
action -1, numVisits=977238, meanQ=2.981527, numObservations: 1
action 0, numVisits=579385, meanQ=2.979245, numObservations: 1
action 3, numVisits=6, meanQ=-1.000000, numObservations: 2
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.893356 0.357506 0.57866 0.842171 0.575003 0.821876 w: 1
Observation: 0 0.883572 0 0.607327 0 0.580098 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=977071, meanQ=5.022570, numObservations: 4
action 0, numVisits=135, meanQ=4.388419, numObservations: 1
action -1, numVisits=21, meanQ=3.395135, numObservations: 1
action 3, numVisits=9, meanQ=2.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 2511658 episodes
GETTING ACTION FROM:
action 2, numVisits=3488728, meanQ=5.077298, numObservations: 4
action 0, numVisits=135, meanQ=4.388419, numObservations: 1
action -1, numVisits=22, meanQ=3.387841, numObservations: 1
action 3, numVisits=9, meanQ=2.333333, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.893356 0.357506 0.57866 0.842171 0.575003 0.821876 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 483
Initial state: 0 0.903534 0.247537 0.518795 0.884152 0.523275 0.82293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2189013 episodes
GETTING ACTION FROM:
action 3, numVisits=2188681, meanQ=4.932092, numObservations: 5
action 2, numVisits=293, meanQ=4.484421, numObservations: 4
action -1, numVisits=36, meanQ=3.627676, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.903534 0.247537 0.518795 0.884152 0.523275 0.82293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 484
Initial state: 0 0.590784 0.840782 0.448501 0.334948 0.619951 0.849641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2265989 episodes
GETTING ACTION FROM:
action 2, numVisits=2265583, meanQ=5.015432, numObservations: 4
action 3, numVisits=371, meanQ=4.611361, numObservations: 3
action 0, numVisits=32, meanQ=3.640060, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.590784 0.840782 0.448501 0.334948 0.619951 0.849641 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=316777, meanQ=8.407826, numObservations: 4
action 1, numVisits=8, meanQ=4.998750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2888436 episodes
GETTING ACTION FROM:
action 3, numVisits=3205209, meanQ=6.309371, numObservations: 4
action 1, numVisits=10, meanQ=3.799000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.590784 0.840782 0.448501 0.334948 0.619951 0.849641 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 485
Initial state: 0 0.602502 0.835316 0.819461 0.72176 0.615305 0.877645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2284635 episodes
GETTING ACTION FROM:
action 2, numVisits=2284145, meanQ=5.013255, numObservations: 3
action 1, numVisits=382, meanQ=4.609106, numObservations: 3
action 0, numVisits=102, meanQ=4.258522, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.602502 0.835316 0.819461 0.72176 0.615305 0.877645 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 486
Initial state: 0 0.64035 0.868658 0.196585 0.173361 0.641403 0.831482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2216847 episodes
GETTING ACTION FROM:
action 2, numVisits=2115115, meanQ=4.944543, numObservations: 4
action 0, numVisits=101719, meanQ=2.869337, numObservations: 1
action 3, numVisits=9, meanQ=0.552222, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 2
Next state: 0 0.64035 0.868658 0.196585 0.173361 0.641403 0.831482 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=345389, meanQ=8.362881, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2900486 episodes
GETTING ACTION FROM:
action 1, numVisits=3241303, meanQ=6.001747, numObservations: 4
action 3, numVisits=4571, meanQ=5.889371, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.64035 0.868658 0.196585 0.173361 0.641403 0.831482 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=88263, meanQ=7.474164, numObservations: 4
action 1, numVisits=8, meanQ=3.998775, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2969712 episodes
GETTING ACTION FROM:
action 3, numVisits=3057971, meanQ=6.284073, numObservations: 4
action 1, numVisits=10, meanQ=2.999020, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.64035 0.868658 0.196585 0.173361 0.641403 0.831482 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 487
Initial state: 0 0.620604 0.894907 0.609488 0.893409 0.431303 0.743591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2279245 episodes
GETTING ACTION FROM:
action 1, numVisits=2279229, meanQ=5.013071, numObservations: 4
action 2, numVisits=11, meanQ=2.452745, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.620604 0.894907 0.609488 0.893409 0.431303 0.743591 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 488
Initial state: 0 0.848437 0.712704 0.543297 0.808726 0.664144 0.898277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2247128 episodes
GETTING ACTION FROM:
action 1, numVisits=2247004, meanQ=4.932933, numObservations: 4
action -1, numVisits=90, meanQ=4.120432, numObservations: 1
action 0, numVisits=32, meanQ=3.547504, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.848437 0.712704 0.543297 0.808726 0.664144 0.898277 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 489
Initial state: 0 0.514088 0.858688 0.589509 0.973013 0.643993 0.851079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2270469 episodes
GETTING ACTION FROM:
action 1, numVisits=2270408, meanQ=5.006849, numObservations: 4
action -1, numVisits=47, meanQ=3.869874, numObservations: 1
action 2, numVisits=10, meanQ=1.799000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.514088 0.858688 0.589509 0.973013 0.643993 0.851079 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 490
Initial state: 0 0.571251 0.82203 0.324465 0.326669 0.693454 0.817532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2271244 episodes
GETTING ACTION FROM:
action 1, numVisits=2271238, meanQ=5.171614, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.571251 0.82203 0.324465 0.326669 0.693454 0.817532 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=152136, meanQ=7.432744, numObservations: 3
action 2, numVisits=3, meanQ=0.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2724192 episodes
GETTING ACTION FROM:
action 2, numVisits=657320, meanQ=5.889522, numObservations: 5
action 1, numVisits=2219009, meanQ=5.402203, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.571251 0.82203 0.324465 0.326669 0.693454 0.817532 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=11274, meanQ=8.360649, numObservations: 4
action 1, numVisits=7, meanQ=5.568571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2965896 episodes
GETTING ACTION FROM:
action 3, numVisits=2976719, meanQ=6.260024, numObservations: 4
action 1, numVisits=456, meanQ=5.876031, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.571251 0.82203 0.324465 0.326669 0.693454 0.817532 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 491
Initial state: 0 0.56871 0.882356 0.92965 0.895758 0.65161 0.818253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2257256 episodes
GETTING ACTION FROM:
action 1, numVisits=2257182, meanQ=5.031122, numObservations: 4
action 0, numVisits=48, meanQ=3.923644, numObservations: 1
action -1, numVisits=24, meanQ=3.393446, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.56871 0.882356 0.92965 0.895758 0.65161 0.818253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.670304 0.869753 0.583668 0.86276 0.208229 0.696985 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2255324 episodes
GETTING ACTION FROM:
action 2, numVisits=2255289, meanQ=5.026067, numObservations: 5
action -1, numVisits=30, meanQ=3.626515, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.670304 0.869753 0.583668 0.86276 0.208229 0.696985 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.510851 0.861404 0.363587 0.684311 0.593698 0.883602 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1576212 episodes
GETTING ACTION FROM:
action -1, numVisits=1576135, meanQ=2.903250, numObservations: 1
action 0, numVisits=72, meanQ=2.012625, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.510851 0.861404 0.363587 0.684311 0.593698 0.883602 w: 1
Observation: 0 0.552569 0 0.275815 0 0.498475 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=1576034, meanQ=4.962950, numObservations: 4
action -1, numVisits=49, meanQ=3.888367, numObservations: 1
action 2, numVisits=48, meanQ=3.784173, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2492005 episodes
GETTING ACTION FROM:
action 3, numVisits=4068038, meanQ=4.970113, numObservations: 4
action -1, numVisits=50, meanQ=3.856990, numObservations: 1
action 2, numVisits=48, meanQ=3.784173, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.510851 0.861404 0.363587 0.684311 0.593698 0.883602 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 494
Initial state: 0 0.659245 0.610479 0.504565 0.881894 0.652066 0.81457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2261488 episodes
GETTING ACTION FROM:
action 1, numVisits=2261435, meanQ=4.997415, numObservations: 4
action 0, numVisits=45, meanQ=3.803857, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.659245 0.610479 0.504565 0.881894 0.652066 0.81457 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=369835, meanQ=8.349651, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 2951633 episodes
GETTING ACTION FROM:
action 2, numVisits=3321465, meanQ=5.972134, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.659245 0.610479 0.504565 0.881894 0.652066 0.81457 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 495
Initial state: 0 0.676947 0.842048 0.604118 0.872588 0.395834 0.922864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2202697 episodes
GETTING ACTION FROM:
action 3, numVisits=2202691, meanQ=4.955002, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.676947 0.842048 0.604118 0.872588 0.395834 0.922864 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.520093 0.833302 0.995914 0.336004 0.650279 0.815508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2121189 episodes
GETTING ACTION FROM:
action 1, numVisits=2121062, meanQ=4.861251, numObservations: 5
action 0, numVisits=90, meanQ=4.050853, numObservations: 1
action -1, numVisits=35, meanQ=3.542876, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.520093 0.833302 0.995914 0.336004 0.650279 0.815508 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.666819 0.877798 0.516975 0.893956 0.986052 0.98829 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2184137 episodes
GETTING ACTION FROM:
action 1, numVisits=2183968, meanQ=4.946119, numObservations: 5
action -1, numVisits=126, meanQ=4.269019, numObservations: 1
action 3, numVisits=30, meanQ=2.933677, numObservations: 4
action 2, numVisits=11, meanQ=1.727282, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.666819 0.877798 0.516975 0.893956 0.986052 0.98829 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.206179 0.391147 0.69704 0.838041 0.697478 0.80693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2203082 episodes
GETTING ACTION FROM:
action 3, numVisits=2203059, meanQ=5.136459, numObservations: 4
action 1, numVisits=18, meanQ=3.106678, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.206179 0.391147 0.69704 0.838041 0.697478 0.80693 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.520068 0.816895 0.633589 0.816156 0.46789 0.96421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2215917 episodes
GETTING ACTION FROM:
action 1, numVisits=2215875, meanQ=5.012136, numObservations: 4
action 0, numVisits=35, meanQ=3.721780, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.520068 0.816895 0.633589 0.816156 0.46789 0.96421 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.579465 0.844387 0.438869 0.734652 0.574124 0.894854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 2181378 episodes
GETTING ACTION FROM:
action 1, numVisits=2181346, meanQ=5.021767, numObservations: 5
action 0, numVisits=28, meanQ=3.555823, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.579465 0.844387 0.438869 0.734652 0.574124 0.894854 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
