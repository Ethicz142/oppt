Run # 1
Initial state: 0 0.686953 0.859198 0.722769 0.380167 0.653263 0.830508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1000052 episodes
GETTING ACTION FROM:
action 3, numVisits=1000046, meanQ=4.924719, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.686953 0.859198 0.722769 0.380167 0.653263 0.830508 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.671678 0.879546 0.272352 0.570336 0.567353 0.818218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094021 episodes
GETTING ACTION FROM:
action 2, numVisits=1094015, meanQ=4.947270, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.671678 0.879546 0.272352 0.570336 0.567353 0.818218 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=113617, meanQ=8.321681, numObservations: 4
action 3, numVisits=66681, meanQ=8.303367, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1413269 episodes
GETTING ACTION FROM:
action 1, numVisits=1303362, meanQ=6.343446, numObservations: 4
action 3, numVisits=290202, meanQ=6.335938, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.671678 0.879546 0.272352 0.570336 0.567353 0.818218 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 3
Initial state: 0 0.770452 0.1482 0.657819 0.856809 0.658237 0.868692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093006 episodes
GETTING ACTION FROM:
action 2, numVisits=1092995, meanQ=5.025075, numObservations: 5
action 1, numVisits=6, meanQ=1.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.770452 0.1482 0.657819 0.856809 0.658237 0.868692 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 4
Initial state: 0 0.665752 0.837344 0.746557 0.817754 0.624533 0.858584 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097441 episodes
GETTING ACTION FROM:
action 2, numVisits=1097419, meanQ=4.943163, numObservations: 4
action 0, numVisits=18, meanQ=3.124270, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.665752 0.837344 0.746557 0.817754 0.624533 0.858584 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 5
Initial state: 0 0.641673 0.809851 0.725807 0.902781 0.664741 0.855021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105220 episodes
GETTING ACTION FROM:
action 3, numVisits=1105123, meanQ=5.016072, numObservations: 4
action 0, numVisits=70, meanQ=4.097277, numObservations: 1
action 2, numVisits=24, meanQ=3.491258, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.641673 0.809851 0.725807 0.902781 0.664741 0.855021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.533059 0.868793 0.581634 0.877209 0.551346 0.237328 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1080467 episodes
GETTING ACTION FROM:
action 2, numVisits=1080460, meanQ=4.958366, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.533059 0.868793 0.581634 0.877209 0.551346 0.237328 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.283993 0.44747 0.611553 0.884052 0.593958 0.839891 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104584 episodes
GETTING ACTION FROM:
action 3, numVisits=1104475, meanQ=5.005860, numObservations: 4
action -1, numVisits=105, meanQ=4.278816, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.283993 0.44747 0.611553 0.884052 0.593958 0.839891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=83836, meanQ=5.549484, numObservations: 4
action -1, numVisits=48, meanQ=4.572548, numObservations: 1
action 0, numVisits=43, meanQ=4.521156, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1291503 episodes
GETTING ACTION FROM:
action 3, numVisits=1375328, meanQ=5.079300, numObservations: 5
action -1, numVisits=54, meanQ=4.030505, numObservations: 1
action 0, numVisits=48, meanQ=3.958240, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.283993 0.44747 0.611553 0.884052 0.593958 0.839891 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 8
Initial state: 0 0.385061 0.78264 0.671988 0.834415 0.514861 0.885785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096517 episodes
GETTING ACTION FROM:
action 1, numVisits=1084480, meanQ=5.031640, numObservations: 5
action -1, numVisits=9860, meanQ=3.058778, numObservations: 1
action 0, numVisits=2170, meanQ=2.988901, numObservations: 1
action 2, numVisits=6, meanQ=-0.669983, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.385061 0.78264 0.671988 0.834415 0.514861 0.885785 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=152044, meanQ=8.384062, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1439195 episodes
GETTING ACTION FROM:
action 3, numVisits=1591237, meanQ=6.387901, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.385061 0.78264 0.671988 0.834415 0.514861 0.885785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=36253, meanQ=7.197404, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1481001 episodes
GETTING ACTION FROM:
action 2, numVisits=1517252, meanQ=5.936592, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.385061 0.78264 0.671988 0.834415 0.514861 0.885785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 9
Initial state: 0 0.658268 0.878429 0.690962 0.895641 0.402844 0.215785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1089806 episodes
GETTING ACTION FROM:
action 2, numVisits=1089763, meanQ=4.924330, numObservations: 5
action 0, numVisits=39, meanQ=3.704723, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.658268 0.878429 0.690962 0.895641 0.402844 0.215785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 10
Initial state: 0 0.90547 0.407856 0.624014 0.897544 0.559395 0.875614 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106331 episodes
GETTING ACTION FROM:
action 1, numVisits=1106170, meanQ=4.940687, numObservations: 4
action -1, numVisits=121, meanQ=4.224605, numObservations: 1
action 2, numVisits=35, meanQ=3.501146, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.90547 0.407856 0.624014 0.897544 0.559395 0.875614 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 11
Initial state: 0 0.110153 0.725139 0.60322 0.828724 0.604623 0.832819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111210 episodes
GETTING ACTION FROM:
action 2, numVisits=1111178, meanQ=5.018093, numObservations: 4
action -1, numVisits=27, meanQ=3.420548, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.110153 0.725139 0.60322 0.828724 0.604623 0.832819 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 12
Initial state: 0 0.642778 0.831941 0.647617 0.821046 0.970635 0.10731 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108838 episodes
GETTING ACTION FROM:
action 1, numVisits=1108821, meanQ=4.953641, numObservations: 3
action 2, numVisits=12, meanQ=1.832508, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.642778 0.831941 0.647617 0.821046 0.970635 0.10731 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 13
Initial state: 0 0.676935 0.839628 0.635485 0.807342 0.340732 0.372092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 742687 episodes
GETTING ACTION FROM:
action -1, numVisits=742679, meanQ=2.786837, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.676935 0.839628 0.635485 0.807342 0.340732 0.372092 w: 1
Observation: 0 0.699594 0 0.667327 0 0.355282 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=736927, meanQ=4.840152, numObservations: 4
action 2, numVisits=5552, meanQ=4.592894, numObservations: 3
action -1, numVisits=166, meanQ=4.196777, numObservations: 1
action 0, numVisits=31, meanQ=3.514510, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
Sampled 1180466 episodes
GETTING ACTION FROM:
action 1, numVisits=1910405, meanQ=4.655061, numObservations: 4
action 2, numVisits=12523, meanQ=4.613633, numObservations: 3
action -1, numVisits=181, meanQ=4.091140, numObservations: 1
action 0, numVisits=33, meanQ=3.293587, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 1 0.676935 0.839628 0.635485 0.807342 0.340732 0.372092 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 14
Initial state: 0 0.559219 0.860138 0.477325 0.710261 0.665913 0.817611 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096500 episodes
GETTING ACTION FROM:
action 2, numVisits=1096425, meanQ=5.012511, numObservations: 5
action 0, numVisits=71, meanQ=4.106068, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.559219 0.860138 0.477325 0.710261 0.665913 0.817611 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.605763 0.826929 0.629735 0.800256 0.723746 0.597862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104155 episodes
GETTING ACTION FROM:
action 2, numVisits=1104094, meanQ=5.009433, numObservations: 4
action 0, numVisits=56, meanQ=3.834864, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.605763 0.826929 0.629735 0.800256 0.723746 0.597862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.198474 0.784085 0.651958 0.889113 0.607331 0.830661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104853 episodes
GETTING ACTION FROM:
action 2, numVisits=1104763, meanQ=4.926339, numObservations: 4
action -1, numVisits=84, meanQ=4.102023, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.198474 0.784085 0.651958 0.889113 0.607331 0.830661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 17
Initial state: 0 0.0428959 0.0577816 0.513199 0.833631 0.508833 0.832303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 760139 episodes
GETTING ACTION FROM:
action 0, numVisits=760122, meanQ=2.935484, numObservations: 1
action 2, numVisits=13, meanQ=0.845392, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0428959 0.0577816 0.513199 0.833631 0.508833 0.832303 w: 1
Observation: 0 0 0.0706514 0 0.74878 0 0.780275 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=760101, meanQ=4.998105, numObservations: 4
action 2, numVisits=15, meanQ=1.792667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1223303 episodes
GETTING ACTION FROM:
action 3, numVisits=1983404, meanQ=4.888447, numObservations: 4
action 2, numVisits=15, meanQ=1.792667, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0428959 0.0577816 0.513199 0.833631 0.508833 0.832303 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 18
Initial state: 0 0.302562 0.862894 0.675225 0.86482 0.537433 0.899863 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093103 episodes
GETTING ACTION FROM:
action 2, numVisits=1093027, meanQ=4.952509, numObservations: 5
action 0, numVisits=59, meanQ=3.981243, numObservations: 2
action 3, numVisits=10, meanQ=1.997010, numObservations: 3
action 1, numVisits=5, meanQ=-0.622000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.302562 0.862894 0.675225 0.86482 0.537433 0.899863 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=78720, meanQ=4.846242, numObservations: 5
action 1, numVisits=14, meanQ=2.427157, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1402103 episodes
GETTING ACTION FROM:
action 3, numVisits=1480823, meanQ=5.663725, numObservations: 5
action 1, numVisits=14, meanQ=2.427157, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.302562 0.862894 0.675225 0.86482 0.537433 0.899863 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 19
Initial state: 0 0.520762 0.840283 0.430136 0.379581 0.579328 0.854113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 763163 episodes
GETTING ACTION FROM:
action 0, numVisits=763157, meanQ=2.920645, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.520762 0.840283 0.430136 0.379581 0.579328 0.854113 w: 1
Observation: 0 0 0.812019 0 0.295064 0 0.932277 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=763136, meanQ=4.982848, numObservations: 4
action 1, numVisits=12, meanQ=1.666692, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1213817 episodes
GETTING ACTION FROM:
action 3, numVisits=1976953, meanQ=4.919617, numObservations: 4
action 1, numVisits=12, meanQ=1.666692, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.520762 0.840283 0.430136 0.379581 0.579328 0.854113 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 20
Initial state: 0 0.106787 0.00962199 0.541349 0.823386 0.529462 0.83521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112981 episodes
GETTING ACTION FROM:
action 2, numVisits=1112969, meanQ=4.946356, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 1, numVisits=4, meanQ=0.025000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.106787 0.00962199 0.541349 0.823386 0.529462 0.83521 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.565984 0.852672 0.517989 0.837029 0.742137 0.507368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098220 episodes
GETTING ACTION FROM:
action 3, numVisits=1098214, meanQ=4.990046, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.565984 0.852672 0.517989 0.837029 0.742137 0.507368 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=78324, meanQ=5.192877, numObservations: 4
action 0, numVisits=50, meanQ=4.239788, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1280730 episodes
GETTING ACTION FROM:
action 3, numVisits=1359049, meanQ=4.724121, numObservations: 5
action 0, numVisits=55, meanQ=3.672534, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.565984 0.852672 0.517989 0.837029 0.742137 0.507368 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 22
Initial state: 0 0.532722 0.836695 0.446012 0.230408 0.61727 0.893563 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103469 episodes
GETTING ACTION FROM:
action 1, numVisits=1103385, meanQ=5.038240, numObservations: 5
action 2, numVisits=57, meanQ=2.746500, numObservations: 4
action 3, numVisits=23, meanQ=2.212191, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.532722 0.836695 0.446012 0.230408 0.61727 0.893563 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 23
Initial state: 0 0.921108 0.145972 0.570836 0.879223 0.508683 0.874025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674275 episodes
GETTING ACTION FROM:
action 0, numVisits=674269, meanQ=4.887320, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.921108 0.145972 0.570836 0.879223 0.508683 0.874025 w: 1
Observation: 0 0 0.231468 0 0.95021 0 0.9428 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=307912, meanQ=5.752383, numObservations: 2
action -1, numVisits=44618, meanQ=5.511533, numObservations: 1
action 3, numVisits=1268, meanQ=4.181334, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 839215 episodes
GETTING ACTION FROM:
action 0, numVisits=1147127, meanQ=5.754545, numObservations: 3
action -1, numVisits=44618, meanQ=5.511533, numObservations: 1
action 3, numVisits=1268, meanQ=4.181334, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.921108 0.145972 0.570836 0.879223 0.508683 0.874025 w: 1
Observation: 0 0 0.112536 0 0.947608 0 0.800761 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=439533, meanQ=8.207092, numObservations: 4
action 2, numVisits=28, meanQ=6.713221, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1227369 episodes
GETTING ACTION FROM:
action 3, numVisits=1666837, meanQ=5.954798, numObservations: 4
action 2, numVisits=61, meanQ=4.857875, numObservations: 4
action 0, numVisits=20, meanQ=4.208907, numObservations: 1
action -1, numVisits=14, meanQ=3.910396, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.921108 0.145972 0.570836 0.879223 0.508683 0.874025 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=135174, meanQ=5.941125, numObservations: 5
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1408094 episodes
GETTING ACTION FROM:
action 2, numVisits=1543266, meanQ=5.682418, numObservations: 5
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.921108 0.145972 0.570836 0.879223 0.508683 0.874025 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.832291
Run # 24
Initial state: 0 0.615221 0.446307 0.661729 0.84261 0.559414 0.863888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103546 episodes
GETTING ACTION FROM:
action 2, numVisits=1103540, meanQ=4.985957, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.615221 0.446307 0.661729 0.84261 0.559414 0.863888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=76433, meanQ=5.448772, numObservations: 4
action 0, numVisits=3646, meanQ=2.624505, numObservations: 1
action 1, numVisits=15, meanQ=1.132007, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1313316 episodes
GETTING ACTION FROM:
action 2, numVisits=1389749, meanQ=5.148310, numObservations: 5
action 0, numVisits=3646, meanQ=2.624505, numObservations: 1
action 1, numVisits=15, meanQ=1.132007, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.615221 0.446307 0.661729 0.84261 0.559414 0.863888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 25
Initial state: 0 0.619428 0.348383 0.610856 0.853641 0.647883 0.836776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100196 episodes
GETTING ACTION FROM:
action 3, numVisits=1100185, meanQ=4.989302, numObservations: 4
action 2, numVisits=6, meanQ=-0.669983, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.619428 0.348383 0.610856 0.853641 0.647883 0.836776 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.558547 0.846709 0.875844 0.16331 0.668809 0.887235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 787624 episodes
GETTING ACTION FROM:
action 0, numVisits=787299, meanQ=5.985504, numObservations: 3
action 3, numVisits=321, meanQ=3.524447, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.558547 0.846709 0.875844 0.16331 0.668809 0.887235 w: 1
Observation: 0 0 0.908846 0 0.127389 0 0.930569 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=257138, meanQ=8.128733, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1222322 episodes
GETTING ACTION FROM:
action 3, numVisits=1479285, meanQ=5.723593, numObservations: 5
action 1, numVisits=123, meanQ=5.032441, numObservations: 5
action -1, numVisits=54, meanQ=4.700197, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.558547 0.846709 0.875844 0.16331 0.668809 0.887235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 27
Initial state: 0 0.600516 0.869662 0.699639 0.827684 0.301409 0.723314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098964 episodes
GETTING ACTION FROM:
action 3, numVisits=1096957, meanQ=5.145307, numObservations: 4
action -1, numVisits=1992, meanQ=3.010961, numObservations: 1
action 1, numVisits=12, meanQ=1.331683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.600516 0.869662 0.699639 0.827684 0.301409 0.723314 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=154112, meanQ=8.352013, numObservations: 5
action 2, numVisits=22, meanQ=6.362732, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1403266 episodes
GETTING ACTION FROM:
action 1, numVisits=1556835, meanQ=6.206535, numObservations: 5
action 2, numVisits=560, meanQ=5.873554, numObservations: 5
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600516 0.869662 0.699639 0.827684 0.301409 0.723314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 28
Initial state: 0 0.534465 0.83416 0.500448 0.805652 0.841155 0.702826 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 764029 episodes
GETTING ACTION FROM:
action 0, numVisits=764016, meanQ=5.533564, numObservations: 2
action 2, numVisits=9, meanQ=0.998889, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.534465 0.83416 0.500448 0.805652 0.841155 0.702826 w: 1
Observation: 0 0 0.820638 0 0.811326 0 0.731397 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=254752, meanQ=8.145284, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1210646 episodes
GETTING ACTION FROM:
action 1, numVisits=1465363, meanQ=5.321830, numObservations: 4
action -1, numVisits=35, meanQ=3.976655, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.534465 0.83416 0.500448 0.805652 0.841155 0.702826 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 29
Initial state: 0 0.532733 0.878897 0.558146 0.861352 0.0669711 0.265527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102461 episodes
GETTING ACTION FROM:
action 3, numVisits=1102455, meanQ=5.207512, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.532733 0.878897 0.558146 0.861352 0.0669711 0.265527 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=102594, meanQ=8.540393, numObservations: 3
action 2, numVisits=23422, meanQ=8.516571, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1422312 episodes
GETTING ACTION FROM:
action 2, numVisits=980827, meanQ=6.210331, numObservations: 4
action 1, numVisits=567494, meanQ=6.207884, numObservations: 4
action -1, numVisits=7, meanQ=3.232857, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.532733 0.878897 0.558146 0.861352 0.0669711 0.265527 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 30
Initial state: 0 0.965196 0.374187 0.604641 0.80238 0.544936 0.808823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 799278 episodes
GETTING ACTION FROM:
action 0, numVisits=799237, meanQ=5.768941, numObservations: 2
action 2, numVisits=21, meanQ=1.745724, numObservations: 3
action 3, numVisits=17, meanQ=1.587659, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.965196 0.374187 0.604641 0.80238 0.544936 0.808823 w: 1
Observation: 0 0 0.324361 0 0.758764 0 0.808141 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=537743, meanQ=7.659209, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1224924 episodes
GETTING ACTION FROM:
action 2, numVisits=1762665, meanQ=5.681256, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.965196 0.374187 0.604641 0.80238 0.544936 0.808823 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 31
Initial state: 0 0.887525 0.418073 0.512762 0.812421 0.594791 0.877155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106713 episodes
GETTING ACTION FROM:
action 1, numVisits=1106674, meanQ=4.943875, numObservations: 4
action -1, numVisits=34, meanQ=3.668619, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.887525 0.418073 0.512762 0.812421 0.594791 0.877155 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 32
Initial state: 0 0.593035 0.822491 0.928801 0.399422 0.672162 0.836143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100876 episodes
GETTING ACTION FROM:
action 3, numVisits=1100870, meanQ=4.949441, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.593035 0.822491 0.928801 0.399422 0.672162 0.836143 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.960244 0.238413 0.538411 0.881843 0.553505 0.861526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093722 episodes
GETTING ACTION FROM:
action 1, numVisits=1087235, meanQ=4.959305, numObservations: 5
action 0, numVisits=6483, meanQ=3.116347, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.960244 0.238413 0.538411 0.881843 0.553505 0.861526 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 34
Initial state: 0 0.708541 0.136516 0.546268 0.829986 0.632301 0.846589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094186 episodes
GETTING ACTION FROM:
action 3, numVisits=1094048, meanQ=4.932944, numObservations: 5
action 0, numVisits=68, meanQ=4.016345, numObservations: 1
action -1, numVisits=28, meanQ=3.514893, numObservations: 1
action 1, numVisits=33, meanQ=3.299697, numObservations: 3
action 2, numVisits=9, meanQ=2.333344, numObservations: 2
action: 3
Next state: 1 0.708541 0.136516 0.546268 0.829986 0.632301 0.846589 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.603176 0.862328 0.543932 0.802187 0.00916341 0.0197838 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092177 episodes
GETTING ACTION FROM:
action 1, numVisits=1092170, meanQ=4.946110, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.603176 0.862328 0.543932 0.802187 0.00916341 0.0197838 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 36
Initial state: 0 0.226342 0.276232 0.658334 0.830216 0.513517 0.816904 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 782740 episodes
GETTING ACTION FROM:
action 0, numVisits=774410, meanQ=5.971391, numObservations: 3
action 1, numVisits=8282, meanQ=4.931554, numObservations: 5
action -1, numVisits=35, meanQ=3.958702, numObservations: 1
action 3, numVisits=9, meanQ=2.333333, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action: 0
Next state: 0 0.226342 0.276232 0.658334 0.830216 0.513517 0.816904 w: 1
Observation: 0 0 0.268388 0 0.793721 0 0.887172 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=239777, meanQ=8.205123, numObservations: 5
action 3, numVisits=1619, meanQ=8.041393, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1148853 episodes
GETTING ACTION FROM:
action 2, numVisits=1383650, meanQ=5.431128, numObservations: 5
action 3, numVisits=6582, meanQ=5.344626, numObservations: 3
action 1, numVisits=17, meanQ=3.335882, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.226342 0.276232 0.658334 0.830216 0.513517 0.816904 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 37
Initial state: 0 0.595293 0.859263 0.678452 0.808504 0.771519 0.66796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116171 episodes
GETTING ACTION FROM:
action 1, numVisits=1114595, meanQ=4.976061, numObservations: 3
action 2, numVisits=1297, meanQ=4.715298, numObservations: 5
action 0, numVisits=115, meanQ=4.282368, numObservations: 1
action 3, numVisits=106, meanQ=4.216191, numObservations: 3
action -1, numVisits=58, meanQ=3.997517, numObservations: 1
action: 1
Next state: 1 0.595293 0.859263 0.678452 0.808504 0.771519 0.66796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 38
Initial state: 0 0.563234 0.896796 0.52335 0.802816 0.0406013 0.413138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097547 episodes
GETTING ACTION FROM:
action 1, numVisits=1097500, meanQ=5.022207, numObservations: 5
action 0, numVisits=24, meanQ=3.423261, numObservations: 1
action -1, numVisits=21, meanQ=3.391324, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.563234 0.896796 0.52335 0.802816 0.0406013 0.413138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=79416, meanQ=5.534089, numObservations: 4
action 0, numVisits=27, meanQ=4.172129, numObservations: 1
action 3, numVisits=10, meanQ=2.399010, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1281220 episodes
GETTING ACTION FROM:
action 1, numVisits=1360631, meanQ=4.990138, numObservations: 5
action 0, numVisits=32, meanQ=3.527311, numObservations: 1
action 3, numVisits=10, meanQ=2.399010, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.563234 0.896796 0.52335 0.802816 0.0406013 0.413138 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 39
Initial state: 0 0.624316 0.865415 0.0163321 0.0636756 0.591641 0.834356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109449 episodes
GETTING ACTION FROM:
action 1, numVisits=1109412, meanQ=5.007715, numObservations: 4
action -1, numVisits=33, meanQ=3.685261, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.624316 0.865415 0.0163321 0.0636756 0.591641 0.834356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 40
Initial state: 0 0.119348 0.562101 0.590952 0.862562 0.522665 0.858473 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111285 episodes
GETTING ACTION FROM:
action 3, numVisits=1111228, meanQ=4.950128, numObservations: 3
action 0, numVisits=41, meanQ=3.786666, numObservations: 1
action 1, numVisits=9, meanQ=1.886667, numObservations: 2
action 2, numVisits=5, meanQ=1.396020, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.119348 0.562101 0.590952 0.862562 0.522665 0.858473 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.375231 0.158975 0.569534 0.81774 0.665103 0.898796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 764195 episodes
GETTING ACTION FROM:
action -1, numVisits=763363, meanQ=3.017250, numObservations: 1
action 0, numVisits=828, meanQ=2.769693, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.375231 0.158975 0.569534 0.81774 0.665103 0.898796 w: 1
Observation: 0 0.335146 0 0.615022 0 0.668196 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=763351, meanQ=5.054602, numObservations: 4
action 1, numVisits=6, meanQ=0.331667, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1223128 episodes
GETTING ACTION FROM:
action 2, numVisits=1986479, meanQ=5.194355, numObservations: 4
action 1, numVisits=6, meanQ=0.331667, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.375231 0.158975 0.569534 0.81774 0.665103 0.898796 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 42
Initial state: 0 0.94026 0.0372604 0.595995 0.808571 0.535129 0.841308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1067127 episodes
GETTING ACTION FROM:
action 3, numVisits=1067107, meanQ=5.052549, numObservations: 5
action 2, numVisits=15, meanQ=2.320667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.94026 0.0372604 0.595995 0.808571 0.535129 0.841308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.603303 0.861447 0.645385 0.875009 0.484909 0.144629 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103441 episodes
GETTING ACTION FROM:
action 3, numVisits=1103398, meanQ=4.953700, numObservations: 4
action 1, numVisits=36, meanQ=3.613064, numObservations: 4
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.603303 0.861447 0.645385 0.875009 0.484909 0.144629 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=181607, meanQ=8.319635, numObservations: 5
action 2, numVisits=24, meanQ=6.832508, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1392913 episodes
GETTING ACTION FROM:
action 1, numVisits=1572744, meanQ=6.310023, numObservations: 5
action 2, numVisits=1797, meanQ=6.133023, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 1
Next state: 1 0.603303 0.861447 0.645385 0.875009 0.484909 0.144629 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 44
Initial state: 0 0.00126245 0.622576 0.635677 0.804453 0.643534 0.882692 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096170 episodes
GETTING ACTION FROM:
action 1, numVisits=1096164, meanQ=5.004413, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.00126245 0.622576 0.635677 0.804453 0.643534 0.882692 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=153967, meanQ=8.388701, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1399845 episodes
GETTING ACTION FROM:
action 3, numVisits=1553810, meanQ=6.312145, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.00126245 0.622576 0.635677 0.804453 0.643534 0.882692 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 45
Initial state: 0 0.648395 0.862569 0.33314 0.360408 0.614226 0.834859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1089982 episodes
GETTING ACTION FROM:
action 1, numVisits=1072472, meanQ=5.141045, numObservations: 5
action 0, numVisits=17000, meanQ=2.943876, numObservations: 1
action -1, numVisits=503, meanQ=2.712803, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 1
Next state: 1 0.648395 0.862569 0.33314 0.360408 0.614226 0.834859 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 46
Initial state: 0 0.579762 0.828966 0.623303 0.894867 0.306879 0.245203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099816 episodes
GETTING ACTION FROM:
action 1, numVisits=1099810, meanQ=5.157725, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.579762 0.828966 0.623303 0.894867 0.306879 0.245203 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.422112 0.308021 0.556925 0.807889 0.623731 0.809079 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102162 episodes
GETTING ACTION FROM:
action 2, numVisits=1102133, meanQ=4.954843, numObservations: 4
action 0, numVisits=24, meanQ=3.374392, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.422112 0.308021 0.556925 0.807889 0.623731 0.809079 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.588971 0.809178 0.158866 0.181705 0.544978 0.818618 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101167 episodes
GETTING ACTION FROM:
action 2, numVisits=1097473, meanQ=5.003440, numObservations: 5
action 1, numVisits=3574, meanQ=4.806214, numObservations: 4
action -1, numVisits=77, meanQ=4.155158, numObservations: 1
action 0, numVisits=41, meanQ=3.823313, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 0 0.588971 0.809178 0.158866 0.181705 0.544978 0.818618 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=125494, meanQ=8.537757, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1427864 episodes
GETTING ACTION FROM:
action 1, numVisits=1553352, meanQ=6.138237, numObservations: 3
action 3, numVisits=5, meanQ=2.598000, numObservations: 2
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.588971 0.809178 0.158866 0.181705 0.544978 0.818618 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 49
Initial state: 0 0.0369414 0.589054 0.652461 0.882439 0.580615 0.869144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112917 episodes
GETTING ACTION FROM:
action 1, numVisits=1112908, meanQ=5.050682, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.0369414 0.589054 0.652461 0.882439 0.580615 0.869144 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=182866, meanQ=8.327141, numObservations: 3
action 2, numVisits=48, meanQ=7.332925, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1438610 episodes
GETTING ACTION FROM:
action 3, numVisits=1619761, meanQ=6.195351, numObservations: 3
action 2, numVisits=1761, meanQ=6.020536, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0369414 0.589054 0.652461 0.882439 0.580615 0.869144 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 50
Initial state: 0 0.684003 0.891205 0.781317 0.734297 0.538119 0.811239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094252 episodes
GETTING ACTION FROM:
action 2, numVisits=1094243, meanQ=4.951020, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.684003 0.891205 0.781317 0.734297 0.538119 0.811239 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 51
Initial state: 0 0.524522 0.827854 0.558912 0.816095 0.35786 0.971703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1089306 episodes
GETTING ACTION FROM:
action 1, numVisits=1088760, meanQ=5.028587, numObservations: 5
action -1, numVisits=538, meanQ=2.334755, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.524522 0.827854 0.558912 0.816095 0.35786 0.971703 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 52
Initial state: 0 0.537866 0.887891 0.562637 0.843095 0.287022 0.104676 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117312 episodes
GETTING ACTION FROM:
action 2, numVisits=1117302, meanQ=4.948876, numObservations: 3
action 3, numVisits=5, meanQ=1.000020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.537866 0.887891 0.562637 0.843095 0.287022 0.104676 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 53
Initial state: 0 0.658688 0.809114 0.69814 0.824691 0.413248 0.457912 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095521 episodes
GETTING ACTION FROM:
action 2, numVisits=1093899, meanQ=5.149251, numObservations: 4
action -1, numVisits=1568, meanQ=2.707834, numObservations: 1
action 0, numVisits=52, meanQ=2.085911, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.658688 0.809114 0.69814 0.824691 0.413248 0.457912 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.519182 0.875334 0.269741 0.604811 0.636099 0.853031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094916 episodes
GETTING ACTION FROM:
action 3, numVisits=1094793, meanQ=4.986310, numObservations: 5
action -1, numVisits=119, meanQ=4.308422, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.519182 0.875334 0.269741 0.604811 0.636099 0.853031 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.594081 0.807578 0.52455 0.870029 0.877974 0.253274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1064868 episodes
GETTING ACTION FROM:
action 3, numVisits=1064632, meanQ=5.016116, numObservations: 5
action 2, numVisits=70, meanQ=4.068859, numObservations: 4
action 0, numVisits=59, meanQ=4.042722, numObservations: 1
action 1, numVisits=67, meanQ=4.034928, numObservations: 4
action -1, numVisits=40, meanQ=3.806810, numObservations: 1
action: 3
Next state: 2 0.594081 0.807578 0.52455 0.870029 0.877974 0.253274 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 56
Initial state: 0 0.540195 0.812441 0.661825 0.801143 0.847267 0.631888 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 691642 episodes
GETTING ACTION FROM:
action 0, numVisits=691637, meanQ=4.928134, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.540195 0.812441 0.661825 0.801143 0.847267 0.631888 w: 1
Observation: 0 0 0.756349 0 0.73504 0 0.651645 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=187395, meanQ=8.383848, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1214849 episodes
GETTING ACTION FROM:
action 2, numVisits=1402183, meanQ=5.417670, numObservations: 5
action 0, numVisits=45, meanQ=4.252112, numObservations: 1
action -1, numVisits=18, meanQ=3.576140, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.540195 0.812441 0.661825 0.801143 0.847267 0.631888 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 57
Initial state: 0 0.62178 0.890404 0.688488 0.884934 0.593858 0.756183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 764176 episodes
GETTING ACTION FROM:
action -1, numVisits=553126, meanQ=2.974778, numObservations: 1
action 0, numVisits=211043, meanQ=2.931545, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.62178 0.890404 0.688488 0.884934 0.593858 0.756183 w: 1
Observation: 0 0.595862 0 0.725042 0 0.661291 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=553119, meanQ=5.022487, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1212218 episodes
GETTING ACTION FROM:
action 2, numVisits=1765337, meanQ=5.053793, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.62178 0.890404 0.688488 0.884934 0.593858 0.756183 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 58
Initial state: 0 0.519873 0.894883 0.559207 0.820049 0.966491 0.0313481 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116333 episodes
GETTING ACTION FROM:
action 2, numVisits=1116314, meanQ=5.023665, numObservations: 4
action -1, numVisits=15, meanQ=2.869521, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.519873 0.894883 0.559207 0.820049 0.966491 0.0313481 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.0330055 0.280579 0.625102 0.830948 0.573336 0.878875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092082 episodes
GETTING ACTION FROM:
action 2, numVisits=1092073, meanQ=4.966786, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.0330055 0.280579 0.625102 0.830948 0.573336 0.878875 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26406, meanQ=7.932284, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1430254 episodes
GETTING ACTION FROM:
action 3, numVisits=1456655, meanQ=6.101455, numObservations: 3
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0330055 0.280579 0.625102 0.830948 0.573336 0.878875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 60
Initial state: 0 0.6264 0.837193 0.557745 0.817421 0.932955 0.551125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114329 episodes
GETTING ACTION FROM:
action 3, numVisits=1114212, meanQ=4.966104, numObservations: 3
action -1, numVisits=79, meanQ=4.110565, numObservations: 1
action 0, numVisits=33, meanQ=3.644388, numObservations: 1
action 2, numVisits=4, meanQ=-2.005000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.6264 0.837193 0.557745 0.817421 0.932955 0.551125 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 61
Initial state: 0 0.635616 0.867393 0.616947 0.861408 0.19678 0.317424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112896 episodes
GETTING ACTION FROM:
action 3, numVisits=1112407, meanQ=5.028165, numObservations: 3
action 1, numVisits=316, meanQ=4.601705, numObservations: 5
action 0, numVisits=139, meanQ=4.398063, numObservations: 1
action 2, numVisits=32, meanQ=3.678441, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.635616 0.867393 0.616947 0.861408 0.19678 0.317424 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=184881, meanQ=8.306771, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1404731 episodes
GETTING ACTION FROM:
action 1, numVisits=1589602, meanQ=6.063107, numObservations: 5
action 2, numVisits=8, meanQ=2.498750, numObservations: 2
action 3, numVisits=4, meanQ=0.997500, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.635616 0.867393 0.616947 0.861408 0.19678 0.317424 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 62
Initial state: 0 0.417817 0.876934 0.538337 0.843411 0.567942 0.888419 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091365 episodes
GETTING ACTION FROM:
action 3, numVisits=1063003, meanQ=4.980137, numObservations: 4
action 2, numVisits=28356, meanQ=4.884829, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.417817 0.876934 0.538337 0.843411 0.567942 0.888419 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.551415 0.896502 0.588913 0.803432 0.459455 0.587483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107313 episodes
GETTING ACTION FROM:
action 1, numVisits=1107168, meanQ=4.948569, numObservations: 4
action -1, numVisits=70, meanQ=2.518445, numObservations: 1
action 3, numVisits=68, meanQ=2.490761, numObservations: 3
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.551415 0.896502 0.588913 0.803432 0.459455 0.587483 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 64
Initial state: 0 0.122932 0.795888 0.559761 0.881647 0.672638 0.821572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100969 episodes
GETTING ACTION FROM:
action 3, numVisits=1086219, meanQ=5.003526, numObservations: 4
action 1, numVisits=14687, meanQ=4.942017, numObservations: 3
action 0, numVisits=32, meanQ=3.689374, numObservations: 1
action -1, numVisits=29, meanQ=3.538243, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 0 0.122932 0.795888 0.559761 0.881647 0.672638 0.821572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=78831, meanQ=5.662350, numObservations: 4
action 2, numVisits=82, meanQ=4.816860, numObservations: 5
action -1, numVisits=25, meanQ=4.296432, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1408496 episodes
GETTING ACTION FROM:
action 2, numVisits=1383323, meanQ=5.875874, numObservations: 5
action 3, numVisits=104085, meanQ=5.432027, numObservations: 5
action -1, numVisits=26, meanQ=4.054262, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.122932 0.795888 0.559761 0.881647 0.672638 0.821572 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 65
Initial state: 0 0.570906 0.847612 0.632493 0.863855 0.907627 0.713024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095269 episodes
GETTING ACTION FROM:
action 1, numVisits=1095172, meanQ=5.009900, numObservations: 5
action 0, numVisits=42, meanQ=3.767100, numObservations: 1
action 2, numVisits=35, meanQ=3.451720, numObservations: 5
action -1, numVisits=19, meanQ=3.277268, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.570906 0.847612 0.632493 0.863855 0.907627 0.713024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.644589 0.854816 0.476491 0.113343 0.687772 0.83172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093962 episodes
GETTING ACTION FROM:
action 1, numVisits=1093942, meanQ=5.011470, numObservations: 5
action 3, numVisits=15, meanQ=1.932673, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.644589 0.854816 0.476491 0.113343 0.687772 0.83172 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 67
Initial state: 0 0.54236 0.828814 0.69467 0.818108 0.776628 0.798298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102344 episodes
GETTING ACTION FROM:
action 2, numVisits=1102338, meanQ=4.985481, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.54236 0.828814 0.69467 0.818108 0.776628 0.798298 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.648896 0.855978 0.567728 0.327734 0.619294 0.850932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088808 episodes
GETTING ACTION FROM:
action 1, numVisits=1088801, meanQ=5.040794, numObservations: 5
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.648896 0.855978 0.567728 0.327734 0.619294 0.850932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.507897 0.838418 0.693185 0.898163 0.275783 0.294537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 966421 episodes
GETTING ACTION FROM:
action 1, numVisits=843750, meanQ=4.523738, numObservations: 4
action -1, numVisits=113485, meanQ=2.901407, numObservations: 1
action 0, numVisits=9180, meanQ=2.799846, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.507897 0.838418 0.693185 0.898163 0.275783 0.294537 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=139215, meanQ=6.231077, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1299723 episodes
GETTING ACTION FROM:
action 1, numVisits=1216991, meanQ=5.164464, numObservations: 5
action -1, numVisits=221941, meanQ=3.916219, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 1
Next state: 1 0.507897 0.838418 0.693185 0.898163 0.275783 0.294537 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 70
Initial state: 0 0.643199 0.855778 0.541211 0.450736 0.544714 0.871041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095065 episodes
GETTING ACTION FROM:
action 2, numVisits=1094989, meanQ=5.005482, numObservations: 4
action 0, numVisits=49, meanQ=3.914848, numObservations: 1
action -1, numVisits=12, meanQ=2.729587, numObservations: 1
action 1, numVisits=12, meanQ=2.675000, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 2
Next state: 2 0.643199 0.855778 0.541211 0.450736 0.544714 0.871041 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 71
Initial state: 0 0.679338 0.843029 0.542491 0.87837 0.198018 0.947097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1060520 episodes
GETTING ACTION FROM:
action 3, numVisits=1060512, meanQ=4.796481, numObservations: 4
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.679338 0.843029 0.542491 0.87837 0.198018 0.947097 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=75585, meanQ=2.632800, numObservations: 1
action 0, numVisits=1900, meanQ=2.503178, numObservations: 1
action 2, numVisits=6, meanQ=-0.348333, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1422474 episodes
GETTING ACTION FROM:
action 2, numVisits=1416398, meanQ=6.056924, numObservations: 4
action -1, numVisits=81520, meanQ=2.376821, numObservations: 1
action 0, numVisits=2047, meanQ=2.251140, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.679338 0.843029 0.542491 0.87837 0.198018 0.947097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=26512, meanQ=7.213239, numObservations: 4
action 2, numVisits=14, meanQ=5.134293, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1462707 episodes
GETTING ACTION FROM:
action 1, numVisits=1489210, meanQ=6.281886, numObservations: 4
action 2, numVisits=21, meanQ=4.518100, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.679338 0.843029 0.542491 0.87837 0.198018 0.947097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 72
Initial state: 0 0.604754 0.868107 0.58291 0.853637 0.145073 0.971446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100786 episodes
GETTING ACTION FROM:
action 1, numVisits=1100752, meanQ=4.923891, numObservations: 4
action 0, numVisits=30, meanQ=3.566050, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.604754 0.868107 0.58291 0.853637 0.145073 0.971446 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 73
Initial state: 0 0.560411 0.836349 0.583716 0.942054 0.696427 0.898918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102227 episodes
GETTING ACTION FROM:
action 1, numVisits=1095404, meanQ=4.949484, numObservations: 4
action 0, numVisits=6816, meanQ=2.860447, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.560411 0.836349 0.583716 0.942054 0.696427 0.898918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 74
Initial state: 0 0.554944 0.882187 0.528164 0.848544 0.814229 0.996432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1049051 episodes
GETTING ACTION FROM:
action 1, numVisits=1048976, meanQ=4.957880, numObservations: 5
action -1, numVisits=62, meanQ=3.930099, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 4
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.554944 0.882187 0.528164 0.848544 0.814229 0.996432 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 75
Initial state: 0 0.629497 0.899486 0.232443 0.732565 0.559174 0.844955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103007 episodes
GETTING ACTION FROM:
action 3, numVisits=1102946, meanQ=4.945122, numObservations: 4
action 0, numVisits=33, meanQ=3.582241, numObservations: 1
action 2, numVisits=25, meanQ=2.520808, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.629497 0.899486 0.232443 0.732565 0.559174 0.844955 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.763687 0.457712 0.597838 0.846962 0.565732 0.872207 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1051213 episodes
GETTING ACTION FROM:
action 2, numVisits=1049775, meanQ=4.863984, numObservations: 5
action -1, numVisits=1422, meanQ=2.941505, numObservations: 1
action 1, numVisits=7, meanQ=0.428571, numObservations: 2
action 3, numVisits=7, meanQ=0.428571, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.763687 0.457712 0.597838 0.846962 0.565732 0.872207 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 77
Initial state: 0 0.362774 0.630895 0.60393 0.819313 0.622877 0.858165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111332 episodes
GETTING ACTION FROM:
action 3, numVisits=1111243, meanQ=5.011949, numObservations: 3
action 2, numVisits=84, meanQ=4.108342, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.362774 0.630895 0.60393 0.819313 0.622877 0.858165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.583583 0.884809 0.30413 0.366267 0.699145 0.814448 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115056 episodes
GETTING ACTION FROM:
action 1, numVisits=1115050, meanQ=4.992733, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.583583 0.884809 0.30413 0.366267 0.699145 0.814448 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 79
Initial state: 0 0.523391 0.850064 0.0851262 0.508058 0.674768 0.892211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112397 episodes
GETTING ACTION FROM:
action 3, numVisits=1109925, meanQ=4.969595, numObservations: 3
action 0, numVisits=2464, meanQ=3.002090, numObservations: 1
action 2, numVisits=4, meanQ=-0.025000, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.523391 0.850064 0.0851262 0.508058 0.674768 0.892211 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 80
Initial state: 0 0.640833 0.84149 0.574696 0.243616 0.579245 0.813353 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090612 episodes
GETTING ACTION FROM:
action 2, numVisits=1090605, meanQ=4.954968, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.640833 0.84149 0.574696 0.243616 0.579245 0.813353 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 81
Initial state: 0 0.547509 0.895012 0.641972 0.888014 0.44898 0.473554 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1083584 episodes
GETTING ACTION FROM:
action 1, numVisits=1083524, meanQ=4.919848, numObservations: 4
action -1, numVisits=53, meanQ=3.900016, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.547509 0.895012 0.641972 0.888014 0.44898 0.473554 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 82
Initial state: 0 0.0608856 0.812806 0.61481 0.87449 0.546303 0.818413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104405 episodes
GETTING ACTION FROM:
action 3, numVisits=1104399, meanQ=4.964554, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0608856 0.812806 0.61481 0.87449 0.546303 0.818413 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.589099 0.808373 0.580273 0.824547 0.459674 0.199163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113552 episodes
GETTING ACTION FROM:
action 2, numVisits=1113447, meanQ=5.002539, numObservations: 4
action -1, numVisits=101, meanQ=4.261373, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.589099 0.808373 0.580273 0.824547 0.459674 0.199163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81274, meanQ=5.552196, numObservations: 3
action 1, numVisits=6, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1306021 episodes
GETTING ACTION FROM:
action 2, numVisits=1387295, meanQ=4.845749, numObservations: 4
action 1, numVisits=6, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.589099 0.808373 0.580273 0.824547 0.459674 0.199163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 84
Initial state: 0 0.110632 0.478301 0.615654 0.882623 0.632399 0.893977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104450 episodes
GETTING ACTION FROM:
action 3, numVisits=1104394, meanQ=4.976457, numObservations: 4
action -1, numVisits=40, meanQ=3.787842, numObservations: 1
action 1, numVisits=10, meanQ=1.799000, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.110632 0.478301 0.615654 0.882623 0.632399 0.893977 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 85
Initial state: 0 0.509829 0.814155 0.861515 0.898922 0.525584 0.809709 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 780636 episodes
GETTING ACTION FROM:
action 0, numVisits=780628, meanQ=4.223694, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.509829 0.814155 0.861515 0.898922 0.525584 0.809709 w: 1
Observation: 0 0 0.827577 0 0.974509 0 0.741222 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=640790, meanQ=6.529171, numObservations: 5
action 0, numVisits=185, meanQ=4.430218, numObservations: 1
action -1, numVisits=109, meanQ=4.290791, numObservations: 1
action 1, numVisits=58, meanQ=3.742590, numObservations: 4
action 3, numVisits=8, meanQ=2.250025, numObservations: 2
Sampled 1215871 episodes
GETTING ACTION FROM:
action 2, numVisits=1856661, meanQ=5.599889, numObservations: 5
action 0, numVisits=185, meanQ=4.430218, numObservations: 1
action -1, numVisits=109, meanQ=4.290791, numObservations: 1
action 1, numVisits=58, meanQ=3.742590, numObservations: 4
action 3, numVisits=8, meanQ=2.250025, numObservations: 2
action: 2
Next state: 1 0.509829 0.814155 0.861515 0.898922 0.525584 0.809709 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 86
Initial state: 0 0.656829 0.807022 0.498576 0.78946 0.605162 0.857227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110037 episodes
GETTING ACTION FROM:
action 2, numVisits=1110031, meanQ=4.955526, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.656829 0.807022 0.498576 0.78946 0.605162 0.857227 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=126562, meanQ=8.537615, numObservations: 3
action 1, numVisits=20, meanQ=7.000005, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1419321 episodes
GETTING ACTION FROM:
action 3, numVisits=1545835, meanQ=6.070350, numObservations: 4
action 1, numVisits=66, meanQ=4.999698, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.656829 0.807022 0.498576 0.78946 0.605162 0.857227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 87
Initial state: 0 0.505938 0.873725 0.568204 0.862894 0.207204 0.990332 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106797 episodes
GETTING ACTION FROM:
action 1, numVisits=1106761, meanQ=5.024711, numObservations: 4
action -1, numVisits=20, meanQ=3.286280, numObservations: 1
action 3, numVisits=13, meanQ=2.536923, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.505938 0.873725 0.568204 0.862894 0.207204 0.990332 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 88
Initial state: 0 0.591623 0.882672 0.31397 0.638304 0.511517 0.886302 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099611 episodes
GETTING ACTION FROM:
action 3, numVisits=1099539, meanQ=4.957036, numObservations: 4
action 1, numVisits=40, meanQ=3.590510, numObservations: 4
action 0, numVisits=25, meanQ=3.433915, numObservations: 1
action 2, numVisits=5, meanQ=1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.591623 0.882672 0.31397 0.638304 0.511517 0.886302 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=11134, meanQ=5.971310, numObservations: 4
action 2, numVisits=10, meanQ=3.780000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1415365 episodes
GETTING ACTION FROM:
action 2, numVisits=1411427, meanQ=5.880532, numObservations: 4
action 3, numVisits=15079, meanQ=5.691018, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.591623 0.882672 0.31397 0.638304 0.511517 0.886302 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=22102, meanQ=7.685659, numObservations: 3
action 1, numVisits=27, meanQ=6.332600, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1443820 episodes
GETTING ACTION FROM:
action 3, numVisits=1465887, meanQ=5.858645, numObservations: 4
action 1, numVisits=60, meanQ=4.799670, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.591623 0.882672 0.31397 0.638304 0.511517 0.886302 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 89
Initial state: 0 0.602624 0.812114 0.520219 0.930034 0.523051 0.814367 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 765043 episodes
GETTING ACTION FROM:
action 0, numVisits=739457, meanQ=3.094210, numObservations: 1
action -1, numVisits=25555, meanQ=3.056719, numObservations: 1
action 1, numVisits=16, meanQ=1.124381, numObservations: 3
action 3, numVisits=12, meanQ=0.665850, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 0
Next state: 0 0.602624 0.812114 0.520219 0.930034 0.523051 0.814367 w: 1
Observation: 0 0 0.901317 0 1 0 0.869593 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=739391, meanQ=5.131607, numObservations: 4
action 1, numVisits=59, meanQ=4.061358, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1229104 episodes
GETTING ACTION FROM:
action 2, numVisits=1968495, meanQ=5.055349, numObservations: 4
action 1, numVisits=59, meanQ=4.061358, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.602624 0.812114 0.520219 0.930034 0.523051 0.814367 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 90
Initial state: 0 0.628367 0.800972 0.684583 0.959966 0.554994 0.842785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1083393 episodes
GETTING ACTION FROM:
action 1, numVisits=402461, meanQ=4.982165, numObservations: 4
action 3, numVisits=680926, meanQ=4.855545, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.628367 0.800972 0.684583 0.959966 0.554994 0.842785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.584881 0.880384 0.921687 0.0948686 0.615453 0.887889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099608 episodes
GETTING ACTION FROM:
action 3, numVisits=1099541, meanQ=4.959733, numObservations: 3
action -1, numVisits=61, meanQ=3.989868, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.584881 0.880384 0.921687 0.0948686 0.615453 0.887889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.882204 0.781865 0.683939 0.867504 0.576527 0.877875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104457 episodes
GETTING ACTION FROM:
action 2, numVisits=1103156, meanQ=5.021114, numObservations: 4
action 1, numVisits=1282, meanQ=4.728079, numObservations: 3
action 0, numVisits=16, meanQ=3.148360, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.882204 0.781865 0.683939 0.867504 0.576527 0.877875 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 93
Initial state: 0 0.668747 0.821007 0.154179 0.536408 0.671619 0.887722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092048 episodes
GETTING ACTION FROM:
action 3, numVisits=1091961, meanQ=4.985983, numObservations: 5
action -1, numVisits=83, meanQ=4.161096, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.668747 0.821007 0.154179 0.536408 0.671619 0.887722 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=14824, meanQ=7.881521, numObservations: 4
action 2, numVisits=11255, meanQ=7.859236, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1418548 episodes
GETTING ACTION FROM:
action 2, numVisits=1351189, meanQ=6.301465, numObservations: 4
action 1, numVisits=93436, meanQ=6.282905, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.668747 0.821007 0.154179 0.536408 0.671619 0.887722 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=13750, meanQ=8.528818, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1460090 episodes
GETTING ACTION FROM:
action 1, numVisits=1473786, meanQ=6.351808, numObservations: 4
action 3, numVisits=54, meanQ=5.070370, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.668747 0.821007 0.154179 0.536408 0.671619 0.887722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 94
Initial state: 0 0.546523 0.823102 0.681616 0.800821 0.823895 0.953906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094527 episodes
GETTING ACTION FROM:
action 3, numVisits=1094444, meanQ=5.004737, numObservations: 5
action -1, numVisits=71, meanQ=4.119957, numObservations: 1
action 1, numVisits=9, meanQ=2.333344, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.546523 0.823102 0.681616 0.800821 0.823895 0.953906 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 95
Initial state: 0 0.588565 0.872869 0.556943 0.859886 0.0175755 0.709459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 769359 episodes
GETTING ACTION FROM:
action 0, numVisits=769342, meanQ=3.097050, numObservations: 1
action 2, numVisits=8, meanQ=0.262513, numObservations: 3
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 0
Next state: 0 0.588565 0.872869 0.556943 0.859886 0.0175755 0.709459 w: 1
Observation: 0 0 0.903121 0 0.870964 0 0.688807 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=769291, meanQ=5.151299, numObservations: 4
action -1, numVisits=34, meanQ=3.877924, numObservations: 1
action 1, numVisits=12, meanQ=2.999167, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1231639 episodes
GETTING ACTION FROM:
action 3, numVisits=2000930, meanQ=5.232767, numObservations: 4
action -1, numVisits=34, meanQ=3.877924, numObservations: 1
action 1, numVisits=12, meanQ=2.999167, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.588565 0.872869 0.556943 0.859886 0.0175755 0.709459 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=222060, meanQ=8.538593, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1419664 episodes
GETTING ACTION FROM:
action 2, numVisits=1641714, meanQ=6.486525, numObservations: 4
action 1, numVisits=10, meanQ=3.799000, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.588565 0.872869 0.556943 0.859886 0.0175755 0.709459 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 2, numVisits=5372, meanQ=8.101871, numObservations: 3
action 1, numVisits=17, meanQ=6.646482, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1459073 episodes
GETTING ACTION FROM:
action 2, numVisits=1464349, meanQ=6.184413, numObservations: 3
action 1, numVisits=111, meanQ=5.396308, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.588565 0.872869 0.556943 0.859886 0.0175755 0.709459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 1, numVisits=4533, meanQ=7.467180, numObservations: 5
action 2, numVisits=919, meanQ=7.097802, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1436250 episodes
GETTING ACTION FROM:
action 1, numVisits=1431059, meanQ=5.736921, numObservations: 5
action 2, numVisits=10641, meanQ=5.666985, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.588565 0.872869 0.556943 0.859886 0.0175755 0.709459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -5.11623
Run # 96
Initial state: 0 0.401686 0.612109 0.512075 0.806854 0.585041 0.82768 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1063520 episodes
GETTING ACTION FROM:
action 2, numVisits=1063514, meanQ=4.850730, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.401686 0.612109 0.512075 0.806854 0.585041 0.82768 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.694978 0.89631 0.608871 0.855176 0.757793 0.963889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102113 episodes
GETTING ACTION FROM:
action 3, numVisits=1102027, meanQ=5.003419, numObservations: 4
action -1, numVisits=81, meanQ=4.176042, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.694978 0.89631 0.608871 0.855176 0.757793 0.963889 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 98
Initial state: 0 0.519055 0.841812 0.55364 0.832896 0.71622 0.656306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109119 episodes
GETTING ACTION FROM:
action 2, numVisits=1109052, meanQ=4.998091, numObservations: 4
action 0, numVisits=62, meanQ=4.051445, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.519055 0.841812 0.55364 0.832896 0.71622 0.656306 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.898575 0.568003 0.59804 0.809858 0.560392 0.865834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099545 episodes
GETTING ACTION FROM:
action 3, numVisits=1099426, meanQ=5.015353, numObservations: 5
action 1, numVisits=111, meanQ=4.265432, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.898575 0.568003 0.59804 0.809858 0.560392 0.865834 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.597975 0.895303 0.581092 0.801924 0.57514 0.59249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105405 episodes
GETTING ACTION FROM:
action 1, numVisits=1105375, meanQ=5.003867, numObservations: 4
action 0, numVisits=21, meanQ=3.262248, numObservations: 1
action 2, numVisits=6, meanQ=0.330033, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.597975 0.895303 0.581092 0.801924 0.57514 0.59249 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 101
Initial state: 0 0.557047 0.894591 0.682967 0.856369 0.781958 0.94812 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099177 episodes
GETTING ACTION FROM:
action 1, numVisits=1099171, meanQ=4.960657, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.557047 0.894591 0.682967 0.856369 0.781958 0.94812 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 102
Initial state: 0 0.327926 0.252362 0.607504 0.844766 0.518103 0.853189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094746 episodes
GETTING ACTION FROM:
action 3, numVisits=1094718, meanQ=4.947504, numObservations: 5
action -1, numVisits=20, meanQ=3.272509, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.327926 0.252362 0.607504 0.844766 0.518103 0.853189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 103
Initial state: 0 0.237215 0.735772 0.558072 0.827922 0.574991 0.897444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 764419 episodes
GETTING ACTION FROM:
action -1, numVisits=764410, meanQ=2.908384, numObservations: 1
action 2, numVisits=4, meanQ=-1.497450, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.237215 0.735772 0.558072 0.827922 0.574991 0.897444 w: 1
Observation: 0 0.158804 0 0.47767 0 0.504493 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=764069, meanQ=4.957883, numObservations: 5
action 0, numVisits=237, meanQ=2.573415, numObservations: 1
action -1, numVisits=92, meanQ=2.370687, numObservations: 1
action 2, numVisits=9, meanQ=0.998889, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
Sampled 1207754 episodes
GETTING ACTION FROM:
action 3, numVisits=1971823, meanQ=5.074766, numObservations: 5
action 0, numVisits=237, meanQ=2.573415, numObservations: 1
action -1, numVisits=92, meanQ=2.370687, numObservations: 1
action 2, numVisits=9, meanQ=0.998889, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.237215 0.735772 0.558072 0.827922 0.574991 0.897444 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 104
Initial state: 0 0.589267 0.889546 0.658948 0.866502 0.241595 0.0946334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104512 episodes
GETTING ACTION FROM:
action 2, numVisits=1104506, meanQ=5.002052, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.589267 0.889546 0.658948 0.866502 0.241595 0.0946334 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.566698 0.897207 0.716632 0.335314 0.569317 0.862765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1083505 episodes
GETTING ACTION FROM:
action 3, numVisits=1083446, meanQ=4.982283, numObservations: 5
action 0, numVisits=44, meanQ=3.864052, numObservations: 1
action 1, numVisits=12, meanQ=1.992508, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.566698 0.897207 0.716632 0.335314 0.569317 0.862765 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.547066 0.798318 0.635498 0.843102 0.63256 0.830873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084444 episodes
GETTING ACTION FROM:
action 2, numVisits=1077707, meanQ=4.968110, numObservations: 5
action 0, numVisits=6719, meanQ=2.855643, numObservations: 1
action 3, numVisits=13, meanQ=0.998462, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.547066 0.798318 0.635498 0.843102 0.63256 0.830873 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.505557 0.898132 0.165147 0.420901 0.551284 0.845817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108514 episodes
GETTING ACTION FROM:
action 3, numVisits=1108382, meanQ=5.003972, numObservations: 3
action 1, numVisits=57, meanQ=3.966149, numObservations: 3
action 0, numVisits=49, meanQ=3.898478, numObservations: 1
action 2, numVisits=24, meanQ=2.990842, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.505557 0.898132 0.165147 0.420901 0.551284 0.845817 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.606041 0.811463 0.548401 0.887038 0.289879 0.520121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096336 episodes
GETTING ACTION FROM:
action 3, numVisits=1077718, meanQ=4.943019, numObservations: 4
action 0, numVisits=18613, meanQ=3.215211, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.606041 0.811463 0.548401 0.887038 0.289879 0.520121 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=151340, meanQ=8.376690, numObservations: 3
action 2, numVisits=4, meanQ=4.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1439698 episodes
GETTING ACTION FROM:
action 1, numVisits=1590155, meanQ=6.192386, numObservations: 3
action 2, numVisits=884, meanQ=5.939016, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.606041 0.811463 0.548401 0.887038 0.289879 0.520121 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 109
Initial state: 0 0.150548 0.51582 0.542157 0.855429 0.682151 0.875293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098772 episodes
GETTING ACTION FROM:
action 3, numVisits=1098764, meanQ=5.012709, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.150548 0.51582 0.542157 0.855429 0.682151 0.875293 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.22778 0.636484 0.624365 0.818374 0.675452 0.896579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115736 episodes
GETTING ACTION FROM:
action 2, numVisits=1115653, meanQ=5.029068, numObservations: 4
action -1, numVisits=68, meanQ=4.118747, numObservations: 1
action 3, numVisits=12, meanQ=2.498342, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.22778 0.636484 0.624365 0.818374 0.675452 0.896579 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 111
Initial state: 0 0.659313 0.921053 0.503237 0.802621 0.547488 0.826041 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094704 episodes
GETTING ACTION FROM:
action 3, numVisits=1094634, meanQ=4.951667, numObservations: 5
action -1, numVisits=56, meanQ=3.946220, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 2, numVisits=6, meanQ=1.663333, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.659313 0.921053 0.503237 0.802621 0.547488 0.826041 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 112
Initial state: 0 0.630327 0.809431 0.127339 0.595688 0.504341 0.802801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112927 episodes
GETTING ACTION FROM:
action 1, numVisits=1112899, meanQ=5.015168, numObservations: 4
action 2, numVisits=22, meanQ=3.350909, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.630327 0.809431 0.127339 0.595688 0.504341 0.802801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 113
Initial state: 0 0.512175 0.889243 0.179092 0.76477 0.55382 0.85388 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109229 episodes
GETTING ACTION FROM:
action 3, numVisits=1109172, meanQ=5.023399, numObservations: 4
action -1, numVisits=53, meanQ=3.964932, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.512175 0.889243 0.179092 0.76477 0.55382 0.85388 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.864641 0.446287 0.527189 0.814854 0.505028 0.813981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096845 episodes
GETTING ACTION FROM:
action 3, numVisits=1096786, meanQ=4.992135, numObservations: 5
action 0, numVisits=32, meanQ=3.672868, numObservations: 1
action 1, numVisits=14, meanQ=2.856436, numObservations: 4
action 2, numVisits=11, meanQ=2.453636, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.864641 0.446287 0.527189 0.814854 0.505028 0.813981 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 115
Initial state: 0 0.914199 0.246853 0.634326 0.879294 0.621667 0.841619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 758897 episodes
GETTING ACTION FROM:
action 0, numVisits=758763, meanQ=2.876336, numObservations: 1
action -1, numVisits=128, meanQ=2.230352, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.914199 0.246853 0.634326 0.879294 0.621667 0.841619 w: 1
Observation: 0 0 0.339608 0 0.948721 0 0.893049 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=758654, meanQ=4.939535, numObservations: 5
action 0, numVisits=58, meanQ=3.975157, numObservations: 1
action -1, numVisits=42, meanQ=3.800120, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=4, meanQ=-0.025000, numObservations: 2
Sampled 1203335 episodes
GETTING ACTION FROM:
action 1, numVisits=1961987, meanQ=4.959330, numObservations: 5
action 0, numVisits=59, meanQ=3.952419, numObservations: 1
action -1, numVisits=43, meanQ=3.777238, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=4, meanQ=-0.025000, numObservations: 2
action: 1
Next state: 2 0.914199 0.246853 0.634326 0.879294 0.621667 0.841619 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 116
Initial state: 0 0.425272 0.788153 0.552157 0.896607 0.601341 0.867405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090745 episodes
GETTING ACTION FROM:
action 2, numVisits=1089028, meanQ=4.947836, numObservations: 5
action 3, numVisits=1693, meanQ=4.747359, numObservations: 5
action 0, numVisits=19, meanQ=3.088611, numObservations: 1
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.425272 0.788153 0.552157 0.896607 0.601341 0.867405 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 117
Initial state: 0 0.600232 0.847772 0.502183 0.889847 0.264785 0.325574 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105894 episodes
GETTING ACTION FROM:
action 1, numVisits=1105855, meanQ=5.001848, numObservations: 4
action -1, numVisits=31, meanQ=3.634807, numObservations: 1
action 3, numVisits=5, meanQ=1.000020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.600232 0.847772 0.502183 0.889847 0.264785 0.325574 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=5701, meanQ=4.207271, numObservations: 4
action 0, numVisits=188, meanQ=3.649434, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1399985 episodes
GETTING ACTION FROM:
action 3, numVisits=1405686, meanQ=5.621465, numObservations: 4
action 0, numVisits=188, meanQ=3.649434, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.600232 0.847772 0.502183 0.889847 0.264785 0.325574 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=30538, meanQ=8.356278, numObservations: 4
action 1, numVisits=5, meanQ=4.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1454492 episodes
GETTING ACTION FROM:
action 2, numVisits=1485026, meanQ=6.315807, numObservations: 4
action 1, numVisits=7, meanQ=2.711429, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.600232 0.847772 0.502183 0.889847 0.264785 0.325574 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=3201, meanQ=7.722177, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1457158 episodes
GETTING ACTION FROM:
action 1, numVisits=1460357, meanQ=6.019270, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.600232 0.847772 0.502183 0.889847 0.264785 0.325574 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 118
Initial state: 0 0.947453 0.0195586 0.574645 0.865379 0.586575 0.831128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096708 episodes
GETTING ACTION FROM:
action 2, numVisits=1096652, meanQ=5.012392, numObservations: 5
action 0, numVisits=49, meanQ=3.944254, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.947453 0.0195586 0.574645 0.865379 0.586575 0.831128 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.627038 0.817154 0.650747 0.843431 0.0757823 0.382729 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104434 episodes
GETTING ACTION FROM:
action 1, numVisits=1104385, meanQ=4.999092, numObservations: 4
action 0, numVisits=45, meanQ=3.873423, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.627038 0.817154 0.650747 0.843431 0.0757823 0.382729 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 120
Initial state: 0 0.646956 0.854065 0.559874 0.865724 0.922885 0.0731449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095309 episodes
GETTING ACTION FROM:
action 3, numVisits=1094143, meanQ=5.019075, numObservations: 5
action 1, numVisits=1074, meanQ=4.718506, numObservations: 4
action -1, numVisits=88, meanQ=4.225103, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.646956 0.854065 0.559874 0.865724 0.922885 0.0731449 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=79917, meanQ=5.516773, numObservations: 4
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1325235 episodes
GETTING ACTION FROM:
action 3, numVisits=1405152, meanQ=5.464700, numObservations: 4
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.646956 0.854065 0.559874 0.865724 0.922885 0.0731449 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 121
Initial state: 0 0.679008 0.891345 0.571374 0.832478 0.485748 0.216075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118045 episodes
GETTING ACTION FROM:
action 3, numVisits=1106563, meanQ=4.996108, numObservations: 3
action 1, numVisits=11401, meanQ=4.819862, numObservations: 4
action -1, numVisits=78, meanQ=4.155097, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.679008 0.891345 0.571374 0.832478 0.485748 0.216075 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=183256, meanQ=8.302730, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1413429 episodes
GETTING ACTION FROM:
action 1, numVisits=1596683, meanQ=5.882590, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.679008 0.891345 0.571374 0.832478 0.485748 0.216075 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 122
Initial state: 0 0.375381 0.892634 0.671686 0.833697 0.565365 0.864197 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091936 episodes
GETTING ACTION FROM:
action 2, numVisits=1091834, meanQ=4.918292, numObservations: 4
action 0, numVisits=98, meanQ=3.675468, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.375381 0.892634 0.671686 0.833697 0.565365 0.864197 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 123
Initial state: 0 0.985826 0.210157 0.626546 0.855392 0.538446 0.882641 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097608 episodes
GETTING ACTION FROM:
action 1, numVisits=1097486, meanQ=5.023208, numObservations: 5
action -1, numVisits=81, meanQ=4.198043, numObservations: 1
action 0, numVisits=37, meanQ=3.750172, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 1
Next state: 2 0.985826 0.210157 0.626546 0.855392 0.538446 0.882641 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 124
Initial state: 0 0.529506 0.854759 0.450607 0.0234626 0.618303 0.846018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1057662 episodes
GETTING ACTION FROM:
action 3, numVisits=1057632, meanQ=4.871305, numObservations: 5
action 1, numVisits=12, meanQ=2.333342, numObservations: 2
action 2, numVisits=14, meanQ=1.998579, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.529506 0.854759 0.450607 0.0234626 0.618303 0.846018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 125
Initial state: 0 0.678597 0.843212 0.656902 0.810972 0.203064 0.486301 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1061876 episodes
GETTING ACTION FROM:
action 1, numVisits=1060391, meanQ=4.871388, numObservations: 5
action -1, numVisits=1478, meanQ=0.671499, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=2, meanQ=-4.994950, numObservations: 1
action: 1
Next state: 0 0.678597 0.843212 0.656902 0.810972 0.203064 0.486301 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=77173, meanQ=3.590474, numObservations: 1
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1311080 episodes
GETTING ACTION FROM:
action 1, numVisits=1258828, meanQ=5.079996, numObservations: 5
action 0, numVisits=129429, meanQ=1.903180, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.678597 0.843212 0.656902 0.810972 0.203064 0.486301 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 126
Initial state: 0 0.535627 0.840678 0.825919 0.819794 0.658536 0.877524 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1043939 episodes
GETTING ACTION FROM:
action 1, numVisits=1043886, meanQ=4.766841, numObservations: 5
action 0, numVisits=47, meanQ=3.651082, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.535627 0.840678 0.825919 0.819794 0.658536 0.877524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=76006, meanQ=5.539182, numObservations: 4
action 2, numVisits=40, meanQ=4.244503, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1295426 episodes
GETTING ACTION FROM:
action 1, numVisits=1371431, meanQ=5.155782, numObservations: 5
action 2, numVisits=41, meanQ=3.872685, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.535627 0.840678 0.825919 0.819794 0.658536 0.877524 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 127
Initial state: 0 0.553492 0.892227 0.525054 0.823233 0.799345 0.945051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 795060 episodes
GETTING ACTION FROM:
action 0, numVisits=794897, meanQ=5.748002, numObservations: 3
action -1, numVisits=160, meanQ=3.091643, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.553492 0.892227 0.525054 0.823233 0.799345 0.945051 w: 1
Observation: 0 0 0.802284 0 0.851917 0 0.971362 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=218620, meanQ=8.308628, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1228928 episodes
GETTING ACTION FROM:
action 2, numVisits=1447546, meanQ=5.399304, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.553492 0.892227 0.525054 0.823233 0.799345 0.945051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 128
Initial state: 0 0.310214 0.626137 0.600551 0.848532 0.57984 0.827516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108842 episodes
GETTING ACTION FROM:
action 3, numVisits=1108783, meanQ=5.009796, numObservations: 4
action -1, numVisits=40, meanQ=3.797068, numObservations: 1
action 1, numVisits=16, meanQ=3.117506, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.310214 0.626137 0.600551 0.848532 0.57984 0.827516 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 129
Initial state: 0 0.511167 0.877419 0.445793 0.0586219 0.536976 0.834151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102682 episodes
GETTING ACTION FROM:
action 2, numVisits=1102619, meanQ=4.958814, numObservations: 4
action -1, numVisits=29, meanQ=3.534131, numObservations: 1
action 0, numVisits=19, meanQ=3.248825, numObservations: 1
action 1, numVisits=13, meanQ=2.383100, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 0 0.511167 0.877419 0.445793 0.0586219 0.536976 0.834151 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=182309, meanQ=8.318101, numObservations: 3
action 3, numVisits=7, meanQ=5.284300, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1440496 episodes
GETTING ACTION FROM:
action 1, numVisits=1622797, meanQ=6.218488, numObservations: 3
action 3, numVisits=13, meanQ=3.922315, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.511167 0.877419 0.445793 0.0586219 0.536976 0.834151 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 130
Initial state: 0 0.58697 0.883796 0.186088 0.204918 0.673322 0.822637 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101404 episodes
GETTING ACTION FROM:
action 3, numVisits=1101391, meanQ=4.945163, numObservations: 4
action 1, numVisits=8, meanQ=1.987513, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.58697 0.883796 0.186088 0.204918 0.673322 0.822637 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=79547, meanQ=4.759688, numObservations: 4
action 0, numVisits=84, meanQ=4.034479, numObservations: 1
action -1, numVisits=20, meanQ=3.203243, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1422238 episodes
GETTING ACTION FROM:
action 1, numVisits=1501785, meanQ=5.839325, numObservations: 4
action 0, numVisits=84, meanQ=4.034479, numObservations: 1
action -1, numVisits=20, meanQ=3.203243, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.58697 0.883796 0.186088 0.204918 0.673322 0.822637 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 131
Initial state: 0 0.165678 0.516951 0.518929 0.850163 0.604166 0.813975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1050681 episodes
GETTING ACTION FROM:
action 2, numVisits=1049656, meanQ=4.965378, numObservations: 5
action 1, numVisits=996, meanQ=4.711036, numObservations: 4
action -1, numVisits=26, meanQ=3.331327, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.165678 0.516951 0.518929 0.850163 0.604166 0.813975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.650776 0.814309 0.535173 0.801747 0.0400477 0.971512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104028 episodes
GETTING ACTION FROM:
action 1, numVisits=1104022, meanQ=4.962544, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.650776 0.814309 0.535173 0.801747 0.0400477 0.971512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.174041 0.422629 0.673425 0.855522 0.554597 0.815622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104272 episodes
GETTING ACTION FROM:
action 2, numVisits=1104156, meanQ=5.027262, numObservations: 5
action -1, numVisits=104, meanQ=4.297660, numObservations: 1
action 0, numVisits=10, meanQ=2.488000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.174041 0.422629 0.673425 0.855522 0.554597 0.815622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 134
Initial state: 0 0.779804 0.99586 0.519453 0.852828 0.625997 0.809243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094181 episodes
GETTING ACTION FROM:
action 3, numVisits=1094153, meanQ=4.955208, numObservations: 4
action 1, numVisits=21, meanQ=3.285719, numObservations: 3
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.779804 0.99586 0.519453 0.852828 0.625997 0.809243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 135
Initial state: 0 0.526033 0.144505 0.558561 0.815283 0.617565 0.849872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088752 episodes
GETTING ACTION FROM:
action 1, numVisits=1088735, meanQ=4.936225, numObservations: 5
action 2, numVisits=9, meanQ=2.333333, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.526033 0.144505 0.558561 0.815283 0.617565 0.849872 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 136
Initial state: 0 0.661567 0.873153 0.956712 0.290956 0.609411 0.807206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094948 episodes
GETTING ACTION FROM:
action 3, numVisits=1094916, meanQ=4.946157, numObservations: 5
action 1, numVisits=26, meanQ=2.998846, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.661567 0.873153 0.956712 0.290956 0.609411 0.807206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.64421 0.892957 0.56318 0.836083 0.345652 0.990306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088073 episodes
GETTING ACTION FROM:
action 1, numVisits=541041, meanQ=5.005024, numObservations: 3
action 3, numVisits=547027, meanQ=4.808861, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.64421 0.892957 0.56318 0.836083 0.345652 0.990306 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.642993 0.846056 0.852817 0.954989 0.699494 0.857806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091953 episodes
GETTING ACTION FROM:
action 1, numVisits=1091946, meanQ=4.945160, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.642993 0.846056 0.852817 0.954989 0.699494 0.857806 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 139
Initial state: 0 0.377928 0.219811 0.68585 0.882973 0.571646 0.850806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107632 episodes
GETTING ACTION FROM:
action 2, numVisits=1107557, meanQ=5.040926, numObservations: 5
action -1, numVisits=71, meanQ=4.159226, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.377928 0.219811 0.68585 0.882973 0.571646 0.850806 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 140
Initial state: 0 0.607868 0.870425 0.635332 0.682435 0.69265 0.862314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104285 episodes
GETTING ACTION FROM:
action 1, numVisits=1104246, meanQ=5.014340, numObservations: 4
action 0, numVisits=35, meanQ=3.734939, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.607868 0.870425 0.635332 0.682435 0.69265 0.862314 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 141
Initial state: 0 0.665499 0.816152 0.527325 0.833472 0.021807 0.580988 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084183 episodes
GETTING ACTION FROM:
action 3, numVisits=1084149, meanQ=4.952701, numObservations: 5
action 2, numVisits=20, meanQ=3.000005, numObservations: 3
action 1, numVisits=10, meanQ=2.598000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.665499 0.816152 0.527325 0.833472 0.021807 0.580988 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=24725, meanQ=7.889988, numObservations: 4
action 2, numVisits=1568, meanQ=7.766580, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1425460 episodes
GETTING ACTION FROM:
action 2, numVisits=1350840, meanQ=6.317787, numObservations: 4
action 1, numVisits=100911, meanQ=6.300422, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.665499 0.816152 0.527325 0.833472 0.021807 0.580988 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 142
Initial state: 0 0.511806 0.87725 0.591833 0.883487 0.498141 0.563807 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113962 episodes
GETTING ACTION FROM:
action 1, numVisits=1113955, meanQ=4.971999, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.511806 0.87725 0.591833 0.883487 0.498141 0.563807 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.262568 0.543648 0.631794 0.801586 0.596276 0.817096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 791855 episodes
GETTING ACTION FROM:
action 0, numVisits=782346, meanQ=5.971478, numObservations: 3
action 1, numVisits=9490, meanQ=4.980061, numObservations: 5
action 2, numVisits=11, meanQ=2.633645, numObservations: 4
action 3, numVisits=6, meanQ=2.333350, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.262568 0.543648 0.631794 0.801586 0.596276 0.817096 w: 1
Observation: 0 0 0.639522 0 0.878167 0 0.758126 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=273309, meanQ=8.008526, numObservations: 4
action 3, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1221327 episodes
GETTING ACTION FROM:
action 2, numVisits=1494512, meanQ=5.667152, numObservations: 4
action 3, numVisits=109, meanQ=4.895201, numObservations: 4
action 0, numVisits=18, meanQ=3.744929, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.262568 0.543648 0.631794 0.801586 0.596276 0.817096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 144
Initial state: 0 0.661374 0.873421 0.675754 0.814218 0.146127 0.966113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 788635 episodes
GETTING ACTION FROM:
action 0, numVisits=788208, meanQ=5.896719, numObservations: 3
action -1, numVisits=399, meanQ=3.665783, numObservations: 1
action 3, numVisits=25, meanQ=1.878812, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.661374 0.873421 0.675754 0.814218 0.146127 0.966113 w: 1
Observation: 0 0 0.811374 0 0.803531 0 0.981045 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=273556, meanQ=7.900992, numObservations: 5
action 3, numVisits=25, meanQ=3.144404, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1206540 episodes
GETTING ACTION FROM:
action 1, numVisits=1480053, meanQ=5.738202, numObservations: 5
action -1, numVisits=43, meanQ=4.590666, numObservations: 1
action 3, numVisits=25, meanQ=3.144404, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.661374 0.873421 0.675754 0.814218 0.146127 0.966113 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 145
Initial state: 0 0.659356 0.803719 0.613012 0.841585 0.516821 0.0416384 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109716 episodes
GETTING ACTION FROM:
action 1, numVisits=1109655, meanQ=5.005486, numObservations: 4
action -1, numVisits=44, meanQ=3.866700, numObservations: 1
action 2, numVisits=14, meanQ=2.122143, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.659356 0.803719 0.613012 0.841585 0.516821 0.0416384 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.521843 0.865595 0.469818 0.246835 0.584956 0.834157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105947 episodes
GETTING ACTION FROM:
action 2, numVisits=1105939, meanQ=4.999247, numObservations: 4
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.521843 0.865595 0.469818 0.246835 0.584956 0.834157 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=89840, meanQ=8.544851, numObservations: 3
action 3, numVisits=36928, meanQ=8.531770, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1392305 episodes
GETTING ACTION FROM:
action 1, numVisits=1209380, meanQ=6.336235, numObservations: 5
action 3, numVisits=309691, meanQ=6.329574, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.521843 0.865595 0.469818 0.246835 0.584956 0.834157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 147
Initial state: 0 0.685567 0.877513 0.665221 0.837758 0.267847 0.249416 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115265 episodes
GETTING ACTION FROM:
action 2, numVisits=1115206, meanQ=5.016038, numObservations: 4
action -1, numVisits=55, meanQ=4.010001, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.685567 0.877513 0.665221 0.837758 0.267847 0.249416 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 148
Initial state: 0 0.612967 0.897073 0.651375 0.894218 0.185292 0.65765 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087568 episodes
GETTING ACTION FROM:
action 1, numVisits=1087453, meanQ=4.928293, numObservations: 5
action 3, numVisits=68, meanQ=3.904569, numObservations: 4
action 2, numVisits=43, meanQ=3.639774, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.612967 0.897073 0.651375 0.894218 0.185292 0.65765 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 149
Initial state: 0 0.568758 0.811131 0.540302 0.831423 0.992248 0.383882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 793720 episodes
GETTING ACTION FROM:
action 0, numVisits=786893, meanQ=5.950591, numObservations: 3
action 2, numVisits=6822, meanQ=4.859781, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.568758 0.811131 0.540302 0.831423 0.992248 0.383882 w: 1
Observation: 0 0 0.781308 0 0.795271 0 0.431226 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=241717, meanQ=8.224757, numObservations: 4
action 1, numVisits=21, meanQ=6.522867, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1219212 episodes
GETTING ACTION FROM:
action 2, numVisits=1460893, meanQ=5.816582, numObservations: 4
action 1, numVisits=40, meanQ=4.495005, numObservations: 3
action 0, numVisits=17, meanQ=3.991781, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.568758 0.811131 0.540302 0.831423 0.992248 0.383882 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=111321, meanQ=5.628675, numObservations: 4
action -1, numVisits=80, meanQ=4.881079, numObservations: 1
action 2, numVisits=6, meanQ=2.663350, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1425182 episodes
GETTING ACTION FROM:
action 1, numVisits=1536503, meanQ=5.991820, numObservations: 4
action -1, numVisits=80, meanQ=4.881079, numObservations: 1
action 2, numVisits=6, meanQ=2.663350, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.568758 0.811131 0.540302 0.831423 0.992248 0.383882 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 150
Initial state: 0 0.648888 0.846829 0.599821 0.883811 0.186835 0.402645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108950 episodes
GETTING ACTION FROM:
action 2, numVisits=1108944, meanQ=4.953884, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.648888 0.846829 0.599821 0.883811 0.186835 0.402645 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.614075 0.819643 0.605589 0.824284 0.133943 0.642247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1081136 episodes
GETTING ACTION FROM:
action 1, numVisits=1081121, meanQ=5.009152, numObservations: 4
action 3, numVisits=7, meanQ=1.568600, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.614075 0.819643 0.605589 0.824284 0.133943 0.642247 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 152
Initial state: 0 0.590508 0.875183 0.87478 0.547055 0.517026 0.862018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1072049 episodes
GETTING ACTION FROM:
action 3, numVisits=1071918, meanQ=4.894048, numObservations: 5
action -1, numVisits=107, meanQ=2.242658, numObservations: 1
action 1, numVisits=21, meanQ=1.570476, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.590508 0.875183 0.87478 0.547055 0.517026 0.862018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.447408 0.625604 0.616066 0.805328 0.602965 0.813176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1089675 episodes
GETTING ACTION FROM:
action 3, numVisits=1089637, meanQ=4.992746, numObservations: 5
action 0, numVisits=31, meanQ=3.659995, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.447408 0.625604 0.616066 0.805328 0.602965 0.813176 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.837159 0.957772 0.518666 0.831616 0.611223 0.845331 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098092 episodes
GETTING ACTION FROM:
action 3, numVisits=1098083, meanQ=5.001194, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.837159 0.957772 0.518666 0.831616 0.611223 0.845331 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.64101 0.823859 0.673747 0.851194 0.737501 0.0807918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114600 episodes
GETTING ACTION FROM:
action 1, numVisits=1114594, meanQ=4.938666, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.64101 0.823859 0.673747 0.851194 0.737501 0.0807918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.13525 0.905394 0.553163 0.844886 0.659652 0.807664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106063 episodes
GETTING ACTION FROM:
action 1, numVisits=1106053, meanQ=5.012343, numObservations: 4
action 3, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.13525 0.905394 0.553163 0.844886 0.659652 0.807664 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=55425, meanQ=7.792977, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1411621 episodes
GETTING ACTION FROM:
action 2, numVisits=1466864, meanQ=5.878504, numObservations: 5
action 3, numVisits=182, meanQ=5.317089, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.13525 0.905394 0.553163 0.844886 0.659652 0.807664 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 157
Initial state: 0 0.576608 0.887144 0.556541 0.885035 0.427817 0.340509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120566 episodes
GETTING ACTION FROM:
action 2, numVisits=1120445, meanQ=4.990447, numObservations: 3
action -1, numVisits=69, meanQ=4.086600, numObservations: 1
action 0, numVisits=48, meanQ=3.893860, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.576608 0.887144 0.556541 0.885035 0.427817 0.340509 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.663358 0.804183 0.512674 0.863082 0.908444 0.977818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1058089 episodes
GETTING ACTION FROM:
action 2, numVisits=1047389, meanQ=4.837653, numObservations: 5
action 0, numVisits=10382, meanQ=3.022151, numObservations: 1
action -1, numVisits=315, meanQ=2.737655, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 1 0.663358 0.804183 0.512674 0.863082 0.908444 0.977818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 159
Initial state: 0 0.678266 0.876435 0.636335 0.842339 0.0282931 0.953354 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099502 episodes
GETTING ACTION FROM:
action 2, numVisits=1099459, meanQ=4.919636, numObservations: 3
action 0, numVisits=39, meanQ=3.676962, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.678266 0.876435 0.636335 0.842339 0.0282931 0.953354 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 160
Initial state: 0 0.670988 0.829532 0.259393 0.727182 0.520552 0.839189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1076325 episodes
GETTING ACTION FROM:
action 1, numVisits=1070293, meanQ=4.935090, numObservations: 5
action 0, numVisits=6026, meanQ=2.814811, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.670988 0.829532 0.259393 0.727182 0.520552 0.839189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 161
Initial state: 0 0.652335 0.859427 0.416772 0.219803 0.583004 0.862839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102293 episodes
GETTING ACTION FROM:
action 2, numVisits=1102287, meanQ=4.958876, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.652335 0.859427 0.416772 0.219803 0.583004 0.862839 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=182247, meanQ=8.290142, numObservations: 4
action 1, numVisits=11, meanQ=6.090000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1418185 episodes
GETTING ACTION FROM:
action 3, numVisits=1600372, meanQ=6.167758, numObservations: 4
action 1, numVisits=68, meanQ=5.234853, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.652335 0.859427 0.416772 0.219803 0.583004 0.862839 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 162
Initial state: 0 0.631857 0.867898 0.0877896 0.589848 0.578335 0.829525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1082776 episodes
GETTING ACTION FROM:
action 3, numVisits=1082766, meanQ=4.952531, numObservations: 5
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.631857 0.867898 0.0877896 0.589848 0.578335 0.829525 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=60290, meanQ=4.473965, numObservations: 4
action 0, numVisits=10608, meanQ=3.020304, numObservations: 1
action 2, numVisits=6, meanQ=-0.338333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1408981 episodes
GETTING ACTION FROM:
action 1, numVisits=1469271, meanQ=5.959233, numObservations: 4
action 0, numVisits=10608, meanQ=3.020304, numObservations: 1
action 2, numVisits=6, meanQ=-0.338333, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.631857 0.867898 0.0877896 0.589848 0.578335 0.829525 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 163
Initial state: 0 0.67362 0.816839 0.268371 0.0375783 0.510791 0.89935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109459 episodes
GETTING ACTION FROM:
action 2, numVisits=1109453, meanQ=5.008973, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.67362 0.816839 0.268371 0.0375783 0.510791 0.89935 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=126691, meanQ=8.534722, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1386896 episodes
GETTING ACTION FROM:
action 3, numVisits=1513555, meanQ=6.325409, numObservations: 5
action 1, numVisits=32, meanQ=4.874688, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.67362 0.816839 0.268371 0.0375783 0.510791 0.89935 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 164
Initial state: 0 0.749356 0.730654 0.53953 0.858068 0.596432 0.804465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084621 episodes
GETTING ACTION FROM:
action 1, numVisits=1084325, meanQ=4.906107, numObservations: 4
action -1, numVisits=292, meanQ=1.481101, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.749356 0.730654 0.53953 0.858068 0.596432 0.804465 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 165
Initial state: 0 0.525263 0.883345 0.544023 0.828241 0.94194 0.173341 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088781 episodes
GETTING ACTION FROM:
action 1, numVisits=1088752, meanQ=4.939009, numObservations: 5
action 0, numVisits=25, meanQ=3.428366, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.525263 0.883345 0.544023 0.828241 0.94194 0.173341 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=78594, meanQ=4.741526, numObservations: 5
action -1, numVisits=220, meanQ=4.303646, numObservations: 1
action 0, numVisits=59, meanQ=3.887362, numObservations: 1
action 3, numVisits=37, meanQ=3.579189, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1383569 episodes
GETTING ACTION FROM:
action 2, numVisits=1462163, meanQ=5.602825, numObservations: 5
action -1, numVisits=220, meanQ=4.303646, numObservations: 1
action 0, numVisits=59, meanQ=3.887362, numObservations: 1
action 3, numVisits=37, meanQ=3.579189, numObservations: 4
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.525263 0.883345 0.544023 0.828241 0.94194 0.173341 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 166
Initial state: 0 0.67 0.856205 0.867268 0.764534 0.545753 0.81114 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095755 episodes
GETTING ACTION FROM:
action 1, numVisits=1094744, meanQ=4.988408, numObservations: 4
action 0, numVisits=1004, meanQ=2.554092, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.67 0.856205 0.867268 0.764534 0.545753 0.81114 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.578122 0.858958 0.763609 0.66238 0.502257 0.811337 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093953 episodes
GETTING ACTION FROM:
action 3, numVisits=1093923, meanQ=5.009414, numObservations: 5
action -1, numVisits=25, meanQ=3.460415, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.578122 0.858958 0.763609 0.66238 0.502257 0.811337 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 168
Initial state: 0 0.874165 0.120272 0.683677 0.842398 0.593499 0.819633 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098851 episodes
GETTING ACTION FROM:
action 2, numVisits=1096796, meanQ=4.984708, numObservations: 4
action 0, numVisits=2050, meanQ=2.828840, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.874165 0.120272 0.683677 0.842398 0.593499 0.819633 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 169
Initial state: 0 0.0243818 0.285928 0.660575 0.816459 0.630113 0.849155 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096665 episodes
GETTING ACTION FROM:
action 2, numVisits=1096328, meanQ=4.945574, numObservations: 5
action 0, numVisits=333, meanQ=2.448596, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.0243818 0.285928 0.660575 0.816459 0.630113 0.849155 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.00523769 0.572189 0.558634 0.822252 0.526931 0.805087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100155 episodes
GETTING ACTION FROM:
action 1, numVisits=1100042, meanQ=4.987607, numObservations: 4
action 0, numVisits=101, meanQ=4.246609, numObservations: 1
action 3, numVisits=9, meanQ=1.665567, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.00523769 0.572189 0.558634 0.822252 0.526931 0.805087 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 171
Initial state: 0 0.566482 0.841356 0.681855 0.818386 0.385926 0.970499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087202 episodes
GETTING ACTION FROM:
action 3, numVisits=1087054, meanQ=4.953565, numObservations: 5
action 0, numVisits=142, meanQ=4.330517, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.566482 0.841356 0.681855 0.818386 0.385926 0.970499 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=26278, meanQ=7.853329, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1426716 episodes
GETTING ACTION FROM:
action 2, numVisits=1452992, meanQ=5.901091, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.566482 0.841356 0.681855 0.818386 0.385926 0.970499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 172
Initial state: 0 0.518303 0.870169 0.750613 0.696907 0.639284 0.897565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103050 episodes
GETTING ACTION FROM:
action 3, numVisits=1101087, meanQ=5.007112, numObservations: 4
action -1, numVisits=1959, meanQ=2.769962, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.518303 0.870169 0.750613 0.696907 0.639284 0.897565 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 173
Initial state: 0 0.645359 0.893502 0.538436 0.802611 0.168389 0.830025 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115908 episodes
GETTING ACTION FROM:
action 2, numVisits=1115902, meanQ=4.958035, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.645359 0.893502 0.538436 0.802611 0.168389 0.830025 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.583255 0.849167 0.57773 0.826063 0.113947 0.0985974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108562 episodes
GETTING ACTION FROM:
action 1, numVisits=969930, meanQ=5.012913, numObservations: 4
action 2, numVisits=138588, meanQ=4.980527, numObservations: 4
action 0, numVisits=41, meanQ=3.820332, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.583255 0.849167 0.57773 0.826063 0.113947 0.0985974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.589078 0.839421 0.678841 0.816929 0.269907 0.565018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102791 episodes
GETTING ACTION FROM:
action 1, numVisits=1102689, meanQ=4.986951, numObservations: 4
action 0, numVisits=75, meanQ=4.131062, numObservations: 1
action 3, numVisits=24, meanQ=2.495425, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.589078 0.839421 0.678841 0.816929 0.269907 0.565018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.186885 0.367032 0.585792 0.868029 0.691066 0.882896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1068634 episodes
GETTING ACTION FROM:
action 3, numVisits=1063491, meanQ=5.083854, numObservations: 5
action 2, numVisits=5109, meanQ=4.983462, numObservations: 5
action -1, numVisits=31, meanQ=3.676071, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.186885 0.367032 0.585792 0.868029 0.691066 0.882896 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 177
Initial state: 0 0.545404 0.854212 0.584269 0.506788 0.512908 0.841287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102527 episodes
GETTING ACTION FROM:
action 2, numVisits=1102515, meanQ=5.022328, numObservations: 5
action 3, numVisits=5, meanQ=1.000000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.545404 0.854212 0.584269 0.506788 0.512908 0.841287 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 178
Initial state: 0 0.57945 0.852355 0.679014 0.683963 0.573493 0.829279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094079 episodes
GETTING ACTION FROM:
action 1, numVisits=1094073, meanQ=4.951246, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.57945 0.852355 0.679014 0.683963 0.573493 0.829279 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.537916 0.829996 0.991108 0.365047 0.531802 0.816052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1071249 episodes
GETTING ACTION FROM:
action 1, numVisits=1071035, meanQ=4.880325, numObservations: 4
action 0, numVisits=209, meanQ=4.368907, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.537916 0.829996 0.991108 0.365047 0.531802 0.816052 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.821817 0.652501 0.537112 0.80717 0.691669 0.863256 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102850 episodes
GETTING ACTION FROM:
action 1, numVisits=1102844, meanQ=5.021321, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.821817 0.652501 0.537112 0.80717 0.691669 0.863256 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=79483, meanQ=5.561690, numObservations: 4
action 2, numVisits=64, meanQ=4.711569, numObservations: 4
action 3, numVisits=66, meanQ=4.630611, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1383881 episodes
GETTING ACTION FROM:
action 3, numVisits=917927, meanQ=5.897377, numObservations: 4
action 1, numVisits=545502, meanQ=5.515522, numObservations: 4
action 2, numVisits=65, meanQ=4.469852, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.821817 0.652501 0.537112 0.80717 0.691669 0.863256 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 181
Initial state: 0 0.856939 0.99156 0.635819 0.839367 0.558824 0.83291 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1075478 episodes
GETTING ACTION FROM:
action 3, numVisits=1075468, meanQ=4.882409, numObservations: 3
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.856939 0.99156 0.635819 0.839367 0.558824 0.83291 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 182
Initial state: 0 0.521905 0.831547 0.907262 0.222717 0.586716 0.843844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093247 episodes
GETTING ACTION FROM:
action 3, numVisits=1093171, meanQ=4.966017, numObservations: 5
action -1, numVisits=25, meanQ=3.332386, numObservations: 1
action 1, numVisits=39, meanQ=3.245649, numObservations: 4
action 2, numVisits=10, meanQ=2.598000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.521905 0.831547 0.907262 0.222717 0.586716 0.843844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.673368 0.881082 0.852486 0.96194 0.645593 0.821797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114560 episodes
GETTING ACTION FROM:
action 2, numVisits=1114382, meanQ=5.013116, numObservations: 4
action 0, numVisits=107, meanQ=4.242693, numObservations: 2
action -1, numVisits=67, meanQ=4.080922, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.673368 0.881082 0.852486 0.96194 0.645593 0.821797 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.614079 0.888053 0.644453 0.855071 0.135212 0.406702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 769097 episodes
GETTING ACTION FROM:
action 0, numVisits=769059, meanQ=2.969192, numObservations: 1
action -1, numVisits=32, meanQ=1.668085, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.614079 0.888053 0.644453 0.855071 0.135212 0.406702 w: 1
Observation: 0 0 0.871422 0 0.896235 0 0.443269 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=769001, meanQ=5.011950, numObservations: 3
action 3, numVisits=39, meanQ=3.661297, numObservations: 3
action 1, numVisits=14, meanQ=2.998571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 1233586 episodes
GETTING ACTION FROM:
action 2, numVisits=2002587, meanQ=5.093990, numObservations: 3
action 3, numVisits=39, meanQ=3.661297, numObservations: 3
action 1, numVisits=14, meanQ=2.998571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.614079 0.888053 0.644453 0.855071 0.135212 0.406702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 185
Initial state: 0 0.340554 0.868169 0.510725 0.867703 0.538416 0.839572 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091987 episodes
GETTING ACTION FROM:
action 2, numVisits=1091957, meanQ=4.950059, numObservations: 5
action 1, numVisits=17, meanQ=2.641176, numObservations: 4
action 3, numVisits=9, meanQ=2.333333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.340554 0.868169 0.510725 0.867703 0.538416 0.839572 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 186
Initial state: 0 0.525253 0.312431 0.637719 0.814792 0.686996 0.893868 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117044 episodes
GETTING ACTION FROM:
action 1, numVisits=1113975, meanQ=4.946344, numObservations: 3
action -1, numVisits=3056, meanQ=2.904811, numObservations: 1
action 3, numVisits=10, meanQ=1.198010, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.525253 0.312431 0.637719 0.814792 0.686996 0.893868 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 187
Initial state: 0 0.627271 0.810082 0.826638 0.199734 0.546601 0.871883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098704 episodes
GETTING ACTION FROM:
action 1, numVisits=1098674, meanQ=4.999978, numObservations: 5
action -1, numVisits=26, meanQ=3.537564, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.627271 0.810082 0.826638 0.199734 0.546601 0.871883 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 188
Initial state: 0 0.555662 0.8255 0.599214 0.857356 0.27775 0.0749287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098959 episodes
GETTING ACTION FROM:
action 1, numVisits=1098953, meanQ=4.934002, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.555662 0.8255 0.599214 0.857356 0.27775 0.0749287 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.539149 0.856374 0.303285 0.525768 0.685933 0.841545 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1056721 episodes
GETTING ACTION FROM:
action 1, numVisits=1056715, meanQ=4.842869, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.539149 0.856374 0.303285 0.525768 0.685933 0.841545 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 190
Initial state: 0 0.510641 0.850382 0.0954779 0.590504 0.569515 0.891294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1085640 episodes
GETTING ACTION FROM:
action 2, numVisits=1085632, meanQ=4.868596, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.510641 0.850382 0.0954779 0.590504 0.569515 0.891294 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=178874, meanQ=8.321358, numObservations: 4
action 1, numVisits=11, meanQ=6.090000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1416766 episodes
GETTING ACTION FROM:
action 3, numVisits=1595614, meanQ=6.089164, numObservations: 4
action 1, numVisits=34, meanQ=4.764118, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.510641 0.850382 0.0954779 0.590504 0.569515 0.891294 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 191
Initial state: 0 0.558303 0.812206 0.671006 0.835411 0.9394 0.962511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090724 episodes
GETTING ACTION FROM:
action 3, numVisits=1090687, meanQ=5.003219, numObservations: 5
action 0, numVisits=14, meanQ=2.906516, numObservations: 1
action 2, numVisits=12, meanQ=1.977500, numObservations: 4
action 1, numVisits=9, meanQ=1.432222, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.558303 0.812206 0.671006 0.835411 0.9394 0.962511 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 192
Initial state: 0 0.950702 0.19548 0.549891 0.831991 0.541166 0.826538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087723 episodes
GETTING ACTION FROM:
action 2, numVisits=1087693, meanQ=5.030121, numObservations: 5
action 1, numVisits=12, meanQ=2.664167, numObservations: 5
action 0, numVisits=12, meanQ=2.619037, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.950702 0.19548 0.549891 0.831991 0.541166 0.826538 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.940178 0.444471 0.522861 0.834118 0.531998 0.884589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087928 episodes
GETTING ACTION FROM:
action 3, numVisits=1087911, meanQ=4.973002, numObservations: 5
action 2, numVisits=9, meanQ=2.098900, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.940178 0.444471 0.522861 0.834118 0.531998 0.884589 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 194
Initial state: 0 0.589024 0.823294 0.513775 0.89544 0.279332 0.13021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 770864 episodes
GETTING ACTION FROM:
action -1, numVisits=770856, meanQ=2.886145, numObservations: 1
action 3, numVisits=4, meanQ=-4.002500, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.589024 0.823294 0.513775 0.89544 0.279332 0.13021 w: 1
Observation: 0 0.651989 0 0.562933 0 0.269604 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=770849, meanQ=4.955688, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1248177 episodes
GETTING ACTION FROM:
action 2, numVisits=2019026, meanQ=5.091672, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.589024 0.823294 0.513775 0.89544 0.279332 0.13021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 195
Initial state: 0 0.222269 0.234674 0.601901 0.82553 0.622939 0.815862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091770 episodes
GETTING ACTION FROM:
action 3, numVisits=1091761, meanQ=4.911684, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=4, meanQ=-2.005000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.222269 0.234674 0.601901 0.82553 0.622939 0.815862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.685865 0.835954 0.524939 0.853276 0.911663 0.181183 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093076 episodes
GETTING ACTION FROM:
action 2, numVisits=1093042, meanQ=5.000427, numObservations: 5
action -1, numVisits=24, meanQ=3.400233, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.685865 0.835954 0.524939 0.853276 0.911663 0.181183 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=78750, meanQ=5.576419, numObservations: 4
action 0, numVisits=12, meanQ=3.615445, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1285553 episodes
GETTING ACTION FROM:
action 2, numVisits=1364301, meanQ=5.197014, numObservations: 4
action 0, numVisits=14, meanQ=2.813239, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.685865 0.835954 0.524939 0.853276 0.911663 0.181183 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=3607, meanQ=6.586597, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1461436 episodes
GETTING ACTION FROM:
action 3, numVisits=1465043, meanQ=6.239229, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.685865 0.835954 0.524939 0.853276 0.911663 0.181183 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 197
Initial state: 0 0.261299 0.620203 0.563103 0.836504 0.611811 0.866764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101302 episodes
GETTING ACTION FROM:
action 2, numVisits=1101235, meanQ=5.031468, numObservations: 5
action -1, numVisits=53, meanQ=4.006978, numObservations: 1
action 3, numVisits=11, meanQ=1.907282, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.261299 0.620203 0.563103 0.836504 0.611811 0.866764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 198
Initial state: 0 0.564718 0.802273 0.503004 0.89576 0.975915 0.204376 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1077998 episodes
GETTING ACTION FROM:
action 2, numVisits=1077960, meanQ=4.943686, numObservations: 4
action -1, numVisits=23, meanQ=3.373257, numObservations: 1
action 1, numVisits=12, meanQ=1.667508, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.564718 0.802273 0.503004 0.89576 0.975915 0.204376 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 199
Initial state: 0 0.689386 0.846757 0.52419 0.899674 0.0658368 0.797415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095630 episodes
GETTING ACTION FROM:
action 3, numVisits=1095614, meanQ=5.017611, numObservations: 5
action 2, numVisits=11, meanQ=2.081818, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.689386 0.846757 0.52419 0.899674 0.0658368 0.797415 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=26448, meanQ=7.934329, numObservations: 4
action 2, numVisits=8, meanQ=5.501263, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1420801 episodes
GETTING ACTION FROM:
action 2, numVisits=1073899, meanQ=5.994328, numObservations: 4
action 1, numVisits=373356, meanQ=5.986508, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.689386 0.846757 0.52419 0.899674 0.0658368 0.797415 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 200
Initial state: 0 0.559113 0.857748 0.770383 0.241415 0.582487 0.861575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120444 episodes
GETTING ACTION FROM:
action 2, numVisits=1120406, meanQ=5.010637, numObservations: 3
action 1, numVisits=33, meanQ=3.520303, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.559113 0.857748 0.770383 0.241415 0.582487 0.861575 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 201
Initial state: 0 0.0689295 0.159236 0.53804 0.805657 0.692322 0.844052 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101253 episodes
GETTING ACTION FROM:
action 2, numVisits=1101097, meanQ=4.947421, numObservations: 5
action -1, numVisits=61, meanQ=3.998133, numObservations: 1
action 1, numVisits=65, meanQ=3.974466, numObservations: 4
action 3, numVisits=28, meanQ=3.483936, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.0689295 0.159236 0.53804 0.805657 0.692322 0.844052 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 202
Initial state: 0 0.622952 0.843892 0.650446 0.802747 0.36339 0.770179 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103146 episodes
GETTING ACTION FROM:
action 2, numVisits=1103140, meanQ=4.987897, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.622952 0.843892 0.650446 0.802747 0.36339 0.770179 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.628639 0.805781 0.596721 0.870015 0.252689 0.925814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109506 episodes
GETTING ACTION FROM:
action 1, numVisits=1097847, meanQ=5.025051, numObservations: 4
action 2, numVisits=11651, meanQ=4.961172, numObservations: 5
action 3, numVisits=4, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.628639 0.805781 0.596721 0.870015 0.252689 0.925814 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.58067 0.878718 0.0608629 0.389876 0.513931 0.82771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104220 episodes
GETTING ACTION FROM:
action 3, numVisits=1104120, meanQ=5.011521, numObservations: 4
action -1, numVisits=93, meanQ=4.238442, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.58067 0.878718 0.0608629 0.389876 0.513931 0.82771 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.335127 0.998127 0.678553 0.845223 0.597667 0.823933 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096315 episodes
GETTING ACTION FROM:
action 3, numVisits=1096296, meanQ=4.941386, numObservations: 4
action 1, numVisits=14, meanQ=2.842864, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.335127 0.998127 0.678553 0.845223 0.597667 0.823933 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.643782 0.895049 0.546507 0.907581 0.638693 0.843764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 763803 episodes
GETTING ACTION FROM:
action -1, numVisits=763794, meanQ=3.034200, numObservations: 1
action 3, numVisits=5, meanQ=-2.603980, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.643782 0.895049 0.546507 0.907581 0.638693 0.843764 w: 1
Observation: 0 0.676042 0 0.54374 0 0.620137 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=756677, meanQ=5.125105, numObservations: 4
action 0, numVisits=7096, meanQ=2.812055, numObservations: 1
action 2, numVisits=9, meanQ=0.777800, numObservations: 4
action 1, numVisits=9, meanQ=0.777800, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 1229113 episodes
GETTING ACTION FROM:
action 3, numVisits=1985790, meanQ=5.207363, numObservations: 4
action 0, numVisits=7096, meanQ=2.812055, numObservations: 1
action 2, numVisits=9, meanQ=0.777800, numObservations: 4
action 1, numVisits=9, meanQ=0.777800, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.643782 0.895049 0.546507 0.907581 0.638693 0.843764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=138519, meanQ=6.976717, numObservations: 3
action 2, numVisits=10, meanQ=0.209000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=4, meanQ=-2.977500, numObservations: 2
Sampled 1338716 episodes
GETTING ACTION FROM:
action 3, numVisits=1477233, meanQ=5.326676, numObservations: 3
action 2, numVisits=10, meanQ=0.209000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=4, meanQ=-2.977500, numObservations: 2
action: 3
Next state: 1 0.643782 0.895049 0.546507 0.907581 0.638693 0.843764 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 207
Initial state: 0 0.265412 0.976103 0.676064 0.853082 0.54594 0.802284 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112875 episodes
GETTING ACTION FROM:
action 3, numVisits=1112846, meanQ=4.937134, numObservations: 3
action 1, numVisits=22, meanQ=0.271382, numObservations: 4
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.265412 0.976103 0.676064 0.853082 0.54594 0.802284 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 208
Initial state: 0 0.560406 0.88967 0.610047 0.835013 0.0800426 0.152434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117682 episodes
GETTING ACTION FROM:
action 3, numVisits=1117589, meanQ=5.018664, numObservations: 3
action -1, numVisits=45, meanQ=3.886152, numObservations: 1
action 0, numVisits=43, meanQ=3.841191, numObservations: 1
action 2, numVisits=4, meanQ=-0.025000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.560406 0.88967 0.610047 0.835013 0.0800426 0.152434 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=175160, meanQ=8.313193, numObservations: 4
action 1, numVisits=9022, meanQ=8.255697, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1410865 episodes
GETTING ACTION FROM:
action 2, numVisits=1490147, meanQ=6.105807, numObservations: 4
action 1, numVisits=104898, meanQ=6.088575, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.560406 0.88967 0.610047 0.835013 0.0800426 0.152434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 209
Initial state: 0 0.644946 0.821729 0.653286 0.828802 0.0983399 0.442704 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100531 episodes
GETTING ACTION FROM:
action 2, numVisits=1100523, meanQ=5.013602, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.644946 0.821729 0.653286 0.828802 0.0983399 0.442704 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.510027 0.829492 0.817617 0.318343 0.560763 0.830346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102468 episodes
GETTING ACTION FROM:
action 3, numVisits=1102306, meanQ=4.940110, numObservations: 4
action -1, numVisits=158, meanQ=4.348316, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.510027 0.829492 0.817617 0.318343 0.560763 0.830346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.500647 0.849518 0.0784723 0.172457 0.571362 0.85555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1085631 episodes
GETTING ACTION FROM:
action 2, numVisits=1085504, meanQ=4.936700, numObservations: 5
action 0, numVisits=122, meanQ=1.733258, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.500647 0.849518 0.0784723 0.172457 0.571362 0.85555 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=151671, meanQ=8.392182, numObservations: 4
action 1, numVisits=7, meanQ=5.568571, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1412546 episodes
GETTING ACTION FROM:
action 3, numVisits=1564214, meanQ=6.262380, numObservations: 4
action 1, numVisits=8, meanQ=3.497500, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.500647 0.849518 0.0784723 0.172457 0.571362 0.85555 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 212
Initial state: 0 0.561538 0.852664 0.96847 0.769559 0.540075 0.848006 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1081601 episodes
GETTING ACTION FROM:
action 1, numVisits=1081453, meanQ=4.930534, numObservations: 4
action 0, numVisits=103, meanQ=4.140078, numObservations: 1
action 3, numVisits=42, meanQ=3.465007, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.561538 0.852664 0.96847 0.769559 0.540075 0.848006 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 213
Initial state: 0 0.332225 0.183917 0.648604 0.834583 0.58489 0.883046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102060 episodes
GETTING ACTION FROM:
action 2, numVisits=1097556, meanQ=4.993725, numObservations: 4
action 0, numVisits=4490, meanQ=2.704409, numObservations: 1
action 1, numVisits=11, meanQ=0.262745, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.332225 0.183917 0.648604 0.834583 0.58489 0.883046 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.595413 0.87164 0.780819 0.888507 0.599178 0.821428 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105908 episodes
GETTING ACTION FROM:
action 1, numVisits=1105881, meanQ=5.152800, numObservations: 4
action 0, numVisits=23, meanQ=3.510208, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.595413 0.87164 0.780819 0.888507 0.599178 0.821428 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 215
Initial state: 0 0.64475 0.89326 0.633231 0.846641 0.949905 0.950219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088694 episodes
GETTING ACTION FROM:
action 2, numVisits=1088688, meanQ=4.985450, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.64475 0.89326 0.633231 0.846641 0.949905 0.950219 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=77921, meanQ=5.193585, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1294552 episodes
GETTING ACTION FROM:
action 2, numVisits=1372473, meanQ=5.041878, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.64475 0.89326 0.633231 0.846641 0.949905 0.950219 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 216
Initial state: 0 0.624228 0.844541 0.0614486 0.895832 0.652213 0.832031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087575 episodes
GETTING ACTION FROM:
action 2, numVisits=1087316, meanQ=4.943119, numObservations: 5
action 0, numVisits=212, meanQ=1.382279, numObservations: 1
action -1, numVisits=41, meanQ=0.967932, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 2
Next state: 0 0.624228 0.844541 0.0614486 0.895832 0.652213 0.832031 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=63334, meanQ=7.877526, numObservations: 5
action 1, numVisits=7, meanQ=3.285714, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1401409 episodes
GETTING ACTION FROM:
action 3, numVisits=1464421, meanQ=6.023489, numObservations: 5
action 1, numVisits=327, meanQ=5.592324, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.624228 0.844541 0.0614486 0.895832 0.652213 0.832031 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 217
Initial state: 0 0.158191 0.519963 0.529743 0.876715 0.687367 0.839055 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1081434 episodes
GETTING ACTION FROM:
action 3, numVisits=1081149, meanQ=4.854336, numObservations: 3
action -1, numVisits=281, meanQ=2.588392, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.158191 0.519963 0.529743 0.876715 0.687367 0.839055 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 218
Initial state: 0 0.95114 0.904862 0.601407 0.865651 0.515835 0.83093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090656 episodes
GETTING ACTION FROM:
action 3, numVisits=1090599, meanQ=5.012388, numObservations: 5
action 1, numVisits=42, meanQ=3.835000, numObservations: 3
action 2, numVisits=11, meanQ=2.436364, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.95114 0.904862 0.601407 0.865651 0.515835 0.83093 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=78862, meanQ=5.514135, numObservations: 4
action -1, numVisits=46, meanQ=4.540490, numObservations: 1
action 1, numVisits=11, meanQ=2.272745, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1308476 episodes
GETTING ACTION FROM:
action 3, numVisits=1387331, meanQ=4.805401, numObservations: 5
action -1, numVisits=53, meanQ=3.766796, numObservations: 1
action 1, numVisits=11, meanQ=2.272745, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.95114 0.904862 0.601407 0.865651 0.515835 0.83093 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 219
Initial state: 0 0.638594 0.89921 0.598906 0.918468 0.695728 0.856819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105799 episodes
GETTING ACTION FROM:
action 2, numVisits=1105740, meanQ=4.960210, numObservations: 4
action -1, numVisits=42, meanQ=3.814433, numObservations: 1
action 1, numVisits=9, meanQ=2.333333, numObservations: 3
action 3, numVisits=6, meanQ=0.331667, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.638594 0.89921 0.598906 0.918468 0.695728 0.856819 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 220
Initial state: 0 0.55324 0.858623 0.0883935 0.792937 0.538519 0.831209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1023732 episodes
GETTING ACTION FROM:
action 3, numVisits=1023725, meanQ=4.647514, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.55324 0.858623 0.0883935 0.792937 0.538519 0.831209 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 221
Initial state: 0 0.611698 0.85089 0.838016 0.62291 0.537541 0.835343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091697 episodes
GETTING ACTION FROM:
action 3, numVisits=886118, meanQ=4.992013, numObservations: 5
action 1, numVisits=196586, meanQ=4.967067, numObservations: 5
action 2, numVisits=8944, meanQ=4.907102, numObservations: 5
action -1, numVisits=47, meanQ=3.866765, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.611698 0.85089 0.838016 0.62291 0.537541 0.835343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 222
Initial state: 0 0.807528 0.6089 0.685728 0.868275 0.643055 0.81802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102365 episodes
GETTING ACTION FROM:
action 2, numVisits=1102309, meanQ=4.950154, numObservations: 4
action 0, numVisits=38, meanQ=3.735962, numObservations: 1
action 3, numVisits=10, meanQ=2.399010, numObservations: 3
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.807528 0.6089 0.685728 0.868275 0.643055 0.81802 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.529351 0.838127 0.702533 0.798279 0.569105 0.846959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099960 episodes
GETTING ACTION FROM:
action 2, numVisits=1093748, meanQ=4.933034, numObservations: 4
action -1, numVisits=6181, meanQ=2.824154, numObservations: 1
action 1, numVisits=28, meanQ=1.565007, numObservations: 4
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.529351 0.838127 0.702533 0.798279 0.569105 0.846959 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 224
Initial state: 0 0.671101 0.896349 0.521307 0.604887 0.502723 0.811681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098205 episodes
GETTING ACTION FROM:
action 3, numVisits=1093268, meanQ=4.996910, numObservations: 4
action -1, numVisits=4919, meanQ=2.739351, numObservations: 1
action 1, numVisits=10, meanQ=0.598000, numObservations: 2
action 2, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.671101 0.896349 0.521307 0.604887 0.502723 0.811681 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.541375 0.81165 0.615998 0.808615 0.266157 0.622424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099820 episodes
GETTING ACTION FROM:
action 3, numVisits=1099703, meanQ=4.990833, numObservations: 4
action 0, numVisits=105, meanQ=4.262682, numObservations: 1
action 2, numVisits=9, meanQ=1.886667, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.541375 0.81165 0.615998 0.808615 0.266157 0.622424 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 226
Initial state: 0 0.903897 0.128791 0.613329 0.873168 0.527214 0.897099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1082277 episodes
GETTING ACTION FROM:
action 3, numVisits=1082184, meanQ=4.901898, numObservations: 4
action 0, numVisits=72, meanQ=4.007999, numObservations: 1
action -1, numVisits=19, meanQ=3.025785, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.903897 0.128791 0.613329 0.873168 0.527214 0.897099 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 227
Initial state: 0 0.545929 0.812564 0.305174 0.0945212 0.53988 0.857898 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 765782 episodes
GETTING ACTION FROM:
action 0, numVisits=765740, meanQ=2.880432, numObservations: 1
action 1, numVisits=25, meanQ=1.316412, numObservations: 4
action 2, numVisits=13, meanQ=0.693085, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.545929 0.812564 0.305174 0.0945212 0.53988 0.857898 w: 1
Observation: 0 0 0.836895 0 0.0448808 0 0.853331 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=765139, meanQ=4.934867, numObservations: 3
action 1, numVisits=595, meanQ=4.432619, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1237751 episodes
GETTING ACTION FROM:
action 3, numVisits=2002890, meanQ=4.767098, numObservations: 3
action 1, numVisits=595, meanQ=4.432619, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.545929 0.812564 0.305174 0.0945212 0.53988 0.857898 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 228
Initial state: 0 0.630167 0.844411 0.634516 0.893252 0.92134 0.574795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113953 episodes
GETTING ACTION FROM:
action 3, numVisits=1113921, meanQ=4.932997, numObservations: 3
action -1, numVisits=28, meanQ=3.522882, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.630167 0.844411 0.634516 0.893252 0.92134 0.574795 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 229
Initial state: 0 0.191619 0.209856 0.564138 0.824218 0.624802 0.854667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 763790 episodes
GETTING ACTION FROM:
action -1, numVisits=727398, meanQ=2.956789, numObservations: 1
action 0, numVisits=36388, meanQ=2.923399, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.191619 0.209856 0.564138 0.824218 0.624802 0.854667 w: 1
Observation: 0 0.121985 0 0.510761 0 0.612698 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=727390, meanQ=5.016712, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1224712 episodes
GETTING ACTION FROM:
action 2, numVisits=1952102, meanQ=5.008841, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.191619 0.209856 0.564138 0.824218 0.624802 0.854667 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 230
Initial state: 0 0.673155 0.838042 0.658878 0.804795 0.0585918 0.639916 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099598 episodes
GETTING ACTION FROM:
action 3, numVisits=1094580, meanQ=4.937236, numObservations: 4
action 0, numVisits=4998, meanQ=2.744641, numObservations: 1
action 1, numVisits=14, meanQ=1.140721, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.673155 0.838042 0.658878 0.804795 0.0585918 0.639916 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=86119, meanQ=8.389495, numObservations: 4
action 1, numVisits=67139, meanQ=8.386202, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1403963 episodes
GETTING ACTION FROM:
action 2, numVisits=1017528, meanQ=6.181703, numObservations: 4
action 1, numVisits=539691, meanQ=6.178776, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.673155 0.838042 0.658878 0.804795 0.0585918 0.639916 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 231
Initial state: 0 0.652352 0.855145 0.536867 0.871566 0.442918 0.464708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094342 episodes
GETTING ACTION FROM:
action 2, numVisits=1094292, meanQ=5.004946, numObservations: 5
action 0, numVisits=46, meanQ=3.871717, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.652352 0.855145 0.536867 0.871566 0.442918 0.464708 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.536785 0.845462 0.635047 0.895482 0.455559 0.348688 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1063698 episodes
GETTING ACTION FROM:
action 3, numVisits=966542, meanQ=4.961127, numObservations: 4
action 0, numVisits=96870, meanQ=3.121508, numObservations: 1
action -1, numVisits=249, meanQ=2.713048, numObservations: 1
action 1, numVisits=27, meanQ=1.362967, numObservations: 4
action 2, numVisits=10, meanQ=0.399020, numObservations: 4
action: 3
Next state: 2 0.536785 0.845462 0.635047 0.895482 0.455559 0.348688 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 233
Initial state: 0 0.550109 0.844359 0.328267 0.465293 0.570928 0.890413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092461 episodes
GETTING ACTION FROM:
action 2, numVisits=1092417, meanQ=4.956835, numObservations: 5
action 1, numVisits=26, meanQ=3.286154, numObservations: 3
action 3, numVisits=14, meanQ=2.563593, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.550109 0.844359 0.328267 0.465293 0.570928 0.890413 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=124713, meanQ=8.534947, numObservations: 3
action 3, numVisits=42, meanQ=7.469526, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1413067 episodes
GETTING ACTION FROM:
action 3, numVisits=932789, meanQ=6.380133, numObservations: 5
action 1, numVisits=605031, meanQ=6.323962, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.550109 0.844359 0.328267 0.465293 0.570928 0.890413 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 234
Initial state: 0 0.158292 0.971888 0.66635 0.806369 0.631436 0.868854 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103217 episodes
GETTING ACTION FROM:
action 3, numVisits=1103122, meanQ=4.996327, numObservations: 4
action 0, numVisits=54, meanQ=3.970964, numObservations: 1
action 2, numVisits=36, meanQ=3.705008, numObservations: 4
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.158292 0.971888 0.66635 0.806369 0.631436 0.868854 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=79313, meanQ=5.520070, numObservations: 4
action 2, numVisits=17, meanQ=0.647082, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1313597 episodes
GETTING ACTION FROM:
action 3, numVisits=1392910, meanQ=5.147983, numObservations: 4
action 2, numVisits=17, meanQ=0.647082, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.158292 0.971888 0.66635 0.806369 0.631436 0.868854 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 235
Initial state: 0 0.517766 0.810302 0.812059 0.413641 0.682267 0.859109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099198 episodes
GETTING ACTION FROM:
action 1, numVisits=1099147, meanQ=5.018102, numObservations: 5
action 0, numVisits=29, meanQ=3.601711, numObservations: 1
action 3, numVisits=19, meanQ=2.052111, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.517766 0.810302 0.812059 0.413641 0.682267 0.859109 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 236
Initial state: 0 0.678177 0.85355 0.748612 0.0420404 0.571377 0.848345 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1067216 episodes
GETTING ACTION FROM:
action 3, numVisits=1067199, meanQ=5.073485, numObservations: 5
action 2, numVisits=11, meanQ=2.088182, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.678177 0.85355 0.748612 0.0420404 0.571377 0.848345 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.27841 0.467482 0.610372 0.878941 0.580882 0.847636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095032 episodes
GETTING ACTION FROM:
action 3, numVisits=1083252, meanQ=4.965202, numObservations: 4
action 1, numVisits=11679, meanQ=4.896865, numObservations: 4
action -1, numVisits=87, meanQ=4.169596, numObservations: 1
action 2, numVisits=12, meanQ=2.498342, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.27841 0.467482 0.610372 0.878941 0.580882 0.847636 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.59419 0.851135 0.206285 0.129613 0.6849 0.894757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 642445 episodes
GETTING ACTION FROM:
action 0, numVisits=642434, meanQ=4.143772, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=3, meanQ=-2.966667, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 0
Next state: 0 0.59419 0.851135 0.206285 0.129613 0.6849 0.894757 w: 1
Observation: 0 0 0.751487 0 0.177217 0 0.843277 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=186828, meanQ=7.840547, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1198801 episodes
GETTING ACTION FROM:
action 3, numVisits=1385629, meanQ=5.217010, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.59419 0.851135 0.206285 0.129613 0.6849 0.894757 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 239
Initial state: 0 0.696592 0.894542 0.330675 0.35086 0.569353 0.872313 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113216 episodes
GETTING ACTION FROM:
action 2, numVisits=1113186, meanQ=5.017830, numObservations: 4
action -1, numVisits=22, meanQ=3.352212, numObservations: 1
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.696592 0.894542 0.330675 0.35086 0.569353 0.872313 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=56298, meanQ=7.769887, numObservations: 3
action 1, numVisits=8, meanQ=4.000000, numObservations: 2
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1431362 episodes
GETTING ACTION FROM:
action 3, numVisits=1487651, meanQ=6.136945, numObservations: 3
action 1, numVisits=15, meanQ=3.666667, numObservations: 3
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.696592 0.894542 0.330675 0.35086 0.569353 0.872313 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 240
Initial state: 0 0.113299 0.0610362 0.627666 0.883266 0.579387 0.859078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107546 episodes
GETTING ACTION FROM:
action 1, numVisits=1107471, meanQ=5.160322, numObservations: 4
action 0, numVisits=71, meanQ=4.269981, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.113299 0.0610362 0.627666 0.883266 0.579387 0.859078 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=126402, meanQ=8.539054, numObservations: 3
action 3, numVisits=11, meanQ=6.455464, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1439847 episodes
GETTING ACTION FROM:
action 2, numVisits=1566231, meanQ=6.072866, numObservations: 3
action 3, numVisits=26, meanQ=4.150777, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.113299 0.0610362 0.627666 0.883266 0.579387 0.859078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 241
Initial state: 0 0.689445 0.874898 0.467634 0.98993 0.605192 0.883668 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106298 episodes
GETTING ACTION FROM:
action 2, numVisits=1106292, meanQ=5.012958, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.689445 0.874898 0.467634 0.98993 0.605192 0.883668 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=80814, meanQ=5.546764, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1302839 episodes
GETTING ACTION FROM:
action 2, numVisits=1383653, meanQ=4.899291, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.689445 0.874898 0.467634 0.98993 0.605192 0.883668 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 242
Initial state: 0 0.594421 0.876113 0.646172 0.406039 0.521161 0.851956 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097285 episodes
GETTING ACTION FROM:
action 2, numVisits=1097268, meanQ=4.983608, numObservations: 4
action 3, numVisits=9, meanQ=-1.003322, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.594421 0.876113 0.646172 0.406039 0.521161 0.851956 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153662, meanQ=8.400961, numObservations: 5
action 3, numVisits=17, meanQ=5.353541, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1401338 episodes
GETTING ACTION FROM:
action 1, numVisits=1554994, meanQ=6.101971, numObservations: 5
action 3, numVisits=21, meanQ=4.143343, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.594421 0.876113 0.646172 0.406039 0.521161 0.851956 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 243
Initial state: 0 0.640292 0.848838 0.633379 0.825902 0.247133 0.69948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090461 episodes
GETTING ACTION FROM:
action 2, numVisits=1090397, meanQ=4.964472, numObservations: 5
action 1, numVisits=35, meanQ=3.625149, numObservations: 5
action -1, numVisits=17, meanQ=3.114420, numObservations: 1
action 0, numVisits=11, meanQ=2.500686, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.640292 0.848838 0.633379 0.825902 0.247133 0.69948 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 244
Initial state: 0 0.817013 0.529767 0.626452 0.864678 0.550134 0.859928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 763417 episodes
GETTING ACTION FROM:
action -1, numVisits=763397, meanQ=2.883969, numObservations: 1
action 2, numVisits=11, meanQ=0.634564, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action: -1
Next state: 0 0.817013 0.529767 0.626452 0.864678 0.550134 0.859928 w: 1
Observation: 0 0.77232 0 0.719086 0 0.627383 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=763321, meanQ=4.947633, numObservations: 5
action -1, numVisits=60, meanQ=3.988445, numObservations: 1
action 2, numVisits=12, meanQ=2.317500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1218357 episodes
GETTING ACTION FROM:
action 1, numVisits=1981678, meanQ=5.034166, numObservations: 5
action -1, numVisits=60, meanQ=3.988445, numObservations: 1
action 2, numVisits=12, meanQ=2.317500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.817013 0.529767 0.626452 0.864678 0.550134 0.859928 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 245
Initial state: 0 0.536224 0.862008 0.646108 0.839439 0.656676 0.646701 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1078651 episodes
GETTING ACTION FROM:
action 3, numVisits=1078525, meanQ=4.935290, numObservations: 5
action -1, numVisits=111, meanQ=4.139709, numObservations: 1
action 1, numVisits=12, meanQ=2.317508, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.536224 0.862008 0.646108 0.839439 0.656676 0.646701 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 246
Initial state: 0 0.596159 0.865281 0.612405 0.887277 0.669256 0.127113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107255 episodes
GETTING ACTION FROM:
action 3, numVisits=1107237, meanQ=5.009511, numObservations: 3
action 2, numVisits=13, meanQ=1.769246, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.596159 0.865281 0.612405 0.887277 0.669256 0.127113 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 247
Initial state: 0 0.572659 0.822867 0.0286728 0.915582 0.560989 0.830499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109362 episodes
GETTING ACTION FROM:
action 1, numVisits=1109356, meanQ=5.016668, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.572659 0.822867 0.0286728 0.915582 0.560989 0.830499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.226969 0.085045 0.671234 0.811943 0.568471 0.874673 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088846 episodes
GETTING ACTION FROM:
action 3, numVisits=1088602, meanQ=5.012769, numObservations: 5
action 1, numVisits=239, meanQ=4.510490, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.226969 0.085045 0.671234 0.811943 0.568471 0.874673 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 249
Initial state: 0 0.434218 0.327641 0.612661 0.854154 0.588932 0.814638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117650 episodes
GETTING ACTION FROM:
action 2, numVisits=1117641, meanQ=4.967679, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.434218 0.327641 0.612661 0.854154 0.588932 0.814638 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 250
Initial state: 0 0.568989 0.897912 0.900534 0.490198 0.579601 0.882511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093297 episodes
GETTING ACTION FROM:
action 3, numVisits=1091719, meanQ=5.011160, numObservations: 5
action 0, numVisits=1574, meanQ=2.748810, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.568989 0.897912 0.900534 0.490198 0.579601 0.882511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.69868 0.804332 0.531888 0.806218 0.700954 0.20662 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098493 episodes
GETTING ACTION FROM:
action 2, numVisits=1098377, meanQ=4.950156, numObservations: 5
action 3, numVisits=102, meanQ=4.179905, numObservations: 4
action -1, numVisits=10, meanQ=2.488000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.69868 0.804332 0.531888 0.806218 0.700954 0.20662 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80311, meanQ=4.772088, numObservations: 5
action 0, numVisits=46, meanQ=3.793624, numObservations: 1
action 2, numVisits=13, meanQ=2.846154, numObservations: 2
action 1, numVisits=17, meanQ=2.764129, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 1379077 episodes
GETTING ACTION FROM:
action 3, numVisits=1459388, meanQ=5.888351, numObservations: 5
action 0, numVisits=46, meanQ=3.793624, numObservations: 1
action 2, numVisits=13, meanQ=2.846154, numObservations: 2
action 1, numVisits=17, meanQ=2.764129, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.69868 0.804332 0.531888 0.806218 0.700954 0.20662 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 252
Initial state: 0 0.667075 0.899999 0.619179 0.877834 0.176265 0.691173 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1086283 episodes
GETTING ACTION FROM:
action 3, numVisits=1086276, meanQ=4.999983, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.667075 0.899999 0.619179 0.877834 0.176265 0.691173 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=152957, meanQ=8.386889, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423285 episodes
GETTING ACTION FROM:
action 2, numVisits=1576240, meanQ=6.242697, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.667075 0.899999 0.619179 0.877834 0.176265 0.691173 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 253
Initial state: 0 0.567193 0.840067 0.015664 0.0487221 0.519758 0.811096 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101127 episodes
GETTING ACTION FROM:
action 1, numVisits=1101079, meanQ=4.994183, numObservations: 4
action 2, numVisits=43, meanQ=3.853726, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.567193 0.840067 0.015664 0.0487221 0.519758 0.811096 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.62523 0.813968 0.623947 0.894293 0.886492 0.526136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104688 episodes
GETTING ACTION FROM:
action 3, numVisits=1104378, meanQ=4.948923, numObservations: 4
action 2, numVisits=251, meanQ=4.464073, numObservations: 4
action -1, numVisits=56, meanQ=3.957245, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.62523 0.813968 0.623947 0.894293 0.886492 0.526136 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 255
Initial state: 0 0.15946 0.644156 0.554308 0.846683 0.617194 0.838094 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096540 episodes
GETTING ACTION FROM:
action 2, numVisits=1096483, meanQ=4.954770, numObservations: 5
action 0, numVisits=49, meanQ=3.855048, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.15946 0.644156 0.554308 0.846683 0.617194 0.838094 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 256
Initial state: 0 0.67195 0.855319 0.0896791 0.166287 0.625238 0.804017 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 765304 episodes
GETTING ACTION FROM:
action -1, numVisits=765294, meanQ=2.942732, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.67195 0.855319 0.0896791 0.166287 0.625238 0.804017 w: 1
Observation: 0 0.664508 0 0.0157845 0 0.567427 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=765247, meanQ=4.990300, numObservations: 4
action 1, numVisits=40, meanQ=3.636762, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1228850 episodes
GETTING ACTION FROM:
action 3, numVisits=1994097, meanQ=5.142000, numObservations: 4
action 1, numVisits=40, meanQ=3.636762, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.67195 0.855319 0.0896791 0.166287 0.625238 0.804017 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 257
Initial state: 0 0.592744 0.848875 0.39746 0.687814 0.669788 0.833923 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095790 episodes
GETTING ACTION FROM:
action 2, numVisits=1095742, meanQ=5.011989, numObservations: 5
action 0, numVisits=44, meanQ=3.845466, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.592744 0.848875 0.39746 0.687814 0.669788 0.833923 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=98444, meanQ=8.396262, numObservations: 4
action 3, numVisits=55358, meanQ=8.389411, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1419203 episodes
GETTING ACTION FROM:
action 3, numVisits=890487, meanQ=6.206092, numObservations: 4
action 1, numVisits=682516, meanQ=6.204945, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.592744 0.848875 0.39746 0.687814 0.669788 0.833923 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 258
Initial state: 0 0.93861 0.524739 0.580759 0.82101 0.650924 0.88905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092579 episodes
GETTING ACTION FROM:
action 1, numVisits=1092024, meanQ=5.140301, numObservations: 5
action 3, numVisits=324, meanQ=4.667577, numObservations: 5
action 0, numVisits=228, meanQ=4.651973, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.93861 0.524739 0.580759 0.82101 0.650924 0.88905 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 259
Initial state: 0 0.548691 0.817964 0.582349 0.850424 0.177109 0.262111 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084834 episodes
GETTING ACTION FROM:
action 1, numVisits=1084733, meanQ=4.995355, numObservations: 5
action -1, numVisits=36, meanQ=3.749860, numObservations: 1
action 0, numVisits=35, meanQ=3.721691, numObservations: 1
action 3, numVisits=23, meanQ=2.999135, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 4
action: 1
Next state: 1 0.548691 0.817964 0.582349 0.850424 0.177109 0.262111 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.253119 0.149999 0.572249 0.865482 0.697274 0.809724 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105020 episodes
GETTING ACTION FROM:
action 1, numVisits=1105005, meanQ=4.964131, numObservations: 4
action 3, numVisits=10, meanQ=2.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.253119 0.149999 0.572249 0.865482 0.697274 0.809724 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=181947, meanQ=8.305351, numObservations: 5
action 3, numVisits=9, meanQ=4.775567, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1415508 episodes
GETTING ACTION FROM:
action 2, numVisits=1597408, meanQ=6.599236, numObservations: 5
action 3, numVisits=56, meanQ=5.463930, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.253119 0.149999 0.572249 0.865482 0.697274 0.809724 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 261
Initial state: 0 0.569809 0.816012 0.547788 0.853283 0.415556 0.991349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097219 episodes
GETTING ACTION FROM:
action 1, numVisits=1095883, meanQ=5.003250, numObservations: 5
action 2, numVisits=1226, meanQ=4.795742, numObservations: 4
action 0, numVisits=87, meanQ=4.197357, numObservations: 1
action 3, numVisits=21, meanQ=3.379538, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.569809 0.816012 0.547788 0.853283 0.415556 0.991349 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.624959 0.875047 0.64207 0.864628 0.359328 0.774623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088084 episodes
GETTING ACTION FROM:
action 2, numVisits=1088038, meanQ=4.932301, numObservations: 4
action 0, numVisits=33, meanQ=3.542264, numObservations: 1
action 1, numVisits=9, meanQ=2.333333, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.624959 0.875047 0.64207 0.864628 0.359328 0.774623 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.604235 0.849547 0.690502 0.817732 0.282422 0.197316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108134 episodes
GETTING ACTION FROM:
action 2, numVisits=1107921, meanQ=5.004610, numObservations: 4
action 0, numVisits=116, meanQ=4.304912, numObservations: 1
action -1, numVisits=49, meanQ=3.910230, numObservations: 1
action 3, numVisits=38, meanQ=3.679221, numObservations: 4
action 1, numVisits=10, meanQ=1.990020, numObservations: 3
action: 2
Next state: 1 0.604235 0.849547 0.690502 0.817732 0.282422 0.197316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.674399 0.876208 0.738999 0.77728 0.549694 0.812165 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1085764 episodes
GETTING ACTION FROM:
action 1, numVisits=1085757, meanQ=4.987667, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.674399 0.876208 0.738999 0.77728 0.549694 0.812165 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.608126 0.876579 0.536793 0.841373 0.802761 0.925517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095364 episodes
GETTING ACTION FROM:
action 1, numVisits=1095318, meanQ=4.956027, numObservations: 5
action -1, numVisits=37, meanQ=3.734522, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.608126 0.876579 0.536793 0.841373 0.802761 0.925517 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.641957 0.880188 0.629572 0.799481 0.507142 0.853623 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113407 episodes
GETTING ACTION FROM:
action 3, numVisits=1113389, meanQ=5.024443, numObservations: 3
action 2, numVisits=13, meanQ=2.222308, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.641957 0.880188 0.629572 0.799481 0.507142 0.853623 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.639522 0.854184 0.411686 0.939686 0.604606 0.832249 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122445 episodes
GETTING ACTION FROM:
action 2, numVisits=1122419, meanQ=4.990055, numObservations: 3
action -1, numVisits=22, meanQ=3.345662, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.639522 0.854184 0.411686 0.939686 0.604606 0.832249 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81842, meanQ=5.350277, numObservations: 3
action -1, numVisits=34, meanQ=4.122853, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1251657 episodes
GETTING ACTION FROM:
action 2, numVisits=1333495, meanQ=5.082998, numObservations: 4
action -1, numVisits=38, meanQ=3.733777, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.639522 0.854184 0.411686 0.939686 0.604606 0.832249 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=21000, meanQ=6.754960, numObservations: 4
action 2, numVisits=8673, meanQ=5.564888, numObservations: 4
action 3, numVisits=8, meanQ=3.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1428143 episodes
GETTING ACTION FROM:
action 3, numVisits=1017848, meanQ=6.195530, numObservations: 5
action 1, numVisits=431300, meanQ=6.035455, numObservations: 4
action 2, numVisits=8673, meanQ=5.564888, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.639522 0.854184 0.411686 0.939686 0.604606 0.832249 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 268
Initial state: 0 0.867336 0.147928 0.68355 0.827576 0.547088 0.895083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 785119 episodes
GETTING ACTION FROM:
action 0, numVisits=785100, meanQ=4.786498, numObservations: 3
action 1, numVisits=13, meanQ=0.692331, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.867336 0.147928 0.68355 0.827576 0.547088 0.895083 w: 1
Observation: 0 0 0.186077 0 0.764807 0 0.851218 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=111033, meanQ=8.436080, numObservations: 4
action 2, numVisits=61453, meanQ=8.427473, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1221756 episodes
GETTING ACTION FROM:
action 2, numVisits=795810, meanQ=5.628731, numObservations: 4
action 3, numVisits=598363, meanQ=5.627167, numObservations: 4
action 0, numVisits=69, meanQ=4.725891, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.867336 0.147928 0.68355 0.827576 0.547088 0.895083 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 269
Initial state: 0 0.659452 0.806634 0.8416 0.693501 0.53195 0.873525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 766397 episodes
GETTING ACTION FROM:
action -1, numVisits=763924, meanQ=2.899060, numObservations: 1
action 0, numVisits=2469, meanQ=2.759307, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.659452 0.806634 0.8416 0.693501 0.53195 0.873525 w: 1
Observation: 0 0.725491 0 0.913692 0 0.493485 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=763895, meanQ=4.940212, numObservations: 4
action 2, numVisits=20, meanQ=2.999020, numObservations: 3
action 3, numVisits=4, meanQ=-0.504975, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1221855 episodes
GETTING ACTION FROM:
action 1, numVisits=1985750, meanQ=4.918376, numObservations: 4
action 2, numVisits=20, meanQ=2.999020, numObservations: 3
action 3, numVisits=4, meanQ=-0.504975, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.659452 0.806634 0.8416 0.693501 0.53195 0.873525 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 270
Initial state: 0 0.408484 0.264491 0.583006 0.890076 0.582057 0.866478 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090148 episodes
GETTING ACTION FROM:
action 2, numVisits=1081362, meanQ=4.981407, numObservations: 5
action -1, numVisits=8768, meanQ=2.952537, numObservations: 1
action 3, numVisits=14, meanQ=1.140721, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 0 0.408484 0.264491 0.583006 0.890076 0.582057 0.866478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=79964, meanQ=5.205442, numObservations: 3
action 0, numVisits=58, meanQ=4.219903, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1314554 episodes
GETTING ACTION FROM:
action 2, numVisits=1394517, meanQ=5.138993, numObservations: 3
action 0, numVisits=59, meanQ=4.114481, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.408484 0.264491 0.583006 0.890076 0.582057 0.866478 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 271
Initial state: 0 0.521351 0.813859 0.518826 0.84398 0.979288 0.0379185 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100835 episodes
GETTING ACTION FROM:
action 2, numVisits=1100828, meanQ=4.947621, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.521351 0.813859 0.518826 0.84398 0.979288 0.0379185 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 272
Initial state: 0 0.463118 0.551782 0.692921 0.830673 0.519684 0.807661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098177 episodes
GETTING ACTION FROM:
action 2, numVisits=1098094, meanQ=4.941684, numObservations: 5
action -1, numVisits=79, meanQ=4.095109, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.463118 0.551782 0.692921 0.830673 0.519684 0.807661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 273
Initial state: 0 0.607293 0.810852 0.89555 0.144053 0.669419 0.840401 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1071989 episodes
GETTING ACTION FROM:
action 1, numVisits=1071896, meanQ=4.865838, numObservations: 4
action 0, numVisits=88, meanQ=4.074769, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.607293 0.810852 0.89555 0.144053 0.669419 0.840401 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.557006 0.879507 0.829973 0.452259 0.592242 0.825482 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108382 episodes
GETTING ACTION FROM:
action 2, numVisits=1108370, meanQ=5.157813, numObservations: 4
action 1, numVisits=7, meanQ=0.428571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.557006 0.879507 0.829973 0.452259 0.592242 0.825482 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 275
Initial state: 0 0.701156 0.111249 0.594789 0.860326 0.587276 0.890294 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108597 episodes
GETTING ACTION FROM:
action 1, numVisits=1107237, meanQ=4.974414, numObservations: 3
action 3, numVisits=1351, meanQ=4.766271, numObservations: 4
action 2, numVisits=5, meanQ=1.000020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.701156 0.111249 0.594789 0.860326 0.587276 0.890294 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 276
Initial state: 0 0.67222 0.898327 0.313538 0.147271 0.62682 0.807849 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105236 episodes
GETTING ACTION FROM:
action 3, numVisits=1105003, meanQ=5.004403, numObservations: 4
action 0, numVisits=118, meanQ=4.322875, numObservations: 1
action 2, numVisits=95, meanQ=4.000952, numObservations: 4
action 1, numVisits=18, meanQ=3.206122, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.67222 0.898327 0.313538 0.147271 0.62682 0.807849 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.212262 0.90931 0.605569 0.828422 0.524214 0.83744 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098345 episodes
GETTING ACTION FROM:
action 2, numVisits=1097985, meanQ=4.929928, numObservations: 4
action -1, numVisits=350, meanQ=1.863308, numObservations: 1
action 1, numVisits=7, meanQ=-0.429986, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.212262 0.90931 0.605569 0.828422 0.524214 0.83744 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.956729 0.231776 0.522669 0.887761 0.647352 0.841306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110523 episodes
GETTING ACTION FROM:
action 2, numVisits=1110472, meanQ=5.013378, numObservations: 4
action 0, numVisits=47, meanQ=3.910932, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.956729 0.231776 0.522669 0.887761 0.647352 0.841306 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 279
Initial state: 0 0.602985 0.881268 0.0330841 0.986448 0.542287 0.88101 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090084 episodes
GETTING ACTION FROM:
action 2, numVisits=1090049, meanQ=4.996001, numObservations: 5
action 1, numVisits=30, meanQ=3.403000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.602985 0.881268 0.0330841 0.986448 0.542287 0.88101 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=78643, meanQ=5.201262, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1283621 episodes
GETTING ACTION FROM:
action 2, numVisits=1362264, meanQ=5.351294, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.602985 0.881268 0.0330841 0.986448 0.542287 0.88101 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=174956, meanQ=8.499598, numObservations: 3
action 3, numVisits=205, meanQ=6.581606, numObservations: 4
action 2, numVisits=6, meanQ=4.953333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1464114 episodes
GETTING ACTION FROM:
action 1, numVisits=1539763, meanQ=6.254597, numObservations: 3
action 3, numVisits=99495, meanQ=6.236582, numObservations: 4
action 2, numVisits=21, meanQ=4.414762, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.602985 0.881268 0.0330841 0.986448 0.542287 0.88101 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 280
Initial state: 0 0.53085 0.877212 0.569423 0.15635 0.69583 0.807559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095640 episodes
GETTING ACTION FROM:
action 1, numVisits=1095535, meanQ=4.954115, numObservations: 4
action -1, numVisits=54, meanQ=3.934119, numObservations: 1
action 0, numVisits=48, meanQ=3.844307, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.53085 0.877212 0.569423 0.15635 0.69583 0.807559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.4595 0.979574 0.673103 0.89608 0.688942 0.855227 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095665 episodes
GETTING ACTION FROM:
action 1, numVisits=1095603, meanQ=4.959810, numObservations: 5
action 2, numVisits=31, meanQ=3.512590, numObservations: 3
action -1, numVisits=25, meanQ=3.443493, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.4595 0.979574 0.673103 0.89608 0.688942 0.855227 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=79655, meanQ=4.833752, numObservations: 3
action 0, numVisits=146, meanQ=4.250173, numObservations: 1
action -1, numVisits=70, meanQ=4.031893, numObservations: 1
action 2, numVisits=41, meanQ=2.645620, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1441115 episodes
GETTING ACTION FROM:
action 3, numVisits=1520770, meanQ=6.055949, numObservations: 3
action 0, numVisits=146, meanQ=4.250173, numObservations: 1
action -1, numVisits=70, meanQ=4.031893, numObservations: 1
action 2, numVisits=41, meanQ=2.645620, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.4595 0.979574 0.673103 0.89608 0.688942 0.855227 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 282
Initial state: 0 0.683242 0.833686 0.598401 0.896072 0.800849 0.803886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105226 episodes
GETTING ACTION FROM:
action 3, numVisits=1105170, meanQ=5.131649, numObservations: 4
action -1, numVisits=23, meanQ=3.459309, numObservations: 1
action 0, numVisits=21, meanQ=3.376748, numObservations: 1
action 1, numVisits=11, meanQ=1.716364, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.683242 0.833686 0.598401 0.896072 0.800849 0.803886 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 283
Initial state: 0 0.502485 0.896331 0.677581 0.353806 0.501614 0.858896 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101327 episodes
GETTING ACTION FROM:
action 3, numVisits=1101290, meanQ=5.030203, numObservations: 4
action -1, numVisits=30, meanQ=3.626636, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.502485 0.896331 0.677581 0.353806 0.501614 0.858896 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.579346 0.884306 0.249591 0.308839 0.642493 0.816532 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103749 episodes
GETTING ACTION FROM:
action 3, numVisits=1103718, meanQ=4.952174, numObservations: 4
action -1, numVisits=21, meanQ=3.305608, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.579346 0.884306 0.249591 0.308839 0.642493 0.816532 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 285
Initial state: 0 0.927456 0.275453 0.554288 0.807299 0.620888 0.837636 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088613 episodes
GETTING ACTION FROM:
action 1, numVisits=1088529, meanQ=4.940626, numObservations: 4
action 0, numVisits=78, meanQ=4.032673, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.927456 0.275453 0.554288 0.807299 0.620888 0.837636 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48483, meanQ=5.275541, numObservations: 3
action -1, numVisits=31565, meanQ=3.518932, numObservations: 1
action 0, numVisits=476, meanQ=3.245903, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1294254 episodes
GETTING ACTION FROM:
action 1, numVisits=1342737, meanQ=5.112527, numObservations: 4
action -1, numVisits=31565, meanQ=3.518932, numObservations: 1
action 0, numVisits=476, meanQ=3.245903, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.927456 0.275453 0.554288 0.807299 0.620888 0.837636 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 286
Initial state: 0 0.695614 0.838848 0.556211 0.890393 0.400318 0.0210276 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091691 episodes
GETTING ACTION FROM:
action 3, numVisits=1091685, meanQ=4.968413, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.695614 0.838848 0.556211 0.890393 0.400318 0.0210276 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=125978, meanQ=8.546689, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1437637 episodes
GETTING ACTION FROM:
action 1, numVisits=1563613, meanQ=6.058504, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.695614 0.838848 0.556211 0.890393 0.400318 0.0210276 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 287
Initial state: 0 0.597755 0.893793 0.226035 0.636714 0.575628 0.807018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108299 episodes
GETTING ACTION FROM:
action 3, numVisits=1108290, meanQ=4.997315, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.597755 0.893793 0.226035 0.636714 0.575628 0.807018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.665944 0.812702 0.615033 0.819161 0.884575 0.0859291 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093065 episodes
GETTING ACTION FROM:
action 1, numVisits=1093007, meanQ=4.959426, numObservations: 5
action 0, numVisits=24, meanQ=3.339642, numObservations: 1
action -1, numVisits=15, meanQ=2.878643, numObservations: 1
action 3, numVisits=12, meanQ=2.333342, numObservations: 3
action 2, numVisits=7, meanQ=1.570000, numObservations: 1
action: 1
Next state: 1 0.665944 0.812702 0.615033 0.819161 0.884575 0.0859291 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 289
Initial state: 0 0.6001 0.854726 0.776855 0.714352 0.640919 0.80752 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090993 episodes
GETTING ACTION FROM:
action 2, numVisits=1090954, meanQ=4.971045, numObservations: 5
action 0, numVisits=31, meanQ=3.635642, numObservations: 1
action 3, numVisits=5, meanQ=-0.201980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.6001 0.854726 0.776855 0.714352 0.640919 0.80752 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80493, meanQ=4.928334, numObservations: 4
action 1, numVisits=21, meanQ=2.896195, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1415923 episodes
GETTING ACTION FROM:
action 3, numVisits=1496416, meanQ=5.700508, numObservations: 4
action 1, numVisits=21, meanQ=2.896195, numObservations: 3
action 2, numVisits=4, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.6001 0.854726 0.776855 0.714352 0.640919 0.80752 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 290
Initial state: 0 0.887194 0.838052 0.647919 0.880771 0.562442 0.835626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094233 episodes
GETTING ACTION FROM:
action 3, numVisits=1094222, meanQ=4.925639, numObservations: 4
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.887194 0.838052 0.647919 0.880771 0.562442 0.835626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.156073 0.435174 0.515074 0.801444 0.580527 0.882955 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 758654 episodes
GETTING ACTION FROM:
action 0, numVisits=641734, meanQ=3.093740, numObservations: 1
action -1, numVisits=116916, meanQ=2.806064, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.156073 0.435174 0.515074 0.801444 0.580527 0.882955 w: 1
Observation: 0 0 0.424987 0 0.74988 0 0.841866 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=641630, meanQ=5.152493, numObservations: 4
action 2, numVisits=91, meanQ=4.238464, numObservations: 5
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1223921 episodes
GETTING ACTION FROM:
action 1, numVisits=1865551, meanQ=5.219668, numObservations: 4
action 2, numVisits=91, meanQ=4.238464, numObservations: 5
action 3, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.156073 0.435174 0.515074 0.801444 0.580527 0.882955 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=117213, meanQ=8.541233, numObservations: 3
action 3, numVisits=98438, meanQ=8.538563, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1414451 episodes
GETTING ACTION FROM:
action 3, numVisits=1136381, meanQ=6.510348, numObservations: 4
action 2, numVisits=493719, meanQ=6.506612, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.156073 0.435174 0.515074 0.801444 0.580527 0.882955 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 292
Initial state: 0 0.624673 0.881607 0.365835 0.826627 0.578177 0.86526 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1079315 episodes
GETTING ACTION FROM:
action 2, numVisits=1079289, meanQ=4.859122, numObservations: 3
action 0, numVisits=20, meanQ=3.156336, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.624673 0.881607 0.365835 0.826627 0.578177 0.86526 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=178202, meanQ=8.311652, numObservations: 4
action 3, numVisits=7, meanQ=5.284300, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1418455 episodes
GETTING ACTION FROM:
action 1, numVisits=1596621, meanQ=6.522930, numObservations: 4
action 3, numVisits=41, meanQ=5.292200, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.624673 0.881607 0.365835 0.826627 0.578177 0.86526 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 293
Initial state: 0 0.50858 0.814779 0.937352 0.816613 0.552859 0.848508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088076 episodes
GETTING ACTION FROM:
action 3, numVisits=1088014, meanQ=5.176336, numObservations: 5
action 1, numVisits=29, meanQ=3.757938, numObservations: 3
action 0, numVisits=26, meanQ=3.697596, numObservations: 2
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.50858 0.814779 0.937352 0.816613 0.552859 0.848508 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.683105 0.0100162 0.513523 0.887833 0.644799 0.830679 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101177 episodes
GETTING ACTION FROM:
action 1, numVisits=1101169, meanQ=5.208232, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.683105 0.0100162 0.513523 0.887833 0.644799 0.830679 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=64853, meanQ=7.924733, numObservations: 5
action 2, numVisits=6, meanQ=4.665017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1390449 episodes
GETTING ACTION FROM:
action 3, numVisits=1357408, meanQ=6.153555, numObservations: 5
action 2, numVisits=97898, meanQ=6.135702, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.683105 0.0100162 0.513523 0.887833 0.644799 0.830679 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 295
Initial state: 0 0.536016 0.857168 0.574469 0.872295 0.12453 0.334825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 762889 episodes
GETTING ACTION FROM:
action 0, numVisits=762868, meanQ=2.972982, numObservations: 1
action 1, numVisits=8, meanQ=-0.001250, numObservations: 2
action 2, numVisits=8, meanQ=-0.512500, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 0
Next state: 0 0.536016 0.857168 0.574469 0.872295 0.12453 0.334825 w: 1
Observation: 0 0 0.930625 0 0.829059 0 0.239088 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=762814, meanQ=5.025817, numObservations: 4
action 0, numVisits=49, meanQ=3.970647, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1224338 episodes
GETTING ACTION FROM:
action 1, numVisits=1987150, meanQ=4.981658, numObservations: 4
action 0, numVisits=51, meanQ=3.907215, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.536016 0.857168 0.574469 0.872295 0.12453 0.334825 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 296
Initial state: 0 0.69926 0.83658 0.569603 0.863149 0.878847 0.516776 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095710 episodes
GETTING ACTION FROM:
action 1, numVisits=1095665, meanQ=4.960573, numObservations: 5
action -1, numVisits=40, meanQ=3.767014, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.69926 0.83658 0.569603 0.863149 0.878847 0.516776 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 297
Initial state: 0 0.502815 0.8554 0.757742 0.71461 0.651502 0.898442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094472 episodes
GETTING ACTION FROM:
action 2, numVisits=1094291, meanQ=4.945130, numObservations: 4
action -1, numVisits=70, meanQ=4.052088, numObservations: 1
action 0, numVisits=56, meanQ=3.942690, numObservations: 1
action 1, numVisits=54, meanQ=3.843990, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.502815 0.8554 0.757742 0.71461 0.651502 0.898442 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 298
Initial state: 0 0.569373 0.833319 0.558779 0.00509215 0.626455 0.827461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103087 episodes
GETTING ACTION FROM:
action 1, numVisits=1103068, meanQ=4.933339, numObservations: 4
action -1, numVisits=15, meanQ=2.744295, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.569373 0.833319 0.558779 0.00509215 0.626455 0.827461 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 299
Initial state: 0 0.648587 0.891411 0.846146 0.0107573 0.587729 0.87015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1120031 episodes
GETTING ACTION FROM:
action 1, numVisits=1119790, meanQ=5.017721, numObservations: 3
action 2, numVisits=172, meanQ=4.169659, numObservations: 4
action -1, numVisits=66, meanQ=4.071277, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.648587 0.891411 0.846146 0.0107573 0.587729 0.87015 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 300
Initial state: 0 0.538677 0.882651 0.544385 0.847745 0.525724 0.260012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107812 episodes
GETTING ACTION FROM:
action 1, numVisits=1107806, meanQ=5.007810, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.538677 0.882651 0.544385 0.847745 0.525724 0.260012 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=80592, meanQ=5.507926, numObservations: 4
action 0, numVisits=26, meanQ=4.200542, numObservations: 1
action 3, numVisits=9, meanQ=2.788889, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1292856 episodes
GETTING ACTION FROM:
action 1, numVisits=1373446, meanQ=5.354575, numObservations: 5
action 0, numVisits=28, meanQ=3.757646, numObservations: 1
action 3, numVisits=9, meanQ=2.788889, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.538677 0.882651 0.544385 0.847745 0.525724 0.260012 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 301
Initial state: 0 0.553419 0.813877 0.342497 0.274865 0.501362 0.897767 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104909 episodes
GETTING ACTION FROM:
action 2, numVisits=1104826, meanQ=5.012123, numObservations: 5
action -1, numVisits=79, meanQ=4.161764, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.553419 0.813877 0.342497 0.274865 0.501362 0.897767 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=126336, meanQ=8.545769, numObservations: 3
action 1, numVisits=16, meanQ=6.623756, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1438576 episodes
GETTING ACTION FROM:
action 3, numVisits=1564803, meanQ=6.210483, numObservations: 3
action 1, numVisits=123, meanQ=5.534960, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.553419 0.813877 0.342497 0.274865 0.501362 0.897767 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 302
Initial state: 0 0.171947 0.67135 0.514146 0.866262 0.52555 0.816184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114721 episodes
GETTING ACTION FROM:
action 2, numVisits=1113999, meanQ=4.959937, numObservations: 3
action 0, numVisits=717, meanQ=2.460458, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.171947 0.67135 0.514146 0.866262 0.52555 0.816184 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 303
Initial state: 0 0.527666 0.812875 0.537482 0.859629 0.423052 0.400148 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1124616 episodes
GETTING ACTION FROM:
action 2, numVisits=1124499, meanQ=5.009066, numObservations: 3
action 0, numVisits=62, meanQ=4.058035, numObservations: 1
action -1, numVisits=53, meanQ=3.979597, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.527666 0.812875 0.537482 0.859629 0.423052 0.400148 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.99846 0.201015 0.634199 0.834097 0.537092 0.80115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 796940 episodes
GETTING ACTION FROM:
action 2, numVisits=117879, meanQ=4.962236, numObservations: 4
action 0, numVisits=679054, meanQ=2.938475, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.99846 0.201015 0.634199 0.834097 0.537092 0.80115 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.780988 0.239112 0.62428 0.872023 0.594246 0.835525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111500 episodes
GETTING ACTION FROM:
action 1, numVisits=1111404, meanQ=5.008711, numObservations: 4
action 0, numVisits=75, meanQ=3.698323, numObservations: 1
action -1, numVisits=18, meanQ=2.979366, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.780988 0.239112 0.62428 0.872023 0.594246 0.835525 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 306
Initial state: 0 0.554923 0.0133088 0.576848 0.822411 0.663874 0.860186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 688832 episodes
GETTING ACTION FROM:
action 0, numVisits=688821, meanQ=5.003438, numObservations: 3
action 2, numVisits=7, meanQ=-1.287143, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 0
Next state: 0 0.554923 0.0133088 0.576848 0.822411 0.663874 0.860186 w: 1
Observation: 0 0 0.098358 0 0.784074 0 0.768412 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=212656, meanQ=8.179173, numObservations: 5
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1194623 episodes
GETTING ACTION FROM:
action 2, numVisits=1407277, meanQ=5.577102, numObservations: 5
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.554923 0.0133088 0.576848 0.822411 0.663874 0.860186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 307
Initial state: 0 0.655525 0.839855 0.141341 0.183414 0.508199 0.835279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1086575 episodes
GETTING ACTION FROM:
action 2, numVisits=1086569, meanQ=4.958230, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.655525 0.839855 0.141341 0.183414 0.508199 0.835279 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=143327, meanQ=8.388884, numObservations: 3
action 3, numVisits=8582, meanQ=8.357493, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1434028 episodes
GETTING ACTION FROM:
action 1, numVisits=1528171, meanQ=6.352206, numObservations: 3
action 3, numVisits=57764, meanQ=6.326391, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.655525 0.839855 0.141341 0.183414 0.508199 0.835279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 308
Initial state: 0 0.594466 0.820841 0.500116 0.826371 0.711551 0.539959 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098594 episodes
GETTING ACTION FROM:
action 2, numVisits=1098536, meanQ=4.945483, numObservations: 4
action 0, numVisits=29, meanQ=3.542095, numObservations: 1
action -1, numVisits=19, meanQ=3.174683, numObservations: 1
action 1, numVisits=9, meanQ=2.333344, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.594466 0.820841 0.500116 0.826371 0.711551 0.539959 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80207, meanQ=4.753534, numObservations: 5
action 0, numVisits=229, meanQ=4.295184, numObservations: 1
action 2, numVisits=13, meanQ=2.683854, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1401582 episodes
GETTING ACTION FROM:
action 3, numVisits=1481789, meanQ=5.947990, numObservations: 5
action 0, numVisits=229, meanQ=4.295184, numObservations: 1
action 2, numVisits=13, meanQ=2.683854, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.594466 0.820841 0.500116 0.826371 0.711551 0.539959 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 309
Initial state: 0 0.0218844 0.522492 0.660115 0.81487 0.531566 0.860638 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100562 episodes
GETTING ACTION FROM:
action 3, numVisits=1100491, meanQ=5.013018, numObservations: 4
action 0, numVisits=43, meanQ=1.907547, numObservations: 2
action 1, numVisits=20, meanQ=1.495010, numObservations: 4
action 2, numVisits=6, meanQ=-0.669983, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.0218844 0.522492 0.660115 0.81487 0.531566 0.860638 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.524351 0.836501 0.363708 0.641383 0.622936 0.863145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105679 episodes
GETTING ACTION FROM:
action 1, numVisits=1099667, meanQ=5.004014, numObservations: 4
action -1, numVisits=6008, meanQ=2.813557, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.524351 0.836501 0.363708 0.641383 0.622936 0.863145 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 311
Initial state: 0 0.219633 0.519237 0.514321 0.823639 0.517463 0.886293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101802 episodes
GETTING ACTION FROM:
action 2, numVisits=1101754, meanQ=4.978315, numObservations: 4
action 0, numVisits=41, meanQ=3.814971, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.219633 0.519237 0.514321 0.823639 0.517463 0.886293 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 312
Initial state: 0 0.666895 0.87752 0.921478 0.0706138 0.538424 0.82292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116424 episodes
GETTING ACTION FROM:
action 3, numVisits=1116345, meanQ=4.968256, numObservations: 3
action -1, numVisits=56, meanQ=3.954878, numObservations: 1
action 2, numVisits=16, meanQ=2.123131, numObservations: 3
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.666895 0.87752 0.921478 0.0706138 0.538424 0.82292 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 313
Initial state: 0 0.59682 0.874113 0.590607 0.423883 0.598942 0.880976 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093381 episodes
GETTING ACTION FROM:
action 3, numVisits=1093315, meanQ=5.018150, numObservations: 5
action -1, numVisits=38, meanQ=3.801587, numObservations: 1
action 1, numVisits=25, meanQ=3.238808, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.59682 0.874113 0.590607 0.423883 0.598942 0.880976 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 314
Initial state: 0 0.509684 0.891571 0.682721 0.256651 0.633953 0.80011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096817 episodes
GETTING ACTION FROM:
action 2, numVisits=1096811, meanQ=5.003584, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.509684 0.891571 0.682721 0.256651 0.633953 0.80011 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=153719, meanQ=8.387308, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1415116 episodes
GETTING ACTION FROM:
action 1, numVisits=1568833, meanQ=6.004462, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.509684 0.891571 0.682721 0.256651 0.633953 0.80011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 315
Initial state: 0 0.683369 0.825589 0.533846 0.853452 0.952489 0.467695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1080336 episodes
GETTING ACTION FROM:
action 1, numVisits=1080327, meanQ=5.002051, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.683369 0.825589 0.533846 0.853452 0.952489 0.467695 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.601943 0.837758 0.821562 0.0595692 0.534872 0.801232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107588 episodes
GETTING ACTION FROM:
action 2, numVisits=1107511, meanQ=5.011679, numObservations: 4
action 0, numVisits=73, meanQ=4.141655, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.601943 0.837758 0.821562 0.0595692 0.534872 0.801232 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 317
Initial state: 0 0.627532 0.800973 0.481145 0.429151 0.635538 0.813153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097369 episodes
GETTING ACTION FROM:
action 2, numVisits=1086307, meanQ=4.993466, numObservations: 5
action 0, numVisits=10986, meanQ=3.034616, numObservations: 1
action -1, numVisits=73, meanQ=2.345822, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 0 0.627532 0.800973 0.481145 0.429151 0.635538 0.813153 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=123574, meanQ=8.536409, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1409882 episodes
GETTING ACTION FROM:
action 1, numVisits=1533454, meanQ=6.190481, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.627532 0.800973 0.481145 0.429151 0.635538 0.813153 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 318
Initial state: 0 0.611718 0.868071 0.696467 0.864155 0.789729 0.229087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121579 episodes
GETTING ACTION FROM:
action 1, numVisits=1121550, meanQ=5.028323, numObservations: 3
action 2, numVisits=24, meanQ=3.411671, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.611718 0.868071 0.696467 0.864155 0.789729 0.229087 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 319
Initial state: 0 0.698335 0.870786 0.508087 0.829196 0.846065 0.00101802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 794846 episodes
GETTING ACTION FROM:
action 0, numVisits=783903, meanQ=5.965570, numObservations: 3
action 3, numVisits=10929, meanQ=5.030909, numObservations: 4
action 1, numVisits=11, meanQ=0.635455, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.698335 0.870786 0.508087 0.829196 0.846065 0.00101802 w: 1
Observation: 0 0 0.890303 0 0.816604 0 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=255435, meanQ=8.097993, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1221577 episodes
GETTING ACTION FROM:
action 1, numVisits=1477010, meanQ=5.735563, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.698335 0.870786 0.508087 0.829196 0.846065 0.00101802 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 320
Initial state: 0 0.648294 0.822462 0.159759 0.327736 0.664912 0.800153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108399 episodes
GETTING ACTION FROM:
action 1, numVisits=1108286, meanQ=5.024373, numObservations: 4
action -1, numVisits=56, meanQ=4.002394, numObservations: 1
action 3, numVisits=54, meanQ=3.110921, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.648294 0.822462 0.159759 0.327736 0.664912 0.800153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=82016, meanQ=5.561858, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1295979 episodes
GETTING ACTION FROM:
action 1, numVisits=1377995, meanQ=5.256926, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.648294 0.822462 0.159759 0.327736 0.664912 0.800153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 321
Initial state: 0 0.222157 0.491922 0.523775 0.846316 0.592271 0.828622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090201 episodes
GETTING ACTION FROM:
action 3, numVisits=1090093, meanQ=5.038038, numObservations: 5
action -1, numVisits=66, meanQ=4.099167, numObservations: 1
action 0, numVisits=33, meanQ=3.742783, numObservations: 1
action 1, numVisits=7, meanQ=2.127143, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 3
Next state: 1 0.222157 0.491922 0.523775 0.846316 0.592271 0.828622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 322
Initial state: 0 0.347088 0.483651 0.689414 0.878024 0.664716 0.872672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105556 episodes
GETTING ACTION FROM:
action 3, numVisits=1105405, meanQ=5.013385, numObservations: 4
action -1, numVisits=112, meanQ=4.309091, numObservations: 1
action 2, numVisits=36, meanQ=3.266947, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.347088 0.483651 0.689414 0.878024 0.664716 0.872672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.670677 0.815816 0.685637 0.838119 0.430332 0.796625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096043 episodes
GETTING ACTION FROM:
action 3, numVisits=1084619, meanQ=4.983267, numObservations: 4
action -1, numVisits=11413, meanQ=3.046163, numObservations: 1
action 1, numVisits=7, meanQ=0.427171, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 0 0.670677 0.815816 0.685637 0.838119 0.430332 0.796625 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=97626, meanQ=8.371169, numObservations: 4
action 1, numVisits=54576, meanQ=8.361778, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1417237 episodes
GETTING ACTION FROM:
action 1, numVisits=1101727, meanQ=6.361263, numObservations: 4
action 2, numVisits=467710, meanQ=6.357381, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.670677 0.815816 0.685637 0.838119 0.430332 0.796625 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 324
Initial state: 0 0.511465 0.899423 0.853976 0.325106 0.600938 0.859784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094010 episodes
GETTING ACTION FROM:
action 1, numVisits=1093946, meanQ=4.947090, numObservations: 5
action 0, numVisits=55, meanQ=3.942169, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.511465 0.899423 0.853976 0.325106 0.600938 0.859784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 325
Initial state: 0 0.554388 0.804181 0.0784329 0.268902 0.559226 0.81254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1064181 episodes
GETTING ACTION FROM:
action 1, numVisits=1029942, meanQ=5.029582, numObservations: 4
action 0, numVisits=34094, meanQ=2.996662, numObservations: 1
action -1, numVisits=134, meanQ=2.463989, numObservations: 1
action 2, numVisits=10, meanQ=0.598000, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.554388 0.804181 0.0784329 0.268902 0.559226 0.81254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 326
Initial state: 0 0.927317 0.947555 0.621722 0.852894 0.558252 0.807222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116239 episodes
GETTING ACTION FROM:
action 2, numVisits=1116231, meanQ=4.949233, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.927317 0.947555 0.621722 0.852894 0.558252 0.807222 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 327
Initial state: 0 0.508138 0.841619 0.441105 0.236546 0.654854 0.821483 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119590 episodes
GETTING ACTION FROM:
action 1, numVisits=1111496, meanQ=5.016615, numObservations: 3
action -1, numVisits=8090, meanQ=2.922959, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.508138 0.841619 0.441105 0.236546 0.654854 0.821483 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.361636 0.794405 0.631636 0.823613 0.685246 0.877369 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110421 episodes
GETTING ACTION FROM:
action 3, numVisits=1110340, meanQ=5.004591, numObservations: 4
action -1, numVisits=48, meanQ=3.894023, numObservations: 1
action 1, numVisits=30, meanQ=3.265680, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.361636 0.794405 0.631636 0.823613 0.685246 0.877369 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 329
Initial state: 0 0.621289 0.802103 0.5674 0.80959 0.468573 0.789713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090255 episodes
GETTING ACTION FROM:
action 3, numVisits=1090195, meanQ=5.015138, numObservations: 5
action -1, numVisits=36, meanQ=3.697493, numObservations: 1
action 1, numVisits=21, meanQ=3.085238, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.621289 0.802103 0.5674 0.80959 0.468573 0.789713 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=153088, meanQ=8.392168, numObservations: 4
action 1, numVisits=10, meanQ=6.189000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1419558 episodes
GETTING ACTION FROM:
action 2, numVisits=1572641, meanQ=6.089967, numObservations: 4
action 1, numVisits=13, meanQ=3.760769, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.621289 0.802103 0.5674 0.80959 0.468573 0.789713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 330
Initial state: 0 0.678353 0.834692 0.850365 0.574687 0.574229 0.87774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091790 episodes
GETTING ACTION FROM:
action 3, numVisits=1091749, meanQ=5.015579, numObservations: 5
action -1, numVisits=36, meanQ=3.709529, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.678353 0.834692 0.850365 0.574687 0.574229 0.87774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.162137 0.527452 0.698482 0.833511 0.624498 0.885538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1121065 episodes
GETTING ACTION FROM:
action 1, numVisits=1120986, meanQ=5.011591, numObservations: 3
action -1, numVisits=65, meanQ=4.080448, numObservations: 1
action 2, numVisits=11, meanQ=2.453636, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.162137 0.527452 0.698482 0.833511 0.624498 0.885538 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=169719, meanQ=8.302157, numObservations: 3
action 3, numVisits=14860, meanQ=8.259999, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1435509 episodes
GETTING ACTION FROM:
action 2, numVisits=1543968, meanQ=6.171122, numObservations: 3
action 3, numVisits=76118, meanQ=6.149615, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.162137 0.527452 0.698482 0.833511 0.624498 0.885538 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 332
Initial state: 0 0.687354 0.827519 0.024725 0.969345 0.570373 0.863277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092602 episodes
GETTING ACTION FROM:
action 2, numVisits=1092547, meanQ=4.995958, numObservations: 5
action -1, numVisits=45, meanQ=3.878747, numObservations: 1
action 1, numVisits=6, meanQ=1.001683, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.687354 0.827519 0.024725 0.969345 0.570373 0.863277 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 333
Initial state: 0 0.875417 0.365811 0.69201 0.874163 0.502487 0.856686 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108414 episodes
GETTING ACTION FROM:
action 1, numVisits=1108406, meanQ=5.009039, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.875417 0.365811 0.69201 0.874163 0.502487 0.856686 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 334
Initial state: 0 0.65947 0.808846 0.667018 0.88703 0.931866 0.32374 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106078 episodes
GETTING ACTION FROM:
action 2, numVisits=1096144, meanQ=4.966902, numObservations: 4
action 0, numVisits=9909, meanQ=2.996572, numObservations: 1
action 1, numVisits=22, meanQ=1.456382, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.65947 0.808846 0.667018 0.88703 0.931866 0.32374 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 335
Initial state: 0 0.605215 0.818868 0.639879 0.829423 0.000882802 0.0680656 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094679 episodes
GETTING ACTION FROM:
action 3, numVisits=1094663, meanQ=5.158262, numObservations: 4
action 2, numVisits=11, meanQ=2.272745, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.605215 0.818868 0.639879 0.829423 0.000882802 0.0680656 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=125677, meanQ=8.540613, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423856 episodes
GETTING ACTION FROM:
action 2, numVisits=1549531, meanQ=6.343979, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.605215 0.818868 0.639879 0.829423 0.000882802 0.0680656 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=24532, meanQ=7.574340, numObservations: 4
action 1, numVisits=9592, meanQ=7.547856, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1447263 episodes
GETTING ACTION FROM:
action 2, numVisits=1377918, meanQ=6.103635, numObservations: 4
action 1, numVisits=103467, meanQ=6.084973, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.605215 0.818868 0.639879 0.829423 0.000882802 0.0680656 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 336
Initial state: 0 0.618683 0.869315 0.56705 0.864427 0.175296 0.928893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108829 episodes
GETTING ACTION FROM:
action 2, numVisits=1108625, meanQ=4.959484, numObservations: 4
action -1, numVisits=129, meanQ=4.301535, numObservations: 1
action 0, numVisits=71, meanQ=4.050000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.618683 0.869315 0.56705 0.864427 0.175296 0.928893 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 337
Initial state: 0 0.627179 0.632463 0.665601 0.871324 0.681074 0.839569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1089289 episodes
GETTING ACTION FROM:
action 2, numVisits=1089250, meanQ=4.947216, numObservations: 4
action 0, numVisits=31, meanQ=3.610768, numObservations: 1
action 3, numVisits=5, meanQ=1.396020, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.627179 0.632463 0.665601 0.871324 0.681074 0.839569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 338
Initial state: 0 0.593099 0.827355 0.545463 0.834947 0.843756 0.0629109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 784421 episodes
GETTING ACTION FROM:
action 0, numVisits=772821, meanQ=5.959460, numObservations: 3
action 1, numVisits=11594, meanQ=5.050993, numObservations: 3
action 3, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.593099 0.827355 0.545463 0.834947 0.843756 0.0629109 w: 1
Observation: 0 0 0.762199 0 0.787552 0 0.0799597 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=232129, meanQ=8.251515, numObservations: 5
action 1, numVisits=4, meanQ=2.497525, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1227313 episodes
GETTING ACTION FROM:
action 2, numVisits=1458770, meanQ=5.299725, numObservations: 5
action 1, numVisits=674, meanQ=5.005124, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.593099 0.827355 0.545463 0.834947 0.843756 0.0629109 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=93454, meanQ=5.491075, numObservations: 4
action 2, numVisits=16585, meanQ=5.461189, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1425035 episodes
GETTING ACTION FROM:
action 1, numVisits=1518433, meanQ=5.669412, numObservations: 4
action 2, numVisits=16641, meanQ=5.459332, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.593099 0.827355 0.545463 0.834947 0.843756 0.0629109 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 339
Initial state: 0 0.651985 0.891138 0.0402725 0.717535 0.534377 0.829963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115514 episodes
GETTING ACTION FROM:
action 1, numVisits=1115508, meanQ=5.012208, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.651985 0.891138 0.0402725 0.717535 0.534377 0.829963 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 340
Initial state: 0 0.519208 0.854511 0.556219 0.829116 0.869175 0.54253 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099117 episodes
GETTING ACTION FROM:
action 2, numVisits=1099104, meanQ=4.998465, numObservations: 5
action 3, numVisits=8, meanQ=-0.249975, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.519208 0.854511 0.556219 0.829116 0.869175 0.54253 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 341
Initial state: 0 0.53786 0.20914 0.66362 0.819761 0.57719 0.850588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1075044 episodes
GETTING ACTION FROM:
action 1, numVisits=1075034, meanQ=4.853425, numObservations: 4
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.53786 0.20914 0.66362 0.819761 0.57719 0.850588 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 342
Initial state: 0 0.545114 0.819442 0.625928 0.874697 0.401177 0.629298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106306 episodes
GETTING ACTION FROM:
action 3, numVisits=1106300, meanQ=4.996096, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.545114 0.819442 0.625928 0.874697 0.401177 0.629298 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=114775, meanQ=8.536607, numObservations: 3
action 1, numVisits=11263, meanQ=8.496235, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1422030 episodes
GETTING ACTION FROM:
action 2, numVisits=1478324, meanQ=6.350709, numObservations: 4
action 1, numVisits=69742, meanQ=6.328182, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.545114 0.819442 0.625928 0.874697 0.401177 0.629298 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 343
Initial state: 0 0.500387 0.810192 0.241801 0.00538183 0.594434 0.80409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111260 episodes
GETTING ACTION FROM:
action 1, numVisits=1111216, meanQ=5.012430, numObservations: 4
action 2, numVisits=39, meanQ=3.704113, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.500387 0.810192 0.241801 0.00538183 0.594434 0.80409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.597145 0.834651 0.8325 0.498136 0.512709 0.839487 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101907 episodes
GETTING ACTION FROM:
action 3, numVisits=1101870, meanQ=4.973981, numObservations: 4
action -1, numVisits=16, meanQ=3.084643, numObservations: 1
action 0, numVisits=17, meanQ=3.079843, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.597145 0.834651 0.8325 0.498136 0.512709 0.839487 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.760392 0.142043 0.675043 0.829582 0.51297 0.846628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096823 episodes
GETTING ACTION FROM:
action 2, numVisits=1096783, meanQ=5.006722, numObservations: 5
action 3, numVisits=35, meanQ=3.220003, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.760392 0.142043 0.675043 0.829582 0.51297 0.846628 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 346
Initial state: 0 0.508879 0.847085 0.652154 0.868633 0.300865 0.230784 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1084156 episodes
GETTING ACTION FROM:
action 3, numVisits=1084132, meanQ=4.961460, numObservations: 5
action 2, numVisits=13, meanQ=2.845408, numObservations: 4
action 1, numVisits=7, meanQ=1.852871, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.508879 0.847085 0.652154 0.868633 0.300865 0.230784 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=152291, meanQ=8.388290, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1407817 episodes
GETTING ACTION FROM:
action 2, numVisits=1560105, meanQ=6.093382, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.508879 0.847085 0.652154 0.868633 0.300865 0.230784 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 347
Initial state: 0 0.432954 0.245231 0.678668 0.812659 0.620805 0.807121 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108457 episodes
GETTING ACTION FROM:
action 1, numVisits=1108451, meanQ=4.964057, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.432954 0.245231 0.678668 0.812659 0.620805 0.807121 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 348
Initial state: 0 0.596204 0.806858 0.102974 0.34473 0.549964 0.844191 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1066528 episodes
GETTING ACTION FROM:
action 1, numVisits=1066522, meanQ=5.003300, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.596204 0.806858 0.102974 0.34473 0.549964 0.844191 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.539823 0.8846 0.771082 0.304863 0.541779 0.853098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1122525 episodes
GETTING ACTION FROM:
action 2, numVisits=1122519, meanQ=5.020077, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.539823 0.8846 0.771082 0.304863 0.541779 0.853098 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=82112, meanQ=5.529511, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1297728 episodes
GETTING ACTION FROM:
action 2, numVisits=1379840, meanQ=4.810721, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.539823 0.8846 0.771082 0.304863 0.541779 0.853098 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 350
Initial state: 0 0.684233 0.849013 0.583664 0.862142 0.756844 0.197869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094837 episodes
GETTING ACTION FROM:
action 2, numVisits=1094766, meanQ=4.998643, numObservations: 5
action 0, numVisits=61, meanQ=4.026439, numObservations: 1
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.684233 0.849013 0.583664 0.862142 0.756844 0.197869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 351
Initial state: 0 0.597216 0.826551 0.574239 0.819826 0.25984 0.245522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104406 episodes
GETTING ACTION FROM:
action 3, numVisits=1104384, meanQ=4.953871, numObservations: 3
action 1, numVisits=11, meanQ=1.907282, numObservations: 2
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.597216 0.826551 0.574239 0.819826 0.25984 0.245522 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=181996, meanQ=8.314635, numObservations: 5
action 1, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1403130 episodes
GETTING ACTION FROM:
action 2, numVisits=1585115, meanQ=6.112282, numObservations: 5
action 1, numVisits=12, meanQ=3.665000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.597216 0.826551 0.574239 0.819826 0.25984 0.245522 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 352
Initial state: 0 0.632002 0.0734781 0.691878 0.853132 0.563655 0.866351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109521 episodes
GETTING ACTION FROM:
action 3, numVisits=1109513, meanQ=5.009002, numObservations: 4
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.632002 0.0734781 0.691878 0.853132 0.563655 0.866351 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.358013 0.108639 0.512228 0.862633 0.693967 0.875569 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111945 episodes
GETTING ACTION FROM:
action 2, numVisits=1110946, meanQ=5.016904, numObservations: 3
action 3, numVisits=849, meanQ=4.710256, numObservations: 3
action 1, numVisits=146, meanQ=4.317283, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.358013 0.108639 0.512228 0.862633 0.693967 0.875569 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.233544 0.404974 0.512928 0.813163 0.54822 0.816661 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096372 episodes
GETTING ACTION FROM:
action 3, numVisits=1096313, meanQ=5.005287, numObservations: 5
action -1, numVisits=25, meanQ=3.471638, numObservations: 1
action 2, numVisits=30, meanQ=2.914670, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.233544 0.404974 0.512928 0.813163 0.54822 0.816661 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 355
Initial state: 0 0.693819 0.846575 0.281525 0.430717 0.557421 0.818076 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1081458 episodes
GETTING ACTION FROM:
action 3, numVisits=1081219, meanQ=5.007717, numObservations: 5
action 2, numVisits=221, meanQ=4.504723, numObservations: 5
action 1, numVisits=14, meanQ=2.856436, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.693819 0.846575 0.281525 0.430717 0.557421 0.818076 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.64303 0.832928 0.547571 0.290535 0.648331 0.805472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102163 episodes
GETTING ACTION FROM:
action 3, numVisits=1098813, meanQ=5.016594, numObservations: 4
action 2, numVisits=3341, meanQ=4.886264, numObservations: 4
action 1, numVisits=5, meanQ=0.196000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.64303 0.832928 0.547571 0.290535 0.648331 0.805472 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 357
Initial state: 0 0.523007 0.824945 0.453944 0.515117 0.567917 0.828469 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090170 episodes
GETTING ACTION FROM:
action 3, numVisits=1090096, meanQ=5.023696, numObservations: 5
action 1, numVisits=55, meanQ=3.992297, numObservations: 4
action 2, numVisits=15, meanQ=2.465340, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.523007 0.824945 0.453944 0.515117 0.567917 0.828469 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.529796 0.818496 0.631146 0.811636 0.934197 0.225153 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090732 episodes
GETTING ACTION FROM:
action 2, numVisits=1090588, meanQ=4.954622, numObservations: 5
action 0, numVisits=99, meanQ=4.210417, numObservations: 1
action 1, numVisits=42, meanQ=3.603574, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.529796 0.818496 0.631146 0.811636 0.934197 0.225153 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.469539 0.658133 0.632049 0.837466 0.531355 0.800556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113328 episodes
GETTING ACTION FROM:
action 1, numVisits=1113321, meanQ=4.946711, numObservations: 3
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.469539 0.658133 0.632049 0.837466 0.531355 0.800556 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=182925, meanQ=8.313985, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1429297 episodes
GETTING ACTION FROM:
action 2, numVisits=1611938, meanQ=6.433466, numObservations: 4
action 3, numVisits=284, meanQ=5.955107, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.469539 0.658133 0.632049 0.837466 0.531355 0.800556 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 360
Initial state: 0 0.680404 0.806962 0.633095 0.825121 0.140923 0.184078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094631 episodes
GETTING ACTION FROM:
action 2, numVisits=1094625, meanQ=5.009561, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.680404 0.806962 0.633095 0.825121 0.140923 0.184078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.676496 0.895454 0.699432 0.88256 0.219243 0.45818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1114825 episodes
GETTING ACTION FROM:
action 3, numVisits=1114818, meanQ=5.029124, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.676496 0.895454 0.699432 0.88256 0.219243 0.45818 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=183765, meanQ=8.324042, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1399249 episodes
GETTING ACTION FROM:
action 1, numVisits=1583012, meanQ=6.333624, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.676496 0.895454 0.699432 0.88256 0.219243 0.45818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 362
Initial state: 0 0.690888 0.846123 0.575956 0.040659 0.557271 0.804368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097027 episodes
GETTING ACTION FROM:
action 3, numVisits=1096995, meanQ=4.946081, numObservations: 4
action 0, numVisits=28, meanQ=3.528724, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.690888 0.846123 0.575956 0.040659 0.557271 0.804368 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.850799 0.356605 0.691134 0.879534 0.674362 0.808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109788 episodes
GETTING ACTION FROM:
action 3, numVisits=1109782, meanQ=4.998340, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.850799 0.356605 0.691134 0.879534 0.674362 0.808 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 364
Initial state: 0 0.515865 0.858309 0.846371 0.201779 0.557868 0.856072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096826 episodes
GETTING ACTION FROM:
action 2, numVisits=1096742, meanQ=5.047184, numObservations: 5
action 0, numVisits=75, meanQ=4.191959, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.515865 0.858309 0.846371 0.201779 0.557868 0.856072 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 365
Initial state: 0 0.884223 0.497711 0.603129 0.86733 0.686459 0.890788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109445 episodes
GETTING ACTION FROM:
action 1, numVisits=1109439, meanQ=5.013478, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.884223 0.497711 0.603129 0.86733 0.686459 0.890788 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 366
Initial state: 0 0.523462 0.82038 0.746164 0.662567 0.557195 0.86402 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104104 episodes
GETTING ACTION FROM:
action 1, numVisits=1104032, meanQ=5.034957, numObservations: 4
action 0, numVisits=45, meanQ=3.905575, numObservations: 1
action -1, numVisits=23, meanQ=3.402266, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.523462 0.82038 0.746164 0.662567 0.557195 0.86402 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.525763 0.851669 0.691142 0.80566 0.327735 0.778174 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091602 episodes
GETTING ACTION FROM:
action 3, numVisits=1091572, meanQ=4.945366, numObservations: 4
action 2, numVisits=25, meanQ=2.843204, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.525763 0.851669 0.691142 0.80566 0.327735 0.778174 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=152637, meanQ=8.390843, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1417005 episodes
GETTING ACTION FROM:
action 2, numVisits=1569537, meanQ=6.240136, numObservations: 4
action 1, numVisits=105, meanQ=5.494190, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.525763 0.851669 0.691142 0.80566 0.327735 0.778174 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 368
Initial state: 0 0.6666 0.867541 0.69727 0.87317 0.888292 0.658886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1112666 episodes
GETTING ACTION FROM:
action 2, numVisits=1112658, meanQ=5.008065, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.6666 0.867541 0.69727 0.87317 0.888292 0.658886 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.54227 0.861991 0.951775 0.193172 0.67378 0.811035 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110934 episodes
GETTING ACTION FROM:
action 1, numVisits=1110926, meanQ=5.013720, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.54227 0.861991 0.951775 0.193172 0.67378 0.811035 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 370
Initial state: 0 0.660838 0.879735 0.511987 0.867506 0.863562 0.181511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100107 episodes
GETTING ACTION FROM:
action 3, numVisits=1100099, meanQ=4.967541, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.660838 0.879735 0.511987 0.867506 0.863562 0.181511 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 371
Initial state: 0 0.588971 0.875817 0.0491492 0.464773 0.507849 0.879268 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095394 episodes
GETTING ACTION FROM:
action 1, numVisits=1095379, meanQ=4.993120, numObservations: 5
action 2, numVisits=10, meanQ=2.598000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.588971 0.875817 0.0491492 0.464773 0.507849 0.879268 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 372
Initial state: 0 0.106736 0.458617 0.649319 0.859352 0.580394 0.815565 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102383 episodes
GETTING ACTION FROM:
action 3, numVisits=1101657, meanQ=5.005844, numObservations: 4
action 2, numVisits=721, meanQ=4.566106, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.106736 0.458617 0.649319 0.859352 0.580394 0.815565 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.640348 0.832959 0.684009 0.843801 0.86258 0.224794 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098068 episodes
GETTING ACTION FROM:
action 2, numVisits=1098034, meanQ=4.955577, numObservations: 5
action -1, numVisits=30, meanQ=3.531079, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.640348 0.832959 0.684009 0.843801 0.86258 0.224794 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 374
Initial state: 0 0.665849 0.839283 0.679304 0.844461 0.321404 0.895603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1068488 episodes
GETTING ACTION FROM:
action 3, numVisits=1068440, meanQ=4.990084, numObservations: 4
action 0, numVisits=44, meanQ=3.864214, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.665849 0.839283 0.679304 0.844461 0.321404 0.895603 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 375
Initial state: 0 0.339223 0.360518 0.62748 0.891027 0.598239 0.830251 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092125 episodes
GETTING ACTION FROM:
action 1, numVisits=1091451, meanQ=4.948465, numObservations: 5
action 2, numVisits=576, meanQ=4.601736, numObservations: 4
action 0, numVisits=85, meanQ=4.131679, numObservations: 1
action 3, numVisits=11, meanQ=1.907282, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.339223 0.360518 0.62748 0.891027 0.598239 0.830251 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=123926, meanQ=8.544428, numObservations: 3
action 3, numVisits=270, meanQ=8.141873, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1432570 episodes
GETTING ACTION FROM:
action 2, numVisits=1555309, meanQ=6.280248, numObservations: 3
action 3, numVisits=1455, meanQ=6.084235, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.339223 0.360518 0.62748 0.891027 0.598239 0.830251 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 376
Initial state: 0 0.606385 0.83817 0.673641 0.803765 0.0377403 0.565723 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090405 episodes
GETTING ACTION FROM:
action 1, numVisits=1090396, meanQ=4.906345, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.606385 0.83817 0.673641 0.803765 0.0377403 0.565723 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 377
Initial state: 0 0.570418 0.87337 0.651777 0.851209 0.24157 0.966338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1118067 episodes
GETTING ACTION FROM:
action 2, numVisits=1118060, meanQ=5.007898, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.570418 0.87337 0.651777 0.851209 0.24157 0.966338 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=81271, meanQ=5.543700, numObservations: 4
action 0, numVisits=23, meanQ=4.153669, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1317095 episodes
GETTING ACTION FROM:
action 2, numVisits=1398362, meanQ=4.849362, numObservations: 4
action 0, numVisits=27, meanQ=3.242014, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.570418 0.87337 0.651777 0.851209 0.24157 0.966338 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 378
Initial state: 0 0.534541 0.809574 0.0525436 0.541335 0.624635 0.870297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098915 episodes
GETTING ACTION FROM:
action 2, numVisits=1098895, meanQ=5.044057, numObservations: 5
action 0, numVisits=16, meanQ=3.084356, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.534541 0.809574 0.0525436 0.541335 0.624635 0.870297 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 379
Initial state: 0 0.553522 0.503361 0.558985 0.894623 0.642683 0.87237 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090527 episodes
GETTING ACTION FROM:
action 1, numVisits=1090520, meanQ=5.020954, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.553522 0.503361 0.558985 0.894623 0.642683 0.87237 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 380
Initial state: 0 0.521178 0.867103 0.628035 0.849876 0.684802 0.42983 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109206 episodes
GETTING ACTION FROM:
action 2, numVisits=857282, meanQ=5.021968, numObservations: 3
action 1, numVisits=251833, meanQ=4.978356, numObservations: 3
action 0, numVisits=58, meanQ=4.027858, numObservations: 1
action 3, numVisits=31, meanQ=3.634097, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.521178 0.867103 0.628035 0.849876 0.684802 0.42983 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.558834 0.849971 0.577847 0.807927 0.520355 0.0814415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104601 episodes
GETTING ACTION FROM:
action 2, numVisits=1097721, meanQ=5.018046, numObservations: 4
action -1, numVisits=6872, meanQ=2.863496, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.558834 0.849971 0.577847 0.807927 0.520355 0.0814415 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 382
Initial state: 0 0.554939 0.843921 0.66082 0.889704 0.812534 0.103811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100007 episodes
GETTING ACTION FROM:
action 1, numVisits=1099922, meanQ=4.933940, numObservations: 4
action 2, numVisits=45, meanQ=3.790004, numObservations: 4
action -1, numVisits=37, meanQ=3.686768, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.554939 0.843921 0.66082 0.889704 0.812534 0.103811 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 383
Initial state: 0 0.662795 0.840877 0.117619 0.991444 0.659233 0.825135 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110367 episodes
GETTING ACTION FROM:
action 1, numVisits=1110361, meanQ=5.003880, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.662795 0.840877 0.117619 0.991444 0.659233 0.825135 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 384
Initial state: 0 0.569846 0.87607 0.660554 0.827819 0.500194 0.224002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096562 episodes
GETTING ACTION FROM:
action 2, numVisits=1096556, meanQ=4.947514, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.569846 0.87607 0.660554 0.827819 0.500194 0.224002 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.953716 0.246622 0.6946 0.805566 0.696339 0.853974 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090343 episodes
GETTING ACTION FROM:
action 2, numVisits=1090301, meanQ=4.921015, numObservations: 4
action 3, numVisits=24, meanQ=2.575013, numObservations: 4
action 1, numVisits=14, meanQ=1.998579, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.953716 0.246622 0.6946 0.805566 0.696339 0.853974 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.613574 0.869327 0.585314 0.853191 0.58588 0.216632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102426 episodes
GETTING ACTION FROM:
action 2, numVisits=1102414, meanQ=4.952896, numObservations: 4
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.613574 0.869327 0.585314 0.853191 0.58588 0.216632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.535289 0.82122 0.767688 0.000668032 0.598874 0.87349 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088660 episodes
GETTING ACTION FROM:
action 3, numVisits=1088621, meanQ=4.906574, numObservations: 4
action -1, numVisits=34, meanQ=3.556148, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.535289 0.82122 0.767688 0.000668032 0.598874 0.87349 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.652675 0.810726 0.375267 0.202616 0.651363 0.868375 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105919 episodes
GETTING ACTION FROM:
action 2, numVisits=1105871, meanQ=5.134253, numObservations: 5
action -1, numVisits=42, meanQ=3.977059, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.652675 0.810726 0.375267 0.202616 0.651363 0.868375 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=126213, meanQ=8.543159, numObservations: 3
action 1, numVisits=24, meanQ=6.832508, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1423013 episodes
GETTING ACTION FROM:
action 3, numVisits=1545642, meanQ=6.138325, numObservations: 4
action 1, numVisits=3606, meanQ=6.017138, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.652675 0.810726 0.375267 0.202616 0.651363 0.868375 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 389
Initial state: 0 0.233901 0.838999 0.695305 0.876246 0.59961 0.819779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113597 episodes
GETTING ACTION FROM:
action 2, numVisits=1113176, meanQ=5.000165, numObservations: 3
action 0, numVisits=416, meanQ=1.666105, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.233901 0.838999 0.695305 0.876246 0.59961 0.819779 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 390
Initial state: 0 0.535341 0.870683 0.551092 0.887039 0.885513 0.959129 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1076584 episodes
GETTING ACTION FROM:
action 3, numVisits=1069329, meanQ=5.147773, numObservations: 5
action -1, numVisits=6191, meanQ=3.008025, numObservations: 1
action 0, numVisits=1062, meanQ=2.900623, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.535341 0.870683 0.551092 0.887039 0.885513 0.959129 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.648193 0.85667 0.545514 0.875801 0.456077 0.208533 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 785349 episodes
GETTING ACTION FROM:
action 0, numVisits=785344, meanQ=5.690953, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.648193 0.85667 0.545514 0.875801 0.456077 0.208533 w: 1
Observation: 0 0 0.75747 0 0.942264 0 0.108803 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=398640, meanQ=7.096970, numObservations: 4
action 3, numVisits=1695, meanQ=3.781149, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 1236771 episodes
GETTING ACTION FROM:
action 1, numVisits=1635411, meanQ=5.621531, numObservations: 4
action 3, numVisits=1695, meanQ=3.781149, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.648193 0.85667 0.545514 0.875801 0.456077 0.208533 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 392
Initial state: 0 0.324539 0.141245 0.682667 0.897794 0.637865 0.888296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103483 episodes
GETTING ACTION FROM:
action 3, numVisits=1103436, meanQ=5.027006, numObservations: 4
action 0, numVisits=27, meanQ=3.567636, numObservations: 1
action 2, numVisits=17, meanQ=2.764124, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.324539 0.141245 0.682667 0.897794 0.637865 0.888296 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 393
Initial state: 0 0.545028 0.859753 0.101914 0.0140551 0.67437 0.895287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1072723 episodes
GETTING ACTION FROM:
action 3, numVisits=1072713, meanQ=5.011307, numObservations: 4
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.545028 0.859753 0.101914 0.0140551 0.67437 0.895287 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.0878027 0.513427 0.507678 0.839529 0.646361 0.831127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101514 episodes
GETTING ACTION FROM:
action 3, numVisits=1101438, meanQ=5.135849, numObservations: 4
action 0, numVisits=50, meanQ=4.072838, numObservations: 1
action 1, numVisits=23, meanQ=2.213043, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0878027 0.513427 0.507678 0.839529 0.646361 0.831127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 395
Initial state: 0 0.574352 0.842163 0.220549 0.58225 0.638373 0.864866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110579 episodes
GETTING ACTION FROM:
action 2, numVisits=1110304, meanQ=4.997209, numObservations: 4
action 0, numVisits=170, meanQ=4.399031, numObservations: 1
action -1, numVisits=103, meanQ=4.246093, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.574352 0.842163 0.220549 0.58225 0.638373 0.864866 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=182551, meanQ=8.322051, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1420170 episodes
GETTING ACTION FROM:
action 1, numVisits=1602719, meanQ=6.318460, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.574352 0.842163 0.220549 0.58225 0.638373 0.864866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 396
Initial state: 0 0.887098 0.164819 0.625409 0.838379 0.627805 0.820684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1102385 episodes
GETTING ACTION FROM:
action 1, numVisits=1102360, meanQ=4.942314, numObservations: 4
action -1, numVisits=21, meanQ=3.305444, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.887098 0.164819 0.625409 0.838379 0.627805 0.820684 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80106, meanQ=4.712955, numObservations: 4
action 2, numVisits=17, meanQ=2.764124, numObservations: 3
action 1, numVisits=5, meanQ=0.602040, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 1402599 episodes
GETTING ACTION FROM:
action 3, numVisits=1482705, meanQ=5.887632, numObservations: 4
action 2, numVisits=17, meanQ=2.764124, numObservations: 3
action 1, numVisits=5, meanQ=0.602040, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.887098 0.164819 0.625409 0.838379 0.627805 0.820684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 397
Initial state: 0 0.534975 0.472007 0.505482 0.849192 0.513873 0.840992 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095018 episodes
GETTING ACTION FROM:
action 3, numVisits=1094998, meanQ=5.004045, numObservations: 5
action 2, numVisits=15, meanQ=2.865347, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.534975 0.472007 0.505482 0.849192 0.513873 0.840992 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.67082 0.871839 0.319919 0.0508734 0.563692 0.892647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1113048 episodes
GETTING ACTION FROM:
action 2, numVisits=1112857, meanQ=4.976337, numObservations: 3
action -1, numVisits=187, meanQ=4.430981, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.67082 0.871839 0.319919 0.0508734 0.563692 0.892647 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=183962, meanQ=8.334773, numObservations: 4
action 1, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1411543 episodes
GETTING ACTION FROM:
action 3, numVisits=1595502, meanQ=6.172333, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.67082 0.871839 0.319919 0.0508734 0.563692 0.892647 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=41820, meanQ=8.102660, numObservations: 3
action 1, numVisits=326, meanQ=7.766479, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1440020 episodes
GETTING ACTION FROM:
action 1, numVisits=1264996, meanQ=5.883114, numObservations: 5
action 3, numVisits=217168, meanQ=5.858833, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.67082 0.871839 0.319919 0.0508734 0.563692 0.892647 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 399
Initial state: 0 0.552973 0.819213 0.530008 0.432838 0.609437 0.858479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105463 episodes
GETTING ACTION FROM:
action 3, numVisits=1105425, meanQ=5.133735, numObservations: 4
action 0, numVisits=31, meanQ=3.756865, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.552973 0.819213 0.530008 0.432838 0.609437 0.858479 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 400
Initial state: 0 0.612466 0.864218 0.525537 0.85057 0.994634 0.505673 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104959 episodes
GETTING ACTION FROM:
action 2, numVisits=1104952, meanQ=4.999050, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.612466 0.864218 0.525537 0.85057 0.994634 0.505673 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 401
Initial state: 0 0.563287 0.827734 0.591504 0.912025 0.629713 0.865015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1093159 episodes
GETTING ACTION FROM:
action 1, numVisits=1093153, meanQ=4.922399, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.563287 0.827734 0.591504 0.912025 0.629713 0.865015 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.836977 0.32928 0.620105 0.888038 0.660231 0.802314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092833 episodes
GETTING ACTION FROM:
action 2, numVisits=1092743, meanQ=4.965421, numObservations: 5
action -1, numVisits=44, meanQ=3.675742, numObservations: 1
action 0, numVisits=44, meanQ=3.667251, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.836977 0.32928 0.620105 0.888038 0.660231 0.802314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 403
Initial state: 0 0.576555 0.865558 0.60393 0.041849 0.594124 0.854103 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101166 episodes
GETTING ACTION FROM:
action 3, numVisits=1101160, meanQ=5.010045, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.576555 0.865558 0.60393 0.041849 0.594124 0.854103 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.024155 0.790498 0.511793 0.893586 0.523525 0.886535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111012 episodes
GETTING ACTION FROM:
action 3, numVisits=1110993, meanQ=5.000877, numObservations: 3
action 2, numVisits=14, meanQ=2.998571, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.024155 0.790498 0.511793 0.893586 0.523525 0.886535 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 405
Initial state: 0 0.109473 0.279501 0.519285 0.815724 0.588308 0.824804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1059145 episodes
GETTING ACTION FROM:
action 2, numVisits=1058983, meanQ=4.939389, numObservations: 4
action 0, numVisits=121, meanQ=4.219822, numObservations: 1
action -1, numVisits=39, meanQ=3.752363, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.109473 0.279501 0.519285 0.815724 0.588308 0.824804 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.509271 0.844354 0.31811 0.957774 0.689714 0.873725 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1070316 episodes
GETTING ACTION FROM:
action 2, numVisits=1070279, meanQ=4.938324, numObservations: 5
action -1, numVisits=24, meanQ=3.359562, numObservations: 1
action 3, numVisits=10, meanQ=1.799000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.509271 0.844354 0.31811 0.957774 0.689714 0.873725 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=78229, meanQ=4.740491, numObservations: 4
action 0, numVisits=24, meanQ=3.385711, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1407415 episodes
GETTING ACTION FROM:
action 3, numVisits=1485644, meanQ=5.910765, numObservations: 4
action 0, numVisits=24, meanQ=3.385711, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.509271 0.844354 0.31811 0.957774 0.689714 0.873725 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 407
Initial state: 0 0.734077 0.779664 0.684759 0.874324 0.632944 0.845928 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094293 episodes
GETTING ACTION FROM:
action 3, numVisits=1093358, meanQ=4.960920, numObservations: 5
action 1, numVisits=870, meanQ=4.696979, numObservations: 5
action -1, numVisits=33, meanQ=3.624089, numObservations: 1
action 0, numVisits=28, meanQ=3.491551, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action: 3
Next state: 1 0.734077 0.779664 0.684759 0.874324 0.632944 0.845928 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 408
Initial state: 0 0.512208 0.805153 0.525539 0.833325 0.467614 0.559459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 747989 episodes
GETTING ACTION FROM:
action -1, numVisits=747981, meanQ=2.906030, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.512208 0.805153 0.525539 0.833325 0.467614 0.559459 w: 1
Observation: 0 0.504459 0 0.460249 0 0.453301 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=747929, meanQ=4.996614, numObservations: 4
action 0, numVisits=41, meanQ=3.845393, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1172625 episodes
GETTING ACTION FROM:
action 1, numVisits=1920552, meanQ=4.992871, numObservations: 4
action 0, numVisits=43, meanQ=3.831799, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.512208 0.805153 0.525539 0.833325 0.467614 0.559459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 409
Initial state: 0 0.56716 0.873641 0.389071 0.084403 0.607525 0.837717 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108264 episodes
GETTING ACTION FROM:
action 2, numVisits=1108227, meanQ=5.047171, numObservations: 5
action -1, numVisits=30, meanQ=3.605113, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.56716 0.873641 0.389071 0.084403 0.607525 0.837717 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=154912, meanQ=8.406249, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1427395 episodes
GETTING ACTION FROM:
action 3, numVisits=1582083, meanQ=6.187696, numObservations: 4
action 1, numVisits=224, meanQ=5.675581, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.56716 0.873641 0.389071 0.084403 0.607525 0.837717 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 410
Initial state: 0 0.585023 0.800703 0.442413 0.955661 0.658848 0.81474 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088127 episodes
GETTING ACTION FROM:
action 2, numVisits=1088100, meanQ=4.935969, numObservations: 5
action 0, numVisits=18, meanQ=2.943934, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.585023 0.800703 0.442413 0.955661 0.658848 0.81474 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=23316, meanQ=6.621022, numObservations: 5
action 1, numVisits=8, meanQ=3.497500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1404726 episodes
GETTING ACTION FROM:
action 3, numVisits=1428040, meanQ=6.159640, numObservations: 5
action 1, numVisits=8, meanQ=3.497500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.585023 0.800703 0.442413 0.955661 0.658848 0.81474 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 411
Initial state: 0 0.302983 0.624307 0.53416 0.891266 0.521035 0.887813 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108420 episodes
GETTING ACTION FROM:
action 2, numVisits=1108409, meanQ=5.006071, numObservations: 4
action 3, numVisits=6, meanQ=0.981667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.302983 0.624307 0.53416 0.891266 0.521035 0.887813 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.551709 0.862027 0.616358 0.83953 0.794487 0.302834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110713 episodes
GETTING ACTION FROM:
action 1, numVisits=1110707, meanQ=5.012730, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.551709 0.862027 0.616358 0.83953 0.794487 0.302834 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=183239, meanQ=8.328250, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1428953 episodes
GETTING ACTION FROM:
action 2, numVisits=1612190, meanQ=6.382971, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.551709 0.862027 0.616358 0.83953 0.794487 0.302834 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=40836, meanQ=8.236422, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1461370 episodes
GETTING ACTION FROM:
action 2, numVisits=1502157, meanQ=5.607350, numObservations: 3
action 1, numVisits=49, meanQ=4.387553, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.551709 0.862027 0.616358 0.83953 0.794487 0.302834 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 413
Initial state: 0 0.729911 0.183068 0.669015 0.815532 0.594922 0.838107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098492 episodes
GETTING ACTION FROM:
action 1, numVisits=1098463, meanQ=5.003488, numObservations: 5
action 0, numVisits=24, meanQ=3.385235, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.729911 0.183068 0.669015 0.815532 0.594922 0.838107 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 414
Initial state: 0 0.598947 0.862666 0.99135 0.757577 0.679208 0.836142 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1059885 episodes
GETTING ACTION FROM:
action 1, numVisits=1059833, meanQ=4.772536, numObservations: 4
action 2, numVisits=47, meanQ=3.542770, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.598947 0.862666 0.99135 0.757577 0.679208 0.836142 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.454422 0.124796 0.501635 0.81588 0.630813 0.869004 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100745 episodes
GETTING ACTION FROM:
action 3, numVisits=1099806, meanQ=4.933933, numObservations: 4
action 1, numVisits=898, meanQ=4.674129, numObservations: 3
action -1, numVisits=38, meanQ=3.708175, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.454422 0.124796 0.501635 0.81588 0.630813 0.869004 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=79254, meanQ=4.776706, numObservations: 5
action 0, numVisits=117, meanQ=4.111285, numObservations: 1
action -1, numVisits=106, meanQ=4.079205, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1406117 episodes
GETTING ACTION FROM:
action 2, numVisits=1485371, meanQ=5.798517, numObservations: 5
action 0, numVisits=117, meanQ=4.111285, numObservations: 1
action -1, numVisits=106, meanQ=4.079205, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.454422 0.124796 0.501635 0.81588 0.630813 0.869004 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 416
Initial state: 0 0.54448 0.850754 0.624201 0.896367 0.569096 0.485391 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1088525 episodes
GETTING ACTION FROM:
action 1, numVisits=1083472, meanQ=4.983490, numObservations: 5
action -1, numVisits=5016, meanQ=3.047448, numObservations: 1
action 0, numVisits=35, meanQ=2.107976, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.54448 0.850754 0.624201 0.896367 0.569096 0.485391 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 417
Initial state: 0 0.813146 0.945833 0.626662 0.836949 0.604245 0.816877 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1092147 episodes
GETTING ACTION FROM:
action 2, numVisits=556207, meanQ=5.006251, numObservations: 5
action 3, numVisits=535863, meanQ=4.957947, numObservations: 5
action 0, numVisits=74, meanQ=4.111638, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.813146 0.945833 0.626662 0.836949 0.604245 0.816877 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 418
Initial state: 0 0.623034 0.808675 0.667208 0.860507 0.170056 0.468283 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 795733 episodes
GETTING ACTION FROM:
action 0, numVisits=788264, meanQ=5.976671, numObservations: 3
action 1, numVisits=7377, meanQ=4.889047, numObservations: 5
action -1, numVisits=80, meanQ=4.294097, numObservations: 1
action 3, numVisits=11, meanQ=2.633645, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.623034 0.808675 0.667208 0.860507 0.170056 0.468283 w: 1
Observation: 0 0 0.808697 0 0.857711 0 0.377927 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=263208, meanQ=8.043704, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1241330 episodes
GETTING ACTION FROM:
action 1, numVisits=1504536, meanQ=5.560479, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.623034 0.808675 0.667208 0.860507 0.170056 0.468283 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 419
Initial state: 0 0.0920919 0.0317335 0.581007 0.827495 0.517775 0.821306 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 760959 episodes
GETTING ACTION FROM:
action 0, numVisits=746813, meanQ=2.942892, numObservations: 1
action -1, numVisits=14105, meanQ=2.889433, numObservations: 1
action 1, numVisits=33, meanQ=1.663039, numObservations: 4
action 2, numVisits=7, meanQ=-0.701429, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0920919 0.0317335 0.581007 0.827495 0.517775 0.821306 w: 1
Observation: 0 0 0.130535 0 0.912836 0 0.730652 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=727483, meanQ=4.992987, numObservations: 4
action 1, numVisits=19280, meanQ=4.946517, numObservations: 3
action 0, numVisits=24, meanQ=3.485031, numObservations: 1
action -1, numVisits=24, meanQ=3.332025, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1228817 episodes
GETTING ACTION FROM:
action 1, numVisits=1139408, meanQ=5.114610, numObservations: 3
action 3, numVisits=836172, meanQ=4.990592, numObservations: 4
action 0, numVisits=24, meanQ=3.485031, numObservations: 1
action -1, numVisits=24, meanQ=3.332025, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0920919 0.0317335 0.581007 0.827495 0.517775 0.821306 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=199706, meanQ=8.336029, numObservations: 3
action 2, numVisits=3, meanQ=2.333333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1423706 episodes
GETTING ACTION FROM:
action 3, numVisits=1623409, meanQ=6.340349, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0920919 0.0317335 0.581007 0.827495 0.517775 0.821306 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 420
Initial state: 0 0.605059 0.810544 0.862837 0.979865 0.533797 0.858289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115929 episodes
GETTING ACTION FROM:
action 2, numVisits=1115827, meanQ=5.151721, numObservations: 4
action -1, numVisits=90, meanQ=4.337724, numObservations: 1
action 3, numVisits=9, meanQ=2.332244, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.605059 0.810544 0.862837 0.979865 0.533797 0.858289 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 421
Initial state: 0 0.523334 0.81084 0.0517594 0.397381 0.667228 0.893498 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107804 episodes
GETTING ACTION FROM:
action 1, numVisits=1018187, meanQ=4.999097, numObservations: 4
action 3, numVisits=89612, meanQ=4.803510, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.523334 0.81084 0.0517594 0.397381 0.667228 0.893498 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 422
Initial state: 0 0.589143 0.830672 0.577799 0.872971 0.300917 0.141793 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115058 episodes
GETTING ACTION FROM:
action 3, numVisits=1114908, meanQ=4.960963, numObservations: 3
action 0, numVisits=77, meanQ=4.106741, numObservations: 1
action -1, numVisits=27, meanQ=3.524419, numObservations: 1
action 2, numVisits=45, meanQ=2.639784, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.589143 0.830672 0.577799 0.872971 0.300917 0.141793 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=183641, meanQ=8.332497, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1437908 episodes
GETTING ACTION FROM:
action 2, numVisits=1621547, meanQ=6.176549, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.589143 0.830672 0.577799 0.872971 0.300917 0.141793 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 423
Initial state: 0 0.672441 0.827337 0.655428 0.289722 0.569416 0.898363 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098013 episodes
GETTING ACTION FROM:
action 1, numVisits=1097963, meanQ=4.966878, numObservations: 5
action -1, numVisits=31, meanQ=3.578961, numObservations: 1
action 3, numVisits=10, meanQ=2.189000, numObservations: 3
action 2, numVisits=7, meanQ=1.570000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.672441 0.827337 0.655428 0.289722 0.569416 0.898363 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.602601 0.881675 0.596162 0.83777 0.0638982 0.7295 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103760 episodes
GETTING ACTION FROM:
action 2, numVisits=1103725, meanQ=4.954548, numObservations: 4
action 0, numVisits=30, meanQ=3.545301, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.602601 0.881675 0.596162 0.83777 0.0638982 0.7295 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 425
Initial state: 0 0.432828 0.811237 0.695052 0.815923 0.584333 0.820193 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100626 episodes
GETTING ACTION FROM:
action 1, numVisits=1100618, meanQ=5.002359, numObservations: 5
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.432828 0.811237 0.695052 0.815923 0.584333 0.820193 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 426
Initial state: 0 0.531434 0.85389 0.667742 0.827218 0.739219 0.477514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107643 episodes
GETTING ACTION FROM:
action 1, numVisits=1107634, meanQ=5.013170, numObservations: 4
action 2, numVisits=4, meanQ=0.025000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.531434 0.85389 0.667742 0.827218 0.739219 0.477514 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 427
Initial state: 0 0.526059 0.84781 0.501427 0.82495 0.661365 0.630502 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1087619 episodes
GETTING ACTION FROM:
action 2, numVisits=1087570, meanQ=4.911975, numObservations: 4
action 0, numVisits=44, meanQ=3.758671, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.526059 0.84781 0.501427 0.82495 0.661365 0.630502 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 428
Initial state: 0 0.169946 0.0437225 0.664662 0.847633 0.652119 0.842499 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1085905 episodes
GETTING ACTION FROM:
action 3, numVisits=1085755, meanQ=4.948552, numObservations: 5
action -1, numVisits=136, meanQ=4.310408, numObservations: 1
action 2, numVisits=8, meanQ=1.996250, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.169946 0.0437225 0.664662 0.847633 0.652119 0.842499 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.991914 0.585644 0.538522 0.852687 0.607827 0.86719 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105523 episodes
GETTING ACTION FROM:
action 3, numVisits=1105302, meanQ=5.023758, numObservations: 4
action 0, numVisits=208, meanQ=4.493663, numObservations: 1
action 1, numVisits=10, meanQ=2.380010, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.991914 0.585644 0.538522 0.852687 0.607827 0.86719 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 430
Initial state: 0 0.227008 0.575997 0.60265 0.810357 0.682169 0.863588 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 761831 episodes
GETTING ACTION FROM:
action 0, numVisits=596970, meanQ=2.981107, numObservations: 1
action -1, numVisits=164850, meanQ=2.879582, numObservations: 1
action 3, numVisits=8, meanQ=-0.001250, numObservations: 3
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.227008 0.575997 0.60265 0.810357 0.682169 0.863588 w: 1
Observation: 0 0 0.615033 0 0.903264 0 0.841871 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=596930, meanQ=5.032493, numObservations: 5
action 0, numVisits=35, meanQ=3.758930, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1199417 episodes
GETTING ACTION FROM:
action 1, numVisits=1796347, meanQ=5.045555, numObservations: 5
action 0, numVisits=35, meanQ=3.758930, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.227008 0.575997 0.60265 0.810357 0.682169 0.863588 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=273249, meanQ=8.419583, numObservations: 5
action 2, numVisits=6, meanQ=4.996667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1397437 episodes
GETTING ACTION FROM:
action 3, numVisits=1670673, meanQ=6.490854, numObservations: 5
action 2, numVisits=16, meanQ=4.248125, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.227008 0.575997 0.60265 0.810357 0.682169 0.863588 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 431
Initial state: 0 0.616067 0.899832 0.522529 0.843103 0.166729 0.384559 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1051941 episodes
GETTING ACTION FROM:
action 3, numVisits=1051901, meanQ=4.841770, numObservations: 5
action 0, numVisits=27, meanQ=3.356342, numObservations: 1
action 1, numVisits=6, meanQ=1.001683, numObservations: 2
action 2, numVisits=5, meanQ=-0.582000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.616067 0.899832 0.522529 0.843103 0.166729 0.384559 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=105929, meanQ=8.544320, numObservations: 3
action 2, numVisits=14870, meanQ=8.508933, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1434991 episodes
GETTING ACTION FROM:
action 1, numVisits=1422470, meanQ=6.273962, numObservations: 3
action 2, numVisits=133318, meanQ=6.259396, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.616067 0.899832 0.522529 0.843103 0.166729 0.384559 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=23566, meanQ=8.281110, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1478998 episodes
GETTING ACTION FROM:
action 2, numVisits=1502555, meanQ=6.187958, numObservations: 3
action 1, numVisits=9, meanQ=3.221111, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.616067 0.899832 0.522529 0.843103 0.166729 0.384559 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 432
Initial state: 0 0.690102 0.847042 0.527424 0.882624 0.654034 0.632555 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101761 episodes
GETTING ACTION FROM:
action 3, numVisits=1101755, meanQ=4.951099, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.690102 0.847042 0.527424 0.882624 0.654034 0.632555 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 433
Initial state: 0 0.655956 0.811907 0.428197 0.163629 0.677151 0.88373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098869 episodes
GETTING ACTION FROM:
action 2, numVisits=1098847, meanQ=4.955755, numObservations: 5
action 1, numVisits=17, meanQ=0.652359, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.655956 0.811907 0.428197 0.163629 0.677151 0.88373 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=154286, meanQ=8.394077, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1440043 episodes
GETTING ACTION FROM:
action 3, numVisits=1594320, meanQ=6.077157, numObservations: 3
action 1, numVisits=9, meanQ=3.221111, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.655956 0.811907 0.428197 0.163629 0.677151 0.88373 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 434
Initial state: 0 0.138032 0.894565 0.578331 0.855697 0.575125 0.898465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 790189 episodes
GETTING ACTION FROM:
action 0, numVisits=790031, meanQ=5.934042, numObservations: 3
action -1, numVisits=155, meanQ=3.129955, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.138032 0.894565 0.578331 0.855697 0.575125 0.898465 w: 1
Observation: 0 0 0.988272 0 0.953847 0 0.918042 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=279748, meanQ=7.909423, numObservations: 3
action 1, numVisits=184, meanQ=7.398181, numObservations: 5
action 2, numVisits=4, meanQ=0.025000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 1237052 episodes
GETTING ACTION FROM:
action 3, numVisits=1516387, meanQ=5.673693, numObservations: 3
action 1, numVisits=582, meanQ=5.345319, numObservations: 5
action 0, numVisits=15, meanQ=3.709634, numObservations: 1
action 2, numVisits=4, meanQ=0.025000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.138032 0.894565 0.578331 0.855697 0.575125 0.898465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 435
Initial state: 0 0.277755 0.167711 0.524603 0.834607 0.666404 0.804801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110447 episodes
GETTING ACTION FROM:
action 2, numVisits=1100088, meanQ=5.046183, numObservations: 4
action 0, numVisits=10355, meanQ=2.966319, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.277755 0.167711 0.524603 0.834607 0.666404 0.804801 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.573542 0.80036 0.535893 0.0657531 0.555573 0.891304 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101305 episodes
GETTING ACTION FROM:
action 3, numVisits=1091646, meanQ=4.943416, numObservations: 3
action -1, numVisits=9643, meanQ=2.986576, numObservations: 1
action 1, numVisits=11, meanQ=0.280927, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.573542 0.80036 0.535893 0.0657531 0.555573 0.891304 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 437
Initial state: 0 0.522301 0.832412 0.312768 0.546648 0.515942 0.833511 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098534 episodes
GETTING ACTION FROM:
action 2, numVisits=1098413, meanQ=5.005827, numObservations: 5
action -1, numVisits=48, meanQ=3.913479, numObservations: 1
action 0, numVisits=34, meanQ=3.654611, numObservations: 1
action 3, numVisits=17, meanQ=3.005300, numObservations: 3
action 1, numVisits=22, meanQ=2.990909, numObservations: 3
action: 2
Next state: 0 0.522301 0.832412 0.312768 0.546648 0.515942 0.833511 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=101626, meanQ=8.544529, numObservations: 3
action 1, numVisits=23422, meanQ=8.521169, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1410891 episodes
GETTING ACTION FROM:
action 1, numVisits=858815, meanQ=6.147985, numObservations: 5
action 3, numVisits=677122, meanQ=6.146913, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.522301 0.832412 0.312768 0.546648 0.515942 0.833511 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 438
Initial state: 0 0.520285 0.855382 0.617433 0.876411 0.14848 0.223852 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1099875 episodes
GETTING ACTION FROM:
action 1, numVisits=1099773, meanQ=5.011797, numObservations: 5
action 0, numVisits=72, meanQ=4.137722, numObservations: 1
action -1, numVisits=27, meanQ=3.463205, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.520285 0.855382 0.617433 0.876411 0.14848 0.223852 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 439
Initial state: 0 0.592597 0.80389 0.148046 0.300014 0.570307 0.809664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094895 episodes
GETTING ACTION FROM:
action 3, numVisits=1094825, meanQ=4.971052, numObservations: 5
action 2, numVisits=59, meanQ=3.897966, numObservations: 3
action 1, numVisits=7, meanQ=2.144300, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.592597 0.80389 0.148046 0.300014 0.570307 0.809664 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.285619 0.999029 0.648293 0.828896 0.52643 0.855659 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103422 episodes
GETTING ACTION FROM:
action 2, numVisits=1103372, meanQ=5.189330, numObservations: 5
action -1, numVisits=41, meanQ=4.011311, numObservations: 1
action 1, numVisits=6, meanQ=1.001683, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.285619 0.999029 0.648293 0.828896 0.52643 0.855659 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 441
Initial state: 0 0.630747 0.867333 0.695258 0.827711 0.972946 0.197845 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111924 episodes
GETTING ACTION FROM:
action 3, numVisits=1111865, meanQ=5.018511, numObservations: 3
action 2, numVisits=52, meanQ=3.953083, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.630747 0.867333 0.695258 0.827711 0.972946 0.197845 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 442
Initial state: 0 0.237207 0.588711 0.586575 0.86798 0.683053 0.805824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1119834 episodes
GETTING ACTION FROM:
action 2, numVisits=1119787, meanQ=5.003002, numObservations: 3
action -1, numVisits=33, meanQ=3.704248, numObservations: 1
action 3, numVisits=11, meanQ=2.627282, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.237207 0.588711 0.586575 0.86798 0.683053 0.805824 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 443
Initial state: 0 0.514792 0.813856 0.531402 0.0992658 0.513197 0.837015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100380 episodes
GETTING ACTION FROM:
action 1, numVisits=1096882, meanQ=5.001551, numObservations: 4
action 0, numVisits=3486, meanQ=2.943160, numObservations: 1
action 2, numVisits=9, meanQ=0.998889, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.514792 0.813856 0.531402 0.0992658 0.513197 0.837015 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.596583 0.884114 0.38632 0.309225 0.690399 0.87093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095583 episodes
GETTING ACTION FROM:
action 1, numVisits=1095564, meanQ=5.126701, numObservations: 5
action 0, numVisits=15, meanQ=3.145385, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.596583 0.884114 0.38632 0.309225 0.690399 0.87093 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 445
Initial state: 0 0.538002 0.821086 0.581975 0.801394 0.0345884 0.77993 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104405 episodes
GETTING ACTION FROM:
action 1, numVisits=1104352, meanQ=4.952544, numObservations: 4
action -1, numVisits=27, meanQ=3.515882, numObservations: 1
action 0, numVisits=24, meanQ=3.398360, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.538002 0.821086 0.581975 0.801394 0.0345884 0.77993 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 446
Initial state: 0 0.696022 0.836692 0.053091 0.14314 0.58743 0.886011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 784688 episodes
GETTING ACTION FROM:
action 0, numVisits=782636, meanQ=5.829035, numObservations: 3
action -1, numVisits=2048, meanQ=3.298032, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.696022 0.836692 0.053091 0.14314 0.58743 0.886011 w: 1
Observation: 0 0 0.874272 0 0.172417 0 0.832451 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=250978, meanQ=8.091953, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1154370 episodes
GETTING ACTION FROM:
action 3, numVisits=1405071, meanQ=5.334765, numObservations: 4
action 1, numVisits=240, meanQ=4.788453, numObservations: 4
action 0, numVisits=32, meanQ=3.998159, numObservations: 1
action -1, numVisits=9, meanQ=2.730000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.696022 0.836692 0.053091 0.14314 0.58743 0.886011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 447
Initial state: 0 0.394692 0.370734 0.55095 0.876346 0.698237 0.884297 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1073012 episodes
GETTING ACTION FROM:
action 3, numVisits=1072999, meanQ=4.962214, numObservations: 5
action 1, numVisits=8, meanQ=-0.001250, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.394692 0.370734 0.55095 0.876346 0.698237 0.884297 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 448
Initial state: 0 0.0272914 0.695942 0.560442 0.809994 0.605376 0.848277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1079371 episodes
GETTING ACTION FROM:
action 3, numVisits=1079365, meanQ=4.905921, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0272914 0.695942 0.560442 0.809994 0.605376 0.848277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.393037 0.688791 0.68098 0.855095 0.567974 0.846981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096840 episodes
GETTING ACTION FROM:
action 1, numVisits=1096807, meanQ=5.015343, numObservations: 5
action 0, numVisits=29, meanQ=3.455531, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.393037 0.688791 0.68098 0.855095 0.567974 0.846981 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=26334, meanQ=7.903679, numObservations: 5
action 2, numVisits=10, meanQ=4.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1386454 episodes
GETTING ACTION FROM:
action 3, numVisits=1412775, meanQ=6.010173, numObservations: 5
action 2, numVisits=21, meanQ=4.046667, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.393037 0.688791 0.68098 0.855095 0.567974 0.846981 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 450
Initial state: 0 0.6568 0.86414 0.0374192 0.725482 0.62046 0.81003 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1108915 episodes
GETTING ACTION FROM:
action 2, numVisits=1108909, meanQ=5.018879, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.6568 0.86414 0.0374192 0.725482 0.62046 0.81003 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=126995, meanQ=8.545983, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1424235 episodes
GETTING ACTION FROM:
action 1, numVisits=1551226, meanQ=6.387900, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.6568 0.86414 0.0374192 0.725482 0.62046 0.81003 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 451
Initial state: 0 0.615726 0.806816 0.643916 0.86954 0.755749 0.931158 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1116942 episodes
GETTING ACTION FROM:
action 1, numVisits=1116936, meanQ=5.023253, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.615726 0.806816 0.643916 0.86954 0.755749 0.931158 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 452
Initial state: 0 0.853894 0.0727072 0.632577 0.886766 0.554482 0.845423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1041840 episodes
GETTING ACTION FROM:
action 2, numVisits=1041834, meanQ=4.780056, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.853894 0.0727072 0.632577 0.886766 0.554482 0.845423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.536994 0.819425 0.191263 0.0540178 0.535774 0.874665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 796810 episodes
GETTING ACTION FROM:
action 0, numVisits=784955, meanQ=5.973848, numObservations: 3
action 2, numVisits=11735, meanQ=5.057174, numObservations: 4
action -1, numVisits=56, meanQ=4.265038, numObservations: 1
action 1, numVisits=63, meanQ=3.729052, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.536994 0.819425 0.191263 0.0540178 0.535774 0.874665 w: 1
Observation: 0 0 0.794099 0 0.0144604 0 0.795198 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=219544, meanQ=8.063273, numObservations: 4
action 3, numVisits=43403, meanQ=8.011514, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1226975 episodes
GETTING ACTION FROM:
action 1, numVisits=1299399, meanQ=5.676584, numObservations: 4
action 3, numVisits=190503, meanQ=5.665858, numObservations: 4
action -1, numVisits=20, meanQ=3.930835, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.536994 0.819425 0.191263 0.0540178 0.535774 0.874665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=98127, meanQ=6.163958, numObservations: 4
action 2, numVisits=8, meanQ=3.497500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1319549 episodes
GETTING ACTION FROM:
action 1, numVisits=1417671, meanQ=5.402044, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 3
action -1, numVisits=4, meanQ=0.475000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.536994 0.819425 0.191263 0.0540178 0.535774 0.874665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 454
Initial state: 0 0.552088 0.872085 0.659759 0.802356 0.302623 0.59359 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1072025 episodes
GETTING ACTION FROM:
action 3, numVisits=1071986, meanQ=4.878548, numObservations: 5
action 2, numVisits=33, meanQ=2.754864, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 0 0.552088 0.872085 0.659759 0.802356 0.302623 0.59359 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=91968, meanQ=8.538614, numObservations: 3
action 2, numVisits=29951, meanQ=8.524575, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1420997 episodes
GETTING ACTION FROM:
action 1, numVisits=1225421, meanQ=6.348904, numObservations: 4
action 2, numVisits=317493, meanQ=6.342297, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.552088 0.872085 0.659759 0.802356 0.302623 0.59359 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 455
Initial state: 0 0.513622 0.876366 0.811811 0.286722 0.505515 0.842047 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101108 episodes
GETTING ACTION FROM:
action 2, numVisits=1100882, meanQ=5.019573, numObservations: 5
action 0, numVisits=221, meanQ=1.329050, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 2
Next state: 2 0.513622 0.876366 0.811811 0.286722 0.505515 0.842047 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 456
Initial state: 0 0.662423 0.824522 0.666401 0.872881 0.369168 0.824801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105384 episodes
GETTING ACTION FROM:
action 2, numVisits=1105339, meanQ=4.931442, numObservations: 4
action -1, numVisits=37, meanQ=3.696980, numObservations: 1
action 1, numVisits=5, meanQ=1.000020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.662423 0.824522 0.666401 0.872881 0.369168 0.824801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 457
Initial state: 0 0.0651016 0.108745 0.660787 0.849742 0.504058 0.859741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1110993 episodes
GETTING ACTION FROM:
action 3, numVisits=1110900, meanQ=5.059936, numObservations: 4
action -1, numVisits=63, meanQ=4.105575, numObservations: 1
action 0, numVisits=24, meanQ=3.542048, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0651016 0.108745 0.660787 0.849742 0.504058 0.859741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 458
Initial state: 0 0.133466 0.397547 0.515941 0.871639 0.585888 0.810567 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 758688 episodes
GETTING ACTION FROM:
action -1, numVisits=758667, meanQ=2.786271, numObservations: 1
action 3, numVisits=13, meanQ=0.383846, numObservations: 2
action 2, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.133466 0.397547 0.515941 0.871639 0.585888 0.810567 w: 1
Observation: 0 0.223175 0 0.49585 0 0.558515 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=758573, meanQ=4.900572, numObservations: 4
action 0, numVisits=53, meanQ=3.823648, numObservations: 1
action 2, numVisits=37, meanQ=3.428124, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1211091 episodes
GETTING ACTION FROM:
action 3, numVisits=1969663, meanQ=4.856324, numObservations: 4
action 0, numVisits=54, meanQ=3.802466, numObservations: 1
action 2, numVisits=37, meanQ=3.428124, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.133466 0.397547 0.515941 0.871639 0.585888 0.810567 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 459
Initial state: 0 0.74275 0.0331845 0.640117 0.878826 0.619677 0.892282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1073135 episodes
GETTING ACTION FROM:
action 1, numVisits=1073103, meanQ=4.927357, numObservations: 5
action -1, numVisits=27, meanQ=3.425050, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.74275 0.0331845 0.640117 0.878826 0.619677 0.892282 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 460
Initial state: 0 0.188517 0.972794 0.613617 0.843915 0.5741 0.835458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111778 episodes
GETTING ACTION FROM:
action 2, numVisits=1111616, meanQ=4.968272, numObservations: 4
action -1, numVisits=119, meanQ=4.278667, numObservations: 1
action 3, numVisits=37, meanQ=3.518116, numObservations: 3
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.188517 0.972794 0.613617 0.843915 0.5741 0.835458 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 461
Initial state: 0 0.648381 0.846416 0.0925308 0.605067 0.631361 0.874981 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1106145 episodes
GETTING ACTION FROM:
action 1, numVisits=1106112, meanQ=4.996550, numObservations: 4
action 3, numVisits=14, meanQ=2.856436, numObservations: 3
action 2, numVisits=15, meanQ=2.725340, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.648381 0.846416 0.0925308 0.605067 0.631361 0.874981 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 462
Initial state: 0 0.157216 0.472237 0.699364 0.85968 0.674466 0.846544 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101889 episodes
GETTING ACTION FROM:
action 3, numVisits=1085885, meanQ=4.944799, numObservations: 4
action -1, numVisits=15999, meanQ=3.041130, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.157216 0.472237 0.699364 0.85968 0.674466 0.846544 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 463
Initial state: 0 0.50146 0.890456 0.117922 0.168111 0.629659 0.802738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091783 episodes
GETTING ACTION FROM:
action 3, numVisits=1091774, meanQ=5.174164, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.50146 0.890456 0.117922 0.168111 0.629659 0.802738 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 464
Initial state: 0 0.523729 0.859633 0.642561 0.889281 0.260043 0.746445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094299 episodes
GETTING ACTION FROM:
action 3, numVisits=1094293, meanQ=4.948103, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.523729 0.859633 0.642561 0.889281 0.260043 0.746445 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=55048, meanQ=8.394511, numObservations: 4
action 2, numVisits=97645, meanQ=8.391427, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1412663 episodes
GETTING ACTION FROM:
action 2, numVisits=792481, meanQ=6.279756, numObservations: 4
action 1, numVisits=772873, meanQ=6.279673, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.523729 0.859633 0.642561 0.889281 0.260043 0.746445 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 465
Initial state: 0 0.528564 0.800818 0.618803 0.89467 0.965518 0.731844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1109431 episodes
GETTING ACTION FROM:
action 1, numVisits=1109335, meanQ=5.161115, numObservations: 4
action 2, numVisits=65, meanQ=4.157540, numObservations: 5
action 0, numVisits=27, meanQ=3.641599, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.528564 0.800818 0.618803 0.89467 0.965518 0.731844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.871042 0.901264 0.608281 0.805914 0.576875 0.867097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095419 episodes
GETTING ACTION FROM:
action 2, numVisits=1095354, meanQ=4.942227, numObservations: 5
action 0, numVisits=58, meanQ=3.956996, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.871042 0.901264 0.608281 0.805914 0.576875 0.867097 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.956323 0.208233 0.672594 0.840406 0.692962 0.878683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1074890 episodes
GETTING ACTION FROM:
action 2, numVisits=1074802, meanQ=4.890171, numObservations: 5
action 3, numVisits=49, meanQ=3.800818, numObservations: 4
action 0, numVisits=36, meanQ=3.587349, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.956323 0.208233 0.672594 0.840406 0.692962 0.878683 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.419616 0.287153 0.607615 0.898531 0.628001 0.884031 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105316 episodes
GETTING ACTION FROM:
action 2, numVisits=1105185, meanQ=4.969364, numObservations: 4
action -1, numVisits=99, meanQ=4.208498, numObservations: 1
action 0, numVisits=27, meanQ=3.478005, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.419616 0.287153 0.607615 0.898531 0.628001 0.884031 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.640786 0.828002 0.368581 0.751136 0.634877 0.809444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103324 episodes
GETTING ACTION FROM:
action 1, numVisits=1103297, meanQ=4.954255, numObservations: 4
action 3, numVisits=17, meanQ=2.640588, numObservations: 3
action 0, numVisits=7, meanQ=1.818571, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.640786 0.828002 0.368581 0.751136 0.634877 0.809444 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 470
Initial state: 0 0.55971 0.807626 0.892201 0.170648 0.688059 0.850086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101069 episodes
GETTING ACTION FROM:
action 3, numVisits=1093341, meanQ=5.002607, numObservations: 4
action 0, numVisits=7697, meanQ=2.920486, numObservations: 1
action -1, numVisits=27, meanQ=1.795912, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 1
action: 3
Next state: 1 0.55971 0.807626 0.892201 0.170648 0.688059 0.850086 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.551585 0.823866 0.387685 0.191956 0.594982 0.83594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103272 episodes
GETTING ACTION FROM:
action 3, numVisits=1103225, meanQ=4.959362, numObservations: 4
action 0, numVisits=43, meanQ=3.796263, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.551585 0.823866 0.387685 0.191956 0.594982 0.83594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.338657 0.0876116 0.601583 0.863913 0.603602 0.87368 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1117065 episodes
GETTING ACTION FROM:
action 2, numVisits=1117037, meanQ=4.964837, numObservations: 3
action 1, numVisits=23, meanQ=3.260439, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.338657 0.0876116 0.601583 0.863913 0.603602 0.87368 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=79927, meanQ=4.761945, numObservations: 5
action 0, numVisits=42, meanQ=3.683293, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1379957 episodes
GETTING ACTION FROM:
action 3, numVisits=1459884, meanQ=5.960398, numObservations: 5
action 0, numVisits=42, meanQ=3.683293, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.338657 0.0876116 0.601583 0.863913 0.603602 0.87368 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 473
Initial state: 0 0.516279 0.876435 0.539703 0.877403 0.76318 0.299671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1083379 episodes
GETTING ACTION FROM:
action 1, numVisits=1083371, meanQ=4.918551, numObservations: 5
action 3, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.516279 0.876435 0.539703 0.877403 0.76318 0.299671 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 474
Initial state: 0 0.536883 0.311758 0.676315 0.813504 0.590332 0.865698 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1101682 episodes
GETTING ACTION FROM:
action 1, numVisits=1093909, meanQ=5.120174, numObservations: 4
action -1, numVisits=7767, meanQ=2.908229, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.536883 0.311758 0.676315 0.813504 0.590332 0.865698 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 475
Initial state: 0 0.642115 0.846922 0.670252 0.806229 0.326021 0.0475917 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105404 episodes
GETTING ACTION FROM:
action 1, numVisits=1105396, meanQ=4.953796, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.642115 0.846922 0.670252 0.806229 0.326021 0.0475917 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.365986 0.0692316 0.5438 0.825237 0.627122 0.87866 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111077 episodes
GETTING ACTION FROM:
action 3, numVisits=1108578, meanQ=4.956135, numObservations: 3
action 1, numVisits=2485, meanQ=4.665535, numObservations: 3
action 2, numVisits=10, meanQ=2.209000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.365986 0.0692316 0.5438 0.825237 0.627122 0.87866 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 477
Initial state: 0 0.692439 0.828021 0.726704 0.838103 0.579598 0.81909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100603 episodes
GETTING ACTION FROM:
action 1, numVisits=1100592, meanQ=4.961984, numObservations: 4
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.692439 0.828021 0.726704 0.838103 0.579598 0.81909 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.550334 0.81326 0.543268 0.833108 0.672989 0.0930038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094976 episodes
GETTING ACTION FROM:
action 3, numVisits=1094911, meanQ=4.927977, numObservations: 4
action 0, numVisits=59, meanQ=3.947678, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 2 0.550334 0.81326 0.543268 0.833108 0.672989 0.0930038 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 479
Initial state: 0 0.508712 0.848532 0.425389 0.84074 0.688942 0.886177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095356 episodes
GETTING ACTION FROM:
action 1, numVisits=1095321, meanQ=5.011813, numObservations: 5
action 0, numVisits=31, meanQ=3.674614, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.508712 0.848532 0.425389 0.84074 0.688942 0.886177 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.667064 0.800211 0.145608 0.403419 0.555035 0.803671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1111308 episodes
GETTING ACTION FROM:
action 1, numVisits=1111280, meanQ=5.014854, numObservations: 4
action -1, numVisits=24, meanQ=3.496432, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.667064 0.800211 0.145608 0.403419 0.555035 0.803671 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 481
Initial state: 0 0.623521 0.871752 0.672587 0.863326 0.226486 0.106918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1095913 episodes
GETTING ACTION FROM:
action 1, numVisits=1084989, meanQ=4.961252, numObservations: 4
action -1, numVisits=9081, meanQ=3.024760, numObservations: 1
action 0, numVisits=1841, meanQ=2.946618, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.623521 0.871752 0.672587 0.863326 0.226486 0.106918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 482
Initial state: 0 0.626279 0.804874 0.415503 0.518215 0.506251 0.88189 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094129 episodes
GETTING ACTION FROM:
action 1, numVisits=1094074, meanQ=4.960480, numObservations: 5
action -1, numVisits=28, meanQ=3.507579, numObservations: 1
action 0, numVisits=22, meanQ=3.255420, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 0 0.626279 0.804874 0.415503 0.518215 0.506251 0.88189 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=80311, meanQ=4.703852, numObservations: 5
action -1, numVisits=45, meanQ=3.713266, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1408842 episodes
GETTING ACTION FROM:
action 3, numVisits=1489153, meanQ=6.126740, numObservations: 5
action -1, numVisits=45, meanQ=3.713266, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.626279 0.804874 0.415503 0.518215 0.506251 0.88189 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 483
Initial state: 0 0.575816 0.889556 0.512231 0.898946 0.781464 0.781245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104637 episodes
GETTING ACTION FROM:
action 3, numVisits=1100856, meanQ=5.008243, numObservations: 4
action -1, numVisits=3777, meanQ=2.965725, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.575816 0.889556 0.512231 0.898946 0.781464 0.781245 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=79391, meanQ=5.547006, numObservations: 4
action 1, numVisits=116, meanQ=4.683961, numObservations: 3
action 2, numVisits=7, meanQ=2.427157, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 1310505 episodes
GETTING ACTION FROM:
action 3, numVisits=1389896, meanQ=5.390130, numObservations: 4
action 1, numVisits=116, meanQ=4.683961, numObservations: 3
action 2, numVisits=7, meanQ=2.427157, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.575816 0.889556 0.512231 0.898946 0.781464 0.781245 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 484
Initial state: 0 0.515512 0.88187 0.648316 0.807136 0.707637 0.8684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1115651 episodes
GETTING ACTION FROM:
action 1, numVisits=1115095, meanQ=4.960141, numObservations: 3
action 3, numVisits=549, meanQ=4.626763, numObservations: 5
action 2, numVisits=3, meanQ=-0.329967, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.515512 0.88187 0.648316 0.807136 0.707637 0.8684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 485
Initial state: 0 0.684793 0.818412 0.571835 0.80665 0.423716 0.12743 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1104087 episodes
GETTING ACTION FROM:
action 2, numVisits=1104057, meanQ=5.199343, numObservations: 5
action 0, numVisits=19, meanQ=3.410774, numObservations: 1
action 3, numVisits=8, meanQ=2.498750, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.684793 0.818412 0.571835 0.80665 0.423716 0.12743 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 486
Initial state: 0 0.687781 0.859686 0.830062 0.682698 0.678135 0.89506 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1077548 episodes
GETTING ACTION FROM:
action 3, numVisits=1077542, meanQ=4.969871, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.687781 0.859686 0.830062 0.682698 0.678135 0.89506 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.690823 0.800083 0.323087 0.370279 0.637543 0.830763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1096669 episodes
GETTING ACTION FROM:
action 3, numVisits=1096659, meanQ=4.933962, numObservations: 4
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.690823 0.800083 0.323087 0.370279 0.637543 0.830763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 488
Initial state: 0 0.955298 0.0900508 0.501871 0.851828 0.503844 0.82317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1042565 episodes
GETTING ACTION FROM:
action 3, numVisits=1039917, meanQ=4.798563, numObservations: 5
action -1, numVisits=2638, meanQ=2.919580, numObservations: 1
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.955298 0.0900508 0.501871 0.851828 0.503844 0.82317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.556148 0.829177 0.605656 0.83356 0.301106 0.398824 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105152 episodes
GETTING ACTION FROM:
action 1, numVisits=1104924, meanQ=4.997891, numObservations: 4
action -1, numVisits=149, meanQ=4.389590, numObservations: 1
action 0, numVisits=70, meanQ=4.095112, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 1
Next state: 1 0.556148 0.829177 0.605656 0.83356 0.301106 0.398824 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 490
Initial state: 0 0.600711 0.814712 0.494753 0.557906 0.531639 0.82212 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1107147 episodes
GETTING ACTION FROM:
action 1, numVisits=1107103, meanQ=5.007668, numObservations: 4
action -1, numVisits=26, meanQ=3.414055, numObservations: 1
action 2, numVisits=15, meanQ=2.197340, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.600711 0.814712 0.494753 0.557906 0.531639 0.82212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=80753, meanQ=5.510369, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1321286 episodes
GETTING ACTION FROM:
action 1, numVisits=1402039, meanQ=4.797635, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.600711 0.814712 0.494753 0.557906 0.531639 0.82212 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 491
Initial state: 0 0.587124 0.846308 0.669725 0.85152 0.954847 0.113739 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1100102 episodes
GETTING ACTION FROM:
action 1, numVisits=1097217, meanQ=5.007823, numObservations: 5
action 3, numVisits=2835, meanQ=4.872128, numObservations: 4
action -1, numVisits=47, meanQ=3.914340, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.587124 0.846308 0.669725 0.85152 0.954847 0.113739 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.0371923 0.145713 0.678655 0.874901 0.680344 0.815995 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 781987 episodes
GETTING ACTION FROM:
action 0, numVisits=781980, meanQ=4.170369, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.0371923 0.145713 0.678655 0.874901 0.680344 0.815995 w: 1
Observation: 0 0 0.203175 0 0.81384 0 0.753814 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=639622, meanQ=6.625114, numObservations: 4
action 0, numVisits=26, meanQ=3.530055, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1236520 episodes
GETTING ACTION FROM:
action 2, numVisits=1876142, meanQ=5.686339, numObservations: 4
action 0, numVisits=26, meanQ=3.530055, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0371923 0.145713 0.678655 0.874901 0.680344 0.815995 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 493
Initial state: 0 0.801962 0.660589 0.681201 0.891391 0.674816 0.808702 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1097662 episodes
GETTING ACTION FROM:
action 2, numVisits=1097510, meanQ=4.961997, numObservations: 5
action -1, numVisits=79, meanQ=4.116248, numObservations: 1
action 0, numVisits=70, meanQ=4.075826, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.801962 0.660589 0.681201 0.891391 0.674816 0.808702 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=79644, meanQ=4.758646, numObservations: 5
action -1, numVisits=167, meanQ=4.255348, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 1410069 episodes
GETTING ACTION FROM:
action 3, numVisits=1489713, meanQ=5.869845, numObservations: 5
action -1, numVisits=167, meanQ=4.255348, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.801962 0.660589 0.681201 0.891391 0.674816 0.808702 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 494
Initial state: 0 0.927265 0.479975 0.544656 0.89443 0.522242 0.813239 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1091671 episodes
GETTING ACTION FROM:
action 2, numVisits=1091660, meanQ=5.015450, numObservations: 5
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.927265 0.479975 0.544656 0.89443 0.522242 0.813239 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 495
Initial state: 0 0.663384 0.8524 0.920757 0.666898 0.51317 0.818082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1103821 episodes
GETTING ACTION FROM:
action 2, numVisits=1103741, meanQ=4.963970, numObservations: 4
action -1, numVisits=44, meanQ=3.822225, numObservations: 1
action 0, numVisits=31, meanQ=3.587393, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.663384 0.8524 0.920757 0.666898 0.51317 0.818082 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 496
Initial state: 0 0.515616 0.848405 0.372188 0.150589 0.675466 0.817265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1098030 episodes
GETTING ACTION FROM:
action 1, numVisits=1098007, meanQ=4.911041, numObservations: 4
action 2, numVisits=9, meanQ=2.333344, numObservations: 5
action 3, numVisits=10, meanQ=1.799000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.515616 0.848405 0.372188 0.150589 0.675466 0.817265 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.595946 0.825535 0.904103 0.339104 0.659882 0.835082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1094817 episodes
GETTING ACTION FROM:
action 1, numVisits=1094755, meanQ=4.929415, numObservations: 4
action 0, numVisits=48, meanQ=3.825143, numObservations: 1
action 2, numVisits=10, meanQ=2.189000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.595946 0.825535 0.904103 0.339104 0.659882 0.835082 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=52880, meanQ=4.772714, numObservations: 5
action -1, numVisits=26688, meanQ=3.335942, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 1397280 episodes
GETTING ACTION FROM:
action 2, numVisits=1450160, meanQ=5.855515, numObservations: 5
action -1, numVisits=26688, meanQ=3.335942, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.595946 0.825535 0.904103 0.339104 0.659882 0.835082 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 498
Initial state: 0 0.865092 0.691498 0.511725 0.866414 0.671736 0.888786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1071207 episodes
GETTING ACTION FROM:
action 3, numVisits=1071199, meanQ=4.783445, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.865092 0.691498 0.511725 0.866414 0.671736 0.888786 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.644166 0.814168 0.689945 0.833006 0.705201 0.582706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1090097 episodes
GETTING ACTION FROM:
action 1, numVisits=1089964, meanQ=4.936138, numObservations: 5
action -1, numVisits=66, meanQ=4.001272, numObservations: 1
action 0, numVisits=63, meanQ=3.984134, numObservations: 1
action 3, numVisits=3, meanQ=0.330033, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.644166 0.814168 0.689945 0.833006 0.705201 0.582706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.515071 0.631361 0.58536 0.887815 0.681032 0.844145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 1105523 episodes
GETTING ACTION FROM:
action 1, numVisits=1105156, meanQ=5.012662, numObservations: 4
action 2, numVisits=206, meanQ=4.432971, numObservations: 4
action -1, numVisits=112, meanQ=4.304157, numObservations: 1
action 0, numVisits=48, meanQ=3.916061, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.515071 0.631361 0.58536 0.887815 0.681032 0.844145 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
