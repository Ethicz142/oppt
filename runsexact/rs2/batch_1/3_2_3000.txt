Run # 1
Initial state: 0 0.634105 0.873376 0.145683 0.0357166 0.58913 0.835315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 618102 episodes
GETTING ACTION FROM:
action 3, numVisits=618066, meanQ=4.945180, numObservations: 5
action 0, numVisits=19, meanQ=3.216587, numObservations: 1
action -1, numVisits=15, meanQ=3.031237, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.634105 0.873376 0.145683 0.0357166 0.58913 0.835315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 2
Initial state: 0 0.987993 0.968207 0.633013 0.846092 0.665797 0.840609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 634570 episodes
GETTING ACTION FROM:
action 1, numVisits=634483, meanQ=4.777674, numObservations: 4
action -1, numVisits=57, meanQ=3.799215, numObservations: 1
action 3, numVisits=26, meanQ=3.069242, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.987993 0.968207 0.633013 0.846092 0.665797 0.840609 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 3
Initial state: 0 0.11967 0.240193 0.663036 0.814001 0.607469 0.847024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666539 episodes
GETTING ACTION FROM:
action 1, numVisits=666474, meanQ=4.998386, numObservations: 4
action -1, numVisits=59, meanQ=4.045507, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.11967 0.240193 0.663036 0.814001 0.607469 0.847024 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=104753, meanQ=8.337723, numObservations: 4
action 2, numVisits=4779, meanQ=8.259059, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 846387 episodes
GETTING ACTION FROM:
action 3, numVisits=902851, meanQ=6.253260, numObservations: 4
action 2, numVisits=53066, meanQ=6.228723, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.11967 0.240193 0.663036 0.814001 0.607469 0.847024 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 4
Initial state: 0 0.678749 0.889923 0.58325 0.887964 0.931029 0.254181 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668141 episodes
GETTING ACTION FROM:
action 2, numVisits=668120, meanQ=5.164079, numObservations: 4
action 3, numVisits=16, meanQ=3.248763, numObservations: 3
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.678749 0.889923 0.58325 0.887964 0.931029 0.254181 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 5
Initial state: 0 0.65904 0.83208 0.697204 0.858433 0.0457038 0.4626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672235 episodes
GETTING ACTION FROM:
action 2, numVisits=672189, meanQ=4.995683, numObservations: 4
action -1, numVisits=42, meanQ=3.836686, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.65904 0.83208 0.697204 0.858433 0.0457038 0.4626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 6
Initial state: 0 0.610432 0.700659 0.615001 0.856454 0.647267 0.845541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 652539 episodes
GETTING ACTION FROM:
action 3, numVisits=652523, meanQ=5.009472, numObservations: 5
action 1, numVisits=7, meanQ=2.155714, numObservations: 2
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.610432 0.700659 0.615001 0.856454 0.647267 0.845541 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 7
Initial state: 0 0.644213 0.882463 0.84785 0.426485 0.639336 0.83815 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658984 episodes
GETTING ACTION FROM:
action 2, numVisits=658973, meanQ=5.022119, numObservations: 5
action 1, numVisits=6, meanQ=1.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.644213 0.882463 0.84785 0.426485 0.639336 0.83815 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 8
Initial state: 0 0.170735 0.797669 0.660744 0.857953 0.627119 0.844512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660424 episodes
GETTING ACTION FROM:
action 3, numVisits=660414, meanQ=5.011888, numObservations: 4
action 1, numVisits=5, meanQ=0.196000, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.170735 0.797669 0.660744 0.857953 0.627119 0.844512 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 9
Initial state: 0 0.387968 0.498513 0.645319 0.838356 0.611811 0.809617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667931 episodes
GETTING ACTION FROM:
action 1, numVisits=667886, meanQ=5.005369, numObservations: 4
action -1, numVisits=22, meanQ=3.376045, numObservations: 1
action 3, numVisits=19, meanQ=3.094737, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.387968 0.498513 0.645319 0.838356 0.611811 0.809617 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=76670, meanQ=8.540362, numObservations: 3
action 3, numVisits=45, meanQ=7.442007, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 853537 episodes
GETTING ACTION FROM:
action 3, numVisits=441668, meanQ=6.268109, numObservations: 3
action 2, numVisits=488582, meanQ=6.198865, numObservations: 5
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.387968 0.498513 0.645319 0.838356 0.611811 0.809617 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 10
Initial state: 0 0.976012 0.956623 0.548761 0.851624 0.670825 0.860601 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663182 episodes
GETTING ACTION FROM:
action 2, numVisits=663019, meanQ=4.937075, numObservations: 4
action 3, numVisits=142, meanQ=4.297351, numObservations: 4
action 1, numVisits=17, meanQ=2.752947, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.976012 0.956623 0.548761 0.851624 0.670825 0.860601 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 11
Initial state: 0 0.61681 0.845458 0.718914 0.565188 0.563352 0.840115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662840 episodes
GETTING ACTION FROM:
action 2, numVisits=662829, meanQ=5.142340, numObservations: 4
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.61681 0.845458 0.718914 0.565188 0.563352 0.840115 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.567278 0.881794 0.50924 0.285541 0.536441 0.821657 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660954 episodes
GETTING ACTION FROM:
action 1, numVisits=660711, meanQ=5.011661, numObservations: 5
action -1, numVisits=221, meanQ=2.529183, numObservations: 1
action 3, numVisits=19, meanQ=1.204737, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.567278 0.881794 0.50924 0.285541 0.536441 0.821657 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48730, meanQ=5.541310, numObservations: 3
action 2, numVisits=9, meanQ=3.221111, numObservations: 3
action 3, numVisits=7, meanQ=2.427157, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 797358 episodes
GETTING ACTION FROM:
action 1, numVisits=846078, meanQ=4.907689, numObservations: 4
action 2, numVisits=11, meanQ=2.453636, numObservations: 3
action 3, numVisits=13, meanQ=2.383854, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.567278 0.881794 0.50924 0.285541 0.536441 0.821657 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 13
Initial state: 0 0.585822 0.852887 0.552656 0.226182 0.65045 0.881177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673433 episodes
GETTING ACTION FROM:
action 3, numVisits=673379, meanQ=5.030945, numObservations: 3
action 0, numVisits=50, meanQ=3.985099, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.585822 0.852887 0.552656 0.226182 0.65045 0.881177 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 14
Initial state: 0 0.518629 0.848637 0.715647 0.145892 0.592249 0.889352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666551 episodes
GETTING ACTION FROM:
action 1, numVisits=666497, meanQ=5.000518, numObservations: 4
action 0, numVisits=50, meanQ=3.956876, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.518629 0.848637 0.715647 0.145892 0.592249 0.889352 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48343, meanQ=5.564251, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 802859 episodes
GETTING ACTION FROM:
action 1, numVisits=851192, meanQ=5.012964, numObservations: 4
action 0, numVisits=10, meanQ=2.554000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.518629 0.848637 0.715647 0.145892 0.592249 0.889352 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 15
Initial state: 0 0.54734 0.827248 0.665645 0.883034 0.469144 0.160133 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661156 episodes
GETTING ACTION FROM:
action 1, numVisits=661146, meanQ=4.964952, numObservations: 5
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.54734 0.827248 0.665645 0.883034 0.469144 0.160133 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 16
Initial state: 0 0.697737 0.844679 0.574899 0.853377 0.737828 0.47805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673101 episodes
GETTING ACTION FROM:
action 2, numVisits=673025, meanQ=4.927845, numObservations: 3
action -1, numVisits=67, meanQ=4.034953, numObservations: 1
action 1, numVisits=6, meanQ=1.331683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.697737 0.844679 0.574899 0.853377 0.737828 0.47805 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=49899, meanQ=4.662530, numObservations: 4
action -1, numVisits=105, meanQ=3.850074, numObservations: 1
action 0, numVisits=61, meanQ=3.678152, numObservations: 1
action 1, numVisits=8, meanQ=2.250025, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 851709 episodes
GETTING ACTION FROM:
action 3, numVisits=901608, meanQ=5.770468, numObservations: 4
action -1, numVisits=105, meanQ=3.850074, numObservations: 1
action 0, numVisits=61, meanQ=3.678152, numObservations: 1
action 1, numVisits=8, meanQ=2.250025, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.697737 0.844679 0.574899 0.853377 0.737828 0.47805 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 17
Initial state: 0 0.814034 0.536084 0.686546 0.826473 0.620812 0.874957 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666388 episodes
GETTING ACTION FROM:
action 2, numVisits=666382, meanQ=5.005408, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.814034 0.536084 0.686546 0.826473 0.620812 0.874957 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 18
Initial state: 0 0.525014 0.857196 0.289464 0.396218 0.591755 0.850346 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662727 episodes
GETTING ACTION FROM:
action 2, numVisits=656147, meanQ=4.996788, numObservations: 5
action 3, numVisits=6419, meanQ=4.790735, numObservations: 4
action -1, numVisits=124, meanQ=4.314533, numObservations: 1
action 1, numVisits=35, meanQ=3.612571, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.525014 0.857196 0.289464 0.396218 0.591755 0.850346 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=92619, meanQ=8.366171, numObservations: 3
action 1, numVisits=75, meanQ=7.603600, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 868960 episodes
GETTING ACTION FROM:
action 3, numVisits=961334, meanQ=6.073535, numObservations: 3
action 1, numVisits=313, meanQ=5.640927, numObservations: 4
action 0, numVisits=6, meanQ=2.620000, numObservations: 1
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.525014 0.857196 0.289464 0.396218 0.591755 0.850346 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 19
Initial state: 0 0.515662 0.598156 0.593151 0.876614 0.607198 0.854325 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670229 episodes
GETTING ACTION FROM:
action 1, numVisits=670179, meanQ=4.940316, numObservations: 3
action -1, numVisits=38, meanQ=3.726752, numObservations: 1
action 3, numVisits=9, meanQ=2.333333, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.515662 0.598156 0.593151 0.876614 0.607198 0.854325 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 20
Initial state: 0 0.568594 0.825317 0.831436 0.679302 0.691583 0.84758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668266 episodes
GETTING ACTION FROM:
action 1, numVisits=668223, meanQ=4.952672, numObservations: 3
action 0, numVisits=34, meanQ=3.702505, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.568594 0.825317 0.831436 0.679302 0.691583 0.84758 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 21
Initial state: 0 0.5239 0.803671 0.942302 0.161669 0.654528 0.855024 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666392 episodes
GETTING ACTION FROM:
action 2, numVisits=666318, meanQ=5.037606, numObservations: 4
action 0, numVisits=69, meanQ=4.162078, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 2 0.5239 0.803671 0.942302 0.161669 0.654528 0.855024 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 22
Initial state: 0 0.521363 0.851983 0.86392 0.432599 0.537214 0.81664 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 470456 episodes
GETTING ACTION FROM:
action 0, numVisits=470448, meanQ=5.809109, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.521363 0.851983 0.86392 0.432599 0.537214 0.81664 w: 1
Observation: 0 0 0.892643 0 0.525407 0 0.863635 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110701, meanQ=8.221498, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 734680 episodes
GETTING ACTION FROM:
action 3, numVisits=845317, meanQ=5.673760, numObservations: 5
action -1, numVisits=36, meanQ=4.441439, numObservations: 1
action 0, numVisits=30, meanQ=4.328254, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.521363 0.851983 0.86392 0.432599 0.537214 0.81664 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 23
Initial state: 0 0.243199 0.680232 0.526718 0.871166 0.680864 0.887649 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662538 episodes
GETTING ACTION FROM:
action 3, numVisits=662439, meanQ=5.014264, numObservations: 4
action 0, numVisits=87, meanQ=4.234852, numObservations: 1
action 1, numVisits=9, meanQ=1.886667, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.243199 0.680232 0.526718 0.871166 0.680864 0.887649 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 24
Initial state: 0 0.678262 0.837379 0.502542 0.857117 0.79534 0.198562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661606 episodes
GETTING ACTION FROM:
action 3, numVisits=661587, meanQ=5.019080, numObservations: 5
action 0, numVisits=15, meanQ=3.038745, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.678262 0.837379 0.502542 0.857117 0.79534 0.198562 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.699971 0.851034 0.297705 0.590118 0.682099 0.842788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658145 episodes
GETTING ACTION FROM:
action 1, numVisits=658087, meanQ=4.960714, numObservations: 5
action 0, numVisits=44, meanQ=3.845404, numObservations: 1
action 2, numVisits=11, meanQ=1.907282, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.699971 0.851034 0.297705 0.590118 0.682099 0.842788 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 26
Initial state: 0 0.518212 0.876747 0.636399 0.873163 0.374696 0.169039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662570 episodes
GETTING ACTION FROM:
action 2, numVisits=662477, meanQ=4.956421, numObservations: 4
action 0, numVisits=84, meanQ=4.158288, numObservations: 1
action 1, numVisits=6, meanQ=-0.350000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.518212 0.876747 0.636399 0.873163 0.374696 0.169039 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 27
Initial state: 0 0.565889 0.89571 0.494246 0.284312 0.699639 0.880092 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661478 episodes
GETTING ACTION FROM:
action 2, numVisits=661288, meanQ=5.041013, numObservations: 5
action -1, numVisits=180, meanQ=1.248217, numObservations: 1
action 1, numVisits=7, meanQ=-0.145714, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.565889 0.89571 0.494246 0.284312 0.699639 0.880092 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15811, meanQ=7.940928, numObservations: 3
action 1, numVisits=16, meanQ=6.248750, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 867209 episodes
GETTING ACTION FROM:
action 3, numVisits=882919, meanQ=6.145211, numObservations: 3
action 1, numVisits=115, meanQ=5.447304, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.565889 0.89571 0.494246 0.284312 0.699639 0.880092 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 28
Initial state: 0 0.698486 0.846973 0.582833 0.834095 0.312943 0.971021 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659683 episodes
GETTING ACTION FROM:
action 3, numVisits=659666, meanQ=4.950807, numObservations: 4
action 2, numVisits=12, meanQ=2.664167, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.698486 0.846973 0.582833 0.834095 0.312943 0.971021 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=47630, meanQ=4.787739, numObservations: 4
action 2, numVisits=10, meanQ=2.399010, numObservations: 3
action 3, numVisits=5, meanQ=1.794000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 855600 episodes
GETTING ACTION FROM:
action 1, numVisits=903230, meanQ=5.862658, numObservations: 4
action 2, numVisits=10, meanQ=2.399010, numObservations: 3
action 3, numVisits=5, meanQ=1.794000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.698486 0.846973 0.582833 0.834095 0.312943 0.971021 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 29
Initial state: 0 0.631678 0.84557 0.0779211 0.843572 0.648928 0.826298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656848 episodes
GETTING ACTION FROM:
action 1, numVisits=656821, meanQ=4.937396, numObservations: 5
action 3, numVisits=21, meanQ=2.987152, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.631678 0.84557 0.0779211 0.843572 0.648928 0.826298 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 30
Initial state: 0 0.583012 0.849137 0.522305 0.847263 0.338312 0.434285 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664510 episodes
GETTING ACTION FROM:
action 2, numVisits=664441, meanQ=4.947452, numObservations: 4
action 1, numVisits=64, meanQ=3.828128, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.583012 0.849137 0.522305 0.847263 0.338312 0.434285 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 31
Initial state: 0 0.736075 0.944365 0.532282 0.858211 0.68522 0.858343 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657756 episodes
GETTING ACTION FROM:
action 2, numVisits=657715, meanQ=4.925676, numObservations: 4
action 3, numVisits=24, meanQ=3.150833, numObservations: 3
action 1, numVisits=13, meanQ=2.222308, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.736075 0.944365 0.532282 0.858211 0.68522 0.858343 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 32
Initial state: 0 0.15611 0.569819 0.67704 0.803417 0.654583 0.853978 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670119 episodes
GETTING ACTION FROM:
action 3, numVisits=670002, meanQ=5.010700, numObservations: 3
action 0, numVisits=105, meanQ=4.299273, numObservations: 1
action 1, numVisits=8, meanQ=0.997500, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.15611 0.569819 0.67704 0.803417 0.654583 0.853978 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 33
Initial state: 0 0.330137 0.374757 0.634068 0.827863 0.646329 0.867252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660113 episodes
GETTING ACTION FROM:
action 1, numVisits=660099, meanQ=5.159499, numObservations: 5
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action 2, numVisits=6, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.330137 0.374757 0.634068 0.827863 0.646329 0.867252 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=38841, meanQ=8.533159, numObservations: 3
action 2, numVisits=36842, meanQ=8.532073, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 851427 episodes
GETTING ACTION FROM:
action 2, numVisits=605023, meanQ=6.341887, numObservations: 4
action 3, numVisits=322085, meanQ=6.338545, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.330137 0.374757 0.634068 0.827863 0.646329 0.867252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 34
Initial state: 0 0.663949 0.859883 0.537276 0.810745 0.464695 0.637653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659259 episodes
GETTING ACTION FROM:
action 2, numVisits=654536, meanQ=4.987518, numObservations: 4
action 0, numVisits=4713, meanQ=2.722441, numObservations: 1
action 3, numVisits=5, meanQ=-1.402000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.663949 0.859883 0.537276 0.810745 0.464695 0.637653 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 35
Initial state: 0 0.367543 0.224166 0.628874 0.82163 0.680043 0.847834 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670319 episodes
GETTING ACTION FROM:
action 1, numVisits=669698, meanQ=5.010137, numObservations: 3
action 3, numVisits=581, meanQ=4.658350, numObservations: 5
action -1, numVisits=37, meanQ=3.795971, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.367543 0.224166 0.628874 0.82163 0.680043 0.847834 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110371, meanQ=8.315704, numObservations: 4
action 2, numVisits=45, meanQ=7.311340, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 850609 episodes
GETTING ACTION FROM:
action 3, numVisits=959743, meanQ=6.313093, numObservations: 4
action 2, numVisits=1280, meanQ=6.105815, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.367543 0.224166 0.628874 0.82163 0.680043 0.847834 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 36
Initial state: 0 0.927333 0.0781701 0.647433 0.852423 0.647243 0.87893 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658667 episodes
GETTING ACTION FROM:
action 3, numVisits=658642, meanQ=4.942188, numObservations: 5
action -1, numVisits=21, meanQ=3.208314, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.927333 0.0781701 0.647433 0.852423 0.647243 0.87893 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 37
Initial state: 0 0.679352 0.884986 0.133934 0.27382 0.572966 0.850293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666245 episodes
GETTING ACTION FROM:
action 2, numVisits=666238, meanQ=5.010573, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.679352 0.884986 0.133934 0.27382 0.572966 0.850293 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=93509, meanQ=8.399517, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 852823 episodes
GETTING ACTION FROM:
action 1, numVisits=946330, meanQ=6.154642, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.679352 0.884986 0.133934 0.27382 0.572966 0.850293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 38
Initial state: 0 0.624753 0.881554 0.611778 0.805847 0.992159 0.324821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663727 episodes
GETTING ACTION FROM:
action 1, numVisits=663721, meanQ=4.965625, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.624753 0.881554 0.611778 0.805847 0.992159 0.324821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 39
Initial state: 0 0.376644 0.391606 0.514388 0.849406 0.686722 0.83594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673248 episodes
GETTING ACTION FROM:
action 1, numVisits=671872, meanQ=5.010537, numObservations: 3
action 2, numVisits=1368, meanQ=4.555003, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.376644 0.391606 0.514388 0.849406 0.686722 0.83594 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110579, meanQ=8.314456, numObservations: 5
action 3, numVisits=26, meanQ=6.685385, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 849117 episodes
GETTING ACTION FROM:
action 2, numVisits=959005, meanQ=6.035679, numObservations: 5
action 3, numVisits=715, meanQ=5.756073, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.376644 0.391606 0.514388 0.849406 0.686722 0.83594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 40
Initial state: 0 0.597739 0.834715 0.643445 0.892333 0.417126 0.378622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655338 episodes
GETTING ACTION FROM:
action 2, numVisits=655332, meanQ=5.021025, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.597739 0.834715 0.643445 0.892333 0.417126 0.378622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 41
Initial state: 0 0.603179 0.820121 0.329227 0.775031 0.600857 0.814683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667362 episodes
GETTING ACTION FROM:
action 1, numVisits=667227, meanQ=5.022263, numObservations: 4
action -1, numVisits=89, meanQ=4.253659, numObservations: 1
action 2, numVisits=40, meanQ=3.795012, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.603179 0.820121 0.329227 0.775031 0.600857 0.814683 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 42
Initial state: 0 0.502538 0.888556 0.317451 0.449069 0.622435 0.878858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669171 episodes
GETTING ACTION FROM:
action 1, numVisits=668979, meanQ=5.160054, numObservations: 4
action 3, numVisits=187, meanQ=4.598148, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.502538 0.888556 0.317451 0.449069 0.622435 0.878858 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 43
Initial state: 0 0.306306 0.244025 0.570123 0.81906 0.559765 0.843032 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667283 episodes
GETTING ACTION FROM:
action 1, numVisits=667277, meanQ=5.023958, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.306306 0.244025 0.570123 0.81906 0.559765 0.843032 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=109502, meanQ=8.334550, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 845809 episodes
GETTING ACTION FROM:
action 2, numVisits=955304, meanQ=6.195222, numObservations: 5
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.306306 0.244025 0.570123 0.81906 0.559765 0.843032 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 44
Initial state: 0 0.00764489 0.0839321 0.561869 0.805196 0.552081 0.877334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 638132 episodes
GETTING ACTION FROM:
action 1, numVisits=638126, meanQ=4.820613, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.00764489 0.0839321 0.561869 0.805196 0.552081 0.877334 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=89685, meanQ=8.389367, numObservations: 4
action 2, numVisits=32, meanQ=7.186878, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 851153 episodes
GETTING ACTION FROM:
action 3, numVisits=938441, meanQ=5.941223, numObservations: 4
action 2, numVisits=2426, meanQ=5.797767, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.00764489 0.0839321 0.561869 0.805196 0.552081 0.877334 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 45
Initial state: 0 0.644565 0.850168 0.683102 0.865308 0.418088 0.343534 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665300 episodes
GETTING ACTION FROM:
action 2, numVisits=665294, meanQ=5.014589, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.644565 0.850168 0.683102 0.865308 0.418088 0.343534 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 46
Initial state: 0 0.941541 0.740717 0.576837 0.836893 0.531311 0.808144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655755 episodes
GETTING ACTION FROM:
action 3, numVisits=655718, meanQ=4.960994, numObservations: 4
action 1, numVisits=32, meanQ=2.981875, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.941541 0.740717 0.576837 0.836893 0.531311 0.808144 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 47
Initial state: 0 0.876419 0.923799 0.590902 0.890461 0.581106 0.898876 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670798 episodes
GETTING ACTION FROM:
action 1, numVisits=670613, meanQ=4.966822, numObservations: 3
action 0, numVisits=89, meanQ=4.194298, numObservations: 1
action 2, numVisits=56, meanQ=3.986798, numObservations: 5
action -1, numVisits=39, meanQ=3.779627, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.876419 0.923799 0.590902 0.890461 0.581106 0.898876 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 48
Initial state: 0 0.513385 0.835763 0.102454 0.641594 0.613644 0.852508 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673389 episodes
GETTING ACTION FROM:
action 2, numVisits=672669, meanQ=5.008642, numObservations: 4
action -1, numVisits=715, meanQ=1.927790, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 2
Next state: 0 0.513385 0.835763 0.102454 0.641594 0.613644 0.852508 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=109857, meanQ=8.280782, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855617 episodes
GETTING ACTION FROM:
action 1, numVisits=965472, meanQ=5.929224, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.513385 0.835763 0.102454 0.641594 0.613644 0.852508 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 49
Initial state: 0 0.674117 0.829159 0.792408 0.174035 0.667386 0.802573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 653913 episodes
GETTING ACTION FROM:
action 3, numVisits=653905, meanQ=5.029668, numObservations: 5
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.674117 0.829159 0.792408 0.174035 0.667386 0.802573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=47838, meanQ=5.534585, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 780738 episodes
GETTING ACTION FROM:
action 3, numVisits=828576, meanQ=5.068217, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.674117 0.829159 0.792408 0.174035 0.667386 0.802573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 50
Initial state: 0 0.634934 0.892573 0.536131 0.880657 0.48254 0.767382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 645194 episodes
GETTING ACTION FROM:
action 3, numVisits=645188, meanQ=4.822882, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.634934 0.892573 0.536131 0.880657 0.48254 0.767382 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=32262, meanQ=5.751483, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 870908 episodes
GETTING ACTION FROM:
action 1, numVisits=851780, meanQ=5.773482, numObservations: 3
action -1, numVisits=51391, meanQ=3.548006, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.634934 0.892573 0.536131 0.880657 0.48254 0.767382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 51
Initial state: 0 0.681722 0.897111 0.311179 0.391259 0.61541 0.855334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661944 episodes
GETTING ACTION FROM:
action 2, numVisits=661914, meanQ=5.001610, numObservations: 5
action -1, numVisits=26, meanQ=3.552390, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.681722 0.897111 0.311179 0.391259 0.61541 0.855334 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93059, meanQ=8.393508, numObservations: 4
action 1, numVisits=17, meanQ=6.646482, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 856869 episodes
GETTING ACTION FROM:
action 1, numVisits=331073, meanQ=5.995710, numObservations: 3
action 3, numVisits=618870, meanQ=5.974263, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.681722 0.897111 0.311179 0.391259 0.61541 0.855334 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 52
Initial state: 0 0.693828 0.883622 0.658785 0.832255 0.0668736 0.203514 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 446288 episodes
GETTING ACTION FROM:
action 0, numVisits=446213, meanQ=3.008375, numObservations: 1
action -1, numVisits=61, meanQ=2.071565, numObservations: 1
action 1, numVisits=6, meanQ=-0.999983, numObservations: 3
action 3, numVisits=7, meanQ=-1.287129, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.693828 0.883622 0.658785 0.832255 0.0668736 0.203514 w: 1
Observation: 0 0 0.815389 0 0.847102 0 0.184186 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=445733, meanQ=5.050356, numObservations: 5
action 1, numVisits=469, meanQ=4.720011, numObservations: 5
action 3, numVisits=6, meanQ=2.001700, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 708303 episodes
GETTING ACTION FROM:
action 2, numVisits=1153867, meanQ=5.002144, numObservations: 5
action 1, numVisits=634, meanQ=4.711558, numObservations: 5
action 3, numVisits=10, meanQ=2.392020, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.693828 0.883622 0.658785 0.832255 0.0668736 0.203514 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 53
Initial state: 0 0.263074 0.383313 0.692154 0.878125 0.68847 0.865464 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665748 episodes
GETTING ACTION FROM:
action 3, numVisits=663958, meanQ=5.007045, numObservations: 4
action 1, numVisits=1720, meanQ=4.570754, numObservations: 3
action -1, numVisits=53, meanQ=3.989539, numObservations: 1
action 2, numVisits=15, meanQ=2.998007, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.263074 0.383313 0.692154 0.878125 0.68847 0.865464 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 54
Initial state: 0 0.566917 0.773587 0.682916 0.813795 0.556171 0.877462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662929 episodes
GETTING ACTION FROM:
action 2, numVisits=662853, meanQ=4.963375, numObservations: 5
action -1, numVisits=69, meanQ=4.071365, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.566917 0.773587 0.682916 0.813795 0.556171 0.877462 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 55
Initial state: 0 0.542176 0.81458 0.967449 0.717522 0.634395 0.853463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 361142 episodes
GETTING ACTION FROM:
action -1, numVisits=361133, meanQ=3.597463, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=2, meanQ=-8.950000, numObservations: 1
action: -1
Next state: 0 0.542176 0.81458 0.967449 0.717522 0.634395 0.853463 w: 1
Observation: 0 0.600516 0 0.930244 0 0.732674 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=353082, meanQ=5.722424, numObservations: 3
action 3, numVisits=8024, meanQ=4.919322, numObservations: 4
action -1, numVisits=23, meanQ=3.692017, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 506118 episodes
GETTING ACTION FROM:
action 0, numVisits=859200, meanQ=5.749779, numObservations: 3
action 3, numVisits=8024, meanQ=4.919322, numObservations: 4
action -1, numVisits=23, meanQ=3.692017, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.542176 0.81458 0.967449 0.717522 0.634395 0.853463 w: 1
Observation: 0 0 0.758434 0 0.654162 0 0.948875 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=188077, meanQ=8.439483, numObservations: 4
action 3, numVisits=22183, meanQ=8.406338, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 726840 episodes
GETTING ACTION FROM:
action 1, numVisits=840655, meanQ=5.933340, numObservations: 4
action 3, numVisits=96424, meanQ=5.917465, numObservations: 4
action -1, numVisits=21, meanQ=4.196571, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.542176 0.81458 0.967449 0.717522 0.634395 0.853463 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.8409
Run # 56
Initial state: 0 0.684525 0.835183 0.0146691 0.982931 0.630622 0.857726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661144 episodes
GETTING ACTION FROM:
action 2, numVisits=661125, meanQ=4.989728, numObservations: 5
action 0, numVisits=15, meanQ=2.723664, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.684525 0.835183 0.0146691 0.982931 0.630622 0.857726 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48303, meanQ=5.389127, numObservations: 4
action 1, numVisits=181, meanQ=4.324756, numObservations: 3
action -1, numVisits=33, meanQ=4.250629, numObservations: 1
action 3, numVisits=7, meanQ=2.155714, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 793073 episodes
GETTING ACTION FROM:
action 2, numVisits=841373, meanQ=5.013869, numObservations: 4
action 1, numVisits=181, meanQ=4.324756, numObservations: 3
action -1, numVisits=36, meanQ=3.729744, numObservations: 1
action 3, numVisits=7, meanQ=2.155714, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.684525 0.835183 0.0146691 0.982931 0.630622 0.857726 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=27754, meanQ=8.336312, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 867806 episodes
GETTING ACTION FROM:
action 3, numVisits=894093, meanQ=6.331816, numObservations: 4
action 1, numVisits=1467, meanQ=6.145431, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.684525 0.835183 0.0146691 0.982931 0.630622 0.857726 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 57
Initial state: 0 0.58015 0.87582 0.607894 0.836472 0.94748 0.92994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659771 episodes
GETTING ACTION FROM:
action 1, numVisits=659762, meanQ=5.018255, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.58015 0.87582 0.607894 0.836472 0.94748 0.92994 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 58
Initial state: 0 0.0235145 0.473602 0.527628 0.86754 0.536936 0.800628 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661339 episodes
GETTING ACTION FROM:
action 3, numVisits=660908, meanQ=4.992255, numObservations: 4
action 2, numVisits=426, meanQ=4.631521, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0235145 0.473602 0.527628 0.86754 0.536936 0.800628 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 59
Initial state: 0 0.55012 0.803062 0.601909 0.889484 0.959242 0.343125 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672670 episodes
GETTING ACTION FROM:
action 2, numVisits=672593, meanQ=5.014077, numObservations: 3
action 0, numVisits=60, meanQ=4.070419, numObservations: 1
action 1, numVisits=14, meanQ=2.998571, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.55012 0.803062 0.601909 0.889484 0.959242 0.343125 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 60
Initial state: 0 0.572389 0.851425 0.566605 0.892241 0.0955338 0.134206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667696 episodes
GETTING ACTION FROM:
action 2, numVisits=667650, meanQ=5.155087, numObservations: 4
action 0, numVisits=26, meanQ=3.685055, numObservations: 1
action -1, numVisits=18, meanQ=3.404696, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.572389 0.851425 0.566605 0.892241 0.0955338 0.134206 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 61
Initial state: 0 0.630605 0.899177 0.872036 0.498759 0.657252 0.837107 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671385 episodes
GETTING ACTION FROM:
action 2, numVisits=664293, meanQ=5.024760, numObservations: 4
action 3, numVisits=7087, meanQ=4.942688, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.630605 0.899177 0.872036 0.498759 0.657252 0.837107 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 62
Initial state: 0 0.559017 0.821763 0.844064 0.184169 0.662516 0.813277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 641126 episodes
GETTING ACTION FROM:
action 3, numVisits=641108, meanQ=4.998966, numObservations: 4
action 2, numVisits=13, meanQ=2.074623, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.559017 0.821763 0.844064 0.184169 0.662516 0.813277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 63
Initial state: 0 0.53663 0.827576 0.878464 0.368298 0.615333 0.813616 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 464867 episodes
GETTING ACTION FROM:
action -1, numVisits=464861, meanQ=2.991245, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.53663 0.827576 0.878464 0.368298 0.615333 0.813616 w: 1
Observation: 0 0.627112 0 0.796219 0 0.691715 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=464827, meanQ=5.044899, numObservations: 4
action -1, numVisits=29, meanQ=3.655758, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 753114 episodes
GETTING ACTION FROM:
action 3, numVisits=1217941, meanQ=5.149007, numObservations: 4
action -1, numVisits=29, meanQ=3.655758, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.53663 0.827576 0.878464 0.368298 0.615333 0.813616 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=21887, meanQ=6.731452, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 859301 episodes
GETTING ACTION FROM:
action 1, numVisits=881186, meanQ=5.510786, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.53663 0.827576 0.878464 0.368298 0.615333 0.813616 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 64
Initial state: 0 0.612177 0.879104 0.705794 0.265785 0.574387 0.880653 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 652418 episodes
GETTING ACTION FROM:
action 3, numVisits=652403, meanQ=5.017980, numObservations: 5
action 2, numVisits=10, meanQ=1.798020, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.612177 0.879104 0.705794 0.265785 0.574387 0.880653 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 65
Initial state: 0 0.529806 0.856375 0.0885577 0.679621 0.5856 0.886405 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659681 episodes
GETTING ACTION FROM:
action 3, numVisits=659624, meanQ=5.013456, numObservations: 5
action 0, numVisits=52, meanQ=3.989465, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.529806 0.856375 0.0885577 0.679621 0.5856 0.886405 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 66
Initial state: 0 0.638877 0.803816 0.056468 0.0282176 0.531691 0.846437 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668387 episodes
GETTING ACTION FROM:
action 2, numVisits=668339, meanQ=5.140920, numObservations: 4
action 0, numVisits=43, meanQ=4.011052, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.638877 0.803816 0.056468 0.0282176 0.531691 0.846437 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=38459, meanQ=7.893469, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 852759 episodes
GETTING ACTION FROM:
action 3, numVisits=384676, meanQ=6.138009, numObservations: 4
action 1, numVisits=506542, meanQ=6.126118, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.638877 0.803816 0.056468 0.0282176 0.531691 0.846437 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 67
Initial state: 0 0.718249 0.0534805 0.660336 0.803027 0.650985 0.806303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657338 episodes
GETTING ACTION FROM:
action 2, numVisits=657305, meanQ=5.003047, numObservations: 5
action 0, numVisits=25, meanQ=3.442893, numObservations: 1
action 1, numVisits=4, meanQ=-0.007500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.718249 0.0534805 0.660336 0.803027 0.650985 0.806303 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 68
Initial state: 0 0.278243 0.00102799 0.596106 0.87193 0.684144 0.836392 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660284 episodes
GETTING ACTION FROM:
action 3, numVisits=660271, meanQ=4.950813, numObservations: 4
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.278243 0.00102799 0.596106 0.87193 0.684144 0.836392 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 69
Initial state: 0 0.543344 0.828905 0.621333 0.829679 0.259585 0.0427335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670385 episodes
GETTING ACTION FROM:
action 2, numVisits=670365, meanQ=5.021641, numObservations: 4
action 1, numVisits=14, meanQ=0.998586, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.543344 0.828905 0.621333 0.829679 0.259585 0.0427335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 70
Initial state: 0 0.609443 0.863884 0.509486 0.87531 0.825768 0.0343134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667591 episodes
GETTING ACTION FROM:
action 3, numVisits=667502, meanQ=5.012130, numObservations: 4
action -1, numVisits=84, meanQ=4.220653, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.609443 0.863884 0.509486 0.87531 0.825768 0.0343134 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 71
Initial state: 0 0.674485 0.874085 0.574728 0.878841 0.846441 0.638796 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660529 episodes
GETTING ACTION FROM:
action 3, numVisits=660514, meanQ=5.013448, numObservations: 4
action 2, numVisits=10, meanQ=2.399010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.674485 0.874085 0.574728 0.878841 0.846441 0.638796 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 72
Initial state: 0 0.677195 0.866639 0.666224 0.56806 0.51305 0.834378 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660231 episodes
GETTING ACTION FROM:
action 2, numVisits=645583, meanQ=5.009046, numObservations: 4
action 0, numVisits=14635, meanQ=3.133014, numObservations: 1
action 3, numVisits=5, meanQ=-0.201980, numObservations: 2
action 1, numVisits=6, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.677195 0.866639 0.666224 0.56806 0.51305 0.834378 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 73
Initial state: 0 0.158196 0.404209 0.514903 0.827746 0.568145 0.806274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 479217 episodes
GETTING ACTION FROM:
action 0, numVisits=479207, meanQ=5.923104, numObservations: 3
action 1, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.158196 0.404209 0.514903 0.827746 0.568145 0.806274 w: 1
Observation: 0 0 0.336922 0 0.750216 0 0.898222 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=143632, meanQ=8.241333, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 731994 episodes
GETTING ACTION FROM:
action 2, numVisits=875623, meanQ=5.354177, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.158196 0.404209 0.514903 0.827746 0.568145 0.806274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 74
Initial state: 0 0.667857 0.840944 0.813199 0.861369 0.686042 0.833841 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 643673 episodes
GETTING ACTION FROM:
action 1, numVisits=643636, meanQ=4.795996, numObservations: 4
action 2, numVisits=30, meanQ=3.453670, numObservations: 4
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.667857 0.840944 0.813199 0.861369 0.686042 0.833841 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=46365, meanQ=2.641720, numObservations: 1
action 0, numVisits=664, meanQ=2.372905, numObservations: 1
action 1, numVisits=12, meanQ=0.170033, numObservations: 2
action 3, numVisits=7, meanQ=-1.287143, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 776769 episodes
GETTING ACTION FROM:
action 1, numVisits=767200, meanQ=5.019279, numObservations: 5
action -1, numVisits=55820, meanQ=2.051960, numObservations: 1
action 0, numVisits=790, meanQ=1.843653, numObservations: 1
action 3, numVisits=7, meanQ=-1.287143, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.667857 0.840944 0.813199 0.861369 0.686042 0.833841 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 75
Initial state: 0 0.66786 0.843032 0.455807 0.0867555 0.596681 0.82808 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667177 episodes
GETTING ACTION FROM:
action 1, numVisits=667133, meanQ=5.133021, numObservations: 4
action -1, numVisits=30, meanQ=3.759175, numObservations: 1
action 2, numVisits=9, meanQ=1.886667, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.66786 0.843032 0.455807 0.0867555 0.596681 0.82808 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 76
Initial state: 0 0.652338 0.874043 0.997964 0.303175 0.634122 0.872081 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666553 episodes
GETTING ACTION FROM:
action 1, numVisits=666441, meanQ=4.985279, numObservations: 4
action -1, numVisits=57, meanQ=4.018695, numObservations: 1
action 3, numVisits=38, meanQ=3.733426, numObservations: 5
action 2, numVisits=15, meanQ=2.598000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.652338 0.874043 0.997964 0.303175 0.634122 0.872081 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 77
Initial state: 0 0.685821 0.899863 0.839372 0.521817 0.676166 0.854788 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 648953 episodes
GETTING ACTION FROM:
action 3, numVisits=613168, meanQ=5.214812, numObservations: 5
action -1, numVisits=35761, meanQ=3.058014, numObservations: 1
action 2, numVisits=19, meanQ=1.420000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 3
Next state: 1 0.685821 0.899863 0.839372 0.521817 0.676166 0.854788 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 78
Initial state: 0 0.3058 0.568981 0.511303 0.891744 0.545419 0.819968 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661724 episodes
GETTING ACTION FROM:
action 2, numVisits=660422, meanQ=4.998108, numObservations: 5
action 0, numVisits=1286, meanQ=2.638207, numObservations: 1
action 3, numVisits=13, meanQ=0.383854, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.3058 0.568981 0.511303 0.891744 0.545419 0.819968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48162, meanQ=5.567961, numObservations: 4
action 3, numVisits=72, meanQ=4.707225, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 844711 episodes
GETTING ACTION FROM:
action 3, numVisits=823484, meanQ=5.951539, numObservations: 4
action 2, numVisits=69459, meanQ=5.271423, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.3058 0.568981 0.511303 0.891744 0.545419 0.819968 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 79
Initial state: 0 0.5782 0.891423 0.597714 0.859543 0.243507 0.159098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462655 episodes
GETTING ACTION FROM:
action -1, numVisits=462649, meanQ=2.904456, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.5782 0.891423 0.597714 0.859543 0.243507 0.159098 w: 1
Observation: 0 0.552405 0 0.60599 0 0.240116 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=462626, meanQ=4.946190, numObservations: 4
action 1, numVisits=10, meanQ=2.597020, numObservations: 4
action 3, numVisits=8, meanQ=1.996250, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 732369 episodes
GETTING ACTION FROM:
action 2, numVisits=1194976, meanQ=4.922140, numObservations: 4
action 1, numVisits=29, meanQ=3.337248, numObservations: 4
action 3, numVisits=8, meanQ=1.996250, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.5782 0.891423 0.597714 0.859543 0.243507 0.159098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 80
Initial state: 0 0.71996 0.0321191 0.516559 0.866773 0.631192 0.811751 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655688 episodes
GETTING ACTION FROM:
action 2, numVisits=655681, meanQ=4.935703, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.71996 0.0321191 0.516559 0.866773 0.631192 0.811751 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 81
Initial state: 0 0.789606 0.185118 0.504502 0.806842 0.630106 0.815935 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 648176 episodes
GETTING ACTION FROM:
action 3, numVisits=648160, meanQ=4.975073, numObservations: 5
action 1, numVisits=11, meanQ=-0.654536, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.789606 0.185118 0.504502 0.806842 0.630106 0.815935 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 82
Initial state: 0 0.663524 0.810972 0.559844 0.491486 0.550612 0.82382 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 653396 episodes
GETTING ACTION FROM:
action 3, numVisits=646357, meanQ=4.932994, numObservations: 5
action -1, numVisits=7033, meanQ=2.871840, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.663524 0.810972 0.559844 0.491486 0.550612 0.82382 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 83
Initial state: 0 0.526227 0.821945 0.573313 0.886527 0.512494 0.783738 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666202 episodes
GETTING ACTION FROM:
action 1, numVisits=664147, meanQ=4.952390, numObservations: 4
action -1, numVisits=2050, meanQ=2.784061, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.526227 0.821945 0.573313 0.886527 0.512494 0.783738 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 84
Initial state: 0 0.489814 0.221647 0.622402 0.842581 0.548795 0.834617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462187 episodes
GETTING ACTION FROM:
action 0, numVisits=462180, meanQ=2.933990, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.489814 0.221647 0.622402 0.842581 0.548795 0.834617 w: 1
Observation: 0 0 0.173597 0 0.913946 0 0.898925 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=462100, meanQ=4.987354, numObservations: 3
action 0, numVisits=55, meanQ=3.979559, numObservations: 1
action 2, numVisits=21, meanQ=3.090957, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 743976 episodes
GETTING ACTION FROM:
action 3, numVisits=1206076, meanQ=5.122835, numObservations: 3
action 0, numVisits=55, meanQ=3.979559, numObservations: 1
action 2, numVisits=21, meanQ=3.090957, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.489814 0.221647 0.622402 0.842581 0.548795 0.834617 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 85
Initial state: 0 0.146635 0.963521 0.574922 0.894014 0.6336 0.857505 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 638810 episodes
GETTING ACTION FROM:
action 2, numVisits=638802, meanQ=4.863743, numObservations: 5
action 1, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.146635 0.963521 0.574922 0.894014 0.6336 0.857505 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 86
Initial state: 0 0.58329 0.884961 0.52265 0.800222 0.229024 0.285172 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 448311 episodes
GETTING ACTION FROM:
action 0, numVisits=448293, meanQ=2.776818, numObservations: 1
action 1, numVisits=9, meanQ=0.331122, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=4, meanQ=-2.502475, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 0
Next state: 0 0.58329 0.884961 0.52265 0.800222 0.229024 0.285172 w: 1
Observation: 0 0 0.797314 0 0.866344 0 0.385037 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=448235, meanQ=4.845103, numObservations: 5
action -1, numVisits=31, meanQ=3.473425, numObservations: 1
action 3, numVisits=12, meanQ=2.497525, numObservations: 3
action 1, numVisits=12, meanQ=1.667508, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 725156 episodes
GETTING ACTION FROM:
action 2, numVisits=1173391, meanQ=5.070318, numObservations: 5
action -1, numVisits=31, meanQ=3.473425, numObservations: 1
action 3, numVisits=12, meanQ=2.497525, numObservations: 3
action 1, numVisits=12, meanQ=1.667508, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.58329 0.884961 0.52265 0.800222 0.229024 0.285172 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 87
Initial state: 0 0.517856 0.869429 0.70554 0.477542 0.645756 0.807198 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664002 episodes
GETTING ACTION FROM:
action 2, numVisits=663910, meanQ=5.019142, numObservations: 5
action -1, numVisits=69, meanQ=4.136273, numObservations: 1
action 3, numVisits=20, meanQ=2.195005, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.517856 0.869429 0.70554 0.477542 0.645756 0.807198 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 88
Initial state: 0 0.688371 0.954694 0.64534 0.852491 0.626009 0.825479 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668093 episodes
GETTING ACTION FROM:
action 1, numVisits=668060, meanQ=5.016262, numObservations: 4
action 0, numVisits=19, meanQ=3.319595, numObservations: 1
action 2, numVisits=8, meanQ=1.747513, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.688371 0.954694 0.64534 0.852491 0.626009 0.825479 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 89
Initial state: 0 0.603984 0.898218 0.503798 0.26304 0.540635 0.820989 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 637828 episodes
GETTING ACTION FROM:
action 2, numVisits=637803, meanQ=4.882487, numObservations: 5
action 0, numVisits=19, meanQ=3.182932, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.603984 0.898218 0.503798 0.26304 0.540635 0.820989 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 90
Initial state: 0 0.564421 0.837063 0.664004 0.82073 0.232038 0.936763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 640783 episodes
GETTING ACTION FROM:
action 1, numVisits=640515, meanQ=4.953553, numObservations: 5
action 2, numVisits=263, meanQ=4.169737, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.564421 0.837063 0.664004 0.82073 0.232038 0.936763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 91
Initial state: 0 0.296251 0.143911 0.503254 0.80366 0.524304 0.859415 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666179 episodes
GETTING ACTION FROM:
action 3, numVisits=666173, meanQ=5.000710, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.296251 0.143911 0.503254 0.80366 0.524304 0.859415 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 92
Initial state: 0 0.595142 0.857113 0.845664 0.344484 0.658958 0.820066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 479120 episodes
GETTING ACTION FROM:
action 0, numVisits=469821, meanQ=5.924912, numObservations: 3
action 2, numVisits=9243, meanQ=4.970330, numObservations: 5
action -1, numVisits=38, meanQ=4.021050, numObservations: 1
action 1, numVisits=17, meanQ=2.652353, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.595142 0.857113 0.845664 0.344484 0.658958 0.820066 w: 1
Observation: 0 0 0.840831 0 0.327794 0 0.773973 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=144091, meanQ=8.174660, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action 3, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 743527 episodes
GETTING ACTION FROM:
action 1, numVisits=887609, meanQ=5.753543, numObservations: 3
action 3, numVisits=6, meanQ=2.333333, numObservations: 2
action 2, numVisits=6, meanQ=2.331700, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.595142 0.857113 0.845664 0.344484 0.658958 0.820066 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 93
Initial state: 0 0.566532 0.557549 0.672901 0.845037 0.503758 0.839972 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661249 episodes
GETTING ACTION FROM:
action 1, numVisits=661179, meanQ=4.963944, numObservations: 4
action -1, numVisits=49, meanQ=3.912376, numObservations: 1
action 2, numVisits=8, meanQ=2.250025, numObservations: 2
action 3, numVisits=11, meanQ=1.907282, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 2 0.566532 0.557549 0.672901 0.845037 0.503758 0.839972 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 94
Initial state: 0 0.540888 0.878915 0.631215 0.718712 0.657264 0.895858 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 450116 episodes
GETTING ACTION FROM:
action -1, numVisits=449632, meanQ=2.943397, numObservations: 1
action 0, numVisits=469, meanQ=2.618568, numObservations: 1
action 1, numVisits=11, meanQ=0.634564, numObservations: 4
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: -1
Next state: 0 0.540888 0.878915 0.631215 0.718712 0.657264 0.895858 w: 1
Observation: 0 0.466686 0 0.664399 0 0.578744 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=449617, meanQ=5.022088, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 710898 episodes
GETTING ACTION FROM:
action 1, numVisits=1160515, meanQ=4.990082, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.540888 0.878915 0.631215 0.718712 0.657264 0.895858 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 0, numVisits=76428, meanQ=5.315686, numObservations: 3
action 2, numVisits=521, meanQ=3.767522, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 838163 episodes
GETTING ACTION FROM:
action 2, numVisits=817120, meanQ=6.236697, numObservations: 4
action 0, numVisits=97992, meanQ=4.042923, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.540888 0.878915 0.631215 0.718712 0.657264 0.895858 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -16.7411
Run # 95
Initial state: 0 0.526564 0.819167 0.548805 0.824851 0.471245 0.94805 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668388 episodes
GETTING ACTION FROM:
action 3, numVisits=668372, meanQ=5.030486, numObservations: 4
action 0, numVisits=12, meanQ=2.399312, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.526564 0.819167 0.548805 0.824851 0.471245 0.94805 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=49084, meanQ=5.612002, numObservations: 4
action 1, numVisits=67, meanQ=4.766419, numObservations: 3
action 2, numVisits=15, meanQ=3.798673, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 862010 episodes
GETTING ACTION FROM:
action 1, numVisits=830811, meanQ=5.811925, numObservations: 3
action 3, numVisits=80336, meanQ=5.329357, numObservations: 4
action 2, numVisits=27, meanQ=3.888152, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 1 0.526564 0.819167 0.548805 0.824851 0.471245 0.94805 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 96
Initial state: 0 0.783062 0.796853 0.672173 0.898391 0.582654 0.865548 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658293 episodes
GETTING ACTION FROM:
action 3, numVisits=658258, meanQ=4.986159, numObservations: 5
action 0, numVisits=29, meanQ=3.617980, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=3, meanQ=-2.966667, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.783062 0.796853 0.672173 0.898391 0.582654 0.865548 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 97
Initial state: 0 0.511856 0.809992 0.546191 0.906618 0.586829 0.870783 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 453635 episodes
GETTING ACTION FROM:
action 0, numVisits=453578, meanQ=2.930552, numObservations: 1
action 2, numVisits=52, meanQ=1.920206, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.511856 0.809992 0.546191 0.906618 0.586829 0.870783 w: 1
Observation: 0 0 0.717811 0 0.983525 0 0.958251 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=453545, meanQ=4.995237, numObservations: 5
action 2, numVisits=22, meanQ=2.362741, numObservations: 3
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 728862 episodes
GETTING ACTION FROM:
action 3, numVisits=1182407, meanQ=5.086914, numObservations: 5
action 2, numVisits=22, meanQ=2.362741, numObservations: 3
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.511856 0.809992 0.546191 0.906618 0.586829 0.870783 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 98
Initial state: 0 0.0184268 0.227465 0.5626 0.890194 0.640607 0.855753 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657249 episodes
GETTING ACTION FROM:
action 3, numVisits=657243, meanQ=4.957041, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.0184268 0.227465 0.5626 0.890194 0.640607 0.855753 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 99
Initial state: 0 0.669415 0.80626 0.459747 0.696118 0.587675 0.87465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667883 episodes
GETTING ACTION FROM:
action 3, numVisits=456680, meanQ=5.032671, numObservations: 3
action 1, numVisits=211143, meanQ=4.917346, numObservations: 5
action -1, numVisits=30, meanQ=3.635953, numObservations: 1
action 0, numVisits=29, meanQ=3.577932, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.669415 0.80626 0.459747 0.696118 0.587675 0.87465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 100
Initial state: 0 0.516011 0.864008 0.330253 0.176611 0.606184 0.857582 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 451928 episodes
GETTING ACTION FROM:
action 0, numVisits=432586, meanQ=2.973995, numObservations: 1
action -1, numVisits=19312, meanQ=2.902810, numObservations: 1
action 1, numVisits=26, meanQ=1.307319, numObservations: 4
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 0
Next state: 0 0.516011 0.864008 0.330253 0.176611 0.606184 0.857582 w: 1
Observation: 0 0 0.903035 0 0.221101 0 0.824615 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=432574, meanQ=5.022977, numObservations: 4
action 3, numVisits=6, meanQ=1.651683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 708000 episodes
GETTING ACTION FROM:
action 2, numVisits=1140574, meanQ=4.934991, numObservations: 4
action 3, numVisits=6, meanQ=1.651683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.516011 0.864008 0.330253 0.176611 0.606184 0.857582 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 101
Initial state: 0 0.602303 0.830616 0.567933 0.803203 0.741405 0.909216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660425 episodes
GETTING ACTION FROM:
action 1, numVisits=660416, meanQ=4.949599, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.602303 0.830616 0.567933 0.803203 0.741405 0.909216 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 102
Initial state: 0 0.316304 0.430308 0.606276 0.857251 0.630147 0.875522 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 355130 episodes
GETTING ACTION FROM:
action -1, numVisits=355121, meanQ=0.954362, numObservations: 1
action 2, numVisits=5, meanQ=-3.001960, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.316304 0.430308 0.606276 0.857251 0.630147 0.875522 w: 1
Observation: 0 0.409566 0 0.572423 0 0.618141 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=113355, meanQ=3.002994, numObservations: 1
action 0, numVisits=241760, meanQ=2.959831, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 500109 episodes
GETTING ACTION FROM:
action -1, numVisits=613464, meanQ=3.029297, numObservations: 1
action 0, numVisits=241760, meanQ=2.959831, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.316304 0.430308 0.606276 0.857251 0.630147 0.875522 w: 1
Observation: 0 0.378923 0 0.525208 0 0.564377 0 
Immediate reward: -2
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=613398, meanQ=5.101233, numObservations: 4
action -1, numVisits=49, meanQ=4.058320, numObservations: 1
action 3, numVisits=12, meanQ=2.833350, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 741693 episodes
GETTING ACTION FROM:
action 1, numVisits=1355090, meanQ=5.100861, numObservations: 4
action -1, numVisits=50, meanQ=4.008021, numObservations: 1
action 3, numVisits=12, meanQ=2.833350, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 2 0.316304 0.430308 0.606276 0.857251 0.630147 0.875522 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.7611
Run # 103
Initial state: 0 0.673121 0.804027 0.618829 0.849407 0.713553 0.73163 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654771 episodes
GETTING ACTION FROM:
action 1, numVisits=654699, meanQ=4.856584, numObservations: 3
action -1, numVisits=68, meanQ=3.953456, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.673121 0.804027 0.618829 0.849407 0.713553 0.73163 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 104
Initial state: 0 0.198696 0.695804 0.591193 0.814834 0.596422 0.813245 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662657 episodes
GETTING ACTION FROM:
action 3, numVisits=648448, meanQ=5.014097, numObservations: 4
action 1, numVisits=14044, meanQ=4.960147, numObservations: 5
action 0, numVisits=162, meanQ=4.439802, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.198696 0.695804 0.591193 0.814834 0.596422 0.813245 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 105
Initial state: 0 0.703718 0.961541 0.518994 0.89401 0.535514 0.809113 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 646689 episodes
GETTING ACTION FROM:
action 3, numVisits=646655, meanQ=4.900193, numObservations: 4
action 1, numVisits=28, meanQ=3.142143, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.703718 0.961541 0.518994 0.89401 0.535514 0.809113 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 106
Initial state: 0 0.698019 0.853727 0.584945 0.863995 0.0480166 0.311322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659195 episodes
GETTING ACTION FROM:
action 2, numVisits=659081, meanQ=4.961316, numObservations: 5
action 0, numVisits=86, meanQ=4.170739, numObservations: 1
action -1, numVisits=26, meanQ=3.486750, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.698019 0.853727 0.584945 0.863995 0.0480166 0.311322 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 107
Initial state: 0 0.668958 0.851149 0.680417 0.834413 0.103836 0.343054 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672415 episodes
GETTING ACTION FROM:
action 1, numVisits=672371, meanQ=5.008541, numObservations: 3
action 0, numVisits=35, meanQ=3.775119, numObservations: 1
action 3, numVisits=3, meanQ=-0.329967, numObservations: 2
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.668958 0.851149 0.680417 0.834413 0.103836 0.343054 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 108
Initial state: 0 0.68323 0.829634 0.381838 0.326034 0.562558 0.809954 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 646341 episodes
GETTING ACTION FROM:
action 1, numVisits=646302, meanQ=4.848914, numObservations: 4
action -1, numVisits=34, meanQ=3.563984, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.68323 0.829634 0.381838 0.326034 0.562558 0.809954 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 109
Initial state: 0 0.594082 0.849498 0.0297599 0.435719 0.636956 0.813703 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659932 episodes
GETTING ACTION FROM:
action 3, numVisits=659819, meanQ=5.016488, numObservations: 5
action 0, numVisits=60, meanQ=4.074443, numObservations: 1
action 2, numVisits=50, meanQ=3.791202, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.594082 0.849498 0.0297599 0.435719 0.636956 0.813703 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 110
Initial state: 0 0.243691 0.137537 0.582907 0.82959 0.588404 0.846152 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669504 episodes
GETTING ACTION FROM:
action 1, numVisits=669487, meanQ=4.968459, numObservations: 3
action 3, numVisits=12, meanQ=2.498342, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.243691 0.137537 0.582907 0.82959 0.588404 0.846152 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=109688, meanQ=8.305000, numObservations: 5
action 3, numVisits=122, meanQ=7.645986, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 842277 episodes
GETTING ACTION FROM:
action 2, numVisits=947787, meanQ=6.070939, numObservations: 5
action 3, numVisits=4298, meanQ=5.963108, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.243691 0.137537 0.582907 0.82959 0.588404 0.846152 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 111
Initial state: 0 0.662269 0.846823 0.123447 0.194935 0.651654 0.882149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674048 episodes
GETTING ACTION FROM:
action 2, numVisits=673980, meanQ=4.957346, numObservations: 3
action -1, numVisits=35, meanQ=3.720104, numObservations: 1
action 0, numVisits=27, meanQ=3.499244, numObservations: 1
action 3, numVisits=5, meanQ=1.000000, numObservations: 3
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.662269 0.846823 0.123447 0.194935 0.651654 0.882149 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110611, meanQ=8.324160, numObservations: 5
action 1, numVisits=14, meanQ=5.992150, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 843119 episodes
GETTING ACTION FROM:
action 3, numVisits=953687, meanQ=6.388883, numObservations: 5
action 1, numVisits=55, meanQ=5.250911, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.662269 0.846823 0.123447 0.194935 0.651654 0.882149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 112
Initial state: 0 0.60452 0.819982 0.525452 0.824399 0.111663 0.132531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671323 episodes
GETTING ACTION FROM:
action 3, numVisits=671083, meanQ=4.945665, numObservations: 3
action 1, numVisits=212, meanQ=4.330879, numObservations: 4
action 0, numVisits=25, meanQ=3.456451, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.60452 0.819982 0.525452 0.824399 0.111663 0.132531 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=111032, meanQ=8.319131, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 856599 episodes
GETTING ACTION FROM:
action 1, numVisits=967626, meanQ=6.363720, numObservations: 4
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.60452 0.819982 0.525452 0.824399 0.111663 0.132531 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 113
Initial state: 0 0.849809 0.607158 0.511026 0.832714 0.554938 0.826394 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659536 episodes
GETTING ACTION FROM:
action 3, numVisits=659530, meanQ=5.169940, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.849809 0.607158 0.511026 0.832714 0.554938 0.826394 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 114
Initial state: 0 0.119315 0.905332 0.614368 0.815041 0.593828 0.829219 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662015 episodes
GETTING ACTION FROM:
action 1, numVisits=661912, meanQ=5.038825, numObservations: 5
action -1, numVisits=77, meanQ=4.207293, numObservations: 1
action 3, numVisits=18, meanQ=3.000561, numObservations: 4
action 2, numVisits=6, meanQ=1.663333, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.119315 0.905332 0.614368 0.815041 0.593828 0.829219 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48669, meanQ=5.518733, numObservations: 3
action 0, numVisits=37, meanQ=4.439754, numObservations: 1
action -1, numVisits=27, meanQ=4.150533, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=5, meanQ=-0.597980, numObservations: 3
Sampled 781217 episodes
GETTING ACTION FROM:
action 1, numVisits=829875, meanQ=4.893064, numObservations: 4
action 0, numVisits=43, meanQ=3.641541, numObservations: 1
action -1, numVisits=32, meanQ=3.437925, numObservations: 1
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action 3, numVisits=5, meanQ=-0.597980, numObservations: 3
action: 1
Next state: 0 0.119315 0.905332 0.614368 0.815041 0.593828 0.829219 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=19524, meanQ=6.985583, numObservations: 5
action 1, numVisits=4, meanQ=2.002525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 861493 episodes
GETTING ACTION FROM:
action 3, numVisits=881017, meanQ=6.502534, numObservations: 5
action 1, numVisits=4, meanQ=2.002525, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.119315 0.905332 0.614368 0.815041 0.593828 0.829219 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 115
Initial state: 0 0.547485 0.815457 0.889444 0.0198001 0.543179 0.84355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 454035 episodes
GETTING ACTION FROM:
action -1, numVisits=454025, meanQ=2.916382, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action: -1
Next state: 0 0.547485 0.815457 0.889444 0.0198001 0.543179 0.84355 w: 1
Observation: 0 0.526782 0 0.877958 0 0.608728 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=453984, meanQ=5.004395, numObservations: 4
action 3, numVisits=30, meanQ=3.453670, numObservations: 4
action 2, numVisits=6, meanQ=0.331683, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 718692 episodes
GETTING ACTION FROM:
action 1, numVisits=1172676, meanQ=5.023380, numObservations: 4
action 3, numVisits=30, meanQ=3.453670, numObservations: 4
action 2, numVisits=6, meanQ=0.331683, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.547485 0.815457 0.889444 0.0198001 0.543179 0.84355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 116
Initial state: 0 0.662345 0.695588 0.595631 0.870384 0.566684 0.880516 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 636069 episodes
GETTING ACTION FROM:
action 1, numVisits=623102, meanQ=4.988882, numObservations: 5
action 0, numVisits=12959, meanQ=3.090669, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.662345 0.695588 0.595631 0.870384 0.566684 0.880516 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 117
Initial state: 0 0.547315 0.845785 0.405454 0.517067 0.589003 0.876214 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664817 episodes
GETTING ACTION FROM:
action 1, numVisits=664730, meanQ=5.016091, numObservations: 4
action 0, numVisits=83, meanQ=4.195540, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.547315 0.845785 0.405454 0.517067 0.589003 0.876214 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 118
Initial state: 0 0.631706 0.870321 0.168084 0.0735332 0.640864 0.831626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658732 episodes
GETTING ACTION FROM:
action 1, numVisits=658586, meanQ=5.023854, numObservations: 5
action 0, numVisits=76, meanQ=4.171750, numObservations: 1
action -1, numVisits=68, meanQ=4.141746, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.631706 0.870321 0.168084 0.0735332 0.640864 0.831626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 119
Initial state: 0 0.682252 0.801205 0.651523 0.866878 0.497734 0.915009 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 645402 episodes
GETTING ACTION FROM:
action 3, numVisits=645327, meanQ=5.005777, numObservations: 4
action -1, numVisits=50, meanQ=3.971046, numObservations: 1
action 0, numVisits=15, meanQ=3.029912, numObservations: 1
action 1, numVisits=5, meanQ=1.396020, numObservations: 3
action 2, numVisits=5, meanQ=1.396020, numObservations: 3
action: 3
Next state: 1 0.682252 0.801205 0.651523 0.866878 0.497734 0.915009 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 120
Initial state: 0 0.757523 0.224424 0.679704 0.835577 0.53664 0.864413 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 642381 episodes
GETTING ACTION FROM:
action 1, numVisits=642327, meanQ=4.834480, numObservations: 4
action 0, numVisits=50, meanQ=1.879829, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.757523 0.224424 0.679704 0.835577 0.53664 0.864413 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 121
Initial state: 0 0.408215 0.919421 0.669476 0.873885 0.532783 0.841038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656658 episodes
GETTING ACTION FROM:
action 3, numVisits=656641, meanQ=4.953833, numObservations: 5
action 0, numVisits=13, meanQ=2.822696, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.408215 0.919421 0.669476 0.873885 0.532783 0.841038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48266, meanQ=4.667048, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 848260 episodes
GETTING ACTION FROM:
action 1, numVisits=896526, meanQ=5.791651, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.408215 0.919421 0.669476 0.873885 0.532783 0.841038 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=19788, meanQ=6.610792, numObservations: 5
action 0, numVisits=163, meanQ=4.021474, numObservations: 1
action -1, numVisits=153, meanQ=4.007825, numObservations: 1
action 1, numVisits=4, meanQ=0.025000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 866489 episodes
GETTING ACTION FROM:
action 2, numVisits=886277, meanQ=6.325595, numObservations: 5
action 0, numVisits=163, meanQ=4.021474, numObservations: 1
action -1, numVisits=153, meanQ=4.007825, numObservations: 1
action 1, numVisits=4, meanQ=0.025000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.408215 0.919421 0.669476 0.873885 0.532783 0.841038 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 122
Initial state: 0 0.570187 0.864029 0.311362 0.0883191 0.547717 0.800531 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462349 episodes
GETTING ACTION FROM:
action -1, numVisits=462324, meanQ=2.895829, numObservations: 1
action 1, numVisits=13, meanQ=0.383092, numObservations: 3
action 2, numVisits=7, meanQ=-0.712843, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 1
action: -1
Next state: 0 0.570187 0.864029 0.311362 0.0883191 0.547717 0.800531 w: 1
Observation: 0 0.558078 0 0.366614 0 0.578475 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=462230, meanQ=4.934313, numObservations: 4
action 0, numVisits=59, meanQ=3.998797, numObservations: 1
action 1, numVisits=23, meanQ=3.329143, numObservations: 4
action 3, numVisits=9, meanQ=2.320000, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
Sampled 733417 episodes
GETTING ACTION FROM:
action 2, numVisits=1195647, meanQ=5.025971, numObservations: 4
action 0, numVisits=59, meanQ=3.998797, numObservations: 1
action 1, numVisits=23, meanQ=3.329143, numObservations: 4
action 3, numVisits=9, meanQ=2.320000, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 0 0.570187 0.864029 0.311362 0.0883191 0.547717 0.800531 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=171001, meanQ=8.411281, numObservations: 3
action 1, numVisits=16, meanQ=6.499388, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 864615 episodes
GETTING ACTION FROM:
action 3, numVisits=1035612, meanQ=6.670419, numObservations: 3
action 1, numVisits=20, meanQ=4.999510, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.570187 0.864029 0.311362 0.0883191 0.547717 0.800531 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 123
Initial state: 0 0.889345 0.613573 0.675842 0.853129 0.659783 0.867434 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 480322 episodes
GETTING ACTION FROM:
action 0, numVisits=471265, meanQ=5.955130, numObservations: 3
action 2, numVisits=9000, meanQ=4.961378, numObservations: 5
action -1, numVisits=46, meanQ=4.120365, numObservations: 1
action 3, numVisits=10, meanQ=1.799000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.889345 0.613573 0.675842 0.853129 0.659783 0.867434 w: 1
Observation: 0 0 0.616751 0 0.909036 0 0.768775 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=142961, meanQ=8.249152, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 748894 episodes
GETTING ACTION FROM:
action 2, numVisits=891779, meanQ=5.663790, numObservations: 4
action 0, numVisits=46, meanQ=4.553933, numObservations: 1
action -1, numVisits=32, meanQ=4.333520, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.889345 0.613573 0.675842 0.853129 0.659783 0.867434 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=58104, meanQ=6.352738, numObservations: 4
action 3, numVisits=28, meanQ=5.001439, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 805162 episodes
GETTING ACTION FROM:
action 3, numVisits=196375, meanQ=5.952910, numObservations: 3
action 2, numVisits=666917, meanQ=5.095328, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.889345 0.613573 0.675842 0.853129 0.659783 0.867434 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 124
Initial state: 0 0.892222 0.23865 0.644653 0.833407 0.582046 0.88716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658155 episodes
GETTING ACTION FROM:
action 1, numVisits=647422, meanQ=5.015957, numObservations: 5
action -1, numVisits=10727, meanQ=3.024143, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.892222 0.23865 0.644653 0.833407 0.582046 0.88716 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 125
Initial state: 0 0.527819 0.807074 0.552564 0.828723 0.563002 0.741154 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673929 episodes
GETTING ACTION FROM:
action 3, numVisits=673670, meanQ=5.041407, numObservations: 3
action -1, numVisits=127, meanQ=4.394273, numObservations: 1
action 0, numVisits=110, meanQ=4.346258, numObservations: 1
action 2, numVisits=20, meanQ=3.281005, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 0 0.527819 0.807074 0.552564 0.828723 0.563002 0.741154 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=108060, meanQ=8.324639, numObservations: 5
action 2, numVisits=2401, meanQ=8.198863, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 848319 episodes
GETTING ACTION FROM:
action 1, numVisits=950087, meanQ=6.502702, numObservations: 5
action 2, numVisits=8693, meanQ=6.428747, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.527819 0.807074 0.552564 0.828723 0.563002 0.741154 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 126
Initial state: 0 0.436869 0.525552 0.573823 0.841433 0.512083 0.899909 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 478870 episodes
GETTING ACTION FROM:
action 0, numVisits=478858, meanQ=5.896363, numObservations: 3
action 1, numVisits=7, meanQ=0.428586, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.436869 0.525552 0.573823 0.841433 0.512083 0.899909 w: 1
Observation: 0 0 0.609708 0 0.917973 0 0.994262 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=122540, meanQ=8.326834, numObservations: 4
action 3, numVisits=13378, meanQ=8.286871, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 740922 episodes
GETTING ACTION FROM:
action 2, numVisits=783159, meanQ=5.599286, numObservations: 4
action 3, numVisits=93679, meanQ=5.583367, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.436869 0.525552 0.573823 0.841433 0.512083 0.899909 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 127
Initial state: 0 0.933159 0.128178 0.506872 0.86658 0.68363 0.837322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671272 episodes
GETTING ACTION FROM:
action 3, numVisits=671148, meanQ=4.998700, numObservations: 3
action -1, numVisits=87, meanQ=4.218755, numObservations: 1
action 0, numVisits=24, meanQ=3.502175, numObservations: 1
action 1, numVisits=8, meanQ=0.501263, numObservations: 2
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action: 3
Next state: 1 0.933159 0.128178 0.506872 0.86658 0.68363 0.837322 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 128
Initial state: 0 0.502211 0.882851 0.28915 0.296702 0.661497 0.811277 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 649812 episodes
GETTING ACTION FROM:
action 3, numVisits=633615, meanQ=5.000808, numObservations: 5
action -1, numVisits=16011, meanQ=3.167355, numObservations: 1
action 0, numVisits=180, meanQ=2.748148, numObservations: 1
action 1, numVisits=4, meanQ=-1.000000, numObservations: 3
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 1 0.502211 0.882851 0.28915 0.296702 0.661497 0.811277 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 129
Initial state: 0 0.500597 0.817492 0.647382 0.886115 0.104578 0.0272671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659814 episodes
GETTING ACTION FROM:
action 2, numVisits=649103, meanQ=5.026899, numObservations: 5
action -1, numVisits=10706, meanQ=3.023382, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.500597 0.817492 0.647382 0.886115 0.104578 0.0272671 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 130
Initial state: 0 0.629373 0.811523 0.354044 0.0998502 0.519607 0.872075 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667816 episodes
GETTING ACTION FROM:
action 3, numVisits=651561, meanQ=5.021832, numObservations: 4
action 1, numVisits=16249, meanQ=4.971048, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.629373 0.811523 0.354044 0.0998502 0.519607 0.872075 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 131
Initial state: 0 0.598375 0.840732 0.650908 0.994954 0.629252 0.818512 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655672 episodes
GETTING ACTION FROM:
action 3, numVisits=655578, meanQ=4.957350, numObservations: 5
action -1, numVisits=53, meanQ=3.948096, numObservations: 1
action 0, numVisits=36, meanQ=3.713266, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.598375 0.840732 0.650908 0.994954 0.629252 0.818512 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 132
Initial state: 0 0.668161 0.887488 0.814458 0.869046 0.575678 0.869124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669897 episodes
GETTING ACTION FROM:
action 3, numVisits=669833, meanQ=4.952875, numObservations: 3
action -1, numVisits=51, meanQ=3.902608, numObservations: 1
action 1, numVisits=10, meanQ=1.390010, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.668161 0.887488 0.814458 0.869046 0.575678 0.869124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 133
Initial state: 0 0.692048 0.883255 0.890241 0.733783 0.560111 0.802902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655666 episodes
GETTING ACTION FROM:
action 1, numVisits=655637, meanQ=5.051221, numObservations: 5
action 0, numVisits=22, meanQ=3.365654, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.692048 0.883255 0.890241 0.733783 0.560111 0.802902 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 134
Initial state: 0 0.5378 0.859788 0.506407 0.817773 0.0195535 0.525609 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656354 episodes
GETTING ACTION FROM:
action 3, numVisits=656327, meanQ=5.017068, numObservations: 5
action 0, numVisits=21, meanQ=3.414040, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.5378 0.859788 0.506407 0.817773 0.0195535 0.525609 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=92377, meanQ=8.400247, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 864630 episodes
GETTING ACTION FROM:
action 2, numVisits=957005, meanQ=6.356634, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.5378 0.859788 0.506407 0.817773 0.0195535 0.525609 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 135
Initial state: 0 0.692393 0.855518 0.358617 0.240126 0.680259 0.883408 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660782 episodes
GETTING ACTION FROM:
action 2, numVisits=660641, meanQ=4.951208, numObservations: 4
action 0, numVisits=131, meanQ=4.316903, numObservations: 1
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.692393 0.855518 0.358617 0.240126 0.680259 0.883408 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92998, meanQ=8.388219, numObservations: 3
action 3, numVisits=21, meanQ=6.428581, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 863082 episodes
GETTING ACTION FROM:
action 1, numVisits=956010, meanQ=6.168986, numObservations: 3
action 3, numVisits=89, meanQ=5.292142, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.692393 0.855518 0.358617 0.240126 0.680259 0.883408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=24635, meanQ=7.677119, numObservations: 4
action 1, numVisits=345, meanQ=7.326510, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 876877 episodes
GETTING ACTION FROM:
action 3, numVisits=896779, meanQ=6.045452, numObservations: 4
action 1, numVisits=5076, meanQ=5.948182, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.692393 0.855518 0.358617 0.240126 0.680259 0.883408 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 136
Initial state: 0 0.559904 0.802294 0.78335 0.245654 0.508713 0.871552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655861 episodes
GETTING ACTION FROM:
action 3, numVisits=643921, meanQ=5.147369, numObservations: 5
action -1, numVisits=11479, meanQ=3.060627, numObservations: 1
action 0, numVisits=457, meanQ=2.830455, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.559904 0.802294 0.78335 0.245654 0.508713 0.871552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 137
Initial state: 0 0.502765 0.809748 0.503048 0.809071 0.0346867 0.633847 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 650934 episodes
GETTING ACTION FROM:
action 1, numVisits=650922, meanQ=4.890933, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.502765 0.809748 0.503048 0.809071 0.0346867 0.633847 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 138
Initial state: 0 0.593033 0.80075 0.54759 0.852344 0.945704 0.512455 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666038 episodes
GETTING ACTION FROM:
action 3, numVisits=665984, meanQ=5.034908, numObservations: 4
action 0, numVisits=33, meanQ=3.744285, numObservations: 1
action 1, numVisits=18, meanQ=1.767800, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.593033 0.80075 0.54759 0.852344 0.945704 0.512455 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 139
Initial state: 0 0.569794 0.879119 0.529621 0.482627 0.630316 0.85288 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659235 episodes
GETTING ACTION FROM:
action 2, numVisits=658939, meanQ=5.016374, numObservations: 5
action 3, numVisits=196, meanQ=4.465912, numObservations: 5
action 0, numVisits=87, meanQ=4.236230, numObservations: 1
action 1, numVisits=11, meanQ=2.081818, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 2 0.569794 0.879119 0.529621 0.482627 0.630316 0.85288 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 140
Initial state: 0 0.500487 0.850289 0.511487 0.835815 0.993804 0.547257 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664592 episodes
GETTING ACTION FROM:
action 1, numVisits=652707, meanQ=5.154316, numObservations: 4
action -1, numVisits=11862, meanQ=3.060091, numObservations: 1
action 3, numVisits=20, meanQ=1.699015, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.500487 0.850289 0.511487 0.835815 0.993804 0.547257 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=42823, meanQ=7.391474, numObservations: 4
action 2, numVisits=69, meanQ=4.661164, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 838380 episodes
GETTING ACTION FROM:
action 2, numVisits=720359, meanQ=6.097113, numObservations: 5
action 1, numVisits=160911, meanQ=5.477571, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.500487 0.850289 0.511487 0.835815 0.993804 0.547257 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 141
Initial state: 0 0.524818 0.829284 0.421699 0.997224 0.665442 0.807356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660962 episodes
GETTING ACTION FROM:
action 3, numVisits=660865, meanQ=5.034054, numObservations: 5
action -1, numVisits=33, meanQ=3.764372, numObservations: 1
action 1, numVisits=61, meanQ=3.051972, numObservations: 5
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.524818 0.829284 0.421699 0.997224 0.665442 0.807356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 142
Initial state: 0 0.610668 0.824712 0.548898 0.834906 0.468137 0.95169 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664972 episodes
GETTING ACTION FROM:
action 2, numVisits=664907, meanQ=5.000157, numObservations: 4
action 0, numVisits=33, meanQ=3.672362, numObservations: 1
action -1, numVisits=30, meanQ=3.623494, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.610668 0.824712 0.548898 0.834906 0.468137 0.95169 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 143
Initial state: 0 0.614784 0.83974 0.606201 0.806259 0.832235 0.679267 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664757 episodes
GETTING ACTION FROM:
action 3, numVisits=664751, meanQ=5.012610, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.614784 0.83974 0.606201 0.806259 0.832235 0.679267 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 144
Initial state: 0 0.908389 0.317918 0.562057 0.872423 0.56315 0.836557 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 621098 episodes
GETTING ACTION FROM:
action 1, numVisits=620990, meanQ=4.658233, numObservations: 4
action 0, numVisits=103, meanQ=3.929793, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.908389 0.317918 0.562057 0.872423 0.56315 0.836557 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 145
Initial state: 0 0.526176 0.866288 0.546943 0.871529 0.462779 0.650057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 648139 episodes
GETTING ACTION FROM:
action 2, numVisits=648110, meanQ=5.021763, numObservations: 4
action -1, numVisits=25, meanQ=3.540340, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.526176 0.866288 0.546943 0.871529 0.462779 0.650057 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 146
Initial state: 0 0.56779 0.81801 0.337679 0.513613 0.644737 0.838663 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660510 episodes
GETTING ACTION FROM:
action 1, numVisits=660437, meanQ=4.999490, numObservations: 5
action -1, numVisits=65, meanQ=3.987274, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.56779 0.81801 0.337679 0.513613 0.644737 0.838663 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 147
Initial state: 0 0.647802 0.85908 0.624948 0.822803 0.147091 0.813774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656609 episodes
GETTING ACTION FROM:
action 3, numVisits=656489, meanQ=4.961518, numObservations: 4
action -1, numVisits=90, meanQ=4.197208, numObservations: 1
action 1, numVisits=15, meanQ=2.865347, numObservations: 3
action 0, numVisits=10, meanQ=2.058510, numObservations: 1
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action: 3
Next state: 2 0.647802 0.85908 0.624948 0.822803 0.147091 0.813774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 148
Initial state: 0 0.520208 0.343223 0.629627 0.840007 0.512085 0.899537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665901 episodes
GETTING ACTION FROM:
action 1, numVisits=665798, meanQ=4.954615, numObservations: 4
action -1, numVisits=95, meanQ=4.203165, numObservations: 1
action 3, numVisits=5, meanQ=-0.622000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.520208 0.343223 0.629627 0.840007 0.512085 0.899537 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 149
Initial state: 0 0.670512 0.220745 0.595767 0.842049 0.64633 0.878282 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 645244 episodes
GETTING ACTION FROM:
action 1, numVisits=643774, meanQ=4.868694, numObservations: 4
action -1, numVisits=1379, meanQ=2.762241, numObservations: 1
action 0, numVisits=78, meanQ=2.295446, numObservations: 1
action 2, numVisits=11, meanQ=1.000927, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 0 0.670512 0.220745 0.595767 0.842049 0.64633 0.878282 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=106293, meanQ=8.345890, numObservations: 4
action 2, numVisits=57, meanQ=7.419300, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 849826 episodes
GETTING ACTION FROM:
action 3, numVisits=955805, meanQ=6.368513, numObservations: 4
action 2, numVisits=368, meanQ=5.988469, numObservations: 4
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.670512 0.220745 0.595767 0.842049 0.64633 0.878282 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 150
Initial state: 0 0.201662 0.298945 0.576809 0.838543 0.618341 0.817695 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655949 episodes
GETTING ACTION FROM:
action 2, numVisits=655848, meanQ=4.976000, numObservations: 5
action 0, numVisits=87, meanQ=4.187667, numObservations: 1
action 1, numVisits=8, meanQ=0.748763, numObservations: 3
action 3, numVisits=4, meanQ=-0.007500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.201662 0.298945 0.576809 0.838543 0.618341 0.817695 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 151
Initial state: 0 0.601837 0.842594 0.840335 0.0564346 0.668546 0.865507 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659170 episodes
GETTING ACTION FROM:
action 2, numVisits=648745, meanQ=4.926191, numObservations: 4
action -1, numVisits=10420, meanQ=3.013811, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 2
Next state: 2 0.601837 0.842594 0.840335 0.0564346 0.668546 0.865507 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 152
Initial state: 0 0.557786 0.416828 0.634447 0.867651 0.528852 0.891915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 651884 episodes
GETTING ACTION FROM:
action 3, numVisits=642157, meanQ=4.979920, numObservations: 5
action -1, numVisits=9722, meanQ=2.989086, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.557786 0.416828 0.634447 0.867651 0.528852 0.891915 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 153
Initial state: 0 0.520316 0.871231 0.506953 0.890172 0.757432 0.856594 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660012 episodes
GETTING ACTION FROM:
action 2, numVisits=659972, meanQ=4.951820, numObservations: 5
action 0, numVisits=36, meanQ=3.658586, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.520316 0.871231 0.506953 0.890172 0.757432 0.856594 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 154
Initial state: 0 0.556195 0.832185 0.155077 0.744847 0.557827 0.841248 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668969 episodes
GETTING ACTION FROM:
action 1, numVisits=668898, meanQ=5.160131, numObservations: 4
action -1, numVisits=44, meanQ=4.053006, numObservations: 1
action 3, numVisits=18, meanQ=3.327228, numObservations: 4
action 2, numVisits=7, meanQ=2.144300, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.556195 0.832185 0.155077 0.744847 0.557827 0.841248 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 155
Initial state: 0 0.681446 0.858633 0.117811 0.546861 0.582674 0.895758 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 651653 episodes
GETTING ACTION FROM:
action 3, numVisits=651639, meanQ=4.906290, numObservations: 4
action 2, numVisits=9, meanQ=1.886667, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.681446 0.858633 0.117811 0.546861 0.582674 0.895758 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 156
Initial state: 0 0.662673 0.888506 0.0695645 0.117082 0.600857 0.850967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657824 episodes
GETTING ACTION FROM:
action 2, numVisits=657815, meanQ=4.941782, numObservations: 5
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.662673 0.888506 0.0695645 0.117082 0.600857 0.850967 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=92956, meanQ=8.370020, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855618 episodes
GETTING ACTION FROM:
action 1, numVisits=947894, meanQ=6.184892, numObservations: 4
action 3, numVisits=680, meanQ=5.903485, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.662673 0.888506 0.0695645 0.117082 0.600857 0.850967 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 157
Initial state: 0 0.579696 0.892298 0.529125 0.837237 0.288652 0.179423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660714 episodes
GETTING ACTION FROM:
action 1, numVisits=660708, meanQ=5.014364, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.579696 0.892298 0.529125 0.837237 0.288652 0.179423 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 158
Initial state: 0 0.146756 0.427381 0.605645 0.820865 0.517864 0.858262 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656616 episodes
GETTING ACTION FROM:
action 1, numVisits=647652, meanQ=5.021377, numObservations: 5
action 0, numVisits=8953, meanQ=2.959795, numObservations: 1
action 2, numVisits=6, meanQ=0.331667, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.146756 0.427381 0.605645 0.820865 0.517864 0.858262 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=90153, meanQ=8.410374, numObservations: 4
action 2, numVisits=495, meanQ=8.125224, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 849425 episodes
GETTING ACTION FROM:
action 3, numVisits=933075, meanQ=6.252849, numObservations: 4
action 2, numVisits=6996, meanQ=6.170485, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.146756 0.427381 0.605645 0.820865 0.517864 0.858262 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 159
Initial state: 0 0.650158 0.813141 0.151834 0.546147 0.561938 0.845535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661588 episodes
GETTING ACTION FROM:
action 2, numVisits=649518, meanQ=5.038523, numObservations: 5
action -1, numVisits=12059, meanQ=3.065567, numObservations: 1
action 3, numVisits=8, meanQ=-0.001250, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.650158 0.813141 0.151834 0.546147 0.561938 0.845535 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=90746, meanQ=8.402198, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 850712 episodes
GETTING ACTION FROM:
action 3, numVisits=940199, meanQ=5.865332, numObservations: 4
action 1, numVisits=1259, meanQ=5.660484, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.650158 0.813141 0.151834 0.546147 0.561938 0.845535 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 160
Initial state: 0 0.51087 0.865572 0.284878 0.224363 0.681178 0.844804 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665408 episodes
GETTING ACTION FROM:
action 1, numVisits=665395, meanQ=4.936977, numObservations: 4
action 2, numVisits=8, meanQ=1.747513, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.51087 0.865572 0.284878 0.224363 0.681178 0.844804 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 161
Initial state: 0 0.688623 0.103841 0.658869 0.809693 0.531499 0.877235 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 455557 episodes
GETTING ACTION FROM:
action -1, numVisits=454211, meanQ=3.008789, numObservations: 1
action 0, numVisits=1339, meanQ=2.731414, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action: -1
Next state: 0 0.688623 0.103841 0.658869 0.809693 0.531499 0.877235 w: 1
Observation: 0 0.726031 0 0.571686 0 0.483223 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=454115, meanQ=5.070720, numObservations: 5
action 0, numVisits=43, meanQ=3.945744, numObservations: 1
action -1, numVisits=39, meanQ=3.918300, numObservations: 1
action 1, numVisits=9, meanQ=2.553344, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
Sampled 729807 episodes
GETTING ACTION FROM:
action 3, numVisits=1183873, meanQ=4.849706, numObservations: 5
action -1, numVisits=65, meanQ=3.916445, numObservations: 1
action 0, numVisits=49, meanQ=3.784866, numObservations: 1
action 1, numVisits=26, meanQ=2.845781, numObservations: 5
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action: 3
Next state: 1 0.688623 0.103841 0.658869 0.809693 0.531499 0.877235 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 162
Initial state: 0 0.607209 0.835031 0.329489 0.711608 0.667482 0.805944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666427 episodes
GETTING ACTION FROM:
action 1, numVisits=666391, meanQ=4.943332, numObservations: 4
action -1, numVisits=20, meanQ=3.305813, numObservations: 1
action 3, numVisits=13, meanQ=1.921554, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.607209 0.835031 0.329489 0.711608 0.667482 0.805944 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 163
Initial state: 0 0.669408 0.890657 0.166161 0.741811 0.53468 0.894931 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670181 episodes
GETTING ACTION FROM:
action 2, numVisits=670161, meanQ=4.944786, numObservations: 4
action -1, numVisits=12, meanQ=2.399312, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.669408 0.890657 0.166161 0.741811 0.53468 0.894931 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=110125, meanQ=8.311591, numObservations: 4
action 3, numVisits=17, meanQ=6.293535, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 860569 episodes
GETTING ACTION FROM:
action 1, numVisits=970497, meanQ=6.362024, numObservations: 4
action 3, numVisits=212, meanQ=5.855425, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.669408 0.890657 0.166161 0.741811 0.53468 0.894931 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 164
Initial state: 0 0.696199 0.872236 0.834319 0.817141 0.617626 0.849467 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 648275 episodes
GETTING ACTION FROM:
action 1, numVisits=648269, meanQ=4.771059, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.696199 0.872236 0.834319 0.817141 0.617626 0.849467 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 165
Initial state: 0 0.535442 0.841408 0.684125 0.034459 0.62895 0.886605 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658158 episodes
GETTING ACTION FROM:
action 1, numVisits=658133, meanQ=5.153719, numObservations: 5
action 3, numVisits=19, meanQ=3.305805, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.535442 0.841408 0.684125 0.034459 0.62895 0.886605 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 166
Initial state: 0 0.520662 0.86116 0.56635 0.413169 0.660855 0.840093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666534 episodes
GETTING ACTION FROM:
action 1, numVisits=666493, meanQ=4.936933, numObservations: 4
action -1, numVisits=34, meanQ=3.643332, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.520662 0.86116 0.56635 0.413169 0.660855 0.840093 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 167
Initial state: 0 0.535638 0.881414 0.641314 0.866752 0.322036 0.633797 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660348 episodes
GETTING ACTION FROM:
action 3, numVisits=660308, meanQ=5.194751, numObservations: 5
action -1, numVisits=31, meanQ=3.854448, numObservations: 1
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.535638 0.881414 0.641314 0.866752 0.322036 0.633797 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=75842, meanQ=8.545305, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 849831 episodes
GETTING ACTION FROM:
action 2, numVisits=925670, meanQ=6.047509, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.535638 0.881414 0.641314 0.866752 0.322036 0.633797 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 168
Initial state: 0 0.899861 0.341596 0.60964 0.854678 0.617322 0.821098 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 473440 episodes
GETTING ACTION FROM:
action 0, numVisits=473434, meanQ=5.457908, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.899861 0.341596 0.60964 0.854678 0.617322 0.821098 w: 1
Observation: 0 0 0.321269 0 0.909989 0 0.778015 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=326997, meanQ=7.647977, numObservations: 4
action 2, numVisits=22, meanQ=3.626823, numObservations: 3
action 1, numVisits=12, meanQ=2.658333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 727966 episodes
GETTING ACTION FROM:
action 3, numVisits=1054931, meanQ=5.959554, numObservations: 4
action -1, numVisits=32, meanQ=4.607761, numObservations: 1
action 2, numVisits=22, meanQ=3.626823, numObservations: 3
action 1, numVisits=12, meanQ=2.658333, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.899861 0.341596 0.60964 0.854678 0.617322 0.821098 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 169
Initial state: 0 0.685341 0.824271 0.913611 0.330765 0.561789 0.80143 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 649302 episodes
GETTING ACTION FROM:
action 1, numVisits=643804, meanQ=4.929177, numObservations: 5
action 0, numVisits=5494, meanQ=2.936243, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.685341 0.824271 0.913611 0.330765 0.561789 0.80143 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 170
Initial state: 0 0.557428 0.871976 0.671597 0.464908 0.613726 0.842589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668586 episodes
GETTING ACTION FROM:
action 2, numVisits=668469, meanQ=4.963859, numObservations: 4
action -1, numVisits=96, meanQ=4.222930, numObservations: 1
action 1, numVisits=14, meanQ=2.998571, numObservations: 3
action 3, numVisits=5, meanQ=1.396020, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.557428 0.871976 0.671597 0.464908 0.613726 0.842589 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110708, meanQ=8.316076, numObservations: 4
action 1, numVisits=26, meanQ=6.918465, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 853587 episodes
GETTING ACTION FROM:
action 3, numVisits=958694, meanQ=6.220106, numObservations: 4
action 1, numVisits=5625, meanQ=6.127678, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.557428 0.871976 0.671597 0.464908 0.613726 0.842589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 171
Initial state: 0 0.569017 0.890497 0.320543 0.685103 0.531919 0.839254 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661601 episodes
GETTING ACTION FROM:
action 1, numVisits=661543, meanQ=5.021555, numObservations: 5
action 0, numVisits=36, meanQ=3.753993, numObservations: 1
action -1, numVisits=19, meanQ=3.178495, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.569017 0.890497 0.320543 0.685103 0.531919 0.839254 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 172
Initial state: 0 0.573736 0.817041 0.186727 0.39247 0.626671 0.892589 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 460317 episodes
GETTING ACTION FROM:
action 0, numVisits=460310, meanQ=2.988688, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.573736 0.817041 0.186727 0.39247 0.626671 0.892589 w: 1
Observation: 0 0 0.892393 0 0.433794 0 0.94079 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=460204, meanQ=5.014304, numObservations: 4
action -1, numVisits=99, meanQ=4.290746, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 737324 episodes
GETTING ACTION FROM:
action 1, numVisits=1197525, meanQ=5.016319, numObservations: 4
action -1, numVisits=102, meanQ=4.277743, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.573736 0.817041 0.186727 0.39247 0.626671 0.892589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=88844, meanQ=5.499327, numObservations: 4
action 0, numVisits=21, meanQ=4.003918, numObservations: 1
action 2, numVisits=7, meanQ=2.711429, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 822799 episodes
GETTING ACTION FROM:
action 2, numVisits=782788, meanQ=6.210405, numObservations: 5
action 1, numVisits=128861, meanQ=5.285295, numObservations: 4
action 0, numVisits=22, meanQ=3.731013, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.573736 0.817041 0.186727 0.39247 0.626671 0.892589 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=8897, meanQ=8.277135, numObservations: 4
action 1, numVisits=4, meanQ=4.975000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 873041 episodes
GETTING ACTION FROM:
action 3, numVisits=881921, meanQ=5.778120, numObservations: 4
action 1, numVisits=19, meanQ=3.942105, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.573736 0.817041 0.186727 0.39247 0.626671 0.892589 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -1.14771
Run # 173
Initial state: 0 0.741836 0.596656 0.635305 0.865823 0.550111 0.850203 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 649040 episodes
GETTING ACTION FROM:
action 2, numVisits=648999, meanQ=4.947774, numObservations: 3
action 0, numVisits=32, meanQ=3.579874, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.741836 0.596656 0.635305 0.865823 0.550111 0.850203 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 174
Initial state: 0 0.54432 0.684926 0.673977 0.878471 0.55058 0.850791 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666117 episodes
GETTING ACTION FROM:
action 2, numVisits=666106, meanQ=5.069617, numObservations: 5
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.54432 0.684926 0.673977 0.878471 0.55058 0.850791 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 175
Initial state: 0 0.575978 0.874663 0.658549 0.857591 0.372821 0.737445 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662305 episodes
GETTING ACTION FROM:
action 2, numVisits=662229, meanQ=4.944668, numObservations: 5
action -1, numVisits=39, meanQ=3.764477, numObservations: 1
action 0, numVisits=21, meanQ=3.200571, numObservations: 1
action 3, numVisits=15, meanQ=2.065333, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.575978 0.874663 0.658549 0.857591 0.372821 0.737445 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 176
Initial state: 0 0.5345 0.872161 0.642169 0.896858 0.891312 0.228117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672119 episodes
GETTING ACTION FROM:
action 3, numVisits=672113, meanQ=4.954698, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.5345 0.872161 0.642169 0.896858 0.891312 0.228117 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 177
Initial state: 0 0.366914 0.587416 0.591454 0.846512 0.66185 0.863127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668953 episodes
GETTING ACTION FROM:
action 1, numVisits=668940, meanQ=5.019356, numObservations: 4
action 2, numVisits=8, meanQ=1.987500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.366914 0.587416 0.591454 0.846512 0.66185 0.863127 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=76528, meanQ=8.539487, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 869059 episodes
GETTING ACTION FROM:
action 2, numVisits=945585, meanQ=6.363569, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.366914 0.587416 0.591454 0.846512 0.66185 0.863127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 178
Initial state: 0 0.519539 0.886416 0.672261 0.888774 0.911716 0.165884 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660010 episodes
GETTING ACTION FROM:
action 1, numVisits=659990, meanQ=5.141160, numObservations: 5
action 3, numVisits=15, meanQ=1.000673, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.519539 0.886416 0.672261 0.888774 0.911716 0.165884 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 179
Initial state: 0 0.53219 0.866603 0.291346 0.291603 0.619266 0.806293 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666631 episodes
GETTING ACTION FROM:
action 3, numVisits=662582, meanQ=5.031165, numObservations: 4
action 1, numVisits=3997, meanQ=4.871796, numObservations: 4
action -1, numVisits=49, meanQ=3.977903, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.53219 0.866603 0.291346 0.291603 0.619266 0.806293 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 180
Initial state: 0 0.329532 0.488504 0.655358 0.847627 0.659475 0.818671 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666687 episodes
GETTING ACTION FROM:
action 2, numVisits=666647, meanQ=5.017108, numObservations: 4
action 0, numVisits=27, meanQ=3.557919, numObservations: 1
action 3, numVisits=10, meanQ=2.591010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.329532 0.488504 0.655358 0.847627 0.659475 0.818671 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49312, meanQ=5.618851, numObservations: 4
action 3, numVisits=23, meanQ=3.607830, numObservations: 4
action 1, numVisits=7, meanQ=2.711429, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 850119 episodes
GETTING ACTION FROM:
action 1, numVisits=757981, meanQ=5.655826, numObservations: 4
action 2, numVisits=141453, meanQ=5.256017, numObservations: 4
action 3, numVisits=23, meanQ=3.607830, numObservations: 4
action 0, numVisits=4, meanQ=0.475000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 0 0.329532 0.488504 0.655358 0.847627 0.659475 0.818671 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=8847, meanQ=7.960046, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 863374 episodes
GETTING ACTION FROM:
action 2, numVisits=872219, meanQ=6.206300, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.329532 0.488504 0.655358 0.847627 0.659475 0.818671 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 181
Initial state: 0 0.587241 0.807095 0.133695 0.971224 0.584572 0.875139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661339 episodes
GETTING ACTION FROM:
action 1, numVisits=659729, meanQ=5.018273, numObservations: 5
action 2, numVisits=1542, meanQ=4.822123, numObservations: 4
action 0, numVisits=52, meanQ=3.994568, numObservations: 1
action 3, numVisits=14, meanQ=2.992871, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.587241 0.807095 0.133695 0.971224 0.584572 0.875139 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 182
Initial state: 0 0.118145 0.546483 0.627382 0.83043 0.564683 0.871795 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664667 episodes
GETTING ACTION FROM:
action 3, numVisits=664620, meanQ=4.934135, numObservations: 4
action -1, numVisits=41, meanQ=3.782353, numObservations: 1
action 2, numVisits=3, meanQ=-0.329967, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.118145 0.546483 0.627382 0.83043 0.564683 0.871795 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 183
Initial state: 0 0.673142 0.844538 0.592529 0.851352 0.655945 0.281552 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668994 episodes
GETTING ACTION FROM:
action 1, numVisits=668924, meanQ=5.017838, numObservations: 4
action -1, numVisits=58, meanQ=4.048064, numObservations: 1
action 3, numVisits=9, meanQ=2.553344, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.673142 0.844538 0.592529 0.851352 0.655945 0.281552 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 184
Initial state: 0 0.544471 0.89949 0.10893 0.514013 0.542082 0.820356 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662326 episodes
GETTING ACTION FROM:
action 3, numVisits=662260, meanQ=4.996539, numObservations: 5
action -1, numVisits=62, meanQ=4.069623, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.544471 0.89949 0.10893 0.514013 0.542082 0.820356 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 185
Initial state: 0 0.980358 0.357096 0.570585 0.806479 0.575724 0.890454 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670981 episodes
GETTING ACTION FROM:
action 3, numVisits=670895, meanQ=5.029191, numObservations: 3
action 0, numVisits=71, meanQ=4.150711, numObservations: 1
action 2, numVisits=12, meanQ=0.490842, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.980358 0.357096 0.570585 0.806479 0.575724 0.890454 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 186
Initial state: 0 0.536135 0.890349 0.642212 0.823629 0.205687 0.546463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661553 episodes
GETTING ACTION FROM:
action 1, numVisits=661507, meanQ=4.985566, numObservations: 4
action 2, numVisits=21, meanQ=3.386200, numObservations: 4
action -1, numVisits=17, meanQ=3.181404, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.536135 0.890349 0.642212 0.823629 0.205687 0.546463 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 187
Initial state: 0 0.513348 0.856626 0.657198 0.853787 0.323134 0.596321 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663212 episodes
GETTING ACTION FROM:
action 2, numVisits=662580, meanQ=4.955039, numObservations: 4
action 1, numVisits=468, meanQ=4.611699, numObservations: 3
action 0, numVisits=93, meanQ=4.187837, numObservations: 1
action 3, numVisits=69, meanQ=3.866980, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.513348 0.856626 0.657198 0.853787 0.323134 0.596321 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48215, meanQ=4.707498, numObservations: 4
action 3, numVisits=14, meanQ=1.857150, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 855021 episodes
GETTING ACTION FROM:
action 1, numVisits=903236, meanQ=5.541380, numObservations: 4
action 3, numVisits=14, meanQ=1.857150, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.513348 0.856626 0.657198 0.853787 0.323134 0.596321 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=20118, meanQ=6.857183, numObservations: 4
action -1, numVisits=198, meanQ=1.935454, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 869131 episodes
GETTING ACTION FROM:
action 1, numVisits=889249, meanQ=5.276595, numObservations: 4
action -1, numVisits=198, meanQ=1.935454, numObservations: 1
action 2, numVisits=5, meanQ=0.196000, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.513348 0.856626 0.657198 0.853787 0.323134 0.596321 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 188
Initial state: 0 0.721928 0.485971 0.644641 0.88308 0.579187 0.896727 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662096 episodes
GETTING ACTION FROM:
action 2, numVisits=654947, meanQ=5.023788, numObservations: 4
action 0, numVisits=7131, meanQ=2.877552, numObservations: 1
action 3, numVisits=15, meanQ=0.999347, numObservations: 3
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.721928 0.485971 0.644641 0.88308 0.579187 0.896727 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 189
Initial state: 0 0.659417 0.843939 0.912921 0.335079 0.672203 0.840228 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660026 episodes
GETTING ACTION FROM:
action 2, numVisits=659573, meanQ=4.992176, numObservations: 5
action 1, numVisits=366, meanQ=4.592972, numObservations: 4
action 0, numVisits=49, meanQ=3.949691, numObservations: 1
action -1, numVisits=37, meanQ=3.761197, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.659417 0.843939 0.912921 0.335079 0.672203 0.840228 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 190
Initial state: 0 0.598863 0.861842 0.879352 0.238135 0.687798 0.836322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 643371 episodes
GETTING ACTION FROM:
action 3, numVisits=643326, meanQ=5.046482, numObservations: 5
action 0, numVisits=39, meanQ=3.854956, numObservations: 1
action 1, numVisits=3, meanQ=0.330033, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.598863 0.861842 0.879352 0.238135 0.687798 0.836322 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 191
Initial state: 0 0.513763 0.868784 0.687164 0.841348 0.376798 0.935684 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657724 episodes
GETTING ACTION FROM:
action 1, numVisits=656853, meanQ=4.957747, numObservations: 5
action 3, numVisits=843, meanQ=4.690444, numObservations: 4
action 0, numVisits=25, meanQ=3.447488, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.513763 0.868784 0.687164 0.841348 0.376798 0.935684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=48731, meanQ=4.748025, numObservations: 5
action 2, numVisits=13, meanQ=2.846162, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 836079 episodes
GETTING ACTION FROM:
action 3, numVisits=884810, meanQ=5.883485, numObservations: 5
action 2, numVisits=13, meanQ=2.846162, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.513763 0.868784 0.687164 0.841348 0.376798 0.935684 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=4668, meanQ=7.395752, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 882308 episodes
GETTING ACTION FROM:
action 2, numVisits=886974, meanQ=6.320060, numObservations: 4
action 1, numVisits=3, meanQ=0.993333, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.513763 0.868784 0.687164 0.841348 0.376798 0.935684 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 192
Initial state: 0 0.69032 0.811797 0.527074 0.384041 0.666644 0.858994 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658627 episodes
GETTING ACTION FROM:
action 1, numVisits=658601, meanQ=4.958816, numObservations: 5
action 2, numVisits=21, meanQ=3.085238, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.69032 0.811797 0.527074 0.384041 0.666644 0.858994 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 193
Initial state: 0 0.24179 0.329507 0.555089 0.803901 0.509345 0.82423 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673722 episodes
GETTING ACTION FROM:
action 1, numVisits=673651, meanQ=4.995709, numObservations: 3
action 0, numVisits=56, meanQ=4.016917, numObservations: 1
action 3, numVisits=12, meanQ=2.668350, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.24179 0.329507 0.555089 0.803901 0.509345 0.82423 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=111028, meanQ=8.342582, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 870601 episodes
GETTING ACTION FROM:
action 2, numVisits=981621, meanQ=6.231063, numObservations: 3
action 3, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.24179 0.329507 0.555089 0.803901 0.509345 0.82423 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=25923, meanQ=7.685176, numObservations: 4
action 2, numVisits=938, meanQ=7.509119, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 872156 episodes
GETTING ACTION FROM:
action 3, numVisits=895735, meanQ=6.363800, numObservations: 4
action 2, numVisits=3280, meanQ=6.241879, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.24179 0.329507 0.555089 0.803901 0.509345 0.82423 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 194
Initial state: 0 0.604013 0.88607 0.668291 0.802383 0.894368 0.436832 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659805 episodes
GETTING ACTION FROM:
action 1, numVisits=659797, meanQ=4.954965, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.604013 0.88607 0.668291 0.802383 0.894368 0.436832 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 195
Initial state: 0 0.608276 0.848968 0.880455 0.534031 0.681098 0.863333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656152 episodes
GETTING ACTION FROM:
action 1, numVisits=656070, meanQ=4.943686, numObservations: 5
action 0, numVisits=77, meanQ=3.887227, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.608276 0.848968 0.880455 0.534031 0.681098 0.863333 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 196
Initial state: 0 0.658504 0.887306 0.59691 0.868896 0.838166 0.315336 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664616 episodes
GETTING ACTION FROM:
action 1, numVisits=664567, meanQ=4.996724, numObservations: 4
action 2, numVisits=31, meanQ=3.063877, numObservations: 4
action 0, numVisits=14, meanQ=2.919392, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.658504 0.887306 0.59691 0.868896 0.838166 0.315336 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 197
Initial state: 0 0.595593 0.830831 0.515821 0.821765 0.854681 0.187232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670752 episodes
GETTING ACTION FROM:
action 3, numVisits=670672, meanQ=4.957364, numObservations: 3
action 0, numVisits=42, meanQ=3.816519, numObservations: 1
action -1, numVisits=25, meanQ=3.498706, numObservations: 1
action 1, numVisits=9, meanQ=1.886667, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action: 3
Next state: 2 0.595593 0.830831 0.515821 0.821765 0.854681 0.187232 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 198
Initial state: 0 0.698331 0.872511 0.13833 0.00414622 0.526849 0.885952 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 453918 episodes
GETTING ACTION FROM:
action 0, numVisits=453871, meanQ=2.961251, numObservations: 1
action -1, numVisits=33, meanQ=1.617288, numObservations: 1
action 2, numVisits=7, meanQ=-0.145714, numObservations: 4
action 3, numVisits=6, meanQ=-2.001650, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.698331 0.872511 0.13833 0.00414622 0.526849 0.885952 w: 1
Observation: 0 0 0.779156 0 0 0 0.868955 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=453863, meanQ=5.015717, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 725699 episodes
GETTING ACTION FROM:
action 3, numVisits=1179562, meanQ=5.152604, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.698331 0.872511 0.13833 0.00414622 0.526849 0.885952 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 199
Initial state: 0 0.635417 0.891084 0.897695 0.0693344 0.662446 0.885892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 643534 episodes
GETTING ACTION FROM:
action 3, numVisits=643502, meanQ=4.862332, numObservations: 4
action 0, numVisits=28, meanQ=3.388626, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.635417 0.891084 0.897695 0.0693344 0.662446 0.885892 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 200
Initial state: 0 0.227472 0.627285 0.648496 0.817118 0.606364 0.877274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654534 episodes
GETTING ACTION FROM:
action 3, numVisits=645727, meanQ=4.896387, numObservations: 4
action 0, numVisits=8803, meanQ=2.953470, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.227472 0.627285 0.648496 0.817118 0.606364 0.877274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 201
Initial state: 0 0.274676 0.161572 0.569868 0.88841 0.694247 0.809279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655879 episodes
GETTING ACTION FROM:
action 1, numVisits=655815, meanQ=4.943644, numObservations: 5
action 0, numVisits=30, meanQ=3.603274, numObservations: 1
action -1, numVisits=29, meanQ=3.526412, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.274676 0.161572 0.569868 0.88841 0.694247 0.809279 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 202
Initial state: 0 0.507864 0.88086 0.890763 0.0840691 0.540349 0.890647 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662152 episodes
GETTING ACTION FROM:
action 3, numVisits=662120, meanQ=4.938696, numObservations: 4
action 1, numVisits=14, meanQ=2.855736, numObservations: 5
action 2, numVisits=14, meanQ=2.705729, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.507864 0.88086 0.890763 0.0840691 0.540349 0.890647 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 203
Initial state: 0 0.542732 0.832747 0.676041 0.876597 0.135605 0.120196 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665487 episodes
GETTING ACTION FROM:
action 1, numVisits=665331, meanQ=4.991630, numObservations: 4
action 3, numVisits=148, meanQ=4.331853, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.542732 0.832747 0.676041 0.876597 0.135605 0.120196 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 204
Initial state: 0 0.551633 0.841415 0.698761 0.801439 0.0287755 0.554449 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666011 episodes
GETTING ACTION FROM:
action 1, numVisits=666000, meanQ=4.951150, numObservations: 4
action 3, numVisits=5, meanQ=1.396020, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.551633 0.841415 0.698761 0.801439 0.0287755 0.554449 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 205
Initial state: 0 0.963215 0.968881 0.630213 0.835007 0.585884 0.841537 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661031 episodes
GETTING ACTION FROM:
action 2, numVisits=660927, meanQ=4.962130, numObservations: 5
action -1, numVisits=75, meanQ=4.114438, numObservations: 1
action 0, numVisits=17, meanQ=3.060096, numObservations: 1
action 1, numVisits=11, meanQ=1.727282, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.963215 0.968881 0.630213 0.835007 0.585884 0.841537 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 206
Initial state: 0 0.62598 0.835922 0.490327 0.587686 0.670789 0.837581 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660063 episodes
GETTING ACTION FROM:
action 3, numVisits=660057, meanQ=5.149478, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.62598 0.835922 0.490327 0.587686 0.670789 0.837581 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 207
Initial state: 0 0.655708 0.841151 0.57312 0.811297 0.237545 0.437444 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657306 episodes
GETTING ACTION FROM:
action 3, numVisits=657267, meanQ=4.941388, numObservations: 5
action 0, numVisits=35, meanQ=3.684171, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.655708 0.841151 0.57312 0.811297 0.237545 0.437444 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=75222, meanQ=8.527311, numObservations: 3
action 1, numVisits=10, meanQ=5.198010, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 857211 episodes
GETTING ACTION FROM:
action 2, numVisits=932425, meanQ=6.034302, numObservations: 4
action 1, numVisits=16, meanQ=4.123756, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.655708 0.841151 0.57312 0.811297 0.237545 0.437444 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 208
Initial state: 0 0.544923 0.870508 0.508961 0.871954 0.204193 0.695386 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664383 episodes
GETTING ACTION FROM:
action 2, numVisits=664252, meanQ=5.007937, numObservations: 5
action -1, numVisits=94, meanQ=4.249480, numObservations: 1
action 3, numVisits=24, meanQ=3.142917, numObservations: 4
action 1, numVisits=11, meanQ=2.272745, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.544923 0.870508 0.508961 0.871954 0.204193 0.695386 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 209
Initial state: 0 0.59323 0.803427 0.608885 0.835583 0.807978 0.00675821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660901 episodes
GETTING ACTION FROM:
action 2, numVisits=660815, meanQ=5.002405, numObservations: 5
action -1, numVisits=78, meanQ=4.167490, numObservations: 1
action 3, numVisits=5, meanQ=1.396020, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.59323 0.803427 0.608885 0.835583 0.807978 0.00675821 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 210
Initial state: 0 0.624731 0.806401 0.853096 0.216792 0.582768 0.890192 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664824 episodes
GETTING ACTION FROM:
action 3, numVisits=654978, meanQ=4.976280, numObservations: 3
action 0, numVisits=9833, meanQ=2.927908, numObservations: 1
action 2, numVisits=10, meanQ=0.598000, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.624731 0.806401 0.853096 0.216792 0.582768 0.890192 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 211
Initial state: 0 0.53162 0.811312 0.657362 0.877758 0.282849 0.113296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659391 episodes
GETTING ACTION FROM:
action 1, numVisits=659302, meanQ=4.958279, numObservations: 5
action 0, numVisits=49, meanQ=3.895868, numObservations: 1
action -1, numVisits=38, meanQ=3.778475, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.53162 0.811312 0.657362 0.877758 0.282849 0.113296 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 212
Initial state: 0 0.613958 0.828432 0.0464927 0.289879 0.560927 0.860048 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661444 episodes
GETTING ACTION FROM:
action 3, numVisits=661429, meanQ=5.012978, numObservations: 4
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 2, numVisits=5, meanQ=1.000020, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.613958 0.828432 0.0464927 0.289879 0.560927 0.860048 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 213
Initial state: 0 0.508768 0.813443 0.612348 0.885016 0.161297 0.691127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 650632 episodes
GETTING ACTION FROM:
action 2, numVisits=650616, meanQ=4.897984, numObservations: 4
action 3, numVisits=11, meanQ=2.081818, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.508768 0.813443 0.612348 0.885016 0.161297 0.691127 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 214
Initial state: 0 0.622521 0.860679 0.209445 0.1414 0.577514 0.842188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 631029 episodes
GETTING ACTION FROM:
action 3, numVisits=630998, meanQ=4.731590, numObservations: 4
action 1, numVisits=26, meanQ=3.229242, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.622521 0.860679 0.209445 0.1414 0.577514 0.842188 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action -1, numVisits=46530, meanQ=2.703910, numObservations: 1
action 0, numVisits=149, meanQ=2.194335, numObservations: 1
action 1, numVisits=12, meanQ=0.485017, numObservations: 3
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 853533 episodes
GETTING ACTION FROM:
action 1, numVisits=848614, meanQ=5.574901, numObservations: 4
action -1, numVisits=51446, meanQ=2.357869, numObservations: 1
action 0, numVisits=164, meanQ=1.861774, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.622521 0.860679 0.209445 0.1414 0.577514 0.842188 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 215
Initial state: 0 0.668121 0.826177 0.247561 0.209092 0.523357 0.88222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 457042 episodes
GETTING ACTION FROM:
action -1, numVisits=457029, meanQ=2.919985, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-8.950000, numObservations: 1
action: -1
Next state: 0 0.668121 0.826177 0.247561 0.209092 0.523357 0.88222 w: 1
Observation: 0 0.639738 0 0.291363 0 0.498242 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=456932, meanQ=4.975223, numObservations: 5
action 0, numVisits=40, meanQ=3.806673, numObservations: 1
action -1, numVisits=36, meanQ=3.776773, numObservations: 1
action 2, numVisits=19, meanQ=3.316326, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 724331 episodes
GETTING ACTION FROM:
action 1, numVisits=1181263, meanQ=5.064515, numObservations: 5
action 0, numVisits=40, meanQ=3.806673, numObservations: 1
action -1, numVisits=36, meanQ=3.776773, numObservations: 1
action 2, numVisits=19, meanQ=3.316326, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.668121 0.826177 0.247561 0.209092 0.523357 0.88222 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=87041, meanQ=4.732736, numObservations: 5
action 0, numVisits=307, meanQ=4.348473, numObservations: 1
action 2, numVisits=18, meanQ=2.216117, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 828738 episodes
GETTING ACTION FROM:
action 3, numVisits=915779, meanQ=5.867268, numObservations: 5
action 0, numVisits=307, meanQ=4.348473, numObservations: 1
action 2, numVisits=18, meanQ=2.216117, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.668121 0.826177 0.247561 0.209092 0.523357 0.88222 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 216
Initial state: 0 0.66339 0.849741 0.144392 0.175445 0.681551 0.852122 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654660 episodes
GETTING ACTION FROM:
action 2, numVisits=602481, meanQ=4.974895, numObservations: 4
action 1, numVisits=52174, meanQ=4.828758, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.66339 0.849741 0.144392 0.175445 0.681551 0.852122 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=69307, meanQ=8.544204, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 848087 episodes
GETTING ACTION FROM:
action 3, numVisits=917322, meanQ=6.550229, numObservations: 5
action 1, numVisits=74, meanQ=5.594461, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.66339 0.849741 0.144392 0.175445 0.681551 0.852122 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=5745, meanQ=8.019244, numObservations: 4
action 3, numVisits=12, meanQ=5.331667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 865413 episodes
GETTING ACTION FROM:
action 3, numVisits=813645, meanQ=5.923294, numObservations: 4
action 1, numVisits=57523, meanQ=5.863857, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.66339 0.849741 0.144392 0.175445 0.681551 0.852122 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 217
Initial state: 0 0.0912425 0.589451 0.52967 0.857099 0.570485 0.812672 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 652284 episodes
GETTING ACTION FROM:
action 3, numVisits=652278, meanQ=4.884200, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.0912425 0.589451 0.52967 0.857099 0.570485 0.812672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=48451, meanQ=5.616833, numObservations: 4
action 2, numVisits=9, meanQ=2.098900, numObservations: 3
action 1, numVisits=5, meanQ=1.794000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 820388 episodes
GETTING ACTION FROM:
action 1, numVisits=491416, meanQ=6.033143, numObservations: 5
action 3, numVisits=377426, meanQ=4.987473, numObservations: 4
action 2, numVisits=9, meanQ=2.098900, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 1
Next state: 0 0.0912425 0.589451 0.52967 0.857099 0.570485 0.812672 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=8147, meanQ=8.406306, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 880560 episodes
GETTING ACTION FROM:
action 2, numVisits=888705, meanQ=5.908627, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.0912425 0.589451 0.52967 0.857099 0.570485 0.812672 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 218
Initial state: 0 0.511673 0.886264 0.660038 0.89595 0.114582 0.941823 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656815 episodes
GETTING ACTION FROM:
action 2, numVisits=644445, meanQ=4.958944, numObservations: 4
action 0, numVisits=12362, meanQ=3.074189, numObservations: 1
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.511673 0.886264 0.660038 0.89595 0.114582 0.941823 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 219
Initial state: 0 0.57502 0.850211 0.582667 0.862751 0.611322 0.784932 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662042 episodes
GETTING ACTION FROM:
action 1, numVisits=657241, meanQ=5.013380, numObservations: 5
action 2, numVisits=4743, meanQ=4.910598, numObservations: 4
action 0, numVisits=55, meanQ=4.016260, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.57502 0.850211 0.582667 0.862751 0.611322 0.784932 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 220
Initial state: 0 0.411257 0.931801 0.65965 0.822391 0.622852 0.804139 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659981 episodes
GETTING ACTION FROM:
action 1, numVisits=659967, meanQ=4.945011, numObservations: 5
action 2, numVisits=9, meanQ=2.312222, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.411257 0.931801 0.65965 0.822391 0.622852 0.804139 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 221
Initial state: 0 0.548376 0.872075 0.578712 0.865399 0.217254 0.0523897 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663929 episodes
GETTING ACTION FROM:
action 3, numVisits=663915, meanQ=5.011515, numObservations: 4
action 1, numVisits=9, meanQ=1.445567, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.548376 0.872075 0.578712 0.865399 0.217254 0.0523897 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=75740, meanQ=8.534747, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 846736 episodes
GETTING ACTION FROM:
action 1, numVisits=852283, meanQ=6.045654, numObservations: 5
action 2, numVisits=70190, meanQ=6.025633, numObservations: 5
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.548376 0.872075 0.578712 0.865399 0.217254 0.0523897 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 222
Initial state: 0 0.679025 0.867878 0.58515 0.826896 0.229843 0.139869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668793 episodes
GETTING ACTION FROM:
action 2, numVisits=668783, meanQ=5.017963, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.679025 0.867878 0.58515 0.826896 0.229843 0.139869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 223
Initial state: 0 0.921536 0.0842452 0.65542 0.819438 0.54581 0.864333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665017 episodes
GETTING ACTION FROM:
action 3, numVisits=665002, meanQ=5.015287, numObservations: 4
action 2, numVisits=10, meanQ=2.598000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.921536 0.0842452 0.65542 0.819438 0.54581 0.864333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 224
Initial state: 0 0.691714 0.845771 0.408941 0.400882 0.66121 0.811465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 633965 episodes
GETTING ACTION FROM:
action 1, numVisits=633892, meanQ=4.812341, numObservations: 5
action 3, numVisits=39, meanQ=3.566679, numObservations: 4
action 0, numVisits=31, meanQ=3.478591, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.691714 0.845771 0.408941 0.400882 0.66121 0.811465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 225
Initial state: 0 0.518372 0.816623 0.585258 0.880312 0.252596 0.286575 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662649 episodes
GETTING ACTION FROM:
action 3, numVisits=662636, meanQ=4.967165, numObservations: 4
action 2, numVisits=6, meanQ=-0.669983, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action: 3
Next state: 2 0.518372 0.816623 0.585258 0.880312 0.252596 0.286575 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 226
Initial state: 0 0.854723 0.492619 0.567698 0.85743 0.508808 0.843911 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462042 episodes
GETTING ACTION FROM:
action -1, numVisits=462031, meanQ=2.909025, numObservations: 1
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=3, meanQ=-2.966667, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.854723 0.492619 0.567698 0.85743 0.508808 0.843911 w: 1
Observation: 0 0.936058 0 0.643838 0 0.579975 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=250984, meanQ=4.948180, numObservations: 4
action 1, numVisits=210944, meanQ=4.940368, numObservations: 4
action -1, numVisits=94, meanQ=4.209727, numObservations: 1
action 3, numVisits=6, meanQ=-0.350000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 738502 episodes
GETTING ACTION FROM:
action 2, numVisits=989486, meanQ=4.980138, numObservations: 4
action 1, numVisits=210944, meanQ=4.940368, numObservations: 4
action -1, numVisits=94, meanQ=4.209727, numObservations: 1
action 3, numVisits=6, meanQ=-0.350000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.854723 0.492619 0.567698 0.85743 0.508808 0.843911 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 227
Initial state: 0 0.571991 0.801576 0.686502 0.867425 0.00592313 0.367012 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 648200 episodes
GETTING ACTION FROM:
action 1, numVisits=604739, meanQ=5.006834, numObservations: 4
action -1, numVisits=43456, meanQ=2.968615, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.571991 0.801576 0.686502 0.867425 0.00592313 0.367012 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 228
Initial state: 0 0.662014 0.83742 0.515655 0.819212 0.722111 0.480322 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 600445 episodes
GETTING ACTION FROM:
action 1, numVisits=600393, meanQ=4.447509, numObservations: 4
action 0, numVisits=24, meanQ=2.941451, numObservations: 1
action 3, numVisits=24, meanQ=2.916254, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.662014 0.83742 0.515655 0.819212 0.722111 0.480322 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=44053, meanQ=2.702053, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 838559 episodes
GETTING ACTION FROM:
action 3, numVisits=739700, meanQ=5.818510, numObservations: 5
action 0, numVisits=142890, meanQ=0.286746, numObservations: 1
action -1, numVisits=26, meanQ=-1.086915, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.662014 0.83742 0.515655 0.819212 0.722111 0.480322 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 229
Initial state: 0 0.521612 0.860218 0.60669 0.801337 0.986839 0.403799 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662956 episodes
GETTING ACTION FROM:
action 1, numVisits=662535, meanQ=5.021260, numObservations: 5
action 2, numVisits=416, meanQ=4.541763, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.521612 0.860218 0.60669 0.801337 0.986839 0.403799 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 230
Initial state: 0 0.684314 0.874914 0.500349 0.88503 0.302647 0.575334 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672455 episodes
GETTING ACTION FROM:
action 1, numVisits=672291, meanQ=4.954697, numObservations: 3
action -1, numVisits=159, meanQ=4.379497, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.684314 0.874914 0.500349 0.88503 0.302647 0.575334 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 231
Initial state: 0 0.517128 0.312255 0.579384 0.801857 0.564031 0.857801 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664994 episodes
GETTING ACTION FROM:
action 3, numVisits=664982, meanQ=4.928865, numObservations: 3
action 1, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.517128 0.312255 0.579384 0.801857 0.564031 0.857801 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 232
Initial state: 0 0.680582 0.858572 0.664152 0.822598 0.029037 0.87023 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664922 episodes
GETTING ACTION FROM:
action 3, numVisits=664910, meanQ=5.002453, numObservations: 4
action 1, numVisits=7, meanQ=1.570000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.680582 0.858572 0.664152 0.822598 0.029037 0.87023 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 233
Initial state: 0 0.669457 0.879342 0.489282 0.988578 0.601396 0.822463 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 459114 episodes
GETTING ACTION FROM:
action -1, numVisits=458986, meanQ=2.869535, numObservations: 1
action 0, numVisits=113, meanQ=2.200491, numObservations: 1
action 3, numVisits=12, meanQ=0.656667, numObservations: 3
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.669457 0.879342 0.489282 0.988578 0.601396 0.822463 w: 1
Observation: 0 0.673562 0 0.537964 0 0.608603 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=458923, meanQ=4.912639, numObservations: 4
action 3, numVisits=51, meanQ=3.878235, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 738167 episodes
GETTING ACTION FROM:
action 1, numVisits=1197090, meanQ=4.984324, numObservations: 4
action 3, numVisits=51, meanQ=3.878235, numObservations: 4
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.669457 0.879342 0.489282 0.988578 0.601396 0.822463 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 234
Initial state: 0 0.60968 0.795575 0.538773 0.831199 0.580697 0.862443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656084 episodes
GETTING ACTION FROM:
action 2, numVisits=656074, meanQ=4.935470, numObservations: 4
action 1, numVisits=5, meanQ=1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.60968 0.795575 0.538773 0.831199 0.580697 0.862443 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 235
Initial state: 0 0.266634 0.861779 0.650184 0.818979 0.687915 0.872716 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666638 episodes
GETTING ACTION FROM:
action 3, numVisits=666559, meanQ=4.947571, numObservations: 3
action 0, numVisits=74, meanQ=4.098876, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.266634 0.861779 0.650184 0.818979 0.687915 0.872716 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=110055, meanQ=8.327819, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 856714 episodes
GETTING ACTION FROM:
action 2, numVisits=966766, meanQ=6.412215, numObservations: 4
action 1, numVisits=5, meanQ=2.598000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.266634 0.861779 0.650184 0.818979 0.687915 0.872716 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 236
Initial state: 0 0.83822 0.812072 0.557944 0.807996 0.600556 0.840754 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665374 episodes
GETTING ACTION FROM:
action 3, numVisits=665336, meanQ=5.000851, numObservations: 4
action 0, numVisits=17, meanQ=3.181048, numObservations: 1
action 1, numVisits=12, meanQ=2.675000, numObservations: 3
action 2, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.83822 0.812072 0.557944 0.807996 0.600556 0.840754 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 237
Initial state: 0 0.608479 0.838979 0.377316 0.634985 0.622322 0.812351 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673030 episodes
GETTING ACTION FROM:
action 1, numVisits=596463, meanQ=5.013833, numObservations: 3
action 2, numVisits=76340, meanQ=4.992604, numObservations: 4
action -1, numVisits=224, meanQ=4.529761, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.608479 0.838979 0.377316 0.634985 0.622322 0.812351 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 238
Initial state: 0 0.553448 0.881731 0.569257 0.872232 0.339801 0.759883 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661152 episodes
GETTING ACTION FROM:
action 3, numVisits=661029, meanQ=4.991087, numObservations: 4
action 0, numVisits=113, meanQ=4.306711, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 0 0.553448 0.881731 0.569257 0.872232 0.339801 0.759883 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=74911, meanQ=8.526967, numObservations: 3
action 1, numVisits=5, meanQ=3.402020, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 843334 episodes
GETTING ACTION FROM:
action 2, numVisits=918240, meanQ=6.076695, numObservations: 5
action 1, numVisits=8, meanQ=3.001263, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.553448 0.881731 0.569257 0.872232 0.339801 0.759883 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 239
Initial state: 0 0.65072 0.822778 0.609197 0.817528 0.990046 0.234279 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 652245 episodes
GETTING ACTION FROM:
action 2, numVisits=651977, meanQ=4.934477, numObservations: 5
action 1, numVisits=237, meanQ=4.449600, numObservations: 3
action 0, numVisits=27, meanQ=3.457131, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.65072 0.822778 0.609197 0.817528 0.990046 0.234279 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 240
Initial state: 0 0.298717 0.692473 0.616378 0.826055 0.631004 0.816043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663088 episodes
GETTING ACTION FROM:
action 1, numVisits=663082, meanQ=4.945911, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.298717 0.692473 0.616378 0.826055 0.631004 0.816043 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=82343, meanQ=8.416947, numObservations: 5
action 2, numVisits=10782, meanQ=8.373293, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 846568 episodes
GETTING ACTION FROM:
action 3, numVisits=882173, meanQ=6.400018, numObservations: 5
action 2, numVisits=57520, meanQ=6.376653, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.298717 0.692473 0.616378 0.826055 0.631004 0.816043 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 241
Initial state: 0 0.562647 0.833674 0.619598 0.873777 0.529348 0.704639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667407 episodes
GETTING ACTION FROM:
action 1, numVisits=667310, meanQ=5.003739, numObservations: 4
action -1, numVisits=84, meanQ=4.207893, numObservations: 1
action 3, numVisits=9, meanQ=1.454444, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.562647 0.833674 0.619598 0.873777 0.529348 0.704639 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 242
Initial state: 0 0.662796 0.899914 0.515264 0.83719 0.415734 0.613592 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 586051 episodes
GETTING ACTION FROM:
action 3, numVisits=421506, meanQ=4.932276, numObservations: 5
action -1, numVisits=164538, meanQ=2.943620, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 3
Next state: 0 0.662796 0.899914 0.515264 0.83719 0.415734 0.613592 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=58554, meanQ=8.399296, numObservations: 3
action 1, numVisits=54, meanQ=7.403524, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 866549 episodes
GETTING ACTION FROM:
action 2, numVisits=908827, meanQ=6.299755, numObservations: 3
action 1, numVisits=16328, meanQ=6.249239, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.662796 0.899914 0.515264 0.83719 0.415734 0.613592 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 243
Initial state: 0 0.696078 0.83286 0.605936 0.817873 0.0523477 0.81855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667108 episodes
GETTING ACTION FROM:
action 1, numVisits=667102, meanQ=5.013250, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.696078 0.83286 0.605936 0.817873 0.0523477 0.81855 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=93932, meanQ=8.379717, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 856782 episodes
GETTING ACTION FROM:
action 2, numVisits=950673, meanQ=6.166196, numObservations: 4
action 3, numVisits=41, meanQ=4.658051, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.696078 0.83286 0.605936 0.817873 0.0523477 0.81855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 244
Initial state: 0 0.0874884 0.974789 0.69582 0.876977 0.581065 0.847665 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660555 episodes
GETTING ACTION FROM:
action 3, numVisits=660542, meanQ=4.961215, numObservations: 4
action 2, numVisits=8, meanQ=-0.002475, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0874884 0.974789 0.69582 0.876977 0.581065 0.847665 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 245
Initial state: 0 0.269967 0.48858 0.662758 0.882226 0.581016 0.849145 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665809 episodes
GETTING ACTION FROM:
action 2, numVisits=665780, meanQ=5.023738, numObservations: 4
action 0, numVisits=24, meanQ=3.531193, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.269967 0.48858 0.662758 0.882226 0.581016 0.849145 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=109329, meanQ=8.349420, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 848294 episodes
GETTING ACTION FROM:
action 1, numVisits=957620, meanQ=6.252076, numObservations: 5
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.269967 0.48858 0.662758 0.882226 0.581016 0.849145 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=10455, meanQ=8.520098, numObservations: 3
action 3, numVisits=34, meanQ=7.116771, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 863693 episodes
GETTING ACTION FROM:
action 2, numVisits=873835, meanQ=6.073864, numObservations: 5
action 3, numVisits=345, meanQ=5.648929, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.269967 0.48858 0.662758 0.882226 0.581016 0.849145 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 246
Initial state: 0 0.550555 0.814818 0.55684 0.237721 0.671635 0.86595 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 647656 episodes
GETTING ACTION FROM:
action 1, numVisits=647621, meanQ=5.021431, numObservations: 4
action 3, numVisits=30, meanQ=2.351821, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.550555 0.814818 0.55684 0.237721 0.671635 0.86595 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 247
Initial state: 0 0.626979 0.845747 0.691406 0.993133 0.545489 0.804067 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662834 episodes
GETTING ACTION FROM:
action 2, numVisits=662712, meanQ=4.977055, numObservations: 5
action -1, numVisits=94, meanQ=4.197955, numObservations: 1
action 0, numVisits=21, meanQ=3.326339, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.626979 0.845747 0.691406 0.993133 0.545489 0.804067 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 248
Initial state: 0 0.530886 0.804281 0.504536 0.970562 0.67474 0.899523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663943 episodes
GETTING ACTION FROM:
action 1, numVisits=663792, meanQ=5.013506, numObservations: 4
action -1, numVisits=110, meanQ=4.219502, numObservations: 1
action 0, numVisits=38, meanQ=3.791147, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.530886 0.804281 0.504536 0.970562 0.67474 0.899523 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=49132, meanQ=5.553514, numObservations: 4
action 3, numVisits=6, meanQ=1.331683, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 799581 episodes
GETTING ACTION FROM:
action 1, numVisits=848711, meanQ=4.916911, numObservations: 4
action 3, numVisits=6, meanQ=1.331683, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.530886 0.804281 0.504536 0.970562 0.67474 0.899523 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 249
Initial state: 0 0.637285 0.808073 0.396592 0.478621 0.666661 0.842934 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 466511 episodes
GETTING ACTION FROM:
action -1, numVisits=466499, meanQ=2.918190, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=3, meanQ=-3.033333, numObservations: 1
action: -1
Next state: 0 0.637285 0.808073 0.396592 0.478621 0.666661 0.842934 w: 1
Observation: 0 0.641615 0 0.360385 0 0.706956 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=466417, meanQ=4.958848, numObservations: 3
action -1, numVisits=73, meanQ=4.097281, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 747346 episodes
GETTING ACTION FROM:
action 2, numVisits=1213760, meanQ=4.895581, numObservations: 3
action -1, numVisits=76, meanQ=4.042304, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.637285 0.808073 0.396592 0.478621 0.666661 0.842934 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=170335, meanQ=8.321142, numObservations: 4
action 3, numVisits=21347, meanQ=8.289035, numObservations: 4
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 844411 episodes
GETTING ACTION FROM:
action 1, numVisits=970033, meanQ=6.595207, numObservations: 4
action 3, numVisits=66058, meanQ=6.573676, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action: 1
Next state: 1 0.637285 0.808073 0.396592 0.478621 0.666661 0.842934 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 2.8609
Run # 250
Initial state: 0 0.553617 0.827826 0.00473383 0.964045 0.695882 0.809465 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663152 episodes
GETTING ACTION FROM:
action 1, numVisits=654745, meanQ=5.020524, numObservations: 4
action -1, numVisits=8403, meanQ=2.936693, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.553617 0.827826 0.00473383 0.964045 0.695882 0.809465 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 251
Initial state: 0 0.903467 0.269491 0.664941 0.881924 0.591541 0.855942 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668882 episodes
GETTING ACTION FROM:
action 2, numVisits=668843, meanQ=5.038874, numObservations: 4
action 0, numVisits=32, meanQ=3.708888, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.903467 0.269491 0.664941 0.881924 0.591541 0.855942 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 252
Initial state: 0 0.577374 0.81018 0.604597 0.863108 0.238195 0.391393 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667471 episodes
GETTING ACTION FROM:
action 2, numVisits=667461, meanQ=5.187318, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.577374 0.81018 0.604597 0.863108 0.238195 0.391393 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 253
Initial state: 0 0.582697 0.848895 0.595096 0.853216 0.960544 0.742922 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660083 episodes
GETTING ACTION FROM:
action 1, numVisits=660020, meanQ=4.973097, numObservations: 5
action -1, numVisits=51, meanQ=3.941478, numObservations: 1
action 0, numVisits=10, meanQ=2.091670, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.582697 0.848895 0.595096 0.853216 0.960544 0.742922 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 254
Initial state: 0 0.66918 0.88 0.615056 0.867984 0.984492 0.867432 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 476452 episodes
GETTING ACTION FROM:
action 0, numVisits=476155, meanQ=5.930001, numObservations: 3
action -1, numVisits=287, meanQ=3.480239, numObservations: 1
action 2, numVisits=7, meanQ=0.428586, numObservations: 2
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.66918 0.88 0.615056 0.867984 0.984492 0.867432 w: 1
Observation: 0 0 0.876507 0 0.927165 0 0.876276 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=170845, meanQ=7.938046, numObservations: 4
action 1, numVisits=5, meanQ=4.196000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 749296 episodes
GETTING ACTION FROM:
action 2, numVisits=920040, meanQ=5.729594, numObservations: 4
action -1, numVisits=98, meanQ=4.977465, numObservations: 1
action 1, numVisits=8, meanQ=2.250025, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.66918 0.88 0.615056 0.867984 0.984492 0.867432 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 255
Initial state: 0 0.502159 0.892062 0.19411 0.708291 0.683311 0.832495 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665733 episodes
GETTING ACTION FROM:
action 2, numVisits=665580, meanQ=5.010592, numObservations: 4
action 0, numVisits=99, meanQ=4.278152, numObservations: 1
action 3, numVisits=31, meanQ=3.570968, numObservations: 4
action -1, numVisits=21, meanQ=3.408921, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 2
Next state: 0 0.502159 0.892062 0.19411 0.708291 0.683311 0.832495 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=94102, meanQ=8.368165, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 856456 episodes
GETTING ACTION FROM:
action 3, numVisits=950254, meanQ=6.396103, numObservations: 4
action 1, numVisits=304, meanQ=5.930955, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.502159 0.892062 0.19411 0.708291 0.683311 0.832495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=25879, meanQ=7.318112, numObservations: 5
action 3, numVisits=5, meanQ=3.402020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 862133 episodes
GETTING ACTION FROM:
action 1, numVisits=888008, meanQ=6.319600, numObservations: 5
action 3, numVisits=7, meanQ=2.144300, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.502159 0.892062 0.19411 0.708291 0.683311 0.832495 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 256
Initial state: 0 0.51072 0.870942 0.244939 0.659524 0.666081 0.883713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 593368 episodes
GETTING ACTION FROM:
action 1, numVisits=436234, meanQ=5.012222, numObservations: 5
action -1, numVisits=156681, meanQ=2.936576, numObservations: 1
action 0, numVisits=430, meanQ=2.550146, numObservations: 1
action 3, numVisits=13, meanQ=0.845392, numObservations: 3
action 2, numVisits=10, meanQ=0.002030, numObservations: 2
action: 1
Next state: 1 0.51072 0.870942 0.244939 0.659524 0.666081 0.883713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 257
Initial state: 0 0.423495 0.0584025 0.619562 0.895779 0.616945 0.82722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665109 episodes
GETTING ACTION FROM:
action 2, numVisits=651619, meanQ=5.006681, numObservations: 3
action 0, numVisits=13482, meanQ=3.104455, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.423495 0.0584025 0.619562 0.895779 0.616945 0.82722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 258
Initial state: 0 0.622114 0.881178 0.495744 0.37834 0.675044 0.832372 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660165 episodes
GETTING ACTION FROM:
action 1, numVisits=660126, meanQ=4.941906, numObservations: 4
action 0, numVisits=32, meanQ=3.609121, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.622114 0.881178 0.495744 0.37834 0.675044 0.832372 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 259
Initial state: 0 0.584145 0.868798 0.520462 0.85285 0.988592 0.932134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663061 episodes
GETTING ACTION FROM:
action 1, numVisits=662997, meanQ=4.945747, numObservations: 4
action 2, numVisits=59, meanQ=3.912037, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.584145 0.868798 0.520462 0.85285 0.988592 0.932134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 260
Initial state: 0 0.548021 0.806415 0.930463 0.498125 0.53917 0.844373 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669565 episodes
GETTING ACTION FROM:
action 2, numVisits=669541, meanQ=5.020422, numObservations: 4
action -1, numVisits=17, meanQ=3.203109, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.548021 0.806415 0.930463 0.498125 0.53917 0.844373 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 261
Initial state: 0 0.782469 0.118653 0.622922 0.85653 0.655343 0.891252 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659487 episodes
GETTING ACTION FROM:
action 2, numVisits=659462, meanQ=5.021342, numObservations: 5
action 0, numVisits=21, meanQ=3.265987, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.782469 0.118653 0.622922 0.85653 0.655343 0.891252 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 262
Initial state: 0 0.592824 0.873862 0.649562 0.866471 0.206581 0.908144 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661769 episodes
GETTING ACTION FROM:
action 3, numVisits=661763, meanQ=4.919040, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.592824 0.873862 0.649562 0.866471 0.206581 0.908144 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 263
Initial state: 0 0.650287 0.861526 0.365621 0.855264 0.530181 0.839226 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658708 episodes
GETTING ACTION FROM:
action 3, numVisits=658650, meanQ=5.016469, numObservations: 4
action -1, numVisits=34, meanQ=3.769067, numObservations: 1
action 1, numVisits=19, meanQ=2.267895, numObservations: 3
action 2, numVisits=3, meanQ=0.330033, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.650287 0.861526 0.365621 0.855264 0.530181 0.839226 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 264
Initial state: 0 0.652605 0.805654 0.00703927 0.444059 0.542157 0.811138 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654250 episodes
GETTING ACTION FROM:
action 3, numVisits=654219, meanQ=4.942244, numObservations: 5
action 0, numVisits=27, meanQ=3.503716, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.652605 0.805654 0.00703927 0.444059 0.542157 0.811138 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 265
Initial state: 0 0.53803 0.890265 0.865205 0.6677 0.596465 0.826074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 669382 episodes
GETTING ACTION FROM:
action 1, numVisits=669346, meanQ=4.972688, numObservations: 3
action 0, numVisits=25, meanQ=3.486942, numObservations: 1
action 3, numVisits=7, meanQ=0.427171, numObservations: 3
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.53803 0.890265 0.865205 0.6677 0.596465 0.826074 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 266
Initial state: 0 0.527004 0.893328 0.311767 0.463173 0.637795 0.867095 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656000 episodes
GETTING ACTION FROM:
action 3, numVisits=655994, meanQ=5.027673, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.527004 0.893328 0.311767 0.463173 0.637795 0.867095 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 267
Initial state: 0 0.60323 0.852757 0.69007 0.83983 0.856513 0.665484 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666754 episodes
GETTING ACTION FROM:
action 2, numVisits=666670, meanQ=4.977083, numObservations: 4
action -1, numVisits=55, meanQ=3.995311, numObservations: 1
action 0, numVisits=22, meanQ=3.352856, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.60323 0.852757 0.69007 0.83983 0.856513 0.665484 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 268
Initial state: 0 0.661704 0.880382 0.297034 0.637494 0.649892 0.891919 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 624641 episodes
GETTING ACTION FROM:
action 1, numVisits=623010, meanQ=4.627836, numObservations: 4
action 0, numVisits=1627, meanQ=2.711698, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.661704 0.880382 0.297034 0.637494 0.649892 0.891919 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 269
Initial state: 0 0.891026 0.0770376 0.563473 0.899539 0.606374 0.855243 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656956 episodes
GETTING ACTION FROM:
action 3, numVisits=656905, meanQ=4.964771, numObservations: 5
action 0, numVisits=47, meanQ=3.891104, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.891026 0.0770376 0.563473 0.899539 0.606374 0.855243 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 270
Initial state: 0 0.856539 0.97391 0.691653 0.865168 0.589293 0.896667 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660226 episodes
GETTING ACTION FROM:
action 1, numVisits=660178, meanQ=5.001212, numObservations: 5
action -1, numVisits=30, meanQ=3.585275, numObservations: 1
action 3, numVisits=10, meanQ=2.399010, numObservations: 3
action 2, numVisits=6, meanQ=1.663333, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.856539 0.97391 0.691653 0.865168 0.589293 0.896667 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 271
Initial state: 0 0.658489 0.816198 0.622218 0.819362 0.0972491 0.108757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 474927 episodes
GETTING ACTION FROM:
action 0, numVisits=474692, meanQ=5.825036, numObservations: 3
action -1, numVisits=203, meanQ=3.336496, numObservations: 1
action 1, numVisits=17, meanQ=1.576476, numObservations: 3
action 2, numVisits=14, meanQ=1.427871, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.658489 0.816198 0.622218 0.819362 0.0972491 0.108757 w: 1
Observation: 0 0 0.764021 0 0.846394 0 0.0401126 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=126801, meanQ=8.399795, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 736729 episodes
GETTING ACTION FROM:
action 1, numVisits=863528, meanQ=5.684414, numObservations: 4
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.658489 0.816198 0.622218 0.819362 0.0972491 0.108757 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 272
Initial state: 0 0.860814 0.476634 0.528863 0.885025 0.594655 0.876941 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660158 episodes
GETTING ACTION FROM:
action 1, numVisits=660121, meanQ=4.944845, numObservations: 5
action -1, numVisits=33, meanQ=3.650964, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.860814 0.476634 0.528863 0.885025 0.594655 0.876941 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 273
Initial state: 0 0.552739 0.865704 0.825546 0.0491396 0.633076 0.846078 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658229 episodes
GETTING ACTION FROM:
action 1, numVisits=658223, meanQ=4.949169, numObservations: 5
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.552739 0.865704 0.825546 0.0491396 0.633076 0.846078 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 274
Initial state: 0 0.393607 0.0835374 0.540216 0.80689 0.654092 0.857072 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462186 episodes
GETTING ACTION FROM:
action 0, numVisits=462174, meanQ=2.954421, numObservations: 1
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=3, meanQ=-3.033333, numObservations: 2
action: 0
Next state: 0 0.393607 0.0835374 0.540216 0.80689 0.654092 0.857072 w: 1
Observation: 0 0 0.171591 0 0.903348 0 0.879819 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=462100, meanQ=5.012436, numObservations: 4
action -1, numVisits=41, meanQ=3.826506, numObservations: 1
action 1, numVisits=29, meanQ=3.485517, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 738553 episodes
GETTING ACTION FROM:
action 3, numVisits=1200646, meanQ=4.826507, numObservations: 4
action -1, numVisits=44, meanQ=3.690046, numObservations: 1
action 1, numVisits=33, meanQ=3.305461, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.393607 0.0835374 0.540216 0.80689 0.654092 0.857072 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 275
Initial state: 0 0.514459 0.879929 0.71575 0.358499 0.564817 0.862099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658506 episodes
GETTING ACTION FROM:
action 1, numVisits=658484, meanQ=4.960025, numObservations: 5
action 2, numVisits=17, meanQ=2.388824, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.514459 0.879929 0.71575 0.358499 0.564817 0.862099 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 276
Initial state: 0 0.625313 0.844064 0.601175 0.823232 0.561253 0.53889 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 653541 episodes
GETTING ACTION FROM:
action 2, numVisits=653507, meanQ=5.165135, numObservations: 5
action 1, numVisits=26, meanQ=2.988846, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.625313 0.844064 0.601175 0.823232 0.561253 0.53889 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 277
Initial state: 0 0.631106 0.807145 0.688683 0.897684 0.795301 0.885806 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659772 episodes
GETTING ACTION FROM:
action 2, numVisits=659766, meanQ=4.931022, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.631106 0.807145 0.688683 0.897684 0.795301 0.885806 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 278
Initial state: 0 0.688123 0.823239 0.0564413 0.217288 0.588222 0.828625 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 464665 episodes
GETTING ACTION FROM:
action -1, numVisits=464634, meanQ=2.906388, numObservations: 1
action 3, numVisits=19, meanQ=1.204737, numObservations: 4
action 1, numVisits=6, meanQ=-0.669983, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action: -1
Next state: 0 0.688123 0.823239 0.0564413 0.217288 0.588222 0.828625 w: 1
Observation: 0 0.634158 0 0 0 0.550134 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=464611, meanQ=4.945161, numObservations: 3
action 2, numVisits=11, meanQ=1.907282, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 745965 episodes
GETTING ACTION FROM:
action 1, numVisits=1210576, meanQ=5.053117, numObservations: 3
action 2, numVisits=11, meanQ=1.907282, numObservations: 4
action 3, numVisits=7, meanQ=1.570000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.688123 0.823239 0.0564413 0.217288 0.588222 0.828625 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 279
Initial state: 0 0.68473 0.899403 0.568904 0.827012 0.745529 0.969015 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 460334 episodes
GETTING ACTION FROM:
action 0, numVisits=460316, meanQ=2.898471, numObservations: 1
action 3, numVisits=10, meanQ=0.209000, numObservations: 2
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 2, numVisits=2, meanQ=-4.004950, numObservations: 1
action: 0
Next state: 0 0.68473 0.899403 0.568904 0.827012 0.745529 0.969015 w: 1
Observation: 0 0 0.992102 0 0.828109 0 0.945875 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=460255, meanQ=4.952300, numObservations: 4
action -1, numVisits=32, meanQ=3.674245, numObservations: 1
action 2, numVisits=23, meanQ=2.382609, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 737985 episodes
GETTING ACTION FROM:
action 1, numVisits=1198233, meanQ=4.774704, numObservations: 4
action -1, numVisits=39, meanQ=3.573568, numObservations: 1
action 2, numVisits=23, meanQ=2.382609, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.68473 0.899403 0.568904 0.827012 0.745529 0.969015 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 280
Initial state: 0 0.53842 0.895138 0.303935 0.660156 0.550518 0.895281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656971 episodes
GETTING ACTION FROM:
action 1, numVisits=656930, meanQ=4.952163, numObservations: 5
action 0, numVisits=21, meanQ=3.165804, numObservations: 1
action 2, numVisits=16, meanQ=1.999375, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.53842 0.895138 0.303935 0.660156 0.550518 0.895281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 281
Initial state: 0 0.662047 0.819326 0.517274 0.897729 0.892712 0.913292 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666732 episodes
GETTING ACTION FROM:
action 3, numVisits=666717, meanQ=5.023637, numObservations: 3
action 2, numVisits=10, meanQ=2.399010, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.662047 0.819326 0.517274 0.897729 0.892712 0.913292 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 282
Initial state: 0 0.57907 0.846435 0.598538 0.888411 0.87103 0.474127 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655770 episodes
GETTING ACTION FROM:
action 3, numVisits=655764, meanQ=4.946497, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.57907 0.846435 0.598538 0.888411 0.87103 0.474127 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 283
Initial state: 0 0.641965 0.813368 0.526075 0.843971 0.500218 0.013722 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661014 episodes
GETTING ACTION FROM:
action 2, numVisits=660962, meanQ=5.025808, numObservations: 5
action -1, numVisits=18, meanQ=3.207473, numObservations: 1
action 0, numVisits=14, meanQ=2.978639, numObservations: 1
action 3, numVisits=15, meanQ=2.606667, numObservations: 3
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action: 2
Next state: 1 0.641965 0.813368 0.526075 0.843971 0.500218 0.013722 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 284
Initial state: 0 0.125043 0.128833 0.66646 0.810613 0.591987 0.855265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661484 episodes
GETTING ACTION FROM:
action 3, numVisits=661418, meanQ=4.954959, numObservations: 4
action 0, numVisits=61, meanQ=4.013755, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.125043 0.128833 0.66646 0.810613 0.591987 0.855265 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=108244, meanQ=8.344798, numObservations: 5
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 844952 episodes
GETTING ACTION FROM:
action 1, numVisits=953104, meanQ=5.966634, numObservations: 5
action 2, numVisits=92, meanQ=5.108480, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.125043 0.128833 0.66646 0.810613 0.591987 0.855265 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=6437, meanQ=7.998223, numObservations: 5
action 3, numVisits=2, meanQ=2.995000, numObservations: 2
action 1, numVisits=3, meanQ=2.333333, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 869380 episodes
GETTING ACTION FROM:
action 2, numVisits=875814, meanQ=6.449767, numObservations: 5
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 2
Next state: 1 0.125043 0.128833 0.66646 0.810613 0.591987 0.855265 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 285
Initial state: 0 0.659139 0.856993 0.695424 0.437082 0.581367 0.848503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666492 episodes
GETTING ACTION FROM:
action 1, numVisits=666453, meanQ=4.997055, numObservations: 4
action 0, numVisits=35, meanQ=3.728715, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.659139 0.856993 0.695424 0.437082 0.581367 0.848503 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 286
Initial state: 0 0.635694 0.829432 0.608555 0.848887 0.138369 0.720556 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662130 episodes
GETTING ACTION FROM:
action 2, numVisits=662025, meanQ=5.012743, numObservations: 5
action 0, numVisits=77, meanQ=4.181358, numObservations: 1
action -1, numVisits=25, meanQ=3.498719, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.635694 0.829432 0.608555 0.848887 0.138369 0.720556 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 287
Initial state: 0 0.589461 0.897522 0.5966 0.889338 0.817181 0.530083 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665673 episodes
GETTING ACTION FROM:
action 1, numVisits=665666, meanQ=5.030776, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.589461 0.897522 0.5966 0.889338 0.817181 0.530083 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 288
Initial state: 0 0.585577 0.861471 0.53362 0.840159 0.157263 0.691513 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666994 episodes
GETTING ACTION FROM:
action 3, numVisits=666930, meanQ=5.010126, numObservations: 4
action -1, numVisits=60, meanQ=4.066989, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.585577 0.861471 0.53362 0.840159 0.157263 0.691513 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=93984, meanQ=8.398117, numObservations: 4
action 2, numVisits=9, meanQ=6.110011, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855925 episodes
GETTING ACTION FROM:
action 1, numVisits=949891, meanQ=6.317566, numObservations: 4
action 2, numVisits=25, meanQ=4.519208, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.585577 0.861471 0.53362 0.840159 0.157263 0.691513 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 289
Initial state: 0 0.14431 0.0279 0.68985 0.804091 0.512206 0.869785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658298 episodes
GETTING ACTION FROM:
action 3, numVisits=658291, meanQ=5.015418, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.14431 0.0279 0.68985 0.804091 0.512206 0.869785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 290
Initial state: 0 0.891488 0.6939 0.510156 0.867223 0.618177 0.806825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655747 episodes
GETTING ACTION FROM:
action 2, numVisits=655600, meanQ=5.000105, numObservations: 5
action 0, numVisits=125, meanQ=4.348319, numObservations: 1
action -1, numVisits=19, meanQ=3.289523, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.891488 0.6939 0.510156 0.867223 0.618177 0.806825 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 291
Initial state: 0 0.658824 0.841526 0.558911 0.852922 0.883359 0.612231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462056 episodes
GETTING ACTION FROM:
action -1, numVisits=462036, meanQ=2.918899, numObservations: 1
action 2, numVisits=9, meanQ=0.097778, numObservations: 3
action 3, numVisits=7, meanQ=-1.287143, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.658824 0.841526 0.558911 0.852922 0.883359 0.612231 w: 1
Observation: 0 0.745592 0 0.599476 0 0.844657 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=461958, meanQ=4.964787, numObservations: 4
action 2, numVisits=38, meanQ=3.628955, numObservations: 4
action 0, numVisits=23, meanQ=3.403858, numObservations: 1
action -1, numVisits=15, meanQ=2.971107, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 731421 episodes
GETTING ACTION FROM:
action 3, numVisits=1193379, meanQ=5.152529, numObservations: 4
action 2, numVisits=38, meanQ=3.628955, numObservations: 4
action 0, numVisits=23, meanQ=3.403858, numObservations: 1
action -1, numVisits=15, meanQ=2.971107, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.658824 0.841526 0.558911 0.852922 0.883359 0.612231 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 292
Initial state: 0 0.614089 0.801374 0.508888 0.823024 0.327087 0.38335 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 651602 episodes
GETTING ACTION FROM:
action 3, numVisits=651596, meanQ=4.969853, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.614089 0.801374 0.508888 0.823024 0.327087 0.38335 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=30556, meanQ=8.530113, numObservations: 3
action 2, numVisits=44330, meanQ=8.528590, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 854825 episodes
GETTING ACTION FROM:
action 1, numVisits=478334, meanQ=6.124893, numObservations: 3
action 2, numVisits=451375, meanQ=6.124309, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.614089 0.801374 0.508888 0.823024 0.327087 0.38335 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 293
Initial state: 0 0.766905 0.431515 0.622317 0.836217 0.688725 0.812708 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 652332 episodes
GETTING ACTION FROM:
action 3, numVisits=652211, meanQ=4.877483, numObservations: 3
action -1, numVisits=116, meanQ=4.195883, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.766905 0.431515 0.622317 0.836217 0.688725 0.812708 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 294
Initial state: 0 0.653147 0.898891 0.574059 0.833024 0.138705 0.868712 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665037 episodes
GETTING ACTION FROM:
action 1, numVisits=664991, meanQ=4.999960, numObservations: 4
action 0, numVisits=42, meanQ=3.877053, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.653147 0.898891 0.574059 0.833024 0.138705 0.868712 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 295
Initial state: 0 0.610781 0.828696 0.561693 0.87274 0.785289 0.708338 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662921 episodes
GETTING ACTION FROM:
action 1, numVisits=662819, meanQ=4.990072, numObservations: 4
action 0, numVisits=51, meanQ=3.954276, numObservations: 1
action -1, numVisits=31, meanQ=3.629078, numObservations: 1
action 2, numVisits=17, meanQ=2.881176, numObservations: 3
action 3, numVisits=3, meanQ=0.330033, numObservations: 2
action: 1
Next state: 1 0.610781 0.828696 0.561693 0.87274 0.785289 0.708338 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 296
Initial state: 0 0.520161 0.861372 0.652815 0.854186 0.972029 0.308171 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665467 episodes
GETTING ACTION FROM:
action 2, numVisits=657573, meanQ=5.020692, numObservations: 4
action -1, numVisits=7888, meanQ=2.907525, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.520161 0.861372 0.652815 0.854186 0.972029 0.308171 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 297
Initial state: 0 0.503379 0.88435 0.365593 0.451061 0.530331 0.894622 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658426 episodes
GETTING ACTION FROM:
action 1, numVisits=658399, meanQ=4.966568, numObservations: 5
action 0, numVisits=23, meanQ=3.416093, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.503379 0.88435 0.365593 0.451061 0.530331 0.894622 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 298
Initial state: 0 0.516739 0.81747 0.0356776 0.38645 0.599063 0.815538 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 641846 episodes
GETTING ACTION FROM:
action 2, numVisits=641835, meanQ=4.854615, numObservations: 4
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.516739 0.81747 0.0356776 0.38645 0.599063 0.815538 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=64033, meanQ=8.541729, numObservations: 3
action 1, numVisits=9360, meanQ=8.497092, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855394 episodes
GETTING ACTION FROM:
action 3, numVisits=816504, meanQ=6.155713, numObservations: 4
action 1, numVisits=112281, meanQ=6.141577, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.516739 0.81747 0.0356776 0.38645 0.599063 0.815538 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=19247, meanQ=7.693899, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 871327 episodes
GETTING ACTION FROM:
action 3, numVisits=890570, meanQ=5.703469, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.516739 0.81747 0.0356776 0.38645 0.599063 0.815538 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 299
Initial state: 0 0.565569 0.810818 0.0781266 0.0808828 0.512292 0.85587 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667255 episodes
GETTING ACTION FROM:
action 2, numVisits=667231, meanQ=5.035742, numObservations: 4
action 0, numVisits=20, meanQ=3.289611, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.565569 0.810818 0.0781266 0.0808828 0.512292 0.85587 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=109800, meanQ=8.330571, numObservations: 5
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 846524 episodes
GETTING ACTION FROM:
action 3, numVisits=956291, meanQ=6.383125, numObservations: 5
action 1, numVisits=32, meanQ=4.874688, numObservations: 4
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.565569 0.810818 0.0781266 0.0808828 0.512292 0.85587 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 300
Initial state: 0 0.704946 0.574069 0.527354 0.811523 0.599258 0.853134 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662089 episodes
GETTING ACTION FROM:
action 2, numVisits=649944, meanQ=5.168197, numObservations: 4
action 3, numVisits=8951, meanQ=5.081585, numObservations: 5
action 1, numVisits=3134, meanQ=5.040062, numObservations: 5
action 0, numVisits=58, meanQ=4.204463, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.704946 0.574069 0.527354 0.811523 0.599258 0.853134 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 301
Initial state: 0 0.512397 0.872727 0.675221 0.835978 0.0709258 0.908785 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657238 episodes
GETTING ACTION FROM:
action 1, numVisits=651663, meanQ=5.024526, numObservations: 5
action -1, numVisits=5564, meanQ=2.785311, numObservations: 1
action 2, numVisits=6, meanQ=-1.331633, numObservations: 2
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.512397 0.872727 0.675221 0.835978 0.0709258 0.908785 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 302
Initial state: 0 0.68929 0.842103 0.931845 0.44394 0.61646 0.833566 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658419 episodes
GETTING ACTION FROM:
action 2, numVisits=658409, meanQ=4.947443, numObservations: 5
action 3, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.68929 0.842103 0.931845 0.44394 0.61646 0.833566 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 303
Initial state: 0 0.696903 0.824159 0.0488801 0.700153 0.524873 0.800188 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667837 episodes
GETTING ACTION FROM:
action 1, numVisits=541696, meanQ=5.005764, numObservations: 4
action 3, numVisits=126135, meanQ=4.931297, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.696903 0.824159 0.0488801 0.700153 0.524873 0.800188 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 304
Initial state: 0 0.520804 0.847009 0.800009 0.948121 0.683783 0.865296 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 646625 episodes
GETTING ACTION FROM:
action 2, numVisits=646562, meanQ=5.046055, numObservations: 4
action 1, numVisits=58, meanQ=3.331728, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.520804 0.847009 0.800009 0.948121 0.683783 0.865296 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 305
Initial state: 0 0.623443 0.812213 0.588057 0.837968 0.150933 0.859043 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 652522 episodes
GETTING ACTION FROM:
action 1, numVisits=652339, meanQ=4.935319, numObservations: 5
action -1, numVisits=179, meanQ=4.387581, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.623443 0.812213 0.588057 0.837968 0.150933 0.859043 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 306
Initial state: 0 0.673681 0.829625 0.143769 0.42572 0.591233 0.81825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 634533 episodes
GETTING ACTION FROM:
action 1, numVisits=634527, meanQ=4.859708, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.673681 0.829625 0.143769 0.42572 0.591233 0.81825 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 307
Initial state: 0 0.333174 0.601995 0.619051 0.873422 0.57841 0.839264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 653589 episodes
GETTING ACTION FROM:
action 3, numVisits=653524, meanQ=4.928759, numObservations: 5
action 0, numVisits=61, meanQ=3.958132, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.333174 0.601995 0.619051 0.873422 0.57841 0.839264 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 308
Initial state: 0 0.764739 0.774851 0.588262 0.806183 0.699686 0.867811 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665832 episodes
GETTING ACTION FROM:
action 2, numVisits=665786, meanQ=5.007055, numObservations: 4
action 1, numVisits=41, meanQ=3.824151, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.764739 0.774851 0.588262 0.806183 0.699686 0.867811 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 309
Initial state: 0 0.538209 0.811148 0.906003 0.388684 0.599434 0.897177 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667371 episodes
GETTING ACTION FROM:
action 1, numVisits=661332, meanQ=4.949041, numObservations: 4
action 2, numVisits=5996, meanQ=4.858277, numObservations: 5
action 0, numVisits=40, meanQ=3.782596, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.538209 0.811148 0.906003 0.388684 0.599434 0.897177 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 310
Initial state: 0 0.582127 0.893235 0.638923 0.846173 0.949652 0.114038 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659071 episodes
GETTING ACTION FROM:
action 2, numVisits=659020, meanQ=4.992730, numObservations: 5
action -1, numVisits=47, meanQ=3.914573, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.582127 0.893235 0.638923 0.846173 0.949652 0.114038 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 311
Initial state: 0 0.537384 0.877819 0.535076 0.888738 0.752289 0.30051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664000 episodes
GETTING ACTION FROM:
action 2, numVisits=663938, meanQ=5.013092, numObservations: 4
action 0, numVisits=54, meanQ=3.967235, numObservations: 1
action 3, numVisits=5, meanQ=-0.597980, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.537384 0.877819 0.535076 0.888738 0.752289 0.30051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49251, meanQ=5.623875, numObservations: 4
action 1, numVisits=43, meanQ=4.255581, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 774713 episodes
GETTING ACTION FROM:
action 2, numVisits=823962, meanQ=5.452097, numObservations: 5
action 1, numVisits=43, meanQ=4.255581, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.537384 0.877819 0.535076 0.888738 0.752289 0.30051 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 312
Initial state: 0 0.639912 0.829727 0.863414 0.750287 0.628657 0.836525 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671838 episodes
GETTING ACTION FROM:
action 3, numVisits=671832, meanQ=5.024785, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.639912 0.829727 0.863414 0.750287 0.628657 0.836525 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 313
Initial state: 0 0.562902 0.862309 0.311153 0.00903549 0.507843 0.885281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665797 episodes
GETTING ACTION FROM:
action 2, numVisits=665465, meanQ=4.954578, numObservations: 4
action -1, numVisits=292, meanQ=2.771810, numObservations: 1
action 3, numVisits=33, meanQ=1.970621, numObservations: 3
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.562902 0.862309 0.311153 0.00903549 0.507843 0.885281 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=68395, meanQ=8.347266, numObservations: 4
action 1, numVisits=41147, meanQ=8.345086, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 857005 episodes
GETTING ACTION FROM:
action 1, numVisits=477613, meanQ=6.334581, numObservations: 3
action 3, numVisits=488932, meanQ=6.334388, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.562902 0.862309 0.311153 0.00903549 0.507843 0.885281 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 314
Initial state: 0 0.593143 0.841623 0.618655 0.867208 0.13965 0.202943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662994 episodes
GETTING ACTION FROM:
action 3, numVisits=652008, meanQ=5.011619, numObservations: 3
action -1, numVisits=10981, meanQ=1.069052, numObservations: 1
action 0, numVisits=3, meanQ=-2.996600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.593143 0.841623 0.618655 0.867208 0.13965 0.202943 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=107616, meanQ=8.345952, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 874124 episodes
GETTING ACTION FROM:
action 2, numVisits=981738, meanQ=6.359033, numObservations: 3
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.593143 0.841623 0.618655 0.867208 0.13965 0.202943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 315
Initial state: 0 0.443301 0.649166 0.679307 0.830996 0.571084 0.850204 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658181 episodes
GETTING ACTION FROM:
action 2, numVisits=658154, meanQ=4.951387, numObservations: 5
action 0, numVisits=23, meanQ=3.410758, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.443301 0.649166 0.679307 0.830996 0.571084 0.850204 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 316
Initial state: 0 0.336757 0.314215 0.522386 0.850694 0.582582 0.812039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 471876 episodes
GETTING ACTION FROM:
action 0, numVisits=471870, meanQ=5.948282, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 0
Next state: 0 0.336757 0.314215 0.522386 0.850694 0.582582 0.812039 w: 1
Observation: 0 0 0.249729 0 0.944107 0 0.82077 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=173337, meanQ=7.793011, numObservations: 5
action 2, numVisits=13, meanQ=3.460015, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 734777 episodes
GETTING ACTION FROM:
action 3, numVisits=907885, meanQ=5.492933, numObservations: 5
action 2, numVisits=240, meanQ=5.006072, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.336757 0.314215 0.522386 0.850694 0.582582 0.812039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 317
Initial state: 0 0.516894 0.893496 0.540999 0.898136 0.958283 0.752027 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665219 episodes
GETTING ACTION FROM:
action 3, numVisits=665194, meanQ=4.979895, numObservations: 3
action 2, numVisits=20, meanQ=2.095510, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.516894 0.893496 0.540999 0.898136 0.958283 0.752027 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 318
Initial state: 0 0.13015 0.0697819 0.634639 0.843268 0.572373 0.88147 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659998 episodes
GETTING ACTION FROM:
action 1, numVisits=650724, meanQ=4.941208, numObservations: 4
action -1, numVisits=9182, meanQ=2.971735, numObservations: 1
action 0, numVisits=83, meanQ=2.368527, numObservations: 1
action 3, numVisits=8, meanQ=0.748763, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.13015 0.0697819 0.634639 0.843268 0.572373 0.88147 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=106889, meanQ=8.331650, numObservations: 4
action 3, numVisits=29, meanQ=6.792076, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 845342 episodes
GETTING ACTION FROM:
action 2, numVisits=952201, meanQ=6.258600, numObservations: 4
action 3, numVisits=57, meanQ=5.103163, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.13015 0.0697819 0.634639 0.843268 0.572373 0.88147 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 319
Initial state: 0 0.421467 0.634152 0.665649 0.83424 0.529507 0.836666 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 650637 episodes
GETTING ACTION FROM:
action 1, numVisits=650510, meanQ=4.948954, numObservations: 5
action 0, numVisits=119, meanQ=4.207513, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.421467 0.634152 0.665649 0.83424 0.529507 0.836666 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=90680, meanQ=8.422998, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 852512 episodes
GETTING ACTION FROM:
action 3, numVisits=943192, meanQ=6.549599, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.421467 0.634152 0.665649 0.83424 0.529507 0.836666 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 320
Initial state: 0 0.596357 0.806995 0.599978 0.826933 0.0719731 0.771425 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660695 episodes
GETTING ACTION FROM:
action 2, numVisits=660564, meanQ=5.008840, numObservations: 5
action 1, numVisits=66, meanQ=4.021064, numObservations: 4
action -1, numVisits=48, meanQ=3.948286, numObservations: 1
action 0, numVisits=16, meanQ=3.164350, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.596357 0.806995 0.599978 0.826933 0.0719731 0.771425 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 321
Initial state: 0 0.541751 0.893109 0.221154 0.343438 0.526594 0.818882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657257 episodes
GETTING ACTION FROM:
action 2, numVisits=657243, meanQ=4.994783, numObservations: 5
action 3, numVisits=9, meanQ=1.218900, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.541751 0.893109 0.221154 0.343438 0.526594 0.818882 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=75394, meanQ=8.540422, numObservations: 3
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 842042 episodes
GETTING ACTION FROM:
action 3, numVisits=917432, meanQ=6.165170, numObservations: 5
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.541751 0.893109 0.221154 0.343438 0.526594 0.818882 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 322
Initial state: 0 0.619002 0.880485 0.994031 0.539257 0.669996 0.898886 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661041 episodes
GETTING ACTION FROM:
action 3, numVisits=659515, meanQ=4.907151, numObservations: 4
action -1, numVisits=1522, meanQ=2.690294, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.619002 0.880485 0.994031 0.539257 0.669996 0.898886 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 323
Initial state: 0 0.557452 0.483943 0.653259 0.876593 0.578462 0.807699 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 653505 episodes
GETTING ACTION FROM:
action 2, numVisits=652590, meanQ=4.947663, numObservations: 5
action 1, numVisits=901, meanQ=4.708744, numObservations: 3
action 0, numVisits=11, meanQ=2.496925, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.557452 0.483943 0.653259 0.876593 0.578462 0.807699 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 324
Initial state: 0 0.262167 0.00420342 0.699719 0.829857 0.508761 0.889085 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668547 episodes
GETTING ACTION FROM:
action 1, numVisits=668442, meanQ=5.022288, numObservations: 4
action 0, numVisits=74, meanQ=1.954345, numObservations: 1
action 3, numVisits=19, meanQ=1.419484, numObservations: 4
action 2, numVisits=10, meanQ=1.008000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.262167 0.00420342 0.699719 0.829857 0.508761 0.889085 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=76467, meanQ=8.540839, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 852780 episodes
GETTING ACTION FROM:
action 3, numVisits=929245, meanQ=6.066697, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.262167 0.00420342 0.699719 0.829857 0.508761 0.889085 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 325
Initial state: 0 0.616819 0.826899 0.849671 0.988849 0.670874 0.808568 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668793 episodes
GETTING ACTION FROM:
action 1, numVisits=668696, meanQ=4.932862, numObservations: 3
action 0, numVisits=81, meanQ=4.121913, numObservations: 1
action 2, numVisits=12, meanQ=1.998333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.616819 0.826899 0.849671 0.988849 0.670874 0.808568 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 326
Initial state: 0 0.24941 0.00266096 0.555328 0.820997 0.659333 0.836409 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 644769 episodes
GETTING ACTION FROM:
action 1, numVisits=644693, meanQ=4.868924, numObservations: 4
action 0, numVisits=72, meanQ=4.014358, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.24941 0.00266096 0.555328 0.820997 0.659333 0.836409 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=90929, meanQ=8.406251, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 858919 episodes
GETTING ACTION FROM:
action 3, numVisits=949846, meanQ=6.219576, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.24941 0.00266096 0.555328 0.820997 0.659333 0.836409 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 327
Initial state: 0 0.542637 0.894601 0.25595 0.551362 0.623704 0.813151 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659963 episodes
GETTING ACTION FROM:
action 3, numVisits=659705, meanQ=4.981106, numObservations: 4
action 0, numVisits=203, meanQ=4.474723, numObservations: 1
action -1, numVisits=51, meanQ=3.932506, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.542637 0.894601 0.25595 0.551362 0.623704 0.813151 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 328
Initial state: 0 0.541574 0.308289 0.670672 0.815232 0.691055 0.889211 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664334 episodes
GETTING ACTION FROM:
action 2, numVisits=659472, meanQ=5.022095, numObservations: 4
action -1, numVisits=4761, meanQ=3.036055, numObservations: 1
action 0, numVisits=96, meanQ=2.514599, numObservations: 1
action 1, numVisits=4, meanQ=-0.999975, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.541574 0.308289 0.670672 0.815232 0.691055 0.889211 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48709, meanQ=5.638703, numObservations: 4
action 3, numVisits=26, meanQ=3.981542, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 799800 episodes
GETTING ACTION FROM:
action 2, numVisits=848501, meanQ=5.190204, numObservations: 4
action 3, numVisits=29, meanQ=3.811038, numObservations: 5
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.541574 0.308289 0.670672 0.815232 0.691055 0.889211 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 329
Initial state: 0 0.638778 0.861558 0.645035 0.802359 0.556394 0.0976771 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667302 episodes
GETTING ACTION FROM:
action 3, numVisits=667284, meanQ=4.970196, numObservations: 3
action 1, numVisits=13, meanQ=2.845400, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.638778 0.861558 0.645035 0.802359 0.556394 0.0976771 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 330
Initial state: 0 0.557865 0.885384 0.409041 0.0103298 0.55409 0.813921 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663198 episodes
GETTING ACTION FROM:
action 1, numVisits=652105, meanQ=4.949228, numObservations: 3
action -1, numVisits=11087, meanQ=3.035849, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=3, meanQ=-4.333333, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.557865 0.885384 0.409041 0.0103298 0.55409 0.813921 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 331
Initial state: 0 0.503237 0.881772 0.12849 0.973613 0.638519 0.874269 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665482 episodes
GETTING ACTION FROM:
action 1, numVisits=665410, meanQ=5.018352, numObservations: 3
action 3, numVisits=67, meanQ=4.100603, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.503237 0.881772 0.12849 0.973613 0.638519 0.874269 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 332
Initial state: 0 0.471324 0.488984 0.524631 0.848044 0.552888 0.884527 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 641747 episodes
GETTING ACTION FROM:
action 1, numVisits=641569, meanQ=4.857032, numObservations: 4
action -1, numVisits=174, meanQ=4.259411, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.471324 0.488984 0.524631 0.848044 0.552888 0.884527 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=73317, meanQ=8.543123, numObservations: 3
action 3, numVisits=19, meanQ=6.998953, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 859779 episodes
GETTING ACTION FROM:
action 2, numVisits=933036, meanQ=6.063639, numObservations: 4
action 3, numVisits=77, meanQ=5.154548, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.471324 0.488984 0.524631 0.848044 0.552888 0.884527 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 333
Initial state: 0 0.508123 0.846812 0.673328 0.82568 0.234598 0.915333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658515 episodes
GETTING ACTION FROM:
action 1, numVisits=658482, meanQ=4.945509, numObservations: 5
action 0, numVisits=29, meanQ=3.571854, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.508123 0.846812 0.673328 0.82568 0.234598 0.915333 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 334
Initial state: 0 0.65329 0.899775 0.950762 0.293125 0.650483 0.812693 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662973 episodes
GETTING ACTION FROM:
action 2, numVisits=662964, meanQ=5.075912, numObservations: 5
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.65329 0.899775 0.950762 0.293125 0.650483 0.812693 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 335
Initial state: 0 0.56015 0.86903 0.297186 0.605672 0.69845 0.84943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655752 episodes
GETTING ACTION FROM:
action 2, numVisits=655743, meanQ=4.932239, numObservations: 5
action 1, numVisits=4, meanQ=-0.504975, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.56015 0.86903 0.297186 0.605672 0.69845 0.84943 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=91731, meanQ=8.396394, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 854778 episodes
GETTING ACTION FROM:
action 3, numVisits=946507, meanQ=6.246528, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.56015 0.86903 0.297186 0.605672 0.69845 0.84943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 336
Initial state: 0 0.522836 0.87102 0.196261 0.137049 0.651579 0.831927 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672896 episodes
GETTING ACTION FROM:
action 2, numVisits=672854, meanQ=5.023763, numObservations: 3
action 0, numVisits=38, meanQ=3.794521, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.522836 0.87102 0.196261 0.137049 0.651579 0.831927 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=110332, meanQ=8.349976, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 849670 episodes
GETTING ACTION FROM:
action 1, numVisits=960000, meanQ=6.086127, numObservations: 4
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.522836 0.87102 0.196261 0.137049 0.651579 0.831927 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 337
Initial state: 0 0.255765 0.132556 0.602369 0.898494 0.648208 0.838082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671924 episodes
GETTING ACTION FROM:
action 1, numVisits=671842, meanQ=4.948869, numObservations: 3
action 0, numVisits=77, meanQ=4.113343, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.255765 0.132556 0.602369 0.898494 0.648208 0.838082 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=110682, meanQ=8.286201, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 849076 episodes
GETTING ACTION FROM:
action 3, numVisits=959754, meanQ=6.387480, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.255765 0.132556 0.602369 0.898494 0.648208 0.838082 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 338
Initial state: 0 0.518134 0.843953 0.231063 0.38541 0.517526 0.804298 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462277 episodes
GETTING ACTION FROM:
action -1, numVisits=446186, meanQ=2.970370, numObservations: 1
action 0, numVisits=16084, meanQ=2.924222, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 2, numVisits=3, meanQ=-1.670000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.518134 0.843953 0.231063 0.38541 0.517526 0.804298 w: 1
Observation: 0 0.498451 0 0.173734 0 0.486433 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=446152, meanQ=5.023402, numObservations: 4
action -1, numVisits=29, meanQ=3.624450, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 736099 episodes
GETTING ACTION FROM:
action 3, numVisits=1182250, meanQ=4.998582, numObservations: 4
action -1, numVisits=30, meanQ=3.550064, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.518134 0.843953 0.231063 0.38541 0.517526 0.804298 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 339
Initial state: 0 0.519683 0.61699 0.638215 0.838373 0.509273 0.837535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660012 episodes
GETTING ACTION FROM:
action 2, numVisits=659996, meanQ=5.017434, numObservations: 4
action 3, numVisits=10, meanQ=1.198010, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.519683 0.61699 0.638215 0.838373 0.509273 0.837535 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 340
Initial state: 0 0.35781 0.718339 0.571258 0.834695 0.607693 0.87962 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 461959 episodes
GETTING ACTION FROM:
action 0, numVisits=461953, meanQ=3.100163, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=2, meanQ=-7.005000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.35781 0.718339 0.571258 0.834695 0.607693 0.87962 w: 1
Observation: 0 0 0.778302 0 0.839144 0 0.793747 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=461933, meanQ=5.148538, numObservations: 4
action 3, numVisits=14, meanQ=2.701436, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 733642 episodes
GETTING ACTION FROM:
action 1, numVisits=1195575, meanQ=5.036636, numObservations: 4
action 3, numVisits=14, meanQ=2.701436, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.35781 0.718339 0.571258 0.834695 0.607693 0.87962 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 341
Initial state: 0 0.00871753 0.667214 0.61923 0.818648 0.653125 0.835013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663252 episodes
GETTING ACTION FROM:
action 2, numVisits=663229, meanQ=4.938805, numObservations: 4
action 0, numVisits=16, meanQ=3.030041, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.00871753 0.667214 0.61923 0.818648 0.653125 0.835013 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 342
Initial state: 0 0.125159 0.0661246 0.603935 0.891362 0.588833 0.869217 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 461864 episodes
GETTING ACTION FROM:
action -1, numVisits=461851, meanQ=2.918797, numObservations: 1
action 3, numVisits=9, meanQ=-1.670000, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.125159 0.0661246 0.603935 0.891362 0.588833 0.869217 w: 1
Observation: 0 0.192535 0 0.506477 0 0.533066 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=461779, meanQ=4.996683, numObservations: 4
action -1, numVisits=34, meanQ=3.760447, numObservations: 1
action 0, numVisits=32, meanQ=3.658674, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 733723 episodes
GETTING ACTION FROM:
action 2, numVisits=1195502, meanQ=5.163263, numObservations: 4
action -1, numVisits=34, meanQ=3.760447, numObservations: 1
action 0, numVisits=32, meanQ=3.658674, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.125159 0.0661246 0.603935 0.891362 0.588833 0.869217 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 343
Initial state: 0 0.690519 0.898181 0.103093 0.324766 0.661882 0.820818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 653508 episodes
GETTING ACTION FROM:
action 3, numVisits=653492, meanQ=5.014484, numObservations: 5
action 2, numVisits=10, meanQ=2.598000, numObservations: 3
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.690519 0.898181 0.103093 0.324766 0.661882 0.820818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 344
Initial state: 0 0.558917 0.823539 0.486527 0.831683 0.552541 0.890779 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670554 episodes
GETTING ACTION FROM:
action 1, numVisits=670544, meanQ=5.169020, numObservations: 4
action 2, numVisits=5, meanQ=-0.597980, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.558917 0.823539 0.486527 0.831683 0.552541 0.890779 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 345
Initial state: 0 0.660233 0.859403 0.534546 0.878213 0.898907 0.643395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 458139 episodes
GETTING ACTION FROM:
action 0, numVisits=458122, meanQ=2.983415, numObservations: 1
action 2, numVisits=10, meanQ=0.598000, numObservations: 4
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 0
Next state: 0 0.660233 0.859403 0.534546 0.878213 0.898907 0.643395 w: 1
Observation: 0 0 0.850276 0 0.950067 0 0.676551 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=458102, meanQ=5.035256, numObservations: 5
action 3, numVisits=11, meanQ=2.819100, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 731073 episodes
GETTING ACTION FROM:
action 1, numVisits=1189175, meanQ=5.079192, numObservations: 5
action 3, numVisits=11, meanQ=2.819100, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.660233 0.859403 0.534546 0.878213 0.898907 0.643395 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 346
Initial state: 0 0.553687 0.866613 0.555482 0.810654 0.633816 0.986086 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664437 episodes
GETTING ACTION FROM:
action 3, numVisits=664410, meanQ=4.960911, numObservations: 4
action 0, numVisits=23, meanQ=3.382891, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.553687 0.866613 0.555482 0.810654 0.633816 0.986086 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 347
Initial state: 0 0.603382 0.422126 0.656905 0.888332 0.511871 0.863764 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658531 episodes
GETTING ACTION FROM:
action 1, numVisits=658525, meanQ=5.146988, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.603382 0.422126 0.656905 0.888332 0.511871 0.863764 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 348
Initial state: 0 0.502799 0.837223 0.266056 0.980717 0.673203 0.893485 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656856 episodes
GETTING ACTION FROM:
action 3, numVisits=656797, meanQ=4.959824, numObservations: 5
action -1, numVisits=30, meanQ=3.597608, numObservations: 1
action 0, numVisits=24, meanQ=3.368009, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.502799 0.837223 0.266056 0.980717 0.673203 0.893485 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 349
Initial state: 0 0.553531 0.890903 0.610723 0.574359 0.689811 0.815159 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 649993 episodes
GETTING ACTION FROM:
action 1, numVisits=649987, meanQ=5.014949, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.553531 0.890903 0.610723 0.574359 0.689811 0.815159 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 350
Initial state: 0 0.640687 0.883082 0.458028 0.480978 0.588986 0.816323 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663997 episodes
GETTING ACTION FROM:
action 2, numVisits=663991, meanQ=5.012838, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.640687 0.883082 0.458028 0.480978 0.588986 0.816323 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=32796, meanQ=7.834540, numObservations: 4
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 850121 episodes
GETTING ACTION FROM:
action 1, numVisits=882893, meanQ=6.083564, numObservations: 4
action 3, numVisits=24, meanQ=4.498333, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.640687 0.883082 0.458028 0.480978 0.588986 0.816323 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 351
Initial state: 0 0.533412 0.0703156 0.67374 0.836758 0.633338 0.837229 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663722 episodes
GETTING ACTION FROM:
action 1, numVisits=663682, meanQ=5.000463, numObservations: 4
action 0, numVisits=36, meanQ=3.780062, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.533412 0.0703156 0.67374 0.836758 0.633338 0.837229 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 352
Initial state: 0 0.602315 0.809074 0.935203 0.530372 0.677471 0.80562 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659303 episodes
GETTING ACTION FROM:
action 3, numVisits=659295, meanQ=5.018345, numObservations: 5
action 2, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.602315 0.809074 0.935203 0.530372 0.677471 0.80562 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 353
Initial state: 0 0.567948 0.843646 0.583147 0.815195 0.27314 0.369626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 643920 episodes
GETTING ACTION FROM:
action 2, numVisits=643914, meanQ=4.839727, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.567948 0.843646 0.583147 0.815195 0.27314 0.369626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 354
Initial state: 0 0.60473 0.80282 0.67632 0.819821 0.713 0.564864 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661360 episodes
GETTING ACTION FROM:
action 3, numVisits=661310, meanQ=5.221277, numObservations: 5
action 0, numVisits=43, meanQ=4.102221, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 2 0.60473 0.80282 0.67632 0.819821 0.713 0.564864 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 355
Initial state: 0 0.680337 0.890923 0.582949 0.869812 0.886279 0.547355 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658777 episodes
GETTING ACTION FROM:
action 2, numVisits=658769, meanQ=5.015310, numObservations: 5
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.680337 0.890923 0.582949 0.869812 0.886279 0.547355 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 356
Initial state: 0 0.706445 0.465129 0.580736 0.821623 0.582085 0.808756 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667154 episodes
GETTING ACTION FROM:
action 2, numVisits=667104, meanQ=5.020517, numObservations: 4
action -1, numVisits=34, meanQ=3.679807, numObservations: 1
action 3, numVisits=8, meanQ=1.747513, numObservations: 3
action 1, numVisits=6, meanQ=1.331683, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.706445 0.465129 0.580736 0.821623 0.582085 0.808756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=49174, meanQ=5.614992, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 790398 episodes
GETTING ACTION FROM:
action 2, numVisits=839568, meanQ=5.225603, numObservations: 4
action -1, numVisits=4, meanQ=0.475000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.706445 0.465129 0.580736 0.821623 0.582085 0.808756 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 357
Initial state: 0 0.849809 0.151174 0.69718 0.817852 0.573009 0.843215 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 650850 episodes
GETTING ACTION FROM:
action 3, numVisits=650760, meanQ=4.934805, numObservations: 5
action 1, numVisits=34, meanQ=3.647074, numObservations: 4
action -1, numVisits=28, meanQ=3.544578, numObservations: 1
action 2, numVisits=14, meanQ=2.714307, numObservations: 2
action 0, numVisits=14, meanQ=2.591219, numObservations: 1
action: 3
Next state: 1 0.849809 0.151174 0.69718 0.817852 0.573009 0.843215 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 358
Initial state: 0 0.526285 0.846372 0.657609 0.840822 0.831403 0.552128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657818 episodes
GETTING ACTION FROM:
action 2, numVisits=657812, meanQ=5.163696, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.526285 0.846372 0.657609 0.840822 0.831403 0.552128 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 359
Initial state: 0 0.634316 0.807447 0.568279 0.891169 0.175744 0.100711 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670333 episodes
GETTING ACTION FROM:
action 2, numVisits=670098, meanQ=4.939912, numObservations: 3
action 0, numVisits=224, meanQ=4.456391, numObservations: 1
action 1, numVisits=8, meanQ=1.747513, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.634316 0.807447 0.568279 0.891169 0.175744 0.100711 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 360
Initial state: 0 0.947534 0.510693 0.684781 0.821867 0.580917 0.838757 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665964 episodes
GETTING ACTION FROM:
action 2, numVisits=565531, meanQ=5.011445, numObservations: 4
action 3, numVisits=100308, meanQ=4.941386, numObservations: 5
action -1, numVisits=78, meanQ=4.180439, numObservations: 1
action 0, numVisits=45, meanQ=3.924549, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 2
Next state: 1 0.947534 0.510693 0.684781 0.821867 0.580917 0.838757 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 361
Initial state: 0 0.510231 0.849681 0.824226 0.396821 0.588937 0.895045 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 638465 episodes
GETTING ACTION FROM:
action 3, numVisits=638392, meanQ=4.850703, numObservations: 5
action 0, numVisits=69, meanQ=3.952852, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.510231 0.849681 0.824226 0.396821 0.588937 0.895045 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 362
Initial state: 0 0.586781 0.838135 0.642322 0.838561 0.928069 0.522821 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666170 episodes
GETTING ACTION FROM:
action 2, numVisits=664003, meanQ=4.961953, numObservations: 4
action 3, numVisits=2162, meanQ=4.802884, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.586781 0.838135 0.642322 0.838561 0.928069 0.522821 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 363
Initial state: 0 0.803502 0.564132 0.67854 0.80128 0.527986 0.840462 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660426 episodes
GETTING ACTION FROM:
action 2, numVisits=651119, meanQ=5.152747, numObservations: 4
action 0, numVisits=9301, meanQ=2.973283, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.803502 0.564132 0.67854 0.80128 0.527986 0.840462 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=46062, meanQ=7.120718, numObservations: 4
action 3, numVisits=20, meanQ=5.195005, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 794603 episodes
GETTING ACTION FROM:
action 2, numVisits=840608, meanQ=5.605484, numObservations: 4
action 3, numVisits=75, meanQ=4.676268, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.803502 0.564132 0.67854 0.80128 0.527986 0.840462 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 364
Initial state: 0 0.529969 0.899449 0.410498 0.898544 0.6329 0.821167 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658386 episodes
GETTING ACTION FROM:
action 2, numVisits=658370, meanQ=5.034023, numObservations: 4
action 3, numVisits=11, meanQ=2.436364, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.529969 0.899449 0.410498 0.898544 0.6329 0.821167 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 365
Initial state: 0 0.6257 0.821048 0.999135 0.519007 0.693002 0.822289 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654927 episodes
GETTING ACTION FROM:
action 2, numVisits=654753, meanQ=4.946442, numObservations: 5
action 0, numVisits=150, meanQ=4.355812, numObservations: 1
action 3, numVisits=21, meanQ=2.141438, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.6257 0.821048 0.999135 0.519007 0.693002 0.822289 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 366
Initial state: 0 0.598399 0.831219 0.501192 0.882671 0.0439911 0.836417 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659622 episodes
GETTING ACTION FROM:
action 2, numVisits=659329, meanQ=5.009649, numObservations: 5
action -1, numVisits=224, meanQ=4.511955, numObservations: 1
action 0, numVisits=59, meanQ=4.050682, numObservations: 1
action 1, numVisits=6, meanQ=1.663333, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action: 2
Next state: 1 0.598399 0.831219 0.501192 0.882671 0.0439911 0.836417 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 367
Initial state: 0 0.043693 0.33639 0.659359 0.801268 0.512329 0.808124 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664565 episodes
GETTING ACTION FROM:
action 3, numVisits=664517, meanQ=5.020611, numObservations: 4
action -1, numVisits=44, meanQ=3.896219, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.043693 0.33639 0.659359 0.801268 0.512329 0.808124 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 368
Initial state: 0 0.098234 0.00643153 0.663187 0.850743 0.652073 0.807459 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 641943 episodes
GETTING ACTION FROM:
action 3, numVisits=641929, meanQ=4.781664, numObservations: 4
action 1, numVisits=7, meanQ=-1.287143, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.098234 0.00643153 0.663187 0.850743 0.652073 0.807459 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 369
Initial state: 0 0.576952 0.827578 0.658945 0.811555 0.88805 0.529892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 455584 episodes
GETTING ACTION FROM:
action 0, numVisits=445321, meanQ=2.944346, numObservations: 1
action -1, numVisits=10246, meanQ=2.883843, numObservations: 1
action 2, numVisits=13, meanQ=0.068477, numObservations: 4
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 0
Next state: 0 0.576952 0.827578 0.658945 0.811555 0.88805 0.529892 w: 1
Observation: 0 0 0.740913 0 0.903796 0 0.588253 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=445285, meanQ=4.997313, numObservations: 5
action 0, numVisits=28, meanQ=3.542146, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 722198 episodes
GETTING ACTION FROM:
action 3, numVisits=1167480, meanQ=4.738274, numObservations: 5
action 0, numVisits=31, meanQ=3.342010, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.576952 0.827578 0.658945 0.811555 0.88805 0.529892 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 370
Initial state: 0 0.569346 0.851533 0.658803 0.842322 0.29928 0.0602136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 643750 episodes
GETTING ACTION FROM:
action 3, numVisits=643688, meanQ=4.807110, numObservations: 4
action -1, numVisits=30, meanQ=3.434170, numObservations: 1
action 0, numVisits=25, meanQ=3.330175, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action: 3
Next state: 0 0.569346 0.851533 0.658803 0.842322 0.29928 0.0602136 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=105271, meanQ=8.340654, numObservations: 3
action 2, numVisits=12, meanQ=6.332500, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 866600 episodes
GETTING ACTION FROM:
action 1, numVisits=971842, meanQ=6.137523, numObservations: 3
action 2, numVisits=39, meanQ=4.948208, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.569346 0.851533 0.658803 0.842322 0.29928 0.0602136 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 371
Initial state: 0 0.565179 0.833952 0.517632 0.845367 0.0409574 0.58726 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657567 episodes
GETTING ACTION FROM:
action 3, numVisits=657361, meanQ=4.952466, numObservations: 5
action -1, numVisits=119, meanQ=4.275947, numObservations: 1
action 0, numVisits=71, meanQ=4.067851, numObservations: 1
action 1, numVisits=15, meanQ=2.733347, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.565179 0.833952 0.517632 0.845367 0.0409574 0.58726 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48892, meanQ=8.539077, numObservations: 3
action 2, numVisits=26740, meanQ=8.530729, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 853638 episodes
GETTING ACTION FROM:
action 1, numVisits=740207, meanQ=6.167955, numObservations: 3
action 2, numVisits=189061, meanQ=6.159529, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.565179 0.833952 0.517632 0.845367 0.0409574 0.58726 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 372
Initial state: 0 0.583902 0.883151 0.531146 0.845813 0.0518079 0.0484066 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657826 episodes
GETTING ACTION FROM:
action 1, numVisits=657767, meanQ=5.009072, numObservations: 5
action 0, numVisits=32, meanQ=3.721338, numObservations: 1
action -1, numVisits=25, meanQ=3.469879, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.583902 0.883151 0.531146 0.845813 0.0518079 0.0484066 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 373
Initial state: 0 0.666783 0.877278 0.693052 0.860055 0.726551 0.612496 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 448833 episodes
GETTING ACTION FROM:
action 0, numVisits=448794, meanQ=2.825877, numObservations: 1
action -1, numVisits=20, meanQ=1.044349, numObservations: 1
action 3, numVisits=9, meanQ=0.097778, numObservations: 4
action 2, numVisits=9, meanQ=-0.123322, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.666783 0.877278 0.693052 0.860055 0.726551 0.612496 w: 1
Observation: 0 0 0.970917 0 0.938772 0 0.574776 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=448786, meanQ=4.855940, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 700830 episodes
GETTING ACTION FROM:
action 1, numVisits=1149616, meanQ=4.962255, numObservations: 5
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.666783 0.877278 0.693052 0.860055 0.726551 0.612496 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 374
Initial state: 0 0.541893 0.877235 0.868536 0.755563 0.51696 0.808008 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 652975 episodes
GETTING ACTION FROM:
action 1, numVisits=652899, meanQ=4.871781, numObservations: 5
action -1, numVisits=72, meanQ=4.009966, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.541893 0.877235 0.868536 0.755563 0.51696 0.808008 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 375
Initial state: 0 0.658688 0.870053 0.757268 0.183952 0.669481 0.892258 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 603769 episodes
GETTING ACTION FROM:
action 2, numVisits=603763, meanQ=4.875943, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.658688 0.870053 0.757268 0.183952 0.669481 0.892258 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 376
Initial state: 0 0.699311 0.82866 0.686913 0.822174 0.510155 0.108 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658185 episodes
GETTING ACTION FROM:
action 3, numVisits=658178, meanQ=4.939769, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.699311 0.82866 0.686913 0.822174 0.510155 0.108 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 377
Initial state: 0 0.698614 0.830565 0.167578 0.572572 0.59978 0.83774 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 642540 episodes
GETTING ACTION FROM:
action 1, numVisits=642370, meanQ=4.837469, numObservations: 4
action -1, numVisits=78, meanQ=4.015141, numObservations: 1
action 2, numVisits=58, meanQ=3.882760, numObservations: 4
action 0, numVisits=33, meanQ=3.523119, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.698614 0.830565 0.167578 0.572572 0.59978 0.83774 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 378
Initial state: 0 0.609021 0.821775 0.257112 0.206924 0.518002 0.814943 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 638964 episodes
GETTING ACTION FROM:
action 2, numVisits=638879, meanQ=4.895472, numObservations: 5
action 0, numVisits=74, meanQ=4.046529, numObservations: 1
action 1, numVisits=5, meanQ=1.000000, numObservations: 3
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.609021 0.821775 0.257112 0.206924 0.518002 0.814943 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=80947, meanQ=8.391185, numObservations: 3
action 3, numVisits=8750, meanQ=8.339468, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 865111 episodes
GETTING ACTION FROM:
action 1, numVisits=898128, meanQ=6.295462, numObservations: 3
action 3, numVisits=56677, meanQ=6.271929, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.609021 0.821775 0.257112 0.206924 0.518002 0.814943 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 379
Initial state: 0 0.174038 0.125006 0.613179 0.842743 0.686243 0.828109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655527 episodes
GETTING ACTION FROM:
action 1, numVisits=655515, meanQ=4.957740, numObservations: 5
action 2, numVisits=5, meanQ=-1.402000, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.174038 0.125006 0.613179 0.842743 0.686243 0.828109 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=91764, meanQ=8.385504, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855664 episodes
GETTING ACTION FROM:
action 3, numVisits=947426, meanQ=6.352136, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.174038 0.125006 0.613179 0.842743 0.686243 0.828109 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 380
Initial state: 0 0.655586 0.878686 0.96143 0.603815 0.538682 0.854735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657975 episodes
GETTING ACTION FROM:
action 1, numVisits=583081, meanQ=4.930692, numObservations: 4
action 2, numVisits=74850, meanQ=4.901204, numObservations: 5
action -1, numVisits=28, meanQ=3.475091, numObservations: 1
action 3, numVisits=14, meanQ=1.857150, numObservations: 3
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 1 0.655586 0.878686 0.96143 0.603815 0.538682 0.854735 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 381
Initial state: 0 0.563041 0.856391 0.625072 0.839658 0.55132 0.975232 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664839 episodes
GETTING ACTION FROM:
action 3, numVisits=664751, meanQ=5.019675, numObservations: 4
action 1, numVisits=56, meanQ=3.949838, numObservations: 4
action 0, numVisits=28, meanQ=3.584941, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 2 0.563041 0.856391 0.625072 0.839658 0.55132 0.975232 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 382
Initial state: 0 0.562431 0.847937 0.55293 0.836826 0.203628 0.504231 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 456686 episodes
GETTING ACTION FROM:
action -1, numVisits=456677, meanQ=2.900914, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=5, meanQ=-3.804000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.562431 0.847937 0.55293 0.836826 0.203628 0.504231 w: 1
Observation: 0 0.658272 0 0.53277 0 0.264059 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=456666, meanQ=4.965458, numObservations: 5
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 731450 episodes
GETTING ACTION FROM:
action 1, numVisits=1188116, meanQ=4.873826, numObservations: 5
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.562431 0.847937 0.55293 0.836826 0.203628 0.504231 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 383
Initial state: 0 0.600865 0.828347 0.353913 0.621184 0.602571 0.860626 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658243 episodes
GETTING ACTION FROM:
action 2, numVisits=658234, meanQ=5.211325, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.600865 0.828347 0.353913 0.621184 0.602571 0.860626 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=75528, meanQ=8.536838, numObservations: 3
action 3, numVisits=6, meanQ=4.335017, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 858618 episodes
GETTING ACTION FROM:
action 1, numVisits=934084, meanQ=6.161833, numObservations: 4
action 3, numVisits=66, meanQ=5.242429, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.600865 0.828347 0.353913 0.621184 0.602571 0.860626 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 384
Initial state: 0 0.390552 0.509208 0.671647 0.813443 0.518773 0.849869 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666009 episodes
GETTING ACTION FROM:
action 2, numVisits=665917, meanQ=5.002897, numObservations: 3
action -1, numVisits=57, meanQ=4.019173, numObservations: 1
action 3, numVisits=32, meanQ=3.430941, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.390552 0.509208 0.671647 0.813443 0.518773 0.849869 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 385
Initial state: 0 0.63937 0.206227 0.511612 0.82507 0.580308 0.826825 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659944 episodes
GETTING ACTION FROM:
action 3, numVisits=659938, meanQ=5.019850, numObservations: 4
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.63937 0.206227 0.511612 0.82507 0.580308 0.826825 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 386
Initial state: 0 0.594922 0.819182 0.616203 0.878134 0.395165 0.59591 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659322 episodes
GETTING ACTION FROM:
action 2, numVisits=659281, meanQ=5.006282, numObservations: 5
action 0, numVisits=36, meanQ=3.770118, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.594922 0.819182 0.616203 0.878134 0.395165 0.59591 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 387
Initial state: 0 0.603011 0.654353 0.609926 0.809401 0.634375 0.873551 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664477 episodes
GETTING ACTION FROM:
action 3, numVisits=664440, meanQ=4.929323, numObservations: 4
action 0, numVisits=31, meanQ=3.582834, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.603011 0.654353 0.609926 0.809401 0.634375 0.873551 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 388
Initial state: 0 0.860126 0.388947 0.569773 0.886966 0.646528 0.885871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657908 episodes
GETTING ACTION FROM:
action 2, numVisits=657829, meanQ=4.964335, numObservations: 5
action 0, numVisits=50, meanQ=3.919215, numObservations: 1
action -1, numVisits=26, meanQ=3.420183, numObservations: 1
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.860126 0.388947 0.569773 0.886966 0.646528 0.885871 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=48590, meanQ=4.856672, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 842694 episodes
GETTING ACTION FROM:
action 1, numVisits=891284, meanQ=5.986243, numObservations: 5
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.860126 0.388947 0.569773 0.886966 0.646528 0.885871 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 389
Initial state: 0 0.626736 0.877183 0.629561 0.877241 0.975299 0.0551715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 653310 episodes
GETTING ACTION FROM:
action 1, numVisits=653292, meanQ=4.938426, numObservations: 5
action 0, numVisits=7, meanQ=1.815743, numObservations: 2
action 3, numVisits=8, meanQ=0.511250, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.626736 0.877183 0.629561 0.877241 0.975299 0.0551715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=48878, meanQ=4.574760, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 831830 episodes
GETTING ACTION FROM:
action 3, numVisits=880708, meanQ=6.046629, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.626736 0.877183 0.629561 0.877241 0.975299 0.0551715 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 390
Initial state: 0 0.500725 0.494256 0.677072 0.883052 0.620462 0.865136 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659250 episodes
GETTING ACTION FROM:
action 2, numVisits=659198, meanQ=4.958753, numObservations: 5
action 0, numVisits=43, meanQ=3.811502, numObservations: 1
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.500725 0.494256 0.677072 0.883052 0.620462 0.865136 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 391
Initial state: 0 0.541436 0.899313 0.605509 0.825712 0.256343 0.275447 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657596 episodes
GETTING ACTION FROM:
action 3, numVisits=657435, meanQ=4.911956, numObservations: 3
action 2, numVisits=156, meanQ=4.318025, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.541436 0.899313 0.605509 0.825712 0.256343 0.275447 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=108692, meanQ=8.328681, numObservations: 3
action 1, numVisits=137, meanQ=7.622414, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 857934 episodes
GETTING ACTION FROM:
action 2, numVisits=964945, meanQ=6.106215, numObservations: 3
action 1, numVisits=1816, meanQ=5.938606, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.541436 0.899313 0.605509 0.825712 0.256343 0.275447 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 392
Initial state: 0 0.600161 0.888401 0.694033 0.887194 0.708296 0.235461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657594 episodes
GETTING ACTION FROM:
action 1, numVisits=657588, meanQ=4.975836, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.600161 0.888401 0.694033 0.887194 0.708296 0.235461 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15304, meanQ=7.994609, numObservations: 4
action 3, numVisits=4, meanQ=4.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 856796 episodes
GETTING ACTION FROM:
action 2, numVisits=872092, meanQ=6.154492, numObservations: 4
action 3, numVisits=10, meanQ=3.000000, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.600161 0.888401 0.694033 0.887194 0.708296 0.235461 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 393
Initial state: 0 0.814561 0.658589 0.564146 0.800841 0.500489 0.856186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658859 episodes
GETTING ACTION FROM:
action 3, numVisits=658833, meanQ=4.973355, numObservations: 4
action 1, numVisits=18, meanQ=3.220567, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.814561 0.658589 0.564146 0.800841 0.500489 0.856186 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 394
Initial state: 0 0.518374 0.890495 0.62291 0.864847 0.19953 0.164918 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 651919 episodes
GETTING ACTION FROM:
action 3, numVisits=631738, meanQ=5.036129, numObservations: 5
action 0, numVisits=20173, meanQ=2.930756, numObservations: 1
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 2, numVisits=2, meanQ=-7.005000, numObservations: 2
action: 3
Next state: 0 0.518374 0.890495 0.62291 0.864847 0.19953 0.164918 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=15096, meanQ=7.974005, numObservations: 5
action 2, numVisits=15, meanQ=6.333340, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 847296 episodes
GETTING ACTION FROM:
action 1, numVisits=862312, meanQ=5.883486, numObservations: 5
action 2, numVisits=93, meanQ=4.976454, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.518374 0.890495 0.62291 0.864847 0.19953 0.164918 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 395
Initial state: 0 0.623763 0.198226 0.590607 0.87544 0.648137 0.852632 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 459988 episodes
GETTING ACTION FROM:
action -1, numVisits=459979, meanQ=2.966210, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=3, meanQ=-2.336600, numObservations: 1
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.623763 0.198226 0.590607 0.87544 0.648137 0.852632 w: 1
Observation: 0 0.543962 0 0.655128 0 0.685674 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=459970, meanQ=5.025121, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 735466 episodes
GETTING ACTION FROM:
action 2, numVisits=1195436, meanQ=4.854985, numObservations: 5
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.623763 0.198226 0.590607 0.87544 0.648137 0.852632 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 396
Initial state: 0 0.572716 0.873415 0.156383 0.291586 0.616586 0.82977 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658561 episodes
GETTING ACTION FROM:
action 1, numVisits=658470, meanQ=5.009938, numObservations: 4
action -1, numVisits=66, meanQ=4.113560, numObservations: 1
action 0, numVisits=22, meanQ=3.372569, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.572716 0.873415 0.156383 0.291586 0.616586 0.82977 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 397
Initial state: 0 0.623411 0.845837 0.74922 0.886391 0.525643 0.824503 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657846 episodes
GETTING ACTION FROM:
action 1, numVisits=645626, meanQ=4.952498, numObservations: 4
action -1, numVisits=12216, meanQ=3.069919, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.623411 0.845837 0.74922 0.886391 0.525643 0.824503 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 398
Initial state: 0 0.502602 0.881652 0.673752 0.85982 0.49551 0.428603 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656800 episodes
GETTING ACTION FROM:
action 1, numVisits=656767, meanQ=5.017721, numObservations: 5
action 3, numVisits=28, meanQ=1.843221, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.502602 0.881652 0.673752 0.85982 0.49551 0.428603 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 399
Initial state: 0 0.576727 0.0373988 0.634413 0.863978 0.668188 0.857333 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661050 episodes
GETTING ACTION FROM:
action 1, numVisits=661023, meanQ=4.913803, numObservations: 4
action 3, numVisits=21, meanQ=2.899524, numObservations: 4
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.576727 0.0373988 0.634413 0.863978 0.668188 0.857333 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=109130, meanQ=8.336393, numObservations: 4
action 3, numVisits=6, meanQ=4.335017, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 859311 episodes
GETTING ACTION FROM:
action 2, numVisits=968437, meanQ=6.263323, numObservations: 4
action 3, numVisits=8, meanQ=3.001263, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.576727 0.0373988 0.634413 0.863978 0.668188 0.857333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=26534, meanQ=7.346978, numObservations: 5
action 2, numVisits=1059, meanQ=7.187468, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 857360 episodes
GETTING ACTION FROM:
action 3, numVisits=881121, meanQ=6.103354, numObservations: 5
action 2, numVisits=3830, meanQ=5.989786, numObservations: 5
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 0 0.576727 0.0373988 0.634413 0.863978 0.668188 0.857333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 3, numVisits=2255, meanQ=8.408334, numObservations: 4
action 2, numVisits=1758, meanQ=7.697909, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 862188 episodes
GETTING ACTION FROM:
action 3, numVisits=814070, meanQ=5.921467, numObservations: 5
action 2, numVisits=52129, meanQ=5.896692, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.576727 0.0373988 0.634413 0.863978 0.668188 0.857333 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -3.14771
Run # 400
Initial state: 0 0.548761 0.875498 0.851382 0.0117302 0.589434 0.849761 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 461008 episodes
GETTING ACTION FROM:
action 0, numVisits=460954, meanQ=2.936206, numObservations: 1
action -1, numVisits=45, meanQ=1.860046, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action 3, numVisits=2, meanQ=-3.010000, numObservations: 2
action: 0
Next state: 0 0.548761 0.875498 0.851382 0.0117302 0.589434 0.849761 w: 1
Observation: 0 0 0.825476 0 0.05636 0 0.858355 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=460922, meanQ=4.966404, numObservations: 4
action -1, numVisits=21, meanQ=3.282732, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 734249 episodes
GETTING ACTION FROM:
action 3, numVisits=1195171, meanQ=4.938076, numObservations: 4
action -1, numVisits=21, meanQ=3.282732, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.548761 0.875498 0.851382 0.0117302 0.589434 0.849761 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 401
Initial state: 0 0.571751 0.848181 0.907302 0.195133 0.501994 0.887247 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657197 episodes
GETTING ACTION FROM:
action 1, numVisits=657188, meanQ=5.013789, numObservations: 5
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.571751 0.848181 0.907302 0.195133 0.501994 0.887247 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 402
Initial state: 0 0.631281 0.883534 0.6569 0.825665 0.183747 0.157963 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654820 episodes
GETTING ACTION FROM:
action 3, numVisits=646949, meanQ=4.950081, numObservations: 4
action -1, numVisits=7107, meanQ=2.909252, numObservations: 1
action 0, numVisits=759, meanQ=2.762854, numObservations: 1
action 2, numVisits=4, meanQ=-1.000000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.631281 0.883534 0.6569 0.825665 0.183747 0.157963 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=90800, meanQ=8.388494, numObservations: 4
action 2, numVisits=24, meanQ=7.000421, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 859509 episodes
GETTING ACTION FROM:
action 1, numVisits=950175, meanQ=6.536453, numObservations: 4
action 2, numVisits=158, meanQ=5.948167, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.631281 0.883534 0.6569 0.825665 0.183747 0.157963 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 403
Initial state: 0 0.573058 0.827014 0.692953 0.843307 0.776675 0.170975 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657515 episodes
GETTING ACTION FROM:
action 2, numVisits=657508, meanQ=4.968284, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.573058 0.827014 0.692953 0.843307 0.776675 0.170975 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 404
Initial state: 0 0.644529 0.894815 0.522244 0.87081 0.477484 0.828156 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657420 episodes
GETTING ACTION FROM:
action 3, numVisits=657396, meanQ=4.929987, numObservations: 5
action -1, numVisits=20, meanQ=3.249276, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.644529 0.894815 0.522244 0.87081 0.477484 0.828156 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=15648, meanQ=7.974998, numObservations: 4
action 1, numVisits=46, meanQ=7.084352, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 855962 episodes
GETTING ACTION FROM:
action 2, numVisits=871467, meanQ=6.188662, numObservations: 4
action 1, numVisits=187, meanQ=5.608505, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.644529 0.894815 0.522244 0.87081 0.477484 0.828156 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 405
Initial state: 0 0.387027 0.739473 0.558296 0.88604 0.694187 0.881875 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657447 episodes
GETTING ACTION FROM:
action 3, numVisits=657291, meanQ=4.957723, numObservations: 5
action 0, numVisits=148, meanQ=2.186701, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 2
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.387027 0.739473 0.558296 0.88604 0.694187 0.881875 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 406
Initial state: 0 0.667939 0.86397 0.51231 0.864723 0.735646 0.547855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 650947 episodes
GETTING ACTION FROM:
action 1, numVisits=650941, meanQ=4.870464, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.667939 0.86397 0.51231 0.864723 0.735646 0.547855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=45678, meanQ=3.554327, numObservations: 1
action -1, numVisits=2715, meanQ=3.458994, numObservations: 1
action 3, numVisits=9, meanQ=0.557800, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 831259 episodes
GETTING ACTION FROM:
action 3, numVisits=818038, meanQ=5.882994, numObservations: 5
action 0, numVisits=58235, meanQ=2.744259, numObservations: 1
action -1, numVisits=3386, meanQ=2.657198, numObservations: 1
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.667939 0.86397 0.51231 0.864723 0.735646 0.547855 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 407
Initial state: 0 0.663404 0.858042 0.698576 0.834542 0.417862 0.17049 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 651624 episodes
GETTING ACTION FROM:
action 3, numVisits=651618, meanQ=4.923199, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.663404 0.858042 0.698576 0.834542 0.417862 0.17049 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=90546, meanQ=8.412691, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 865799 episodes
GETTING ACTION FROM:
action 2, numVisits=956343, meanQ=6.091239, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.663404 0.858042 0.698576 0.834542 0.417862 0.17049 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 408
Initial state: 0 0.530606 0.866399 0.968656 0.618383 0.583118 0.882461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662840 episodes
GETTING ACTION FROM:
action 3, numVisits=657392, meanQ=4.963161, numObservations: 4
action -1, numVisits=5443, meanQ=2.776633, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.530606 0.866399 0.968656 0.618383 0.583118 0.882461 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=46301, meanQ=4.429203, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 856545 episodes
GETTING ACTION FROM:
action 1, numVisits=902846, meanQ=5.740889, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.530606 0.866399 0.968656 0.618383 0.583118 0.882461 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 409
Initial state: 0 0.137581 0.285432 0.698835 0.868212 0.508268 0.882109 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 608399 episodes
GETTING ACTION FROM:
action 3, numVisits=593789, meanQ=4.645956, numObservations: 5
action -1, numVisits=14597, meanQ=3.135145, numObservations: 1
action 1, numVisits=10, meanQ=1.198010, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.137581 0.285432 0.698835 0.868212 0.508268 0.882109 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 410
Initial state: 0 0.569115 0.865722 0.0403337 0.296891 0.62233 0.874929 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 462683 episodes
GETTING ACTION FROM:
action 0, numVisits=182199, meanQ=3.054018, numObservations: 1
action -1, numVisits=280463, meanQ=2.990522, numObservations: 1
action 2, numVisits=18, meanQ=0.998889, numObservations: 3
action 1, numVisits=2, meanQ=-7.005000, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.569115 0.865722 0.0403337 0.296891 0.62233 0.874929 w: 1
Observation: 0 0 0.811276 0 0.276745 0 0.832105 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=182176, meanQ=5.125211, numObservations: 4
action 0, numVisits=13, meanQ=2.569104, numObservations: 2
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 740272 episodes
GETTING ACTION FROM:
action 1, numVisits=922448, meanQ=4.987502, numObservations: 4
action 0, numVisits=13, meanQ=2.569104, numObservations: 2
action 3, numVisits=6, meanQ=1.663333, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.569115 0.865722 0.0403337 0.296891 0.62233 0.874929 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 411
Initial state: 0 0.72024 0.981394 0.63377 0.896246 0.679259 0.848357 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658263 episodes
GETTING ACTION FROM:
action 3, numVisits=658230, meanQ=5.164295, numObservations: 5
action 0, numVisits=29, meanQ=3.773220, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.72024 0.981394 0.63377 0.896246 0.679259 0.848357 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 412
Initial state: 0 0.647995 0.815178 0.429327 0.00181005 0.574043 0.845308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660312 episodes
GETTING ACTION FROM:
action 3, numVisits=652403, meanQ=4.937342, numObservations: 4
action 0, numVisits=7757, meanQ=2.913886, numObservations: 1
action -1, numVisits=144, meanQ=2.480264, numObservations: 1
action 1, numVisits=5, meanQ=-1.402000, numObservations: 3
action 2, numVisits=3, meanQ=-1.670000, numObservations: 2
action: 3
Next state: 1 0.647995 0.815178 0.429327 0.00181005 0.574043 0.845308 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 413
Initial state: 0 0.85971 0.321624 0.641585 0.858813 0.529191 0.866819 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 460291 episodes
GETTING ACTION FROM:
action 0, numVisits=460274, meanQ=3.113294, numObservations: 1
action 2, numVisits=9, meanQ=0.110022, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=4, meanQ=-2.005000, numObservations: 2
action 1, numVisits=2, meanQ=-7.005000, numObservations: 1
action: 0
Next state: 0 0.85971 0.321624 0.641585 0.858813 0.529191 0.866819 w: 1
Observation: 0 0 0.247698 0 0.896154 0 0.96143 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=460264, meanQ=5.147239, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 740280 episodes
GETTING ACTION FROM:
action 1, numVisits=1200544, meanQ=5.130731, numObservations: 4
action 2, numVisits=4, meanQ=-1.000000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.85971 0.321624 0.641585 0.858813 0.529191 0.866819 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -12.89
Run # 414
Initial state: 0 0.861132 0.454456 0.652553 0.866041 0.66683 0.8287 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661572 episodes
GETTING ACTION FROM:
action 2, numVisits=661566, meanQ=5.003850, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.861132 0.454456 0.652553 0.866041 0.66683 0.8287 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 415
Initial state: 0 0.582703 0.881233 0.293675 0.71631 0.56366 0.818314 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663384 episodes
GETTING ACTION FROM:
action 1, numVisits=663369, meanQ=5.021292, numObservations: 5
action 3, numVisits=10, meanQ=1.390000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.582703 0.881233 0.293675 0.71631 0.56366 0.818314 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 416
Initial state: 0 0.887434 0.0580633 0.51783 0.836418 0.584746 0.86762 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 642374 episodes
GETTING ACTION FROM:
action 1, numVisits=642368, meanQ=4.811816, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.887434 0.0580633 0.51783 0.836418 0.584746 0.86762 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 417
Initial state: 0 0.540219 0.812657 0.625788 0.848493 0.13827 0.811396 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664967 episodes
GETTING ACTION FROM:
action 3, numVisits=664959, meanQ=4.960110, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action 2, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 0 0.540219 0.812657 0.625788 0.848493 0.13827 0.811396 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=109051, meanQ=8.335824, numObservations: 3
action 1, numVisits=11, meanQ=6.090000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 864515 episodes
GETTING ACTION FROM:
action 2, numVisits=973368, meanQ=6.196435, numObservations: 3
action 1, numVisits=207, meanQ=5.676716, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.540219 0.812657 0.625788 0.848493 0.13827 0.811396 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 418
Initial state: 0 0.694 0.847166 0.0820153 0.353842 0.644608 0.816535 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 651873 episodes
GETTING ACTION FROM:
action 2, numVisits=651839, meanQ=4.942111, numObservations: 5
action 3, numVisits=26, meanQ=3.453462, numObservations: 4
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.694 0.847166 0.0820153 0.353842 0.644608 0.816535 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=15712, meanQ=7.935935, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 850112 episodes
GETTING ACTION FROM:
action 3, numVisits=865819, meanQ=5.918899, numObservations: 4
action 1, numVisits=5, meanQ=2.598000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.694 0.847166 0.0820153 0.353842 0.644608 0.816535 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 419
Initial state: 0 0.679569 0.83037 0.691134 0.38864 0.605351 0.866361 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661260 episodes
GETTING ACTION FROM:
action 3, numVisits=661241, meanQ=4.998669, numObservations: 4
action 2, numVisits=14, meanQ=2.427857, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.679569 0.83037 0.691134 0.38864 0.605351 0.866361 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 420
Initial state: 0 0.698698 0.837354 0.422341 0.144169 0.614403 0.811497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659137 episodes
GETTING ACTION FROM:
action 3, numVisits=659074, meanQ=4.951666, numObservations: 4
action -1, numVisits=30, meanQ=3.593847, numObservations: 1
action 1, numVisits=25, meanQ=2.843204, numObservations: 3
action 2, numVisits=6, meanQ=1.001683, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.698698 0.837354 0.422341 0.144169 0.614403 0.811497 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 421
Initial state: 0 0.380014 0.372893 0.660278 0.814795 0.592939 0.894082 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663482 episodes
GETTING ACTION FROM:
action 1, numVisits=663476, meanQ=5.019982, numObservations: 5
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.380014 0.372893 0.660278 0.814795 0.592939 0.894082 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=93368, meanQ=8.396589, numObservations: 4
action 2, numVisits=17, meanQ=6.177065, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 848914 episodes
GETTING ACTION FROM:
action 3, numVisits=940768, meanQ=6.152877, numObservations: 4
action 2, numVisits=1528, meanQ=5.965594, numObservations: 3
action -1, numVisits=3, meanQ=1.300000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.380014 0.372893 0.660278 0.814795 0.592939 0.894082 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 422
Initial state: 0 0.853666 0.628546 0.617284 0.880089 0.617908 0.858843 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658933 episodes
GETTING ACTION FROM:
action 1, numVisits=658915, meanQ=4.953664, numObservations: 5
action 3, numVisits=13, meanQ=1.613077, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 2 0.853666 0.628546 0.617284 0.880089 0.617908 0.858843 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 423
Initial state: 0 0.03431 0.15332 0.517725 0.831636 0.606737 0.852741 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654875 episodes
GETTING ACTION FROM:
action 2, numVisits=654850, meanQ=5.047330, numObservations: 5
action 1, numVisits=20, meanQ=3.185500, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.03431 0.15332 0.517725 0.831636 0.606737 0.852741 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 424
Initial state: 0 0.375771 0.167466 0.530254 0.803489 0.565899 0.868236 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655243 episodes
GETTING ACTION FROM:
action 3, numVisits=655229, meanQ=5.010658, numObservations: 5
action 1, numVisits=8, meanQ=-0.001250, numObservations: 2
action 2, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.375771 0.167466 0.530254 0.803489 0.565899 0.868236 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 425
Initial state: 0 0.293027 0.114229 0.535334 0.899982 0.663042 0.868061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661592 episodes
GETTING ACTION FROM:
action 1, numVisits=661584, meanQ=5.025619, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.293027 0.114229 0.535334 0.899982 0.663042 0.868061 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=88096, meanQ=8.420243, numObservations: 3
action 2, numVisits=4146, meanQ=8.331439, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 861297 episodes
GETTING ACTION FROM:
action 3, numVisits=925511, meanQ=6.433351, numObservations: 3
action 2, numVisits=28028, meanQ=6.396340, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.293027 0.114229 0.535334 0.899982 0.663042 0.868061 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 426
Initial state: 0 0.176492 0.562793 0.569715 0.878679 0.681684 0.859074 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662331 episodes
GETTING ACTION FROM:
action 3, numVisits=662296, meanQ=5.029074, numObservations: 4
action 1, numVisits=15, meanQ=2.064680, numObservations: 4
action 2, numVisits=16, meanQ=1.998762, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.176492 0.562793 0.569715 0.878679 0.681684 0.859074 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 427
Initial state: 0 0.152634 0.092239 0.69392 0.826199 0.527219 0.846573 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658309 episodes
GETTING ACTION FROM:
action 1, numVisits=658264, meanQ=4.945618, numObservations: 5
action -1, numVisits=32, meanQ=3.613348, numObservations: 1
action 2, numVisits=10, meanQ=1.799000, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.152634 0.092239 0.69392 0.826199 0.527219 0.846573 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=91711, meanQ=8.396311, numObservations: 3
action 2, numVisits=525, meanQ=8.120246, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 858405 episodes
GETTING ACTION FROM:
action 3, numVisits=947105, meanQ=6.545159, numObservations: 3
action 2, numVisits=3536, meanQ=6.426686, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.152634 0.092239 0.69392 0.826199 0.527219 0.846573 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 428
Initial state: 0 0.477013 0.218253 0.597426 0.824414 0.575662 0.87818 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 644201 episodes
GETTING ACTION FROM:
action 2, numVisits=638751, meanQ=4.897325, numObservations: 5
action 0, numVisits=5444, meanQ=2.776793, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=3, meanQ=-4.333333, numObservations: 2
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.477013 0.218253 0.597426 0.824414 0.575662 0.87818 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 429
Initial state: 0 0.433857 0.557589 0.660163 0.822546 0.536965 0.830857 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 674896 episodes
GETTING ACTION FROM:
action 2, numVisits=672329, meanQ=5.041494, numObservations: 3
action -1, numVisits=2563, meanQ=2.851804, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.433857 0.557589 0.660163 0.822546 0.536965 0.830857 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 430
Initial state: 0 0.0147088 0.507058 0.56868 0.842814 0.558292 0.832648 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658982 episodes
GETTING ACTION FROM:
action 3, numVisits=658975, meanQ=4.995863, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.0147088 0.507058 0.56868 0.842814 0.558292 0.832648 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 431
Initial state: 0 0.641084 0.856104 0.657487 0.887744 0.478392 0.433157 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660641 episodes
GETTING ACTION FROM:
action 2, numVisits=601263, meanQ=5.036335, numObservations: 5
action 3, numVisits=59305, meanQ=4.916245, numObservations: 5
action 0, numVisits=35, meanQ=3.805628, numObservations: 1
action 1, numVisits=36, meanQ=3.602503, numObservations: 4
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.641084 0.856104 0.657487 0.887744 0.478392 0.433157 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 432
Initial state: 0 0.130844 0.990181 0.678285 0.818068 0.688983 0.891126 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 652394 episodes
GETTING ACTION FROM:
action 1, numVisits=652349, meanQ=4.864292, numObservations: 3
action -1, numVisits=41, meanQ=3.719298, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.130844 0.990181 0.678285 0.818068 0.688983 0.891126 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 0, numVisits=48490, meanQ=3.546231, numObservations: 1
action 3, numVisits=4, meanQ=-0.999975, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 847950 episodes
GETTING ACTION FROM:
action 2, numVisits=829088, meanQ=6.077783, numObservations: 5
action 0, numVisits=67343, meanQ=2.349065, numObservations: 1
action -1, numVisits=9, meanQ=-0.021100, numObservations: 1
action 3, numVisits=4, meanQ=-0.999975, numObservations: 2
action 1, numVisits=4, meanQ=-2.005000, numObservations: 2
action: 2
Next state: 1 0.130844 0.990181 0.678285 0.818068 0.688983 0.891126 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 433
Initial state: 0 0.541828 0.87283 0.241477 0.708932 0.557072 0.893274 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666132 episodes
GETTING ACTION FROM:
action 2, numVisits=666126, meanQ=4.961988, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.541828 0.87283 0.241477 0.708932 0.557072 0.893274 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=109350, meanQ=8.311816, numObservations: 3
action 3, numVisits=2, meanQ=2.995000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 862045 episodes
GETTING ACTION FROM:
action 1, numVisits=971391, meanQ=6.240367, numObservations: 3
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.541828 0.87283 0.241477 0.708932 0.557072 0.893274 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 434
Initial state: 0 0.681413 0.843505 0.578323 0.804915 0.219827 0.363329 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667743 episodes
GETTING ACTION FROM:
action 1, numVisits=667669, meanQ=5.043805, numObservations: 4
action 0, numVisits=38, meanQ=3.833026, numObservations: 1
action -1, numVisits=19, meanQ=3.344251, numObservations: 1
action 3, numVisits=16, meanQ=3.117506, numObservations: 4
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.681413 0.843505 0.578323 0.804915 0.219827 0.363329 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 435
Initial state: 0 0.943856 0.633072 0.54039 0.866041 0.575217 0.867697 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666789 episodes
GETTING ACTION FROM:
action 2, numVisits=666403, meanQ=5.005297, numObservations: 4
action -1, numVisits=359, meanQ=1.195119, numObservations: 1
action 3, numVisits=17, meanQ=0.058241, numObservations: 3
action 1, numVisits=8, meanQ=-1.263737, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.943856 0.633072 0.54039 0.866041 0.575217 0.867697 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 436
Initial state: 0 0.699916 0.857538 0.63405 0.807802 0.800501 0.50316 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667466 episodes
GETTING ACTION FROM:
action 2, numVisits=662642, meanQ=5.010140, numObservations: 4
action 0, numVisits=4819, meanQ=2.730626, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.699916 0.857538 0.63405 0.807802 0.800501 0.50316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48196, meanQ=5.596348, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 788470 episodes
GETTING ACTION FROM:
action 2, numVisits=836664, meanQ=4.971224, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.699916 0.857538 0.63405 0.807802 0.800501 0.50316 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 437
Initial state: 0 0.624155 0.844714 0.94893 0.319222 0.549905 0.834299 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661712 episodes
GETTING ACTION FROM:
action 1, numVisits=661670, meanQ=5.013445, numObservations: 5
action -1, numVisits=33, meanQ=3.720093, numObservations: 1
action 3, numVisits=6, meanQ=0.331667, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.624155 0.844714 0.94893 0.319222 0.549905 0.834299 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 438
Initial state: 0 0.528982 0.864415 0.633891 0.854369 0.304197 0.720873 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 654752 episodes
GETTING ACTION FROM:
action 3, numVisits=654724, meanQ=4.991683, numObservations: 5
action 0, numVisits=24, meanQ=3.447239, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.528982 0.864415 0.633891 0.854369 0.304197 0.720873 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 439
Initial state: 0 0.643363 0.804561 0.638457 0.814814 0.344358 0.975119 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661013 episodes
GETTING ACTION FROM:
action 1, numVisits=660982, meanQ=5.013954, numObservations: 5
action -1, numVisits=27, meanQ=3.491658, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.643363 0.804561 0.638457 0.814814 0.344358 0.975119 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 440
Initial state: 0 0.502976 0.863839 0.583664 0.842889 0.346325 0.135091 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661770 episodes
GETTING ACTION FROM:
action 1, numVisits=661707, meanQ=5.020154, numObservations: 5
action -1, numVisits=58, meanQ=4.063658, numObservations: 1
action 3, numVisits=2, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.502976 0.863839 0.583664 0.842889 0.346325 0.135091 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 441
Initial state: 0 0.580692 0.875051 0.0512322 0.821771 0.594599 0.850018 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 652963 episodes
GETTING ACTION FROM:
action 1, numVisits=652934, meanQ=4.973136, numObservations: 5
action 3, numVisits=21, meanQ=3.379538, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.580692 0.875051 0.0512322 0.821771 0.594599 0.850018 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 442
Initial state: 0 0.27926 0.216103 0.638075 0.874312 0.63088 0.880817 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667601 episodes
GETTING ACTION FROM:
action 1, numVisits=662449, meanQ=5.017858, numObservations: 4
action 2, numVisits=2766, meanQ=4.886036, numObservations: 5
action 3, numVisits=2382, meanQ=4.874853, numObservations: 5
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 0 0.27926 0.216103 0.638075 0.874312 0.63088 0.880817 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=86993, meanQ=8.405518, numObservations: 4
action 2, numVisits=6226, meanQ=8.341070, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 854675 episodes
GETTING ACTION FROM:
action 3, numVisits=788609, meanQ=6.033009, numObservations: 4
action 2, numVisits=159282, meanQ=6.022637, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.27926 0.216103 0.638075 0.874312 0.63088 0.880817 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 443
Initial state: 0 0.63127 0.891201 0.0733938 0.256483 0.676328 0.896542 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662286 episodes
GETTING ACTION FROM:
action 3, numVisits=662266, meanQ=5.003779, numObservations: 4
action 1, numVisits=12, meanQ=2.332517, numObservations: 4
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.63127 0.891201 0.0733938 0.256483 0.676328 0.896542 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 444
Initial state: 0 0.584191 0.13588 0.677028 0.831512 0.59771 0.825385 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659562 episodes
GETTING ACTION FROM:
action 1, numVisits=649775, meanQ=4.965311, numObservations: 4
action 0, numVisits=9783, meanQ=2.991339, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 0 0.584191 0.13588 0.677028 0.831512 0.59771 0.825385 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=91168, meanQ=8.402647, numObservations: 3
action 3, numVisits=59, meanQ=7.502373, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 869763 episodes
GETTING ACTION FROM:
action 2, numVisits=960450, meanQ=6.158216, numObservations: 3
action 3, numVisits=537, meanQ=5.844078, numObservations: 3
action 0, numVisits=3, meanQ=1.300000, numObservations: 1
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.584191 0.13588 0.677028 0.831512 0.59771 0.825385 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 445
Initial state: 0 0.681624 0.845919 0.636067 0.842918 0.00163546 0.0632395 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656577 episodes
GETTING ACTION FROM:
action 1, numVisits=656438, meanQ=4.948000, numObservations: 5
action -1, numVisits=71, meanQ=4.082138, numObservations: 1
action 0, numVisits=55, meanQ=3.959338, numObservations: 1
action 3, numVisits=9, meanQ=1.432222, numObservations: 3
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action: 1
Next state: 1 0.681624 0.845919 0.636067 0.842918 0.00163546 0.0632395 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 446
Initial state: 0 0.813517 0.113331 0.635403 0.84864 0.528601 0.829461 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 656270 episodes
GETTING ACTION FROM:
action 1, numVisits=563064, meanQ=4.937820, numObservations: 5
action 3, numVisits=93197, meanQ=4.868513, numObservations: 4
action 2, numVisits=5, meanQ=1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 2 0.813517 0.113331 0.635403 0.84864 0.528601 0.829461 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 447
Initial state: 0 0.584696 0.809752 0.0826219 0.966956 0.658836 0.865999 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664485 episodes
GETTING ACTION FROM:
action 2, numVisits=664438, meanQ=5.040729, numObservations: 5
action -1, numVisits=16, meanQ=3.181165, numObservations: 1
action 1, numVisits=16, meanQ=2.873756, numObservations: 4
action 3, numVisits=13, meanQ=2.845400, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.584696 0.809752 0.0826219 0.966956 0.658836 0.865999 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=13324, meanQ=5.573222, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 779713 episodes
GETTING ACTION FROM:
action 2, numVisits=793035, meanQ=5.030797, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.584696 0.809752 0.0826219 0.966956 0.658836 0.865999 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 3, numVisits=15133, meanQ=6.956502, numObservations: 4
action 2, numVisits=13, meanQ=5.264615, numObservations: 2
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 869538 episodes
GETTING ACTION FROM:
action 3, numVisits=884668, meanQ=6.213642, numObservations: 4
action 2, numVisits=14, meanQ=4.102857, numObservations: 2
action 1, numVisits=5, meanQ=2.598000, numObservations: 2
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 3
Next state: 1 0.584696 0.809752 0.0826219 0.966956 0.658836 0.865999 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 0.8609
Run # 448
Initial state: 0 0.614259 0.802083 0.456325 0.624611 0.637038 0.889713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658204 episodes
GETTING ACTION FROM:
action 1, numVisits=658145, meanQ=4.991033, numObservations: 5
action 0, numVisits=48, meanQ=3.864201, numObservations: 1
action 2, numVisits=8, meanQ=1.747513, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.614259 0.802083 0.456325 0.624611 0.637038 0.889713 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 449
Initial state: 0 0.859218 0.702787 0.515752 0.837032 0.625618 0.807872 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659773 episodes
GETTING ACTION FROM:
action 2, numVisits=659735, meanQ=5.012227, numObservations: 5
action 0, numVisits=21, meanQ=3.383829, numObservations: 1
action 3, numVisits=14, meanQ=2.998571, numObservations: 3
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 0 0.859218 0.702787 0.515752 0.837032 0.625618 0.807872 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48467, meanQ=5.587830, numObservations: 3
action 3, numVisits=97, meanQ=4.445981, numObservations: 4
action 1, numVisits=8, meanQ=3.248763, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 783430 episodes
GETTING ACTION FROM:
action 2, numVisits=831765, meanQ=5.182674, numObservations: 4
action 1, numVisits=131, meanQ=4.464199, numObservations: 4
action 3, numVisits=104, meanQ=4.367887, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 2
Next state: 1 0.859218 0.702787 0.515752 0.837032 0.625618 0.807872 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 450
Initial state: 0 0.690592 0.846316 0.621144 0.825497 0.13851 0.831051 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666142 episodes
GETTING ACTION FROM:
action 3, numVisits=666136, meanQ=5.016201, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.690592 0.846316 0.621144 0.825497 0.13851 0.831051 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 451
Initial state: 0 0.130614 0.762419 0.502791 0.802601 0.620481 0.84715 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666375 episodes
GETTING ACTION FROM:
action 1, numVisits=666362, meanQ=4.954429, numObservations: 4
action 2, numVisits=8, meanQ=1.747513, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.130614 0.762419 0.502791 0.802601 0.620481 0.84715 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=93920, meanQ=8.413908, numObservations: 4
action 3, numVisits=20, meanQ=6.399010, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 856086 episodes
GETTING ACTION FROM:
action 2, numVisits=949944, meanQ=6.026827, numObservations: 4
action 3, numVisits=80, meanQ=5.024629, numObservations: 4
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.130614 0.762419 0.502791 0.802601 0.620481 0.84715 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 452
Initial state: 0 0.946173 0.386393 0.584728 0.854634 0.697092 0.860433 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666669 episodes
GETTING ACTION FROM:
action 3, numVisits=666530, meanQ=4.991256, numObservations: 4
action -1, numVisits=59, meanQ=4.034785, numObservations: 1
action 0, numVisits=57, meanQ=4.017647, numObservations: 1
action 2, numVisits=20, meanQ=2.699505, numObservations: 3
action 1, numVisits=3, meanQ=-1.670000, numObservations: 3
action: 3
Next state: 1 0.946173 0.386393 0.584728 0.854634 0.697092 0.860433 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 453
Initial state: 0 0.589915 0.805716 0.585079 0.943662 0.596365 0.829905 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 461429 episodes
GETTING ACTION FROM:
action -1, numVisits=457436, meanQ=2.960805, numObservations: 1
action 0, numVisits=3988, meanQ=2.857094, numObservations: 1
action 2, numVisits=2, meanQ=-3.010000, numObservations: 2
action 3, numVisits=2, meanQ=-8.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.589915 0.805716 0.585079 0.943662 0.596365 0.829905 w: 1
Observation: 0 0.499187 0 0.668688 0 0.588755 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=457364, meanQ=5.016007, numObservations: 4
action -1, numVisits=59, meanQ=4.077784, numObservations: 1
action 1, numVisits=9, meanQ=2.332244, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 732803 episodes
GETTING ACTION FROM:
action 3, numVisits=1190165, meanQ=5.025605, numObservations: 4
action -1, numVisits=61, meanQ=4.066235, numObservations: 1
action 1, numVisits=9, meanQ=2.332244, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.589915 0.805716 0.585079 0.943662 0.596365 0.829905 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 454
Initial state: 0 0.654317 0.865364 0.9105 0.928228 0.548709 0.896443 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661725 episodes
GETTING ACTION FROM:
action 2, numVisits=661646, meanQ=4.955396, numObservations: 5
action 3, numVisits=44, meanQ=3.680234, numObservations: 4
action -1, numVisits=30, meanQ=3.607300, numObservations: 1
action 1, numVisits=3, meanQ=-1.670000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.654317 0.865364 0.9105 0.928228 0.548709 0.896443 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 455
Initial state: 0 0.611952 0.896889 0.557695 0.86732 0.30332 0.58218 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657055 episodes
GETTING ACTION FROM:
action 2, numVisits=656898, meanQ=4.939202, numObservations: 5
action 0, numVisits=153, meanQ=4.350406, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.611952 0.896889 0.557695 0.86732 0.30332 0.58218 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 456
Initial state: 0 0.669153 0.826906 0.536325 0.885123 0.0718614 0.792882 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655632 episodes
GETTING ACTION FROM:
action 2, numVisits=655529, meanQ=4.905689, numObservations: 3
action 0, numVisits=99, meanQ=4.177782, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.669153 0.826906 0.536325 0.885123 0.0718614 0.792882 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=106973, meanQ=8.308751, numObservations: 5
action 1, numVisits=496, meanQ=8.021283, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 839527 episodes
GETTING ACTION FROM:
action 3, numVisits=939048, meanQ=6.253435, numObservations: 5
action 1, numVisits=7946, meanQ=6.176917, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.669153 0.826906 0.536325 0.885123 0.0718614 0.792882 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 457
Initial state: 0 0.586336 0.563011 0.607748 0.879578 0.679547 0.885833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658808 episodes
GETTING ACTION FROM:
action 1, numVisits=658638, meanQ=4.943703, numObservations: 5
action -1, numVisits=166, meanQ=4.280254, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.586336 0.563011 0.607748 0.879578 0.679547 0.885833 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=32636, meanQ=7.852013, numObservations: 4
action 2, numVisits=93, meanQ=7.034842, numObservations: 4
action 1, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 846847 episodes
GETTING ACTION FROM:
action 3, numVisits=879136, meanQ=6.188610, numObservations: 4
action 2, numVisits=430, meanQ=5.822825, numObservations: 4
action 1, numVisits=7, meanQ=2.144300, numObservations: 4
action -1, numVisits=5, meanQ=1.762000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action: 3
Next state: 1 0.586336 0.563011 0.607748 0.879578 0.679547 0.885833 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 458
Initial state: 0 0.189308 0.320048 0.627733 0.87517 0.648133 0.81967 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667949 episodes
GETTING ACTION FROM:
action 1, numVisits=667860, meanQ=5.019628, numObservations: 4
action 0, numVisits=83, meanQ=4.223537, numObservations: 1
action 2, numVisits=3, meanQ=0.330033, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 0 0.189308 0.320048 0.627733 0.87517 0.648133 0.81967 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=109788, meanQ=8.339233, numObservations: 5
action 3, numVisits=7, meanQ=5.284300, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 837930 episodes
GETTING ACTION FROM:
action 2, numVisits=947670, meanQ=6.346096, numObservations: 5
action 3, numVisits=53, meanQ=5.263775, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.189308 0.320048 0.627733 0.87517 0.648133 0.81967 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 459
Initial state: 0 0.820647 0.649975 0.555092 0.803833 0.571535 0.860308 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 634518 episodes
GETTING ACTION FROM:
action 3, numVisits=634404, meanQ=4.793989, numObservations: 5
action -1, numVisits=109, meanQ=0.920884, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=2, meanQ=-4.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.820647 0.649975 0.555092 0.803833 0.571535 0.860308 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 460
Initial state: 0 0.483285 0.506487 0.596472 0.892831 0.546014 0.833521 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 461520 episodes
GETTING ACTION FROM:
action 0, numVisits=461468, meanQ=2.997407, numObservations: 1
action 3, numVisits=47, meanQ=1.864539, numObservations: 4
action -1, numVisits=3, meanQ=-2.336600, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 0
Next state: 0 0.483285 0.506487 0.596472 0.892831 0.546014 0.833521 w: 1
Observation: 0 0 0.497102 0 0.925793 0 0.763423 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=438640, meanQ=5.029511, numObservations: 4
action 1, numVisits=22778, meanQ=4.987413, numObservations: 4
action -1, numVisits=43, meanQ=3.908877, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
Sampled 739339 episodes
GETTING ACTION FROM:
action 2, numVisits=1177979, meanQ=5.237242, numObservations: 4
action 1, numVisits=22778, meanQ=4.987413, numObservations: 4
action -1, numVisits=43, meanQ=3.908877, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 1 0.483285 0.506487 0.596472 0.892831 0.546014 0.833521 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 6.91
Run # 461
Initial state: 0 0.546105 0.832645 0.294377 0.111436 0.681159 0.833057 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 644485 episodes
GETTING ACTION FROM:
action 3, numVisits=644444, meanQ=4.890670, numObservations: 4
action 0, numVisits=37, meanQ=3.620013, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.546105 0.832645 0.294377 0.111436 0.681159 0.833057 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 462
Initial state: 0 0.607652 0.80106 0.555738 0.60768 0.592091 0.882654 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671464 episodes
GETTING ACTION FROM:
action 1, numVisits=671454, meanQ=5.007192, numObservations: 4
action 2, numVisits=5, meanQ=-0.201980, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.607652 0.80106 0.555738 0.60768 0.592091 0.882654 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=49938, meanQ=5.584744, numObservations: 4
action 2, numVisits=5, meanQ=2.598000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 787394 episodes
GETTING ACTION FROM:
action 1, numVisits=837325, meanQ=4.971089, numObservations: 5
action 2, numVisits=10, meanQ=1.799000, numObservations: 2
action 3, numVisits=4, meanQ=-1.000000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 1
Next state: 1 0.607652 0.80106 0.555738 0.60768 0.592091 0.882654 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 463
Initial state: 0 0.608008 0.880456 0.574205 0.815856 0.0609882 0.571115 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663704 episodes
GETTING ACTION FROM:
action 1, numVisits=663650, meanQ=4.942998, numObservations: 4
action -1, numVisits=27, meanQ=3.515216, numObservations: 1
action 0, numVisits=19, meanQ=3.241731, numObservations: 1
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action 2, numVisits=4, meanQ=-2.005000, numObservations: 3
action: 1
Next state: 0 0.608008 0.880456 0.574205 0.815856 0.0609882 0.571115 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=48421, meanQ=4.749849, numObservations: 5
action -1, numVisits=1035, meanQ=2.568130, numObservations: 1
action 3, numVisits=21, meanQ=1.085252, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 837531 episodes
GETTING ACTION FROM:
action 2, numVisits=885952, meanQ=5.829571, numObservations: 5
action -1, numVisits=1035, meanQ=2.568130, numObservations: 1
action 3, numVisits=21, meanQ=1.085252, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.608008 0.880456 0.574205 0.815856 0.0609882 0.571115 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 464
Initial state: 0 0.57164 0.807748 0.282786 0.867584 0.510653 0.842222 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 649784 episodes
GETTING ACTION FROM:
action 3, numVisits=642679, meanQ=4.951913, numObservations: 5
action -1, numVisits=7101, meanQ=3.140896, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.57164 0.807748 0.282786 0.867584 0.510653 0.842222 w: 1
Observation: 8 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 465
Initial state: 0 0.70027 0.255923 0.65266 0.828948 0.679782 0.801579 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665727 episodes
GETTING ACTION FROM:
action 2, numVisits=665716, meanQ=4.966388, numObservations: 4
action 3, numVisits=6, meanQ=1.663333, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.70027 0.255923 0.65266 0.828948 0.679782 0.801579 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 466
Initial state: 0 0.58404 0.841947 0.695104 0.825159 0.649033 0.346442 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664177 episodes
GETTING ACTION FROM:
action 2, numVisits=664148, meanQ=4.942606, numObservations: 3
action 1, numVisits=21, meanQ=3.280000, numObservations: 5
action 3, numVisits=4, meanQ=0.997500, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.58404 0.841947 0.695104 0.825159 0.649033 0.346442 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 467
Initial state: 0 0.544207 0.665684 0.651289 0.81773 0.538057 0.810862 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 658533 episodes
GETTING ACTION FROM:
action 3, numVisits=658515, meanQ=5.015652, numObservations: 5
action 0, numVisits=11, meanQ=2.803780, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.544207 0.665684 0.651289 0.81773 0.538057 0.810862 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 468
Initial state: 0 0.688981 0.881059 0.74795 0.789208 0.641744 0.831011 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659602 episodes
GETTING ACTION FROM:
action 3, numVisits=659575, meanQ=5.031657, numObservations: 5
action 2, numVisits=22, meanQ=1.181364, numObservations: 4
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.688981 0.881059 0.74795 0.789208 0.641744 0.831011 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 469
Initial state: 0 0.676262 0.899982 0.0297043 0.55466 0.559401 0.854855 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663811 episodes
GETTING ACTION FROM:
action 3, numVisits=663788, meanQ=5.019113, numObservations: 4
action 0, numVisits=19, meanQ=3.303191, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.676262 0.899982 0.0297043 0.55466 0.559401 0.854855 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 470
Initial state: 0 0.519826 0.854669 0.56602 0.889003 0.955252 0.475205 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664043 episodes
GETTING ACTION FROM:
action 1, numVisits=663973, meanQ=5.047025, numObservations: 5
action 0, numVisits=35, meanQ=3.782521, numObservations: 1
action -1, numVisits=24, meanQ=3.525515, numObservations: 1
action 2, numVisits=9, meanQ=0.998889, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action: 1
Next state: 1 0.519826 0.854669 0.56602 0.889003 0.955252 0.475205 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 471
Initial state: 0 0.779898 0.501472 0.574061 0.899491 0.671096 0.89777 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 643229 episodes
GETTING ACTION FROM:
action 2, numVisits=643223, meanQ=4.776009, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.779898 0.501472 0.574061 0.899491 0.671096 0.89777 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 472
Initial state: 0 0.641032 0.477779 0.607161 0.825038 0.623207 0.814209 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664025 episodes
GETTING ACTION FROM:
action 1, numVisits=664001, meanQ=4.948625, numObservations: 4
action -1, numVisits=17, meanQ=3.150492, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.641032 0.477779 0.607161 0.825038 0.623207 0.814209 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 473
Initial state: 0 0.699118 0.815845 0.697371 0.0872653 0.602436 0.87264 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 665008 episodes
GETTING ACTION FROM:
action 2, numVisits=664807, meanQ=5.016638, numObservations: 3
action 1, numVisits=194, meanQ=4.489635, numObservations: 3
action 3, numVisits=3, meanQ=-1.670000, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 2 0.699118 0.815845 0.697371 0.0872653 0.602436 0.87264 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 474
Initial state: 0 0.769716 0.144729 0.580958 0.87056 0.611471 0.88424 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662218 episodes
GETTING ACTION FROM:
action 3, numVisits=662171, meanQ=5.020831, numObservations: 4
action 0, numVisits=37, meanQ=3.782574, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 2, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 3
Next state: 1 0.769716 0.144729 0.580958 0.87056 0.611471 0.88424 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 475
Initial state: 0 0.522281 0.811962 0.519628 0.849441 0.916935 0.783745 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663223 episodes
GETTING ACTION FROM:
action 2, numVisits=663214, meanQ=4.985589, numObservations: 4
action 3, numVisits=4, meanQ=0.997500, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.522281 0.811962 0.519628 0.849441 0.916935 0.783745 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 476
Initial state: 0 0.673746 0.842303 0.512873 0.820935 0.871638 0.225176 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657024 episodes
GETTING ACTION FROM:
action 2, numVisits=656994, meanQ=5.194423, numObservations: 5
action 1, numVisits=25, meanQ=3.712000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.673746 0.842303 0.512873 0.820935 0.871638 0.225176 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=91784, meanQ=8.402690, numObservations: 5
action 1, numVisits=11, meanQ=6.090000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 842264 episodes
GETTING ACTION FROM:
action 3, numVisits=933805, meanQ=6.466735, numObservations: 5
action 1, numVisits=254, meanQ=5.966576, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 2 0.673746 0.842303 0.512873 0.820935 0.871638 0.225176 w: 1
Observation: 4 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 477
Initial state: 0 0.866037 0.914248 0.679591 0.887276 0.601116 0.869446 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666207 episodes
GETTING ACTION FROM:
action 2, numVisits=666126, meanQ=5.020528, numObservations: 4
action 0, numVisits=70, meanQ=4.121710, numObservations: 1
action 1, numVisits=4, meanQ=0.997500, numObservations: 2
action 3, numVisits=5, meanQ=0.196000, numObservations: 4
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.866037 0.914248 0.679591 0.887276 0.601116 0.869446 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 478
Initial state: 0 0.549235 0.880508 0.474246 0.712109 0.588863 0.8906 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655551 episodes
GETTING ACTION FROM:
action 3, numVisits=655545, meanQ=5.040845, numObservations: 5
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.549235 0.880508 0.474246 0.712109 0.588863 0.8906 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 479
Initial state: 0 0.544918 0.010106 0.544785 0.866414 0.548931 0.896915 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 671773 episodes
GETTING ACTION FROM:
action 3, numVisits=670071, meanQ=5.037651, numObservations: 3
action 2, numVisits=1622, meanQ=4.824996, numObservations: 3
action 0, numVisits=77, meanQ=4.196296, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.544918 0.010106 0.544785 0.866414 0.548931 0.896915 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 480
Initial state: 0 0.68668 0.851564 0.592414 0.834028 0.1393 0.771149 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662066 episodes
GETTING ACTION FROM:
action 1, numVisits=655923, meanQ=4.994840, numObservations: 4
action -1, numVisits=6139, meanQ=2.853859, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.68668 0.851564 0.592414 0.834028 0.1393 0.771149 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 481
Initial state: 0 0.522915 0.860652 0.0181969 0.99981 0.501299 0.891002 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670990 episodes
GETTING ACTION FROM:
action 2, numVisits=670493, meanQ=4.967497, numObservations: 3
action 3, numVisits=484, meanQ=4.617380, numObservations: 4
action 1, numVisits=9, meanQ=1.886667, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action: 2
Next state: 0 0.522915 0.860652 0.0181969 0.99981 0.501299 0.891002 w: 1
Observation: 6 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=49612, meanQ=4.765773, numObservations: 4
action 2, numVisits=32, meanQ=3.436878, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 848677 episodes
GETTING ACTION FROM:
action 3, numVisits=898289, meanQ=5.722036, numObservations: 4
action 2, numVisits=32, meanQ=3.436878, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.522915 0.860652 0.0181969 0.99981 0.501299 0.891002 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 482
Initial state: 0 0.522355 0.860251 0.416699 0.365394 0.699452 0.833087 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666450 episodes
GETTING ACTION FROM:
action 1, numVisits=666357, meanQ=5.016046, numObservations: 4
action 0, numVisits=40, meanQ=3.822712, numObservations: 1
action -1, numVisits=25, meanQ=3.481467, numObservations: 1
action 2, numVisits=21, meanQ=2.990014, numObservations: 4
action 3, numVisits=7, meanQ=2.155714, numObservations: 2
action: 1
Next state: 1 0.522355 0.860251 0.416699 0.365394 0.699452 0.833087 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 483
Initial state: 0 0.603732 0.846108 0.149239 0.293121 0.592824 0.879786 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 661271 episodes
GETTING ACTION FROM:
action 2, numVisits=661179, meanQ=4.956728, numObservations: 5
action -1, numVisits=46, meanQ=3.857235, numObservations: 1
action 0, numVisits=21, meanQ=3.258172, numObservations: 1
action 3, numVisits=19, meanQ=2.674211, numObservations: 4
action 1, numVisits=6, meanQ=0.331667, numObservations: 3
action: 2
Next state: 0 0.603732 0.846108 0.149239 0.293121 0.592824 0.879786 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=78130, meanQ=8.404203, numObservations: 3
action 1, numVisits=14865, meanQ=8.362735, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 865906 episodes
GETTING ACTION FROM:
action 3, numVisits=849374, meanQ=6.222877, numObservations: 3
action 1, numVisits=109525, meanQ=6.208324, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.603732 0.846108 0.149239 0.293121 0.592824 0.879786 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 484
Initial state: 0 0.46245 0.0404903 0.643532 0.880755 0.532678 0.885208 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 657583 episodes
GETTING ACTION FROM:
action 1, numVisits=646564, meanQ=5.115887, numObservations: 4
action -1, numVisits=8951, meanQ=3.027093, numObservations: 1
action 0, numVisits=2036, meanQ=2.956377, numObservations: 1
action 3, numVisits=16, meanQ=1.500013, numObservations: 4
action 2, numVisits=16, meanQ=1.137506, numObservations: 3
action: 1
Next state: 0 0.46245 0.0404903 0.643532 0.880755 0.532678 0.885208 w: 1
Observation: 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=37567, meanQ=7.947276, numObservations: 3
action 2, numVisits=2, meanQ=2.995000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 861242 episodes
GETTING ACTION FROM:
action 3, numVisits=898801, meanQ=6.202087, numObservations: 3
action 2, numVisits=8, meanQ=2.498750, numObservations: 3
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.46245 0.0404903 0.643532 0.880755 0.532678 0.885208 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 485
Initial state: 0 0.674741 0.811354 0.167334 0.420814 0.599669 0.891013 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 655044 episodes
GETTING ACTION FROM:
action 2, numVisits=647515, meanQ=5.165977, numObservations: 5
action -1, numVisits=7511, meanQ=2.895935, numObservations: 1
action 1, numVisits=15, meanQ=1.264667, numObservations: 3
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.674741 0.811354 0.167334 0.420814 0.599669 0.891013 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=54607, meanQ=8.534893, numObservations: 3
action 3, numVisits=19801, meanQ=8.515523, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 845908 episodes
GETTING ACTION FROM:
action 1, numVisits=512353, meanQ=6.127606, numObservations: 5
action 3, numVisits=407961, meanQ=6.126416, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.674741 0.811354 0.167334 0.420814 0.599669 0.891013 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 4.91
Run # 486
Initial state: 0 0.118609 0.198703 0.500381 0.873387 0.600521 0.851317 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659008 episodes
GETTING ACTION FROM:
action 3, numVisits=658932, meanQ=4.998342, numObservations: 4
action 0, numVisits=69, meanQ=4.122831, numObservations: 1
action 2, numVisits=4, meanQ=0.997500, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action -1, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 3
Next state: 1 0.118609 0.198703 0.500381 0.873387 0.600521 0.851317 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 487
Initial state: 0 0.399412 0.430949 0.610143 0.864742 0.510017 0.819763 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 459346 episodes
GETTING ACTION FROM:
action -1, numVisits=459338, meanQ=3.106514, numObservations: 1
action 3, numVisits=4, meanQ=-0.504975, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: -1
Next state: 0 0.399412 0.430949 0.610143 0.864742 0.510017 0.819763 w: 1
Observation: 0 0.483848 0 0.709726 0 0.447024 0 
Immediate reward: -2
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 2, numVisits=459330, meanQ=5.155371, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
Sampled 749000 episodes
GETTING ACTION FROM:
action 2, numVisits=1208330, meanQ=5.301962, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 0 0.399412 0.430949 0.610143 0.864742 0.510017 0.819763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=80762, meanQ=7.501413, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 804415 episodes
GETTING ACTION FROM:
action 2, numVisits=885175, meanQ=5.590850, numObservations: 4
action 1, numVisits=2, meanQ=-1.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.399412 0.430949 0.610143 0.864742 0.510017 0.819763 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 1, numVisits=24157, meanQ=6.412275, numObservations: 4
action 3, numVisits=9, meanQ=3.221111, numObservations: 3
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
Sampled 871104 episodes
GETTING ACTION FROM:
action 1, numVisits=895259, meanQ=6.065970, numObservations: 4
action 3, numVisits=9, meanQ=3.221111, numObservations: 3
action 2, numVisits=5, meanQ=1.396020, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 1
Next state: 0 0.399412 0.430949 0.610143 0.864742 0.510017 0.819763 w: 1
Observation: 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 4
Improving policy...
PLANNING FROM:
action 2, numVisits=2234, meanQ=8.530256, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 877089 episodes
GETTING ACTION FROM:
action 2, numVisits=879321, meanQ=6.071265, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 1
action 0, numVisits=2, meanQ=-1.505000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.399412 0.430949 0.610143 0.864742 0.510017 0.819763 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -5.11623
Run # 488
Initial state: 0 0.96854 0.715525 0.501669 0.86492 0.647292 0.846951 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 659153 episodes
GETTING ACTION FROM:
action 2, numVisits=659116, meanQ=4.955058, numObservations: 5
action 0, numVisits=21, meanQ=3.271674, numObservations: 1
action 1, numVisits=12, meanQ=1.998333, numObservations: 3
action 3, numVisits=2, meanQ=-1.000000, numObservations: 1
action -1, numVisits=2, meanQ=-2.994950, numObservations: 1
action: 2
Next state: 1 0.96854 0.715525 0.501669 0.86492 0.647292 0.846951 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 489
Initial state: 0 0.683635 0.835209 0.503655 0.0217957 0.56997 0.836944 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 673694 episodes
GETTING ACTION FROM:
action 2, numVisits=673554, meanQ=5.060587, numObservations: 4
action -1, numVisits=136, meanQ=4.428568, numObservations: 1
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 2 0.683635 0.835209 0.503655 0.0217957 0.56997 0.836944 w: 1
Observation: 2 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 490
Initial state: 0 0.663434 0.827 0.891334 0.0834298 0.6437 0.88736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 664294 episodes
GETTING ACTION FROM:
action 3, numVisits=664230, meanQ=5.025673, numObservations: 4
action 0, numVisits=36, meanQ=3.805244, numObservations: 1
action -1, numVisits=21, meanQ=3.324927, numObservations: 1
action 1, numVisits=6, meanQ=1.001683, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.663434 0.827 0.891334 0.0834298 0.6437 0.88736 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 491
Initial state: 0 0.741755 0.449184 0.625276 0.87281 0.68704 0.858706 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 668763 episodes
GETTING ACTION FROM:
action 2, numVisits=668736, meanQ=5.049040, numObservations: 4
action -1, numVisits=12, meanQ=2.877812, numObservations: 1
action 3, numVisits=8, meanQ=1.747513, numObservations: 4
action 1, numVisits=5, meanQ=-0.622000, numObservations: 2
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.741755 0.449184 0.625276 0.87281 0.68704 0.858706 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 492
Initial state: 0 0.582734 0.893154 0.162446 0.0401393 0.609032 0.830541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 637554 episodes
GETTING ACTION FROM:
action 1, numVisits=637546, meanQ=4.776121, numObservations: 5
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.582734 0.893154 0.162446 0.0401393 0.609032 0.830541 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 493
Initial state: 0 0.687441 0.838151 0.817739 0.978251 0.668672 0.865132 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 663892 episodes
GETTING ACTION FROM:
action 2, numVisits=663732, meanQ=5.013728, numObservations: 4
action 0, numVisits=146, meanQ=4.415605, numObservations: 1
action 3, numVisits=11, meanQ=1.000918, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.687441 0.838151 0.817739 0.978251 0.668672 0.865132 w: 1
Observation: 9 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 494
Initial state: 0 0.850692 0.798037 0.611669 0.846881 0.616905 0.818195 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 670133 episodes
GETTING ACTION FROM:
action 2, numVisits=670027, meanQ=4.997568, numObservations: 3
action 3, numVisits=101, meanQ=4.171985, numObservations: 4
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 2
Next state: 1 0.850692 0.798037 0.611669 0.846881 0.616905 0.818195 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 495
Initial state: 0 0.513098 0.811767 0.503127 0.803514 0.37333 0.995844 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 672174 episodes
GETTING ACTION FROM:
action 1, numVisits=672103, meanQ=4.982615, numObservations: 3
action -1, numVisits=26, meanQ=3.519404, numObservations: 1
action 3, numVisits=42, meanQ=3.413102, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 0, numVisits=2, meanQ=-6.950000, numObservations: 1
action: 1
Next state: 1 0.513098 0.811767 0.503127 0.803514 0.37333 0.995844 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 496
Initial state: 0 0.670599 0.852679 0.239003 0.275767 0.525714 0.894315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662593 episodes
GETTING ACTION FROM:
action 3, numVisits=662509, meanQ=5.155400, numObservations: 4
action -1, numVisits=50, meanQ=4.121094, numObservations: 1
action 0, numVisits=32, meanQ=3.843580, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.670599 0.852679 0.239003 0.275767 0.525714 0.894315 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 497
Initial state: 0 0.584964 0.893535 0.491538 0.464999 0.549253 0.807639 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 660674 episodes
GETTING ACTION FROM:
action 3, numVisits=660612, meanQ=4.924102, numObservations: 4
action 1, numVisits=57, meanQ=3.868951, numObservations: 3
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 3
Next state: 1 0.584964 0.893535 0.491538 0.464999 0.549253 0.807639 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 498
Initial state: 0 0.577562 0.847449 0.502146 0.810516 0.199719 0.45871 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 667444 episodes
GETTING ACTION FROM:
action 1, numVisits=655966, meanQ=5.021465, numObservations: 3
action -1, numVisits=11472, meanQ=3.047867, numObservations: 1
action 3, numVisits=3, meanQ=-1.670000, numObservations: 2
action 0, numVisits=2, meanQ=-2.004950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.577562 0.847449 0.502146 0.810516 0.199719 0.45871 w: 1
Observation: 7 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 499
Initial state: 0 0.613542 0.883194 0.567741 0.884808 0.40881 0.731039 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 666632 episodes
GETTING ACTION FROM:
action 2, numVisits=666485, meanQ=5.011951, numObservations: 4
action 0, numVisits=143, meanQ=2.180424, numObservations: 1
action -1, numVisits=2, meanQ=-2.004950, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 2
Next state: 1 0.613542 0.883194 0.567741 0.884808 0.40881 0.731039 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
Run # 500
Initial state: 0 0.0463402 0.00241273 0.652279 0.850506 0.502606 0.845802 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 662200 episodes
GETTING ACTION FROM:
action 3, numVisits=662170, meanQ=5.013968, numObservations: 4
action -1, numVisits=22, meanQ=3.383482, numObservations: 1
action 1, numVisits=5, meanQ=0.196000, numObservations: 2
action 0, numVisits=2, meanQ=-2.994950, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.0463402 0.00241273 0.652279 0.850506 0.502606 0.845802 w: 1
Observation: 5 0 0 0 0 0 0 
Immediate reward: 9
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 9
