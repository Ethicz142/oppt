Run # 1
Initial state: 0 0.0215801 0.722175 0.348908 0.290206 0.386392 0.803266 0.979457 0.0632133 0.563091 0.348204 0.653303 0.41947 0.0488243 0.246502 0.0741336 0.137376 0.899042 0.744148 0.849943 0.176053 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48995 episodes
GETTING ACTION FROM:
action 6, numVisits=48953, meanQ=11.511690, numObservations: 9
action 5, numVisits=9, meanQ=9.167778, numObservations: 5
action 9, numVisits=6, meanQ=7.831667, numObservations: 5
action 4, numVisits=7, meanQ=6.282857, numObservations: 4
action 2, numVisits=5, meanQ=6.008040, numObservations: 3
action 8, numVisits=5, meanQ=5.998000, numObservations: 3
action 10, numVisits=3, meanQ=5.663333, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 6
Next state: 1 0.0215801 0.722175 0.348908 0.290206 0.386392 0.803266 0.979457 0.0632133 0.563091 0.348204 0.653303 0.41947 0.0488243 0.246502 0.0741336 0.137376 0.899042 0.744148 0.849943 0.176053 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 2
Initial state: 0 0.657526 0.855063 0.729229 0.313313 0.892608 0.20999 0.296957 0.930989 0.277632 0.307757 0.591791 0.420856 0.800695 0.382306 0.641583 0.955321 0.460146 0.149812 0.558594 0.331281 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49194 episodes
GETTING ACTION FROM:
action 6, numVisits=49170, meanQ=11.380405, numObservations: 9
action 3, numVisits=12, meanQ=9.375008, numObservations: 6
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.657526 0.855063 0.729229 0.313313 0.892608 0.20999 0.296957 0.930989 0.277632 0.307757 0.591791 0.420856 0.800695 0.382306 0.641583 0.955321 0.460146 0.149812 0.558594 0.331281 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.0679582 0.308308 0.579155 0.368241 0.33026 0.609902 0.767667 0.0835451 0.395779 0.12171 0.535984 0.850175 0.83051 0.204046 0.914887 0.998389 0.628869 0.0639554 0.717571 0.678541 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48223 episodes
GETTING ACTION FROM:
action 1, numVisits=46322, meanQ=11.255321, numObservations: 9
action 5, numVisits=1871, meanQ=10.735450, numObservations: 9
action 10, numVisits=8, meanQ=8.373750, numObservations: 4
action 6, numVisits=8, meanQ=7.375000, numObservations: 6
action 8, numVisits=7, meanQ=7.282857, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.0679582 0.308308 0.579155 0.368241 0.33026 0.609902 0.767667 0.0835451 0.395779 0.12171 0.535984 0.850175 0.83051 0.204046 0.914887 0.998389 0.628869 0.0639554 0.717571 0.678541 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=1740, meanQ=12.948249, numObservations: 9
action 1, numVisits=4, meanQ=3.742500, numObservations: 3
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10497 episodes
GETTING ACTION FROM:
action 6, numVisits=12223, meanQ=11.059819, numObservations: 9
action 1, numVisits=4, meanQ=3.742500, numObservations: 3
action 8, numVisits=4, meanQ=-0.533535, numObservations: 4
action 0, numVisits=9, meanQ=-1.120000, numObservations: 9
action -1, numVisits=6, meanQ=-1.505000, numObservations: 6
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.0679582 0.308308 0.579155 0.368241 0.33026 0.609902 0.767667 0.0835451 0.395779 0.12171 0.535984 0.850175 0.83051 0.204046 0.914887 0.998389 0.628869 0.0639554 0.717571 0.678541 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 4
Initial state: 0 0.594698 0.388717 0.0984022 0.0908633 0.942874 0.887334 0.959969 0.556787 0.42827 0.339793 0.180616 0.985094 0.314137 0.222973 0.417351 0.785758 0.744217 0.503399 0.73772 0.921458 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47176 episodes
GETTING ACTION FROM:
action 7, numVisits=33972, meanQ=11.442618, numObservations: 9
action 2, numVisits=13064, meanQ=11.425336, numObservations: 9
action 10, numVisits=125, meanQ=10.815938, numObservations: 9
action 6, numVisits=3, meanQ=5.663333, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 9, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 0 0.594698 0.388717 0.0984022 0.0908633 0.942874 0.887334 0.959969 0.556787 0.42827 0.339793 0.180616 0.985094 0.314137 0.222973 0.417351 0.785758 0.744217 0.503399 0.73772 0.921458 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=347, meanQ=13.203514, numObservations: 9
action 8, numVisits=19, meanQ=11.159489, numObservations: 7
action 5, numVisits=5, meanQ=7.000020, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 38216 episodes
GETTING ACTION FROM:
action 4, numVisits=3093, meanQ=8.165623, numObservations: 9
action 8, numVisits=35369, meanQ=8.013785, numObservations: 9
action 10, numVisits=99, meanQ=6.679411, numObservations: 9
action 5, numVisits=10, meanQ=5.000010, numObservations: 7
action 6, numVisits=6, meanQ=2.263300, numObservations: 5
action 9, numVisits=4, meanQ=0.012027, numObservations: 3
action 0, numVisits=5, meanQ=-1.604000, numObservations: 5
action -1, numVisits=5, meanQ=-1.802000, numObservations: 5
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=2, meanQ=-6.444044, numObservations: 2
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.594698 0.388717 0.0984022 0.0908633 0.942874 0.887334 0.959969 0.556787 0.42827 0.339793 0.180616 0.985094 0.314137 0.222973 0.417351 0.785758 0.744217 0.503399 0.73772 0.921458 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 5
Initial state: 0 0.23715 0.874335 0.378758 0.326156 0.546351 0.375015 0.472338 0.963984 0.0648558 0.420867 0.37068 0.809074 0.121996 0.439544 0.790558 0.0298187 0.837509 0.987635 0.0853767 0.681617 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49666 episodes
GETTING ACTION FROM:
action 9, numVisits=49646, meanQ=11.292562, numObservations: 9
action 1, numVisits=9, meanQ=7.972233, numObservations: 6
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.23715 0.874335 0.378758 0.326156 0.546351 0.375015 0.472338 0.963984 0.0648558 0.420867 0.37068 0.809074 0.121996 0.439544 0.790558 0.0298187 0.837509 0.987635 0.0853767 0.681617 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.789627 0.983156 0.959086 0.0131637 0.137017 0.383064 0.972492 0.936589 0.16945 0.553305 0.213776 0.582848 0.293911 0.172909 0.281859 0.921249 0.0546085 0.0134598 0.586554 0.340063 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45993 episodes
GETTING ACTION FROM:
action 8, numVisits=45961, meanQ=11.369244, numObservations: 9
action 6, numVisits=20, meanQ=5.654505, numObservations: 7
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 0 0.789627 0.983156 0.959086 0.0131637 0.137017 0.383064 0.972492 0.936589 0.16945 0.553305 0.213776 0.582848 0.293911 0.172909 0.281859 0.921249 0.0546085 0.0134598 0.586554 0.340063 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=7820, meanQ=11.539712, numObservations: 9
action 5, numVisits=5, meanQ=7.000020, numObservations: 3
action 6, numVisits=2, meanQ=6.500000, numObservations: 2
action 1, numVisits=7, meanQ=6.282857, numObservations: 5
action 3, numVisits=5, meanQ=6.196000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 12669 episodes
GETTING ACTION FROM:
action 5, numVisits=12576, meanQ=16.000986, numObservations: 9
action 10, numVisits=7820, meanQ=11.539712, numObservations: 9
action 1, numVisits=7, meanQ=6.282857, numObservations: 5
action 3, numVisits=5, meanQ=6.196000, numObservations: 3
action 6, numVisits=94, meanQ=1.940160, numObservations: 9
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.789627 0.983156 0.959086 0.0131637 0.137017 0.383064 0.972492 0.936589 0.16945 0.553305 0.213776 0.582848 0.293911 0.172909 0.281859 0.921249 0.0546085 0.0134598 0.586554 0.340063 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 7
Initial state: 0 0.725811 0.273793 0.755028 0.375732 0.00990809 0.894167 0.377346 0.109769 0.179712 0.770972 0.560605 0.664292 0.145981 0.841482 0.968269 0.229569 0.368675 0.46101 0.570343 0.315681 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49272 episodes
GETTING ACTION FROM:
action 9, numVisits=49243, meanQ=11.278911, numObservations: 9
action 2, numVisits=15, meanQ=9.334673, numObservations: 6
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.725811 0.273793 0.755028 0.375732 0.00990809 0.894167 0.377346 0.109769 0.179712 0.770972 0.560605 0.664292 0.145981 0.841482 0.968269 0.229569 0.368675 0.46101 0.570343 0.315681 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 6, numVisits=8465, meanQ=11.471198, numObservations: 9
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action 5, numVisits=3, meanQ=5.993333, numObservations: 3
action 7, numVisits=3, meanQ=5.993333, numObservations: 3
action 2, numVisits=7, meanQ=5.141429, numObservations: 4
action 8, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11151 episodes
GETTING ACTION FROM:
action 4, numVisits=10690, meanQ=14.673009, numObservations: 9
action 6, numVisits=8691, meanQ=11.536848, numObservations: 9
action 7, numVisits=239, meanQ=10.342001, numObservations: 9
action 2, numVisits=7, meanQ=5.141429, numObservations: 4
action 8, numVisits=3, meanQ=3.330000, numObservations: 2
action 5, numVisits=4, meanQ=1.745000, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.725811 0.273793 0.755028 0.375732 0.00990809 0.894167 0.377346 0.109769 0.179712 0.770972 0.560605 0.664292 0.145981 0.841482 0.968269 0.229569 0.368675 0.46101 0.570343 0.315681 w: 1
Observation: 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 1, numVisits=668, meanQ=11.727568, numObservations: 9
action 7, numVisits=8, meanQ=6.710393, numObservations: 6
action 8, numVisits=4, meanQ=6.500000, numObservations: 4
action 10, numVisits=5, meanQ=3.245430, numObservations: 3
action 6, numVisits=5, meanQ=2.588243, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-9.906304, numObservations: 1
action 2, numVisits=1, meanQ=-10.194031, numObservations: 1
action 4, numVisits=1, meanQ=-10.204168, numObservations: 1
action 3, numVisits=1, meanQ=-10.215477, numObservations: 1
action 9, numVisits=1, meanQ=-1036.230990, numObservations: 1
Sampled 7380 episodes
GETTING ACTION FROM:
action 1, numVisits=8048, meanQ=13.526790, numObservations: 9
action 7, numVisits=8, meanQ=6.710393, numObservations: 6
action 8, numVisits=4, meanQ=6.500000, numObservations: 4
action 10, numVisits=5, meanQ=3.245430, numObservations: 3
action 6, numVisits=5, meanQ=2.588243, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 5, numVisits=1, meanQ=-9.906304, numObservations: 1
action 2, numVisits=1, meanQ=-10.194031, numObservations: 1
action 4, numVisits=1, meanQ=-10.204168, numObservations: 1
action 3, numVisits=1, meanQ=-10.215477, numObservations: 1
action 9, numVisits=1, meanQ=-1036.230990, numObservations: 1
action: 1
Next state: 2 0.725811 0.273793 0.755028 0.375732 0.00990809 0.894167 0.377346 0.109769 0.179712 0.770972 0.560605 0.664292 0.145981 0.841482 0.968269 0.229569 0.368675 0.46101 0.570343 0.315681 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 8
Initial state: 0 0.901725 0.514182 0.886809 0.121042 0.817288 0.420745 0.606072 0.238812 0.909544 0.808375 0.840307 0.494556 0.222901 0.440037 0.433139 0.284763 0.953339 0.225464 0.592534 0.305128 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45372 episodes
GETTING ACTION FROM:
action 2, numVisits=45327, meanQ=11.409223, numObservations: 9
action 4, numVisits=17, meanQ=7.273553, numObservations: 6
action 8, numVisits=15, meanQ=6.920020, numObservations: 5
action 6, numVisits=3, meanQ=3.330000, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.901725 0.514182 0.886809 0.121042 0.817288 0.420745 0.606072 0.238812 0.909544 0.808375 0.840307 0.494556 0.222901 0.440037 0.433139 0.284763 0.953339 0.225464 0.592534 0.305128 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 9
Initial state: 0 0.0551659 0.081922 0.775953 0.222345 0.517691 0.282067 0.613507 0.383713 0.964523 0.454626 0.854871 0.650878 0.0921383 0.980571 0.738457 0.800993 0.688527 0.348661 0.812978 0.975326 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48572 episodes
GETTING ACTION FROM:
action 4, numVisits=48549, meanQ=11.434096, numObservations: 9
action 2, numVisits=9, meanQ=7.004467, numObservations: 6
action 8, numVisits=4, meanQ=6.500000, numObservations: 3
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.0551659 0.081922 0.775953 0.222345 0.517691 0.282067 0.613507 0.383713 0.964523 0.454626 0.854871 0.650878 0.0921383 0.980571 0.738457 0.800993 0.688527 0.348661 0.812978 0.975326 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 10
Initial state: 0 0.259384 0.0858105 0.395912 0.449358 0.431368 0.498345 0.406066 0.975594 0.777983 0.830251 0.758215 0.803684 0.202343 0.1644 0.626597 0.340755 0.823615 0.810458 0.298384 0.744265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48575 episodes
GETTING ACTION FROM:
action 10, numVisits=48540, meanQ=11.358591, numObservations: 9
action 1, numVisits=6, meanQ=7.666667, numObservations: 5
action 4, numVisits=9, meanQ=7.415556, numObservations: 7
action 5, numVisits=8, meanQ=7.375000, numObservations: 5
action 9, numVisits=3, meanQ=5.663333, numObservations: 3
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 1 0.259384 0.0858105 0.395912 0.449358 0.431368 0.498345 0.406066 0.975594 0.777983 0.830251 0.758215 0.803684 0.202343 0.1644 0.626597 0.340755 0.823615 0.810458 0.298384 0.744265 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 11
Initial state: 0 0.411117 0.438126 0.834521 0.552985 0.980611 0.658094 0.167715 0.546508 0.370125 0.137636 0.595554 0.335676 0.513402 0.576122 0.906301 0.897962 0.362881 0.847072 0.821447 0.474939 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48598 episodes
GETTING ACTION FROM:
action 4, numVisits=48579, meanQ=11.126765, numObservations: 9
action 2, numVisits=7, meanQ=4.444286, numObservations: 3
action 1, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.411117 0.438126 0.834521 0.552985 0.980611 0.658094 0.167715 0.546508 0.370125 0.137636 0.595554 0.335676 0.513402 0.576122 0.906301 0.897962 0.362881 0.847072 0.821447 0.474939 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=8075, meanQ=11.102592, numObservations: 9
action 2, numVisits=32, meanQ=9.524694, numObservations: 9
action 7, numVisits=18, meanQ=8.942783, numObservations: 8
action 10, numVisits=6, meanQ=8.501683, numObservations: 4
action 8, numVisits=9, meanQ=8.106667, numObservations: 7
action 3, numVisits=6, meanQ=7.831667, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11005 episodes
GETTING ACTION FROM:
action 2, numVisits=11001, meanQ=12.611989, numObservations: 9
action 1, numVisits=8075, meanQ=11.102592, numObservations: 9
action 7, numVisits=20, meanQ=8.899510, numObservations: 8
action 8, numVisits=10, meanQ=5.807000, numObservations: 7
action 3, numVisits=7, meanQ=5.422434, numObservations: 5
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action -1, numVisits=3, meanQ=-1.670000, numObservations: 3
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=34, meanQ=-18.647691, numObservations: 8
action: 2
Next state: 1 0.411117 0.438126 0.834521 0.552985 0.980611 0.658094 0.167715 0.546508 0.370125 0.137636 0.595554 0.335676 0.513402 0.576122 0.906301 0.897962 0.362881 0.847072 0.821447 0.474939 w: 1
Observation: 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 12
Initial state: 0 0.614911 0.491647 0.635345 0.925191 0.523333 0.148234 0.725678 0.954309 0.124352 0.288564 0.617916 0.301869 0.57687 0.524208 0.648152 0.426143 0.55326 0.045198 0.377462 0.893735 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 44818 episodes
GETTING ACTION FROM:
action 3, numVisits=44784, meanQ=11.430261, numObservations: 9
action 1, numVisits=16, meanQ=7.812500, numObservations: 7
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=6, meanQ=6.500000, numObservations: 5
action 8, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 2 0.614911 0.491647 0.635345 0.925191 0.523333 0.148234 0.725678 0.954309 0.124352 0.288564 0.617916 0.301869 0.57687 0.524208 0.648152 0.426143 0.55326 0.045198 0.377462 0.893735 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 13
Initial state: 0 0.932049 0.383014 0.539735 0.340306 0.405225 0.550715 0.81753 0.444516 0.215555 0.675172 0.594443 0.865416 0.751988 0.359368 0.343609 0.46531 0.439789 0.0676466 0.252108 0.581352 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48346 episodes
GETTING ACTION FROM:
action 9, numVisits=48318, meanQ=11.309233, numObservations: 9
action 6, numVisits=10, meanQ=8.103020, numObservations: 4
action 10, numVisits=5, meanQ=7.398000, numObservations: 5
action 1, numVisits=5, meanQ=6.196000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.932049 0.383014 0.539735 0.340306 0.405225 0.550715 0.81753 0.444516 0.215555 0.675172 0.594443 0.865416 0.751988 0.359368 0.343609 0.46531 0.439789 0.0676466 0.252108 0.581352 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=4982, meanQ=12.015096, numObservations: 9
action 8, numVisits=23, meanQ=9.826965, numObservations: 6
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=3, meanQ=2.033333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 8800 episodes
GETTING ACTION FROM:
action 1, numVisits=13766, meanQ=11.498526, numObservations: 9
action 8, numVisits=31, meanQ=8.065168, numObservations: 8
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 10, numVisits=3, meanQ=2.033333, numObservations: 2
action 3, numVisits=3, meanQ=0.666667, numObservations: 2
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 1
Next state: 1 0.932049 0.383014 0.539735 0.340306 0.405225 0.550715 0.81753 0.444516 0.215555 0.675172 0.594443 0.865416 0.751988 0.359368 0.343609 0.46531 0.439789 0.0676466 0.252108 0.581352 w: 1
Observation: 0 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 14
Initial state: 0 0.916834 0.531281 0.684111 0.0903171 0.380458 0.199888 0.624666 0.379548 0.530717 0.97419 0.164111 0.717712 0.357108 0.412048 0.399298 0.638315 0.341966 0.868461 0.572818 0.145303 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48841 episodes
GETTING ACTION FROM:
action 10, numVisits=26360, meanQ=11.469212, numObservations: 9
action 3, numVisits=17645, meanQ=11.430042, numObservations: 9
action 6, numVisits=4813, meanQ=11.384038, numObservations: 9
action 1, numVisits=8, meanQ=9.000013, numObservations: 4
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=3, meanQ=5.663333, numObservations: 3
action 8, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 2 0.916834 0.531281 0.684111 0.0903171 0.380458 0.199888 0.624666 0.379548 0.530717 0.97419 0.164111 0.717712 0.357108 0.412048 0.399298 0.638315 0.341966 0.868461 0.572818 0.145303 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 15
Initial state: 0 0.592537 0.354474 0.372078 0.898604 0.846573 0.450696 0.68558 0.57733 0.320919 0.389998 0.116485 0.280214 0.616691 0.081438 0.140573 0.0718081 0.940156 0.547047 0.366157 0.950517 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48432 episodes
GETTING ACTION FROM:
action 4, numVisits=48410, meanQ=11.492881, numObservations: 9
action 2, numVisits=5, meanQ=5.998000, numObservations: 4
action 9, numVisits=8, meanQ=4.625013, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.592537 0.354474 0.372078 0.898604 0.846573 0.450696 0.68558 0.57733 0.320919 0.389998 0.116485 0.280214 0.616691 0.081438 0.140573 0.0718081 0.940156 0.547047 0.366157 0.950517 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.823321 0.568305 0.0774191 0.968431 0.4994 0.84947 0.230215 0.997077 0.441619 0.865747 0.124581 0.663645 0.553552 0.000657267 0.64183 0.901706 0.564571 0.385121 0.981834 0.626683 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47248 episodes
GETTING ACTION FROM:
action 6, numVisits=47229, meanQ=11.321748, numObservations: 9
action 7, numVisits=5, meanQ=6.604020, numObservations: 4
action 5, numVisits=5, meanQ=4.400000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 0 0.823321 0.568305 0.0774191 0.968431 0.4994 0.84947 0.230215 0.997077 0.441619 0.865747 0.124581 0.663645 0.553552 0.000657267 0.64183 0.901706 0.564571 0.385121 0.981834 0.626683 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=8097, meanQ=11.908429, numObservations: 9
action 2, numVisits=6, meanQ=7.831667, numObservations: 5
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=5, meanQ=4.598000, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 10303 episodes
GETTING ACTION FROM:
action 3, numVisits=18371, meanQ=12.552559, numObservations: 9
action 4, numVisits=5, meanQ=4.598000, numObservations: 5
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 8, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=30, meanQ=-23.709496, numObservations: 7
action: 3
Next state: 1 0.823321 0.568305 0.0774191 0.968431 0.4994 0.84947 0.230215 0.997077 0.441619 0.865747 0.124581 0.663645 0.553552 0.000657267 0.64183 0.901706 0.564571 0.385121 0.981834 0.626683 w: 1
Observation: 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 17
Initial state: 0 0.625095 0.349572 0.929653 0.450505 0.725193 0.551256 0.811811 0.74774 0.485818 0.445774 0.749704 0.847364 0.602451 0.0392263 0.839308 0.985035 0.0739458 0.0188331 0.233811 0.573833 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45762 episodes
GETTING ACTION FROM:
action 7, numVisits=45737, meanQ=11.265592, numObservations: 9
action 3, numVisits=9, meanQ=7.445567, numObservations: 6
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action 6, numVisits=3, meanQ=3.330000, numObservations: 3
action 10, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 0 0.625095 0.349572 0.929653 0.450505 0.725193 0.551256 0.811811 0.74774 0.485818 0.445774 0.749704 0.847364 0.602451 0.0392263 0.839308 0.985035 0.0739458 0.0188331 0.233811 0.573833 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 10, numVisits=618, meanQ=11.777002, numObservations: 9
action 8, numVisits=38, meanQ=8.184474, numObservations: 9
action 3, numVisits=4, meanQ=6.500000, numObservations: 2
action 9, numVisits=3, meanQ=4.670033, numObservations: 2
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action 6, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 19859 episodes
GETTING ACTION FROM:
action 10, numVisits=20433, meanQ=9.378734, numObservations: 9
action 8, numVisits=38, meanQ=8.184474, numObservations: 9
action 6, numVisits=15, meanQ=7.182975, numObservations: 5
action 3, numVisits=16, meanQ=6.511040, numObservations: 6
action 9, numVisits=14, meanQ=4.857864, numObservations: 6
action 4, numVisits=4, meanQ=-0.252500, numObservations: 2
action -1, numVisits=5, meanQ=-1.604000, numObservations: 5
action 0, numVisits=5, meanQ=-1.802000, numObservations: 5
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 0 0.625095 0.349572 0.929653 0.450505 0.725193 0.551256 0.811811 0.74774 0.485818 0.445774 0.749704 0.847364 0.602451 0.0392263 0.839308 0.985035 0.0739458 0.0188331 0.233811 0.573833 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 8, numVisits=1397, meanQ=12.393034, numObservations: 9
action 6, numVisits=12, meanQ=4.249167, numObservations: 7
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 16355 episodes
GETTING ACTION FROM:
action 8, numVisits=17750, meanQ=11.050177, numObservations: 9
action 6, numVisits=12, meanQ=4.249167, numObservations: 7
action 0, numVisits=4, meanQ=-1.010000, numObservations: 4
action -1, numVisits=4, meanQ=-1.257500, numObservations: 4
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 1 0.625095 0.349572 0.929653 0.450505 0.725193 0.551256 0.811811 0.74774 0.485818 0.445774 0.749704 0.847364 0.602451 0.0392263 0.839308 0.985035 0.0739458 0.0188331 0.233811 0.573833 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 18
Initial state: 0 0.305169 0.390146 0.471077 0.423263 0.667741 0.421293 0.154225 0.846241 0.454665 0.18667 0.513979 0.325254 0.636814 0.95678 0.745701 0.205545 0.359349 0.360487 0.682395 0.954216 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 46283 episodes
GETTING ACTION FROM:
action 2, numVisits=46239, meanQ=11.250701, numObservations: 9
action 6, numVisits=19, meanQ=9.777368, numObservations: 9
action 3, numVisits=9, meanQ=7.775567, numObservations: 5
action 1, numVisits=5, meanQ=7.398000, numObservations: 5
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=3, meanQ=4.340033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.305169 0.390146 0.471077 0.423263 0.667741 0.421293 0.154225 0.846241 0.454665 0.18667 0.513979 0.325254 0.636814 0.95678 0.745701 0.205545 0.359349 0.360487 0.682395 0.954216 w: 1
Observation: 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 19
Initial state: 0 0.0980218 0.502485 0.823108 0.507206 0.950054 0.623951 0.582255 0.0741452 0.573791 0.322969 0.227153 0.3297 0.453538 0.205923 0.422295 0.930609 0.403062 0.1095 0.743727 0.369736 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47425 episodes
GETTING ACTION FROM:
action 7, numVisits=47402, meanQ=11.355035, numObservations: 9
action 2, numVisits=5, meanQ=6.802020, numObservations: 4
action 5, numVisits=5, meanQ=5.998000, numObservations: 3
action 8, numVisits=3, meanQ=5.663333, numObservations: 3
action 4, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 0 0.0980218 0.502485 0.823108 0.507206 0.950054 0.623951 0.582255 0.0741452 0.573791 0.322969 0.227153 0.3297 0.453538 0.205923 0.422295 0.930609 0.403062 0.1095 0.743727 0.369736 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 9, numVisits=4677, meanQ=12.102501, numObservations: 9
action 4, numVisits=36, meanQ=4.860844, numObservations: 9
action 1, numVisits=5, meanQ=0.794000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8628 episodes
GETTING ACTION FROM:
action 9, numVisits=13301, meanQ=11.601813, numObservations: 9
action 4, numVisits=36, meanQ=4.860844, numObservations: 9
action 1, numVisits=5, meanQ=0.794000, numObservations: 5
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.0980218 0.502485 0.823108 0.507206 0.950054 0.623951 0.582255 0.0741452 0.573791 0.322969 0.227153 0.3297 0.453538 0.205923 0.422295 0.930609 0.403062 0.1095 0.743727 0.369736 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 4, numVisits=1129, meanQ=11.243708, numObservations: 9
action 1, numVisits=7, meanQ=5.534952, numObservations: 3
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=3, meanQ=-1.010000, numObservations: 3
action 0, numVisits=3, meanQ=-1.010000, numObservations: 3
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5208 episodes
GETTING ACTION FROM:
action 4, numVisits=3305, meanQ=10.357004, numObservations: 9
action 8, numVisits=2886, meanQ=9.831285, numObservations: 9
action 5, numVisits=143, meanQ=6.786873, numObservations: 9
action 1, numVisits=8, meanQ=3.673905, numObservations: 4
action -1, numVisits=6, meanQ=-1.010000, numObservations: 6
action 0, numVisits=6, meanQ=-1.175000, numObservations: 6
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.0980218 0.502485 0.823108 0.507206 0.950054 0.623951 0.582255 0.0741452 0.573791 0.322969 0.227153 0.3297 0.453538 0.205923 0.422295 0.930609 0.403062 0.1095 0.743727 0.369736 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 20
Initial state: 0 0.461118 0.623308 0.531116 0.348786 0.951897 0.663959 0.786274 0.984288 0.247863 0.816539 0.653594 0.234883 0.181601 0.311265 0.0859278 0.286204 0.538305 0.0875883 0.626561 0.840315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47572 episodes
GETTING ACTION FROM:
action 2, numVisits=47522, meanQ=11.262817, numObservations: 9
action 1, numVisits=40, meanQ=7.770012, numObservations: 9
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 1 0.461118 0.623308 0.531116 0.348786 0.951897 0.663959 0.786274 0.984288 0.247863 0.816539 0.653594 0.234883 0.181601 0.311265 0.0859278 0.286204 0.538305 0.0875883 0.626561 0.840315 w: 1
Observation: 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.325841 0.77939 0.585016 0.288683 0.949774 0.554887 0.555855 0.22592 0.616828 0.467429 0.583485 0.273407 0.877043 0.563633 0.419262 0.340238 0.0715023 0.285456 0.553816 0.318225 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48464 episodes
GETTING ACTION FROM:
action 1, numVisits=48437, meanQ=11.342380, numObservations: 9
action 7, numVisits=15, meanQ=3.531347, numObservations: 7
action 5, numVisits=3, meanQ=1.703333, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 1
Next state: 1 0.325841 0.77939 0.585016 0.288683 0.949774 0.554887 0.555855 0.22592 0.616828 0.467429 0.583485 0.273407 0.877043 0.563633 0.419262 0.340238 0.0715023 0.285456 0.553816 0.318225 w: 1
Observation: 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.689035 0.840071 0.126321 0.0517969 0.449346 0.560082 0.62673 0.852019 0.53099 0.435672 0.115681 0.996536 0.800253 0.860103 0.617124 0.32842 0.305299 0.505142 0.607325 0.432273 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48900 episodes
GETTING ACTION FROM:
action 4, numVisits=48883, meanQ=11.302191, numObservations: 9
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action 9, numVisits=3, meanQ=3.000000, numObservations: 2
action 10, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.689035 0.840071 0.126321 0.0517969 0.449346 0.560082 0.62673 0.852019 0.53099 0.435672 0.115681 0.996536 0.800253 0.860103 0.617124 0.32842 0.305299 0.505142 0.607325 0.432273 w: 1
Observation: 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 23
Initial state: 0 0.404771 0.335685 0.254965 0.0977033 0.389191 0.0729824 0.626738 0.719705 0.850402 0.220572 0.308881 0.952257 0.501039 0.0830159 0.615626 0.743444 0.914784 0.242085 0.618652 0.374061 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45144 episodes
GETTING ACTION FROM:
action 7, numVisits=45119, meanQ=11.667763, numObservations: 9
action 4, numVisits=9, meanQ=7.776667, numObservations: 8
action 9, numVisits=5, meanQ=5.998000, numObservations: 4
action 3, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.404771 0.335685 0.254965 0.0977033 0.389191 0.0729824 0.626738 0.719705 0.850402 0.220572 0.308881 0.952257 0.501039 0.0830159 0.615626 0.743444 0.914784 0.242085 0.618652 0.374061 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.029298 0.303484 0.245186 0.920633 0.159681 0.819561 0.519084 0.317099 0.435181 0.266832 0.269016 0.0102662 0.55629 0.095902 0.547852 0.805679 0.0813671 0.799209 0.484181 0.198466 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 49234 episodes
GETTING ACTION FROM:
action 7, numVisits=49216, meanQ=11.305004, numObservations: 9
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=5, meanQ=5.204020, numObservations: 4
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.029298 0.303484 0.245186 0.920633 0.159681 0.819561 0.519084 0.317099 0.435181 0.266832 0.269016 0.0102662 0.55629 0.095902 0.547852 0.805679 0.0813671 0.799209 0.484181 0.198466 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 25
Initial state: 0 0.265188 0.0214522 0.420182 0.473729 0.559447 0.299503 0.636104 0.29711 0.766504 0.689108 0.774467 0.237509 0.836884 0.787333 0.484815 0.88695 0.0727578 0.786789 0.897 0.18206 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 43695 episodes
GETTING ACTION FROM:
action 4, numVisits=43661, meanQ=11.651774, numObservations: 9
action 5, numVisits=11, meanQ=8.000009, numObservations: 6
action 3, numVisits=11, meanQ=6.554545, numObservations: 8
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=5.333333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.265188 0.0214522 0.420182 0.473729 0.559447 0.299503 0.636104 0.29711 0.766504 0.689108 0.774467 0.237509 0.836884 0.787333 0.484815 0.88695 0.0727578 0.786789 0.897 0.18206 w: 1
Observation: 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 26
Initial state: 0 0.955725 0.424638 0.920166 0.308474 0.957734 0.936338 0.834923 0.00680753 0.159443 0.504346 0.387686 0.633457 0.853868 0.511162 0.585267 0.259877 0.207621 0.346607 0.603164 0.318814 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 45281 episodes
GETTING ACTION FROM:
action 8, numVisits=45230, meanQ=11.635830, numObservations: 9
action 10, numVisits=33, meanQ=10.133033, numObservations: 8
action 1, numVisits=7, meanQ=6.998586, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 2 0.955725 0.424638 0.920166 0.308474 0.957734 0.936338 0.834923 0.00680753 0.159443 0.504346 0.387686 0.633457 0.853868 0.511162 0.585267 0.259877 0.207621 0.346607 0.603164 0.318814 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 27
Initial state: 0 0.254107 0.831471 0.818581 0.961115 0.525287 0.298274 0.523346 0.662602 0.402293 0.297383 0.0227807 0.861292 0.758757 0.839133 0.237341 0.402916 0.726036 0.0324109 0.870393 0.707426 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47372 episodes
GETTING ACTION FROM:
action 3, numVisits=47352, meanQ=11.304769, numObservations: 9
action 5, numVisits=5, meanQ=6.802020, numObservations: 3
action 6, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action 2, numVisits=3, meanQ=5.663333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.254107 0.831471 0.818581 0.961115 0.525287 0.298274 0.523346 0.662602 0.402293 0.297383 0.0227807 0.861292 0.758757 0.839133 0.237341 0.402916 0.726036 0.0324109 0.870393 0.707426 w: 1
Observation: 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 28
Initial state: 0 0.905284 0.132515 0.677708 0.261825 0.739106 0.300425 0.294709 0.177929 0.405028 0.688922 0.509071 0.327129 0.638274 0.0744795 0.794766 0.307805 0.566426 0.785664 0.936557 0.476669 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48296 episodes
GETTING ACTION FROM:
action 6, numVisits=48265, meanQ=11.517211, numObservations: 9
action 7, numVisits=7, meanQ=6.282857, numObservations: 5
action 2, numVisits=9, meanQ=5.898889, numObservations: 5
action 9, numVisits=3, meanQ=5.333333, numObservations: 3
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action 10, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.905284 0.132515 0.677708 0.261825 0.739106 0.300425 0.294709 0.177929 0.405028 0.688922 0.509071 0.327129 0.638274 0.0744795 0.794766 0.307805 0.566426 0.785664 0.936557 0.476669 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 29
Initial state: 0 0.0493031 0.374901 0.590824 0.936697 0.987037 0.481818 0.817127 0.424939 0.62181 0.294367 0.601818 0.732312 0.387926 0.487307 0.00728321 0.956165 0.37361 0.765295 0.30768 0.687859 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 47119 episodes
GETTING ACTION FROM:
action 9, numVisits=47092, meanQ=11.278295, numObservations: 9
action 7, numVisits=11, meanQ=7.339091, numObservations: 7
action 1, numVisits=5, meanQ=5.998000, numObservations: 5
action 4, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 9
Next state: 0 0.0493031 0.374901 0.590824 0.936697 0.987037 0.481818 0.817127 0.424939 0.62181 0.294367 0.601818 0.732312 0.387926 0.487307 0.00728321 0.956165 0.37361 0.765295 0.30768 0.687859 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=7986, meanQ=11.886175, numObservations: 9
action 8, numVisits=4, meanQ=8.497500, numObservations: 3
action 6, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 11976 episodes
GETTING ACTION FROM:
action 8, numVisits=11657, meanQ=13.888332, numObservations: 9
action 4, numVisits=8296, meanQ=11.914452, numObservations: 9
action 6, numVisits=7, meanQ=5.000000, numObservations: 3
action 10, numVisits=5, meanQ=3.607110, numObservations: 4
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=3, meanQ=-1.340000, numObservations: 3
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 8
Next state: 1 0.0493031 0.374901 0.590824 0.936697 0.987037 0.481818 0.817127 0.424939 0.62181 0.294367 0.601818 0.732312 0.387926 0.487307 0.00728321 0.956165 0.37361 0.765295 0.30768 0.687859 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 30
Initial state: 0 0.781594 0.913712 0.603903 0.357731 0.491828 0.100448 0.0699334 0.117341 0.559834 0.51249 0.982771 0.487007 0.984313 0.123351 0.651351 0.633634 0.2575 0.965786 0.266744 0.903865 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 48462 episodes
GETTING ACTION FROM:
action 7, numVisits=48387, meanQ=11.227568, numObservations: 9
action 6, numVisits=35, meanQ=8.178583, numObservations: 7
action 8, numVisits=19, meanQ=7.501595, numObservations: 7
action 9, numVisits=5, meanQ=5.998000, numObservations: 4
action 10, numVisits=5, meanQ=5.800000, numObservations: 4
action 1, numVisits=3, meanQ=5.333333, numObservations: 3
action 4, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.781594 0.913712 0.603903 0.357731 0.491828 0.100448 0.0699334 0.117341 0.559834 0.51249 0.982771 0.487007 0.984313 0.123351 0.651351 0.633634 0.2575 0.965786 0.266744 0.903865 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
[32m ProblemEnvironment.hpp 351: Done.[39m
