Run # 1
Initial state: 0 0.506856 0.538406 0.846863 0.476036 0.780119 0.865164 0.917211 0.873818 0.400775 0.351599 0.722242 0.384495 0.125955 0.932242 0.500279 0.789486 0.875566 0.206681 0.771628 0.359184 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17184 episodes
GETTING ACTION FROM:
action 1, numVisits=17155, meanQ=11.678220, numObservations: 9
action 9, numVisits=10, meanQ=9.300000, numObservations: 7
action 6, numVisits=6, meanQ=7.666667, numObservations: 3
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 2 0.506856 0.538406 0.846863 0.476036 0.780119 0.865164 0.917211 0.873818 0.400775 0.351599 0.722242 0.384495 0.125955 0.932242 0.500279 0.789486 0.875566 0.206681 0.771628 0.359184 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 2
Initial state: 0 0.662223 0.352391 0.644216 0.928333 0.443366 0.101251 0.912951 0.173807 0.0908214 0.644982 0.142568 0.456995 0.390963 0.541052 0.914791 0.557562 0.516809 0.354566 0.0310773 0.958965 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17792 episodes
GETTING ACTION FROM:
action 1, numVisits=17779, meanQ=11.775923, numObservations: 9
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.662223 0.352391 0.644216 0.928333 0.443366 0.101251 0.912951 0.173807 0.0908214 0.644982 0.142568 0.456995 0.390963 0.541052 0.914791 0.557562 0.516809 0.354566 0.0310773 0.958965 w: 1
Observation: 0 3 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 3
Initial state: 0 0.139584 0.473393 0.230148 0.885039 0.550779 0.0484655 0.222266 0.568588 0.149739 0.138801 0.953526 0.807094 0.450416 0.403573 0.221677 0.942356 0.0651797 0.691009 0.191428 0.164798 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18436 episodes
GETTING ACTION FROM:
action 6, numVisits=18395, meanQ=11.682635, numObservations: 9
action 4, numVisits=8, meanQ=8.373750, numObservations: 5
action 2, numVisits=9, meanQ=6.566667, numObservations: 6
action 1, numVisits=4, meanQ=6.500000, numObservations: 3
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action 8, numVisits=7, meanQ=6.000000, numObservations: 6
action 5, numVisits=5, meanQ=5.998000, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.139584 0.473393 0.230148 0.885039 0.550779 0.0484655 0.222266 0.568588 0.149739 0.138801 0.953526 0.807094 0.450416 0.403573 0.221677 0.942356 0.0651797 0.691009 0.191428 0.164798 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 4
Initial state: 0 0.740826 0.320756 0.0492835 0.0493109 0.631289 0.409239 0.490519 0.367838 0.106155 0.779181 0.82153 0.648488 0.901532 0.749301 0.272607 0.5558 0.567625 0.998822 0.543865 0.1543 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19157 episodes
GETTING ACTION FROM:
action 5, numVisits=19071, meanQ=11.659556, numObservations: 9
action 1, numVisits=48, meanQ=8.666877, numObservations: 9
action 3, numVisits=10, meanQ=7.900000, numObservations: 7
action 2, numVisits=11, meanQ=6.547282, numObservations: 6
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action 9, numVisits=5, meanQ=4.598000, numObservations: 4
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 1 0.740826 0.320756 0.0492835 0.0493109 0.631289 0.409239 0.490519 0.367838 0.106155 0.779181 0.82153 0.648488 0.901532 0.749301 0.272607 0.5558 0.567625 0.998822 0.543865 0.1543 w: 1
Observation: 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 5
Initial state: 0 0.757171 0.112729 0.869408 0.743367 0.482488 0.353534 0.0505483 0.992593 0.262209 0.710245 0.573757 0.575198 0.380321 0.918315 0.229452 0.876813 0.70707 0.595889 0.166413 0.454892 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18447 episodes
GETTING ACTION FROM:
action 6, numVisits=18403, meanQ=11.602498, numObservations: 9
action 9, numVisits=16, meanQ=8.046256, numObservations: 7
action 7, numVisits=13, meanQ=7.536154, numObservations: 8
action 10, numVisits=7, meanQ=7.282857, numObservations: 6
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.757171 0.112729 0.869408 0.743367 0.482488 0.353534 0.0505483 0.992593 0.262209 0.710245 0.573757 0.575198 0.380321 0.918315 0.229452 0.876813 0.70707 0.595889 0.166413 0.454892 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 6
Initial state: 0 0.623691 0.485523 0.301467 0.703857 0.556744 0.219528 0.455937 0.282662 0.398294 0.882106 0.742109 0.911106 0.0415495 0.648889 0.531217 0.729639 0.555055 0.254807 0.184045 0.349948 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17660 episodes
GETTING ACTION FROM:
action 6, numVisits=17626, meanQ=11.385242, numObservations: 9
action 8, numVisits=10, meanQ=8.897000, numObservations: 4
action 5, numVisits=9, meanQ=7.775567, numObservations: 6
action 1, numVisits=5, meanQ=7.596000, numObservations: 4
action 2, numVisits=2, meanQ=6.500000, numObservations: 2
action 4, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.623691 0.485523 0.301467 0.703857 0.556744 0.219528 0.455937 0.282662 0.398294 0.882106 0.742109 0.911106 0.0415495 0.648889 0.531217 0.729639 0.555055 0.254807 0.184045 0.349948 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 7
Initial state: 0 0.450211 0.167849 0.682151 0.872949 0.254171 0.812532 0.0658576 0.639131 0.850534 0.67056 0.173507 0.768645 0.285211 0.216038 0.680326 0.918572 0.432168 0.384103 0.993944 0.591694 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18736 episodes
GETTING ACTION FROM:
action 4, numVisits=18679, meanQ=11.572187, numObservations: 9
action 3, numVisits=45, meanQ=10.416667, numObservations: 9
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.450211 0.167849 0.682151 0.872949 0.254171 0.812532 0.0658576 0.639131 0.850534 0.67056 0.173507 0.768645 0.285211 0.216038 0.680326 0.918572 0.432168 0.384103 0.993944 0.591694 w: 1
Observation: 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 7, numVisits=115, meanQ=12.699307, numObservations: 9
action 10, numVisits=10, meanQ=6.201020, numObservations: 5
action 2, numVisits=14, meanQ=6.140721, numObservations: 7
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 14517 episodes
GETTING ACTION FROM:
action 7, numVisits=14630, meanQ=13.567054, numObservations: 9
action 10, numVisits=10, meanQ=6.201020, numObservations: 5
action 2, numVisits=14, meanQ=6.140721, numObservations: 7
action 1, numVisits=3, meanQ=4.670033, numObservations: 2
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 7
Next state: 0 0.450211 0.167849 0.682151 0.872949 0.254171 0.812532 0.0658576 0.639131 0.850534 0.67056 0.173507 0.768645 0.285211 0.216038 0.680326 0.918572 0.432168 0.384103 0.993944 0.591694 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 2, numVisits=107, meanQ=12.974637, numObservations: 9
action 6, numVisits=12, meanQ=9.209028, numObservations: 7
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=5.932256, numObservations: 2
action 9, numVisits=2, meanQ=5.827891, numObservations: 1
action 1, numVisits=2, meanQ=5.665064, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 10, numVisits=1, meanQ=-10.789976, numObservations: 1
action 7, numVisits=1, meanQ=-11.336515, numObservations: 1
action 8, numVisits=1, meanQ=-11.385175, numObservations: 1
action 4, numVisits=1, meanQ=-1020.443311, numObservations: 1
Sampled 10614 episodes
GETTING ACTION FROM:
action 1, numVisits=1736, meanQ=12.513427, numObservations: 9
action 5, numVisits=8291, meanQ=10.690278, numObservations: 9
action 3, numVisits=233, meanQ=9.465596, numObservations: 9
action 2, numVisits=220, meanQ=9.369358, numObservations: 9
action 6, numVisits=53, meanQ=8.535250, numObservations: 9
action 9, numVisits=204, meanQ=8.379818, numObservations: 9
action -1, numVisits=4, meanQ=-1.505000, numObservations: 4
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action 10, numVisits=1, meanQ=-10.789976, numObservations: 1
action 7, numVisits=1, meanQ=-11.336515, numObservations: 1
action 8, numVisits=1, meanQ=-11.385175, numObservations: 1
action 4, numVisits=1, meanQ=-1020.443311, numObservations: 1
action: 1
Next state: 2 0.450211 0.167849 0.682151 0.872949 0.254171 0.812532 0.0658576 0.639131 0.850534 0.67056 0.173507 0.768645 0.285211 0.216038 0.680326 0.918572 0.432168 0.384103 0.993944 0.591694 w: 1
Observation: 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -18.7411
Run # 8
Initial state: 0 0.854581 0.970978 0.846939 0.957044 0.154123 0.607049 0.0929731 0.431064 0.123207 0.0291191 0.86078 0.976678 0.140266 0.570729 0.528478 0.383971 0.104832 0.512468 0.299602 0.984497 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17366 episodes
GETTING ACTION FROM:
action 3, numVisits=17339, meanQ=11.821734, numObservations: 9
action 7, numVisits=15, meanQ=7.133340, numObservations: 7
action 10, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.854581 0.970978 0.846939 0.957044 0.154123 0.607049 0.0929731 0.431064 0.123207 0.0291191 0.86078 0.976678 0.140266 0.570729 0.528478 0.383971 0.104832 0.512468 0.299602 0.984497 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 7, numVisits=1668, meanQ=12.996856, numObservations: 9
action 2, numVisits=504, meanQ=12.813895, numObservations: 9
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action 8, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6201 episodes
GETTING ACTION FROM:
action 7, numVisits=7857, meanQ=13.027616, numObservations: 9
action 2, numVisits=505, meanQ=12.766738, numObservations: 9
action 8, numVisits=11, meanQ=9.158182, numObservations: 7
action 9, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 0 0.854581 0.970978 0.846939 0.957044 0.154123 0.607049 0.0929731 0.431064 0.123207 0.0291191 0.86078 0.976678 0.140266 0.570729 0.528478 0.383971 0.104832 0.512468 0.299602 0.984497 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 9, numVisits=605, meanQ=11.918766, numObservations: 9
action 7, numVisits=3, meanQ=5.993333, numObservations: 2
action 10, numVisits=7, meanQ=5.378011, numObservations: 6
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6020 episodes
GETTING ACTION FROM:
action 9, numVisits=6625, meanQ=13.447220, numObservations: 9
action 7, numVisits=3, meanQ=5.993333, numObservations: 2
action 10, numVisits=7, meanQ=5.378011, numObservations: 6
action 1, numVisits=3, meanQ=3.330000, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.854581 0.970978 0.846939 0.957044 0.154123 0.607049 0.0929731 0.431064 0.123207 0.0291191 0.86078 0.976678 0.140266 0.570729 0.528478 0.383971 0.104832 0.512468 0.299602 0.984497 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 
Immediate reward: -4
Updated belief

t = 3
Improving policy...
PLANNING FROM:
action 8, numVisits=338, meanQ=13.767978, numObservations: 9
action 5, numVisits=5, meanQ=4.783447, numObservations: 5
action 6, numVisits=3, meanQ=0.975324, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 8464 episodes
GETTING ACTION FROM:
action 8, numVisits=8802, meanQ=13.891879, numObservations: 9
action 5, numVisits=5, meanQ=4.783447, numObservations: 5
action 6, numVisits=3, meanQ=0.975324, numObservations: 2
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 7, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 1 0.854581 0.970978 0.846939 0.957044 0.154123 0.607049 0.0929731 0.431064 0.123207 0.0291191 0.86078 0.976678 0.140266 0.570729 0.528478 0.383971 0.104832 0.512468 0.299602 0.984497 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 11.4068
Run # 9
Initial state: 0 0.724846 0.101353 0.038686 0.115923 0.455586 0.639356 0.621664 0.356286 0.941607 0.591854 0.316425 0.973343 0.874832 0.0503092 0.682257 0.697511 0.752821 0.350462 0.500186 0.326026 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17397 episodes
GETTING ACTION FROM:
action 2, numVisits=17322, meanQ=11.816675, numObservations: 9
action 10, numVisits=22, meanQ=10.353186, numObservations: 8
action 6, numVisits=20, meanQ=10.352015, numObservations: 8
action 8, numVisits=7, meanQ=9.394286, numObservations: 5
action 9, numVisits=6, meanQ=9.163333, numObservations: 5
action 7, numVisits=7, meanQ=9.000000, numObservations: 4
action 3, numVisits=6, meanQ=7.831667, numObservations: 4
action 4, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 0 0.724846 0.101353 0.038686 0.115923 0.455586 0.639356 0.621664 0.356286 0.941607 0.591854 0.316425 0.973343 0.874832 0.0503092 0.682257 0.697511 0.752821 0.350462 0.500186 0.326026 w: 1
Observation: 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 7, numVisits=241, meanQ=11.207999, numObservations: 9
action 5, numVisits=21, meanQ=5.191938, numObservations: 8
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 14465 episodes
GETTING ACTION FROM:
action 7, numVisits=14680, meanQ=7.484851, numObservations: 9
action 9, numVisits=14, meanQ=4.570714, numObservations: 6
action 5, numVisits=22, meanQ=4.455941, numObservations: 8
action 0, numVisits=6, meanQ=-1.505000, numObservations: 6
action -1, numVisits=5, meanQ=-1.802000, numObservations: 5
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=2, meanQ=-7.005000, numObservations: 2
action 4, numVisits=2, meanQ=-7.005000, numObservations: 2
action 8, numVisits=2, meanQ=-7.005000, numObservations: 2
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.724846 0.101353 0.038686 0.115923 0.455586 0.639356 0.621664 0.356286 0.941607 0.591854 0.316425 0.973343 0.874832 0.0503092 0.682257 0.697511 0.752821 0.350462 0.500186 0.326026 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 10
Initial state: 0 0.258419 0.682954 0.821103 0.995635 0.525592 0.395785 0.862032 0.138169 0.871619 0.215337 0.290058 0.206255 0.360298 0.821734 0.614297 0.0538662 0.200706 0.332383 0.318792 0.153421 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18114 episodes
GETTING ACTION FROM:
action 9, numVisits=18084, meanQ=11.749550, numObservations: 9
action 1, numVisits=10, meanQ=7.602010, numObservations: 6
action 4, numVisits=5, meanQ=6.196000, numObservations: 4
action 7, numVisits=3, meanQ=5.333333, numObservations: 2
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action 6, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 0 0.258419 0.682954 0.821103 0.995635 0.525592 0.395785 0.862032 0.138169 0.871619 0.215337 0.290058 0.206255 0.360298 0.821734 0.614297 0.0538662 0.200706 0.332383 0.318792 0.153421 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 2 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 4, numVisits=650, meanQ=12.583688, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action 7, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5548 episodes
GETTING ACTION FROM:
action 4, numVisits=6191, meanQ=12.001537, numObservations: 9
action 5, numVisits=3, meanQ=3.330000, numObservations: 3
action 8, numVisits=3, meanQ=3.330000, numObservations: 3
action 7, numVisits=3, meanQ=0.666667, numObservations: 2
action -1, numVisits=5, meanQ=-1.208000, numObservations: 5
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 2 0.258419 0.682954 0.821103 0.995635 0.525592 0.395785 0.862032 0.138169 0.871619 0.215337 0.290058 0.206255 0.360298 0.821734 0.614297 0.0538662 0.200706 0.332383 0.318792 0.153421 w: 1
Observation: 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 11
Initial state: 0 0.677851 0.543842 0.723101 0.545405 0.498411 0.38142 0.0230564 0.569492 0.62972 0.54399 0.145981 0.478838 0.834685 0.490203 0.122169 0.872765 0.0984061 0.375964 0.859684 0.0857645 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18500 episodes
GETTING ACTION FROM:
action 5, numVisits=18351, meanQ=11.782386, numObservations: 9
action 2, numVisits=96, meanQ=11.131460, numObservations: 9
action 7, numVisits=24, meanQ=10.250833, numObservations: 9
action 6, numVisits=16, meanQ=10.123750, numObservations: 9
action 8, numVisits=6, meanQ=8.833333, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.677851 0.543842 0.723101 0.545405 0.498411 0.38142 0.0230564 0.569492 0.62972 0.54399 0.145981 0.478838 0.834685 0.490203 0.122169 0.872765 0.0984061 0.375964 0.859684 0.0857645 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 12
Initial state: 0 0.367539 0.713021 0.897603 0.679392 0.476981 0.0594629 0.117233 0.778908 0.0444272 0.897425 0.165431 0.745371 0.346246 0.911079 0.426727 0.873744 0.514173 0.3011 0.101735 0.076046 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17384 episodes
GETTING ACTION FROM:
action 10, numVisits=17347, meanQ=11.525183, numObservations: 9
action 9, numVisits=23, meanQ=9.689565, numObservations: 8
action 8, numVisits=4, meanQ=8.250000, numObservations: 3
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 10
Next state: 0 0.367539 0.713021 0.897603 0.679392 0.476981 0.0594629 0.117233 0.778908 0.0444272 0.897425 0.165431 0.745371 0.346246 0.911079 0.426727 0.873744 0.514173 0.3011 0.101735 0.076046 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=1233, meanQ=12.061826, numObservations: 9
action 4, numVisits=18, meanQ=8.853333, numObservations: 6
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=4, meanQ=6.500000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 5210 episodes
GETTING ACTION FROM:
action 1, numVisits=6431, meanQ=10.538453, numObservations: 9
action 4, numVisits=22, meanQ=6.909985, numObservations: 7
action 9, numVisits=5, meanQ=3.000000, numObservations: 4
action 7, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=4, meanQ=-1.010000, numObservations: 4
action 0, numVisits=4, meanQ=-1.257500, numObservations: 4
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 0 0.367539 0.713021 0.897603 0.679392 0.476981 0.0594629 0.117233 0.778908 0.0444272 0.897425 0.165431 0.745371 0.346246 0.911079 0.426727 0.873744 0.514173 0.3011 0.101735 0.076046 w: 1
Observation: 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 2
Improving policy...
PLANNING FROM:
action 6, numVisits=10, meanQ=17.315362, numObservations: 4
action 7, numVisits=7, meanQ=13.685328, numObservations: 3
action 5, numVisits=3, meanQ=12.851921, numObservations: 3
action 2, numVisits=3, meanQ=12.333333, numObservations: 3
action 3, numVisits=3, meanQ=12.333333, numObservations: 3
action 8, numVisits=3, meanQ=12.333333, numObservations: 2
action 1, numVisits=2, meanQ=6.846984, numObservations: 1
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 14726 episodes
GETTING ACTION FROM:
action 6, numVisits=14472, meanQ=16.142699, numObservations: 9
action 7, numVisits=184, meanQ=11.472787, numObservations: 9
action 9, numVisits=19, meanQ=9.263314, numObservations: 9
action 3, numVisits=6, meanQ=7.666667, numObservations: 5
action 8, numVisits=64, meanQ=6.919775, numObservations: 9
action 5, numVisits=4, meanQ=6.888941, numObservations: 4
action 1, numVisits=2, meanQ=6.846984, numObservations: 1
action 2, numVisits=6, meanQ=6.500000, numObservations: 4
action -1, numVisits=2, meanQ=-1.505000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 6
Next state: 1 0.367539 0.713021 0.897603 0.679392 0.476981 0.0594629 0.117233 0.778908 0.0444272 0.897425 0.165431 0.745371 0.346246 0.911079 0.426727 0.873744 0.514173 0.3011 0.101735 0.076046 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 15.5624
Run # 13
Initial state: 0 0.769282 0.867311 0.809865 0.109368 0.337345 0.563007 0.749114 0.471695 0.864832 0.592946 0.809813 0.358765 0.544444 0.656056 0.20107 0.536928 0.464384 0.809578 0.426607 0.392093 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19292 episodes
GETTING ACTION FROM:
action 3, numVisits=19274, meanQ=11.615647, numObservations: 9
action 2, numVisits=7, meanQ=7.282857, numObservations: 5
action 5, numVisits=2, meanQ=6.500000, numObservations: 1
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.769282 0.867311 0.809865 0.109368 0.337345 0.563007 0.749114 0.471695 0.864832 0.592946 0.809813 0.358765 0.544444 0.656056 0.20107 0.536928 0.464384 0.809578 0.426607 0.392093 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 5, numVisits=2444, meanQ=12.656139, numObservations: 9
action 2, numVisits=14, meanQ=8.212143, numObservations: 7
action 7, numVisits=5, meanQ=7.000020, numObservations: 4
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action 6, numVisits=3, meanQ=5.993333, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
Sampled 6106 episodes
GETTING ACTION FROM:
action 5, numVisits=8526, meanQ=13.256543, numObservations: 9
action 7, numVisits=19, meanQ=8.667797, numObservations: 7
action 2, numVisits=15, meanQ=6.931333, numObservations: 7
action 6, numVisits=7, meanQ=6.446341, numObservations: 6
action 10, numVisits=5, meanQ=3.786700, numObservations: 4
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.010000, numObservations: 2
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action: 5
Next state: 1 0.769282 0.867311 0.809865 0.109368 0.337345 0.563007 0.749114 0.471695 0.864832 0.592946 0.809813 0.358765 0.544444 0.656056 0.20107 0.536928 0.464384 0.809578 0.426607 0.392093 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 14
Initial state: 0 0.53058 0.357132 0.826807 0.175632 0.232166 0.916015 0.262888 0.0449727 0.813976 0.313519 0.448133 0.804933 0.406092 0.789209 0.577463 0.954747 0.382475 0.903505 0.174168 0.161949 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18072 episodes
GETTING ACTION FROM:
action 4, numVisits=18043, meanQ=11.695339, numObservations: 9
action 1, numVisits=11, meanQ=8.817273, numObservations: 6
action 9, numVisits=4, meanQ=8.250000, numObservations: 4
action 10, numVisits=4, meanQ=8.250000, numObservations: 4
action 3, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 0 0.53058 0.357132 0.826807 0.175632 0.232166 0.916015 0.262888 0.0449727 0.813976 0.313519 0.448133 0.804933 0.406092 0.789209 0.577463 0.954747 0.382475 0.903505 0.174168 0.161949 w: 1
Observation: 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 3, numVisits=237, meanQ=12.104114, numObservations: 9
action 8, numVisits=14, meanQ=10.712143, numObservations: 7
action 7, numVisits=5, meanQ=10.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-3.010000, numObservations: 1
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 11073 episodes
GETTING ACTION FROM:
action 1, numVisits=8443, meanQ=10.782747, numObservations: 9
action 3, numVisits=2846, meanQ=9.168335, numObservations: 9
action 8, numVisits=26, meanQ=7.421923, numObservations: 9
action 7, numVisits=7, meanQ=4.000000, numObservations: 4
action -1, numVisits=5, meanQ=-1.802000, numObservations: 5
action 0, numVisits=5, meanQ=-1.802000, numObservations: 5
action 6, numVisits=1, meanQ=-3.010000, numObservations: 1
action 9, numVisits=1, meanQ=-3.010000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.53058 0.357132 0.826807 0.175632 0.232166 0.916015 0.262888 0.0449727 0.813976 0.313519 0.448133 0.804933 0.406092 0.789209 0.577463 0.954747 0.382475 0.903505 0.174168 0.161949 w: 1
Observation: 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 15
Initial state: 0 0.390103 0.85643 0.0122766 0.755209 0.220152 0.225884 0.512791 0.157769 0.675178 0.896375 0.47915 0.403695 0.779912 0.253175 0.285777 0.164167 0.852984 0.283103 0.818877 0.519305 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 17031 episodes
GETTING ACTION FROM:
action 1, numVisits=17008, meanQ=11.870222, numObservations: 9
action 9, numVisits=6, meanQ=3.165000, numObservations: 4
action 6, numVisits=8, meanQ=3.123750, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 1
Next state: 1 0.390103 0.85643 0.0122766 0.755209 0.220152 0.225884 0.512791 0.157769 0.675178 0.896375 0.47915 0.403695 0.779912 0.253175 0.285777 0.164167 0.852984 0.283103 0.818877 0.519305 w: 1
Observation: 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 16
Initial state: 0 0.542948 0.306777 0.628746 0.327687 0.368981 0.724569 0.378044 0.801368 0.805367 0.62777 0.854752 0.898222 0.27715 0.124832 0.486628 0.7537 0.484923 0.945372 0.512207 0.151099 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18493 episodes
GETTING ACTION FROM:
action 8, numVisits=18416, meanQ=11.693897, numObservations: 9
action 3, numVisits=33, meanQ=9.883642, numObservations: 9
action 7, numVisits=17, meanQ=8.985294, numObservations: 8
action 2, numVisits=10, meanQ=7.999000, numObservations: 6
action 1, numVisits=10, meanQ=7.602010, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 8
Next state: 2 0.542948 0.306777 0.628746 0.327687 0.368981 0.724569 0.378044 0.801368 0.805367 0.62777 0.854752 0.898222 0.27715 0.124832 0.486628 0.7537 0.484923 0.945372 0.512207 0.151099 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 17
Initial state: 0 0.221044 0.687744 0.282999 0.944955 0.555683 0.579673 0.67312 0.428995 0.704085 0.71933 0.670123 0.334835 0.732012 0.427862 0.914526 0.630308 0.50054 0.403678 0.282068 0.922097 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18716 episodes
GETTING ACTION FROM:
action 9, numVisits=18696, meanQ=11.754839, numObservations: 9
action 6, numVisits=8, meanQ=8.373750, numObservations: 6
action 1, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 1 0.221044 0.687744 0.282999 0.944955 0.555683 0.579673 0.67312 0.428995 0.704085 0.71933 0.670123 0.334835 0.732012 0.427862 0.914526 0.630308 0.50054 0.403678 0.282068 0.922097 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 18
Initial state: 0 0.918552 0.741551 0.47925 0.27475 0.0243416 0.295698 0.917797 0.348051 0.837006 0.54534 0.361664 0.217952 0.527727 0.019143 0.63182 0.236628 0.280374 0.0489957 0.0385495 0.556509 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18485 episodes
GETTING ACTION FROM:
action 7, numVisits=18447, meanQ=11.612210, numObservations: 9
action 3, numVisits=11, meanQ=5.886364, numObservations: 6
action 1, numVisits=12, meanQ=5.415833, numObservations: 8
action 5, numVisits=3, meanQ=3.000000, numObservations: 3
action 10, numVisits=3, meanQ=3.000000, numObservations: 3
action 9, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 2 0.918552 0.741551 0.47925 0.27475 0.0243416 0.295698 0.917797 0.348051 0.837006 0.54534 0.361664 0.217952 0.527727 0.019143 0.63182 0.236628 0.280374 0.0489957 0.0385495 0.556509 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 1 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 19
Initial state: 0 0.639824 0.191185 0.915144 0.154053 0.232653 0.569789 0.392241 0.72399 0.489495 0.680374 0.713185 0.449592 0.530195 0.313456 0.172404 0.0326307 0.283286 0.5022 0.891897 0.161619 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18154 episodes
GETTING ACTION FROM:
action 7, numVisits=18110, meanQ=11.738825, numObservations: 9
action 2, numVisits=21, meanQ=10.000000, numObservations: 7
action 3, numVisits=6, meanQ=8.833333, numObservations: 5
action 6, numVisits=2, meanQ=6.500000, numObservations: 2
action 9, numVisits=4, meanQ=6.500000, numObservations: 3
action 4, numVisits=5, meanQ=5.800000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 7
Next state: 1 0.639824 0.191185 0.915144 0.154053 0.232653 0.569789 0.392241 0.72399 0.489495 0.680374 0.713185 0.449592 0.530195 0.313456 0.172404 0.0326307 0.283286 0.5022 0.891897 0.161619 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 20
Initial state: 0 0.887898 0.953643 0.235361 0.526342 0.544769 0.963205 0.386302 0.0120623 0.483524 0.78305 0.221724 0.41743 0.307402 0.5034 0.0237252 0.0615874 0.429814 0.297431 0.404401 0.958839 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19119 episodes
GETTING ACTION FROM:
action 9, numVisits=19097, meanQ=11.736332, numObservations: 9
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=3, meanQ=5.333333, numObservations: 3
action 2, numVisits=3, meanQ=3.000000, numObservations: 3
action 3, numVisits=3, meanQ=3.000000, numObservations: 3
action 4, numVisits=3, meanQ=0.666667, numObservations: 3
action 7, numVisits=3, meanQ=0.666667, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 9
Next state: 1 0.887898 0.953643 0.235361 0.526342 0.544769 0.963205 0.386302 0.0120623 0.483524 0.78305 0.221724 0.41743 0.307402 0.5034 0.0237252 0.0615874 0.429814 0.297431 0.404401 0.958839 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 2 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 21
Initial state: 0 0.447726 0.495563 0.601485 0.541336 0.407104 0.332198 0.784859 0.944639 0.207437 0.727066 0.696766 0.363895 0.888825 0.279237 0.150887 0.650688 0.764415 0.107027 0.0246049 0.916457 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19195 episodes
GETTING ACTION FROM:
action 4, numVisits=19128, meanQ=11.478037, numObservations: 9
action 9, numVisits=51, meanQ=8.013141, numObservations: 9
action 1, numVisits=5, meanQ=6.196000, numObservations: 4
action 3, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 6, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 4
Next state: 1 0.447726 0.495563 0.601485 0.541336 0.407104 0.332198 0.784859 0.944639 0.207437 0.727066 0.696766 0.363895 0.888825 0.279237 0.150887 0.650688 0.764415 0.107027 0.0246049 0.916457 w: 1
Observation: 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 22
Initial state: 0 0.550637 0.15462 0.39068 0.235718 0.0899587 0.740232 0.819634 0.963701 0.406076 0.951859 0.456494 0.340965 0.561845 0.734683 0.738084 0.331739 0.989941 0.108001 0.204733 0.913472 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19088 episodes
GETTING ACTION FROM:
action 3, numVisits=19055, meanQ=11.374630, numObservations: 9
action 4, numVisits=19, meanQ=6.728947, numObservations: 7
action 9, numVisits=3, meanQ=5.663333, numObservations: 2
action 2, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 0 0.550637 0.15462 0.39068 0.235718 0.0899587 0.740232 0.819634 0.963701 0.406076 0.951859 0.456494 0.340965 0.561845 0.734683 0.738084 0.331739 0.989941 0.108001 0.204733 0.913472 w: 1
Observation: 0 0 0 0 0 1 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 7, numVisits=2360, meanQ=11.653794, numObservations: 9
action 6, numVisits=32, meanQ=8.600631, numObservations: 9
action 5, numVisits=20, meanQ=8.309505, numObservations: 8
action 9, numVisits=17, meanQ=8.220000, numObservations: 9
action 2, numVisits=7, meanQ=6.301443, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 6092 episodes
GETTING ACTION FROM:
action 7, numVisits=8450, meanQ=13.564849, numObservations: 9
action 6, numVisits=32, meanQ=8.600631, numObservations: 9
action 5, numVisits=20, meanQ=8.309505, numObservations: 8
action 9, numVisits=17, meanQ=8.220000, numObservations: 9
action 2, numVisits=7, meanQ=6.301443, numObservations: 4
action 1, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=2, meanQ=-1.010000, numObservations: 2
action 0, numVisits=2, meanQ=-1.505000, numObservations: 2
action 3, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.550637 0.15462 0.39068 0.235718 0.0899587 0.740232 0.819634 0.963701 0.406076 0.951859 0.456494 0.340965 0.561845 0.734683 0.738084 0.331739 0.989941 0.108001 0.204733 0.913472 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 2 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 19.76
Run # 23
Initial state: 0 0.444389 0.660903 0.535162 0.494943 0.9523 0.979112 0.466448 0.540319 0.500537 0.142881 0.810493 0.772542 0.635751 0.835098 0.768234 0.563895 0.426241 0.274345 0.880709 0.696186 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19251 episodes
GETTING ACTION FROM:
action 2, numVisits=19222, meanQ=11.544550, numObservations: 9
action 10, numVisits=11, meanQ=8.180009, numObservations: 7
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action 6, numVisits=4, meanQ=6.500000, numObservations: 2
action 8, numVisits=2, meanQ=6.500000, numObservations: 1
action 9, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 3, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 2
Next state: 2 0.444389 0.660903 0.535162 0.494943 0.9523 0.979112 0.466448 0.540319 0.500537 0.142881 0.810493 0.772542 0.635751 0.835098 0.768234 0.563895 0.426241 0.274345 0.880709 0.696186 w: 1
Observation: 0 0 0 2 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 24
Initial state: 0 0.238308 0.319913 0.443191 0.225492 0.403689 0.338154 0.980474 0.761406 0.664791 0.238016 0.000590536 0.882176 0.961851 0.814448 0.831397 0.685767 0.702316 0.209691 0.305081 0.585713 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19141 episodes
GETTING ACTION FROM:
action 3, numVisits=19121, meanQ=11.548908, numObservations: 9
action 7, numVisits=6, meanQ=4.166667, numObservations: 5
action 10, numVisits=5, meanQ=3.000000, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 3
Next state: 1 0.238308 0.319913 0.443191 0.225492 0.403689 0.338154 0.980474 0.761406 0.664791 0.238016 0.000590536 0.882176 0.961851 0.814448 0.831397 0.685767 0.702316 0.209691 0.305081 0.585713 w: 1
Observation: 0 0 0 0 0 2 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 25
Initial state: 0 0.877463 0.99867 0.401481 0.829265 0.667498 0.0124795 0.534924 0.856874 0.700612 0.532371 0.465191 0.351159 0.0634656 0.430473 0.0486817 0.266475 0.351452 0.292523 0.0514788 0.379315 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18895 episodes
GETTING ACTION FROM:
action 7, numVisits=18865, meanQ=11.285420, numObservations: 9
action 6, numVisits=15, meanQ=8.633333, numObservations: 9
action 2, numVisits=4, meanQ=7.277500, numObservations: 3
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 5, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 8, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.877463 0.99867 0.401481 0.829265 0.667498 0.0124795 0.534924 0.856874 0.700612 0.532371 0.465191 0.351159 0.0634656 0.430473 0.0486817 0.266475 0.351452 0.292523 0.0514788 0.379315 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 1 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 26
Initial state: 0 0.438729 0.387753 0.364924 0.297237 0.895448 0.965629 0.652636 0.799811 0.489082 0.133701 0.885445 0.742874 0.75182 0.689788 0.831856 0.480411 0.994763 0.920553 0.850217 0.409902 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18458 episodes
GETTING ACTION FROM:
action 3, numVisits=18417, meanQ=11.514775, numObservations: 9
action 9, numVisits=10, meanQ=7.199010, numObservations: 7
action 4, numVisits=2, meanQ=6.500000, numObservations: 2
action 7, numVisits=4, meanQ=6.500000, numObservations: 4
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action 6, numVisits=9, meanQ=6.456667, numObservations: 6
action 8, numVisits=7, meanQ=5.715729, numObservations: 6
action 1, numVisits=3, meanQ=3.000000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action: 3
Next state: 1 0.438729 0.387753 0.364924 0.297237 0.895448 0.965629 0.652636 0.799811 0.489082 0.133701 0.885445 0.742874 0.75182 0.689788 0.831856 0.480411 0.994763 0.920553 0.850217 0.409902 w: 1
Observation: 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
Run # 27
Initial state: 0 0.486844 0.477494 0.559166 0.696665 0.66318 0.993731 0.809311 0.780054 0.709834 0.908215 0.329039 0.027733 0.0812876 0.90416 0.530711 0.208482 0.918617 0.376986 0.514677 0.38117 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18042 episodes
GETTING ACTION FROM:
action 9, numVisits=18025, meanQ=11.749167, numObservations: 9
action 4, numVisits=5, meanQ=7.198020, numObservations: 3
action 8, numVisits=2, meanQ=6.500000, numObservations: 2
action 10, numVisits=2, meanQ=6.500000, numObservations: 2
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 7, numVisits=1, meanQ=-4.000000, numObservations: 1
action 1, numVisits=1, meanQ=-11.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 2 0.486844 0.477494 0.559166 0.696665 0.66318 0.993731 0.809311 0.780054 0.709834 0.908215 0.329039 0.027733 0.0812876 0.90416 0.530711 0.208482 0.918617 0.376986 0.514677 0.38117 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 2 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 28
Initial state: 0 0.438604 0.358804 0.491192 0.588013 0.899423 0.051715 0.421568 0.453391 0.791366 0.223441 0.866813 0.231627 0.684372 0.99955 0.536099 0.66317 0.578027 0.125661 0.495487 0.0907597 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 19028 episodes
GETTING ACTION FROM:
action 5, numVisits=18986, meanQ=11.548450, numObservations: 9
action 3, numVisits=21, meanQ=7.713810, numObservations: 4
action 4, numVisits=4, meanQ=6.500000, numObservations: 3
action 10, numVisits=3, meanQ=5.663333, numObservations: 3
action 1, numVisits=7, meanQ=4.444286, numObservations: 4
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 5
Next state: 2 0.438604 0.358804 0.491192 0.588013 0.899423 0.051715 0.421568 0.453391 0.791366 0.223441 0.866813 0.231627 0.684372 0.99955 0.536099 0.66317 0.578027 0.125661 0.495487 0.0907597 w: 1
Observation: 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 0 0 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -11
Run # 29
Initial state: 0 0.158498 0.680771 0.261942 0.0678054 0.761582 0.878513 0.217971 0.0197958 0.409758 0.352716 0.660341 0.633738 0.0542826 0.0578495 0.625887 0.260003 0.848826 0.254436 0.719109 0.488523 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18488 episodes
GETTING ACTION FROM:
action 7, numVisits=18464, meanQ=11.450973, numObservations: 9
action 1, numVisits=11, meanQ=8.727273, numObservations: 8
action 2, numVisits=2, meanQ=6.500000, numObservations: 1
action 10, numVisits=3, meanQ=3.000000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 9, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 5, numVisits=1, meanQ=-11.000000, numObservations: 1
action 8, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 0 0.158498 0.680771 0.261942 0.0678054 0.761582 0.878513 0.217971 0.0197958 0.409758 0.352716 0.660341 0.633738 0.0542826 0.0578495 0.625887 0.260003 0.848826 0.254436 0.719109 0.488523 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 0 0 0 0 
Immediate reward: -4
Updated belief

t = 1
Improving policy...
PLANNING FROM:
action 1, numVisits=228, meanQ=11.859566, numObservations: 9
action 3, numVisits=35, meanQ=10.664574, numObservations: 8
action 9, numVisits=9, meanQ=10.220000, numObservations: 5
action 6, numVisits=3, meanQ=3.330000, numObservations: 3
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
Sampled 18123 episodes
GETTING ACTION FROM:
action 9, numVisits=17828, meanQ=9.381116, numObservations: 9
action 1, numVisits=447, meanQ=9.322630, numObservations: 9
action 3, numVisits=109, meanQ=8.099036, numObservations: 9
action 6, numVisits=8, meanQ=3.123750, numObservations: 7
action 0, numVisits=4, meanQ=-1.505000, numObservations: 4
action -1, numVisits=4, meanQ=-1.752500, numObservations: 4
action 2, numVisits=1, meanQ=-3.010000, numObservations: 1
action 5, numVisits=1, meanQ=-3.010000, numObservations: 1
action 8, numVisits=1, meanQ=-3.010000, numObservations: 1
action 10, numVisits=1, meanQ=-3.010000, numObservations: 1
action 4, numVisits=1, meanQ=-11.000000, numObservations: 1
action 7, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 9
Next state: 2 0.158498 0.680771 0.261942 0.0678054 0.761582 0.878513 0.217971 0.0197958 0.409758 0.352716 0.660341 0.633738 0.0542826 0.0578495 0.625887 0.260003 0.848826 0.254436 0.719109 0.488523 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 1 0 0 
Immediate reward: -11
Terminal state reached!
Updated belief
Run finished 
Discounted reward: -14.89
Run # 30
Initial state: 0 0.902131 0.280039 0.1027 0.881337 0.493885 0.337196 0.74559 0.121783 0.839438 0.849999 0.209848 0.216143 0.828962 0.615027 0.731913 0.817645 0.747688 0.657888 0.842952 0.218265 w: 1

t = 0
Improving policy...
PLANNING FROM:
action -1, numVisits=0, meanQ=-inf, numObservations: 0
action 0, numVisits=0, meanQ=-inf, numObservations: 0
action 1, numVisits=0, meanQ=-inf, numObservations: 0
action 2, numVisits=0, meanQ=-inf, numObservations: 0
action 3, numVisits=0, meanQ=-inf, numObservations: 0
action 4, numVisits=0, meanQ=-inf, numObservations: 0
action 5, numVisits=0, meanQ=-inf, numObservations: 0
action 6, numVisits=0, meanQ=-inf, numObservations: 0
action 7, numVisits=0, meanQ=-inf, numObservations: 0
action 8, numVisits=0, meanQ=-inf, numObservations: 0
action 9, numVisits=0, meanQ=-inf, numObservations: 0
action 10, numVisits=0, meanQ=-inf, numObservations: 0
Sampled 18675 episodes
GETTING ACTION FROM:
action 7, numVisits=18652, meanQ=11.721689, numObservations: 9
action 8, numVisits=13, meanQ=0.856162, numObservations: 5
action -1, numVisits=1, meanQ=-1.010000, numObservations: 1
action 0, numVisits=1, meanQ=-1.010000, numObservations: 1
action 1, numVisits=1, meanQ=-4.000000, numObservations: 1
action 3, numVisits=1, meanQ=-4.000000, numObservations: 1
action 4, numVisits=1, meanQ=-4.000000, numObservations: 1
action 5, numVisits=1, meanQ=-4.000000, numObservations: 1
action 6, numVisits=1, meanQ=-4.000000, numObservations: 1
action 10, numVisits=1, meanQ=-4.000000, numObservations: 1
action 2, numVisits=1, meanQ=-11.000000, numObservations: 1
action 9, numVisits=1, meanQ=-11.000000, numObservations: 1
action: 7
Next state: 1 0.902131 0.280039 0.1027 0.881337 0.493885 0.337196 0.74559 0.121783 0.839438 0.849999 0.209848 0.216143 0.828962 0.615027 0.731913 0.817645 0.747688 0.657888 0.842952 0.218265 w: 1
Observation: 0 0 0 0 0 0 0 0 0 0 0 0 0 3 3 0 0 0 0 0 0 
Immediate reward: 24
Terminal state reached!
Updated belief
Run finished 
Discounted reward: 24
[32m ProblemEnvironment.hpp 351: Done.[39m
